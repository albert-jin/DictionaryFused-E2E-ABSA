{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# many_model_absa_insert.ipynb 是 many_model_absa.ipynb(默认不加都是concat方式) \n","# 的基础上，进行的insertion策略的实验结果记录"],"metadata":{"id":"o9xzcuhlMpIg"}},{"cell_type":"markdown","source":["https://github.com/albert-jin/DictionaryFused-E2E-ABSA 仓库中的所有模型的训练记事本"],"metadata":{"id":"OFOKxkAadSNu"}},{"cell_type":"markdown","source":["## 包含了对lstm tdlstm tclstm ataelstm  ian memnet cabasc\n","## 对 acl2014data + semeval 2014,+15,+16 + aclshortdata 的 ABSA 模型表现实验"],"metadata":{"id":"J-SVg4o9eDKG"}},{"cell_type":"code","source":["!/opt/bin/nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GTBSIS15U9zA","outputId":"97487fac-9e43-4756-c909-6e8b0e1f428f","executionInfo":{"status":"ok","timestamp":1662088660812,"user_tz":-480,"elapsed":6,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Sep  2 03:17:42 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["所有模型 include lstm,td_lstm,tc_lstm,atae_lstm,ian,memnet,ram,cabasc,tnet_lf,aoa,mgan,bert_spc,aen_bert,lcf_bert"],"metadata":{"id":"nIIL8EEidqsy"}},{"cell_type":"code","source":["# 下载实验项目\n","!git clone https://github.com/albert-jin/DictionaryFused-E2E-ABSA.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Whu5t87el5zC","outputId":"74d1c4b8-de33-4d25-e45b-eaaa75bae91b","executionInfo":{"status":"ok","timestamp":1662107009825,"user_tz":-480,"elapsed":1631,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'DictionaryFused-E2E-ABSA'...\n","remote: Enumerating objects: 183, done.\u001b[K\n","remote: Counting objects: 100% (183/183), done.\u001b[K\n","remote: Compressing objects: 100% (107/107), done.\u001b[K\n","remote: Total 183 (delta 97), reused 148 (delta 74), pack-reused 0\u001b[K\n","Receiving objects: 100% (183/183), 2.07 MiB | 10.12 MiB/s, done.\n","Resolving deltas: 100% (97/97), done.\n"]}]},{"cell_type":"markdown","source":["安装python解释器环境"],"metadata":{"id":"l1afDUM4ywog"}},{"cell_type":"code","source":["!pip install -r /content/DictionaryFused-E2E-ABSA/requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h1m-MGqSy0S7","outputId":"3e60e275-fed9-476c-ee95-84a24749e715","executionInfo":{"status":"ok","timestamp":1662107125792,"user_tz":-480,"elapsed":111057,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from -r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 1)) (1.21.6)\n","Collecting torch==1.7\n","  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n","\u001b[K     |████████████████████████████████| 776.7 MB 4.5 kB/s \n","\u001b[?25hCollecting transformers<4.0.0,>=3.5.1\n","  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 48.8 MB/s \n","\u001b[?25hCollecting sklearn\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Collecting dataclasses\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 2)) (4.1.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 2)) (0.16.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (3.17.3)\n","Collecting tokenizers==0.9.3\n","  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 46.3 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (2022.6.2)\n","Collecting sentencepiece==0.1.91\n","  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 69.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (3.8.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 70.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (4.64.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 4)) (1.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 4)) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 4)) (3.1.0)\n","Building wheels for collected packages: sklearn, sacremoses\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=f79dc1d4756cfc1d97d6ac026ecf31277e14968b488b7d01e17359b6560bbb94\n","  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=a1739efb4fa1c7dfc7ec9b72e558f7adb271dcbdc92b071cdf680d8ef34fe27d\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sklearn sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, dataclasses, transformers, torch, sklearn\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.7.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.7.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.7.0 which is incompatible.\u001b[0m\n","Successfully installed dataclasses-0.6 sacremoses-0.0.53 sentencepiece-0.1.91 sklearn-0.0 tokenizers-0.9.3 torch-1.7.0 transformers-3.5.1\n"]}]},{"cell_type":"code","source":["#!pip install torch==1.7 # 需要兼容transformer包"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6KCeMqoD1r64","outputId":"6ed53367-0bc7-4432-915f-1047631cdba9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==1.7\n","  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n","\u001b[K     |████████████████████████████████| 776.7 MB 3.9 kB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7) (1.21.6)\n","Collecting dataclasses\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7) (4.2.0)\n","Installing collected packages: dataclasses, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n","Successfully installed dataclasses-0.6 torch-1.7.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PRyTlscNdDTQ","outputId":"b0f51644-fd43-47d9-8dd3-901d4a9d18ba","executionInfo":{"status":"ok","timestamp":1662089037645,"user_tz":-480,"elapsed":77899,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-09-02 03:22:42--  https://huggingface.co/stanfordnlp/glove/resolve/main/glove.twitter.27B.zip\n","Resolving huggingface.co (huggingface.co)... 52.202.207.64, 52.6.16.131, 2600:1f18:147f:e850:db35:e0c7:187b:c770, ...\n","Connecting to huggingface.co (huggingface.co)|52.202.207.64|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs.huggingface.co/stanfordnlp/glove/3123e7f5c3f6a30095d413b12fc3284bbf717acd2a9bed63d1c7c13bf5223352?response-content-disposition=attachment%3B%20filename%3D%22glove.twitter.27B.zip%22 [following]\n","--2022-09-02 03:22:42--  https://cdn-lfs.huggingface.co/stanfordnlp/glove/3123e7f5c3f6a30095d413b12fc3284bbf717acd2a9bed63d1c7c13bf5223352?response-content-disposition=attachment%3B%20filename%3D%22glove.twitter.27B.zip%22\n","Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 65.9.86.27, 65.9.86.70, 65.9.86.14, ...\n","Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|65.9.86.27|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1520408741 (1.4G) [application/zip]\n","Saving to: ‘glove.twitter.27B.zip’\n","\n","glove.twitter.27B.z 100%[===================>]   1.42G  27.1MB/s    in 39s     \n","\n","2022-09-02 03:23:22 (36.9 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408741/1520408741]\n","\n","Archive:  glove.twitter.27B.zip\n","  inflating: /content/DictionaryFused-E2E-ABSA/glove_embeddings/glove.twitter.27B.100d.txt  \n","  inflating: /content/DictionaryFused-E2E-ABSA/glove_embeddings/glove.twitter.27B.200d.txt  \n","  inflating: /content/DictionaryFused-E2E-ABSA/glove_embeddings/glove.twitter.27B.25d.txt  \n","  inflating: /content/DictionaryFused-E2E-ABSA/glove_embeddings/glove.twitter.27B.50d.txt  \n"]}],"source":["# train.py embed_size == 200 则需要下载\n","!wget https://huggingface.co/stanfordnlp/glove/resolve/main/glove.twitter.27B.zip #twitter数据集,不区分大小写\n","!unzip glove.twitter.27B.zip -d /content/DictionaryFused-E2E-ABSA/glove_embeddings"]},{"cell_type":"code","source":["!head -n 5 /content/DictionaryFused-E2E-ABSA/glove_embeddings/glove.twitter.27B.200d.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YrzJEdZCx6ZF","outputId":"10cd580c-bcdc-469e-a4c3-97cfbe77fd25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<user> 0.31553 0.53765 0.10177 0.032553 0.003798 0.015364 -0.20344 0.33294 -0.20886 0.10061 0.30976 0.50015 0.32018 0.13537 0.0087039 0.1911 0.24668 -0.060752 -0.43623 0.019302 0.59972 0.13444 0.012801 -0.54052 0.27387 -1.182 -0.27677 0.11279 0.46596 -0.090685 0.24253 0.15654 -0.23618 0.57694 0.17563 -0.01969 0.018295 0.37569 -0.41984 0.22613 -0.20438 -0.076249 0.40356 0.61582 -0.10064 0.23318 0.22808 0.34576 -0.14627 -0.1988 0.033232 -0.84885 -0.25684 0.26369 0.29562 0.1847 -0.20668 -0.013297 0.12233 -0.47751 -0.17202 -0.14577 0.047446 -0.15824 0.054215 -0.19426 -0.081484 0.099009 0.10159 0.043571 0.50245 0.13362 0.065985 0.032969 -0.2017 -0.56905 -0.13203 0.073347 -0.063728 -0.2796 -0.38481 -0.020193 0.22298 -0.059115 0.045198 -0.13995 -0.13299 0.47309 -0.021874 0.38758 -0.074926 -0.0028093 -0.29829 -0.074987 -0.58542 -0.18065 -0.041805 0.41938 0.41004 -0.5911 0.10459 0.10724 0.69768 -0.15901 -0.059596 0.29368 -0.19609 0.39124 -0.29333 -0.0050833 -0.37854 0.33858 0.24782 0.29144 -0.22833 0.19421 -0.055409 0.10322 0.38963 -0.27813 0.21963 0.40014 0.071036 -0.079786 0.19534 -0.69432 -0.093075 -0.13729 -0.54014 0.57165 0.24443 0.036741 0.033606 -0.14398 0.25873 0.089008 0.11109 0.38387 0.19013 -0.23252 -0.26271 -0.26936 -0.32409 0.55236 -0.46158 -0.11086 -0.38417 0.59605 -0.14479 -0.28762 -0.29638 0.21889 -4.1257 0.69382 -0.26307 -0.013691 0.032916 0.017627 -0.02909 0.42807 -0.20815 0.50598 -0.080836 0.45083 -0.11466 -0.27782 -0.038373 0.15672 -0.010899 0.082053 -0.19766 0.20574 -0.075329 0.083754 -0.72767 0.10403 0.42831 0.41023 -0.097314 0.15128 0.39287 -0.17807 -0.029196 0.57502 -0.17823 -0.76488 -0.47383 -0.21984 0.2119 -0.015729 -0.062927 0.26674 -0.23617 0.18109 -0.26583 0.090904 -0.81205 -0.45664 -0.4654 0.52066\n",". 0.35132 0.00056084 -0.21488 -0.04707 -0.17777 0.66162 -0.0074805 -0.15963 -0.22129 0.65523 0.346 -0.22968 -0.078954 0.27465 0.36018 0.20373 -0.048134 0.091749 -0.093562 -0.088653 -0.61514 -0.1124 -0.21046 0.13129 0.11224 -0.92995 -0.18006 0.0096874 0.93647 -0.19493 -0.13873 0.18719 -0.022502 0.39516 0.33007 0.36089 0.0078608 -0.024064 -0.3289 -0.28101 -0.20223 0.30049 -0.22843 0.0639 0.59025 -0.17992 0.72733 0.028216 -0.43656 -0.06433 0.087363 0.0054825 0.34902 0.081738 0.35089 0.053459 0.05537 0.10797 0.19663 0.63077 -0.074041 0.13848 0.24849 -0.10183 0.42992 -0.41886 0.010814 -0.48654 0.19154 -0.18615 0.17851 0.4053 0.14635 0.22446 0.12614 -0.45649 -0.16633 0.15915 -0.12543 -0.055649 -0.30481 0.12712 -0.015809 -0.062656 0.87436 0.4834 -0.16578 0.39106 0.11319 -0.1763 0.01411 -0.40942 0.32281 -0.22064 0.022058 0.076171 0.13255 -0.067011 0.45695 0.04404 0.076988 -0.1565 0.35628 0.18131 -0.040064 0.56617 -0.37482 -0.36297 -0.18098 0.026808 -0.16885 0.24951 -0.14548 -0.23878 -0.074018 -0.032295 0.16866 0.33322 0.023116 -0.4722 0.27615 0.25764 -0.14382 -0.3359 0.029436 -0.15695 -0.084597 -0.10684 -0.24784 0.021849 -0.14485 -0.12874 -0.17975 -0.20351 -0.085811 0.31607 0.28477 -0.011954 0.1486 -0.15402 0.36125 -0.082339 0.27478 0.056358 -0.21401 0.74459 0.048518 0.06175 0.17656 -0.075019 -0.61491 0.063787 -3.9376 0.54504 0.15964 -0.41187 0.51993 0.1342 -0.031554 -0.26429 0.040603 0.2661 0.082515 -0.090602 0.0057244 0.40602 -0.30109 0.37078 0.11716 -0.26164 -0.38366 -0.13616 -0.30152 -0.17193 0.14108 0.31278 0.16425 0.17671 -0.29942 0.43029 0.057682 -0.1411 -0.031367 0.058953 -0.3055 -0.88512 -0.47983 -0.056183 -0.10459 0.039792 -0.4437 0.14186 -0.42475 0.023551 -0.096965 0.079513 -1.4683 0.036684 -0.037206 0.85384\n",": 0.80767 0.49786 0.082696 -0.0079298 0.082471 -0.5936 -0.18753 0.48645 0.10719 -0.31299 0.17609 0.046026 0.036029 0.47656 -0.1215 -0.098428 -0.18983 0.038915 -0.20902 -0.316 0.5007 -0.22646 0.12353 -0.27012 0.70739 -0.98348 -0.54111 0.32431 -0.19345 -0.18299 -0.45738 -0.44089 -0.47504 -0.090636 0.085478 0.028124 -0.28045 0.21273 0.0060152 -0.37948 -0.68825 -0.59779 -0.046953 0.65887 0.44564 -0.25169 -0.030223 0.25673 -0.293 -0.047083 -0.43578 -0.45254 -0.15416 0.35722 0.48247 0.42448 -0.32445 -0.27119 0.31039 -0.40884 -0.4227 0.080102 0.28311 0.013829 0.94008 -0.58542 0.34853 -0.15336 0.1654 0.093904 0.46697 0.11781 0.091151 -0.41349 -0.19446 -0.58665 0.094378 0.14077 0.35482 -0.17125 -0.050602 0.21653 -0.11619 0.45904 -0.30238 0.072354 -0.46345 1.3963 -0.21264 -0.25539 -0.31002 -0.27831 -0.40129 0.10612 -0.42636 0.035816 0.20376 0.22088 0.47981 -0.0767 0.3361 0.34746 0.088655 0.65177 0.45665 0.091346 -0.53175 0.14724 -0.4377 0.27911 -0.67202 0.38052 -0.011494 -0.11314 -0.29098 0.43887 -0.004587 0.079091 -0.0045291 -0.63007 0.1432 0.1942 -0.076888 -0.21021 0.25376 -0.47742 0.14886 0.2257 -0.40912 0.18141 -0.19515 -0.3797 -0.3215 0.0075749 0.68672 0.06226 0.0010575 0.30921 0.10123 -0.28578 0.20308 -0.13243 -0.8974 0.70887 -0.04753 0.54342 -0.40847 0.14928 0.23341 0.024772 0.30833 -0.14153 -3.6293 0.40686 0.22129 -0.2993 -0.01763 0.045388 -0.03538 -0.14189 -0.098312 0.083338 -0.20842 0.59749 0.039259 -0.046968 -0.038719 0.04147 0.40501 -0.13983 -0.40245 0.30089 -0.03762 0.12831 -0.15879 0.17023 0.75995 0.3549 0.0046914 -0.053001 0.13518 0.40568 -0.22714 -0.063414 -0.36388 -0.4503 -0.47098 -0.0973 0.77199 -0.01085 -0.15552 0.11186 0.068971 -0.55048 -0.5001 0.1886 -0.85631 -0.073302 -0.47785 0.67059\n","rt 0.55687 0.63284 -0.15609 0.26397 0.28015 -0.36506 -0.12128 0.45217 -0.16123 0.015791 0.49511 0.054643 0.66865 0.44101 -0.48446 0.12594 0.40596 -0.086889 -0.2352 -0.0073657 0.58835 -0.12101 -0.11671 -0.47415 0.47753 -1.3069 -0.42765 -0.0055401 0.2247 0.061141 0.010707 0.20652 -0.48375 0.40042 0.35776 0.17049 -0.23819 0.28888 -0.069899 0.094793 -0.33917 -0.11422 0.016834 0.53581 0.25739 -0.2775 0.056731 0.34448 -0.10715 -0.21423 0.020693 -0.59172 -0.39452 -0.1925 0.20454 0.40205 -0.096825 -0.037272 0.32491 -0.26628 0.0072484 0.19783 0.17485 -0.071738 0.084738 -0.43062 0.016838 0.14359 -0.13822 0.27964 0.31179 0.33653 0.12314 -0.15906 -0.62741 -0.83838 -0.069363 0.28698 -0.11668 -0.43706 -0.063269 -0.19582 0.42072 0.19197 0.057278 0.32468 -0.59688 0.82594 -0.7103 0.47354 0.11517 -0.11188 -0.53444 0.015748 -0.57038 -0.1253 -0.45733 0.42662 0.41064 -0.27635 -0.2032 0.14295 0.46532 0.16804 0.022694 -0.24602 0.059308 0.73777 -0.29451 -0.33315 -0.29938 0.33871 0.37681 0.31939 -0.014027 0.32298 0.054817 0.13213 0.3252 -0.6153 -0.12941 0.28465 0.32881 0.25362 0.27244 -0.82169 0.41908 -0.62524 -1.2176 0.27902 -0.33003 -0.20213 -0.28881 -0.071473 0.23549 0.38409 0.13101 0.17312 0.018403 -0.29669 0.17959 -0.33733 -0.82358 0.1042 -0.51619 0.035018 -0.19027 0.50867 0.023113 -0.53112 0.10043 0.27881 -4.2515 0.44271 0.29931 -0.23305 0.011018 0.07118 0.14536 0.2012 -0.046338 0.36196 -0.33985 0.65517 -0.045043 -0.39308 0.22788 0.30343 -0.058125 0.18367 -0.22463 -0.46903 -0.20435 -0.13256 -0.73335 -0.42302 0.14038 0.59022 -0.28843 -0.09194 0.18957 0.039595 -0.11694 0.67706 -0.23313 -0.079736 -0.46375 -0.054137 0.0557 -0.12069 -0.30669 -0.15438 -0.19857 0.064394 -0.14346 -0.10524 -0.57253 0.23857 -0.79235 0.23761\n",", 0.3927 -0.084181 -0.6075 0.3231 -0.35919 0.62664 0.29758 -0.21039 -0.23201 0.11897 0.41827 -0.21206 -0.036036 0.39526 0.53432 -0.33607 -0.23529 0.027524 -0.21025 -0.49712 0.12486 -0.14865 -0.45697 0.35445 -0.31083 -1.8664 -0.32149 -0.41014 0.35596 0.25467 -0.35302 0.059504 0.1571 0.61731 -0.13229 0.18362 0.1329 -0.13754 -0.068064 -0.29138 -0.53293 -0.048187 -0.1334 0.11968 -0.045649 -0.42278 0.69403 0.30971 -0.66289 0.017076 -0.45864 -0.23924 0.24663 0.13362 -0.34587 0.031223 -0.43579 0.16547 -0.25115 0.48124 -0.21432 0.22534 0.20446 -0.45843 0.60826 0.20866 -0.46438 -0.34758 0.088277 -0.30944 0.41937 0.12139 -0.46349 0.08518 -0.070756 -0.84094 -0.32331 -0.53684 0.28473 0.22625 0.092721 0.039561 -0.48258 0.069858 0.49982 0.54392 -0.34694 0.72118 -0.30233 -0.049354 -0.47386 -0.26428 0.27401 0.1476 0.091779 0.10067 0.15366 -0.65149 -0.085811 -0.22351 0.28081 0.046785 0.42656 0.12003 0.13375 -0.035338 0.0067347 -0.36015 -0.70746 -0.033635 -0.11495 0.45643 0.11071 -0.18302 -0.335 -0.13371 -0.32718 0.28352 0.19098 -0.53333 0.49566 -0.18797 -0.1495 -0.027403 -0.0051272 -1.2365 0.049948 -0.0711 -0.74201 -0.13454 -0.35839 -0.20315 -0.20721 -0.10175 -0.13152 0.089342 -0.13269 0.36283 0.03283 -0.36339 -0.0097338 -0.20782 -0.17021 0.44278 -0.29718 0.76858 0.29221 0.21189 0.39831 -0.12685 -0.49607 -0.21184 -4.3586 -0.0046878 -0.01809 -0.13526 -0.44054 -0.496 0.11789 -1.0292 0.17799 -0.021813 0.2141 -0.27944 0.024458 0.28278 -0.49199 0.49358 0.34139 -0.67217 -0.44666 -0.46249 -0.56888 -0.71003 -0.39095 0.2495 0.46399 0.15134 -0.5881 -0.1399 -0.11789 0.17936 -0.22037 -0.27648 0.16274 -1.1748 -0.99164 0.13503 0.016681 -0.45423 -0.61859 -0.32079 -0.25119 0.27893 0.25774 -0.46615 -0.48912 0.093868 -0.58506 0.19544\n"]}]},{"cell_type":"markdown","source":["# 测试Glove模型在Twitter数据集上的表现"],"metadata":{"id":"IFrdga2_rc3f"}},{"cell_type":"markdown","source":["增加字典知识后：Training **twitter** dataset on model**(LSTM)**"],"metadata":{"id":"z2TAF_B5QZ-I"}},{"cell_type":"code","source":["!pwd\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name lstm --dataset twitter_know --embed_dim 200 --patience 50 --log_step 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EWCXsluCQaLH","outputId":"6546c821-4522-4927-edee-55e5947cc12b","executionInfo":{"status":"ok","timestamp":1662089168208,"user_tz":-480,"elapsed":129191,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    glove_embeddings  many_model_absa.ipynb  requirements.txt\n","data_utils.py\t    infer_example.py  models\t\t     train_insert.py\n","deberta_abas.ipynb  layers\t      README.md\t\t     train.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.twitter.27B.200d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1664.\n","> testing dataset count: 419.\n","cuda memory allocated: 17950720\n","> n_trainable_params: 603303, n_nontrainable_params: 3884000\n","> training arguments:\n",">>> model_name: lstm\n",">>> dataset: twitter_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f7adbfc3c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 30\n",">>> embed_dim: 200\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 50\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.lstm.LSTM'>\n",">>> dataset_file: {'train': './datasets/twitter/output_know_insert/train.tsv', 'test': './datasets/twitter/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 03:24:36\n","loss: 1.1269, acc: 0.1146\n","E2E-ABSA >>> 2022-09-02 03:24:36\n","loss: 1.0989, acc: 0.2948\n","E2E-ABSA >>> 2022-09-02 03:24:36\n","loss: 1.0764, acc: 0.4042\n","E2E-ABSA >>> 2022-09-02 03:24:37\n",">>> val_acc: 0.6802, val_precision: 0.6802 val_recall: 0.6802, val_f1: 0.6802\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.6802\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 03:24:37\n","loss: 0.9578, acc: 0.6602\n","E2E-ABSA >>> 2022-09-02 03:24:37\n","loss: 0.9273, acc: 0.6793\n","E2E-ABSA >>> 2022-09-02 03:24:37\n","loss: 0.9175, acc: 0.6711\n","E2E-ABSA >>> 2022-09-02 03:24:38\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 03:24:38\n","loss: 0.8676, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:24:38\n","loss: 0.8531, acc: 0.6660\n","E2E-ABSA >>> 2022-09-02 03:24:38\n","loss: 0.8329, acc: 0.6784\n","E2E-ABSA >>> 2022-09-02 03:24:38\n","loss: 0.8258, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:24:39\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 03:24:39\n","loss: 0.8281, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:24:39\n","loss: 0.8164, acc: 0.6628\n","E2E-ABSA >>> 2022-09-02 03:24:39\n","loss: 0.8025, acc: 0.6691\n","E2E-ABSA >>> 2022-09-02 03:24:40\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 03:24:40\n","loss: 0.7711, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:24:40\n","loss: 0.7984, acc: 0.6599\n","E2E-ABSA >>> 2022-09-02 03:24:40\n","loss: 0.7758, acc: 0.6846\n","E2E-ABSA >>> 2022-09-02 03:24:40\n","loss: 0.7873, acc: 0.6742\n","E2E-ABSA >>> 2022-09-02 03:24:41\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 03:24:41\n","loss: 0.8090, acc: 0.6500\n","E2E-ABSA >>> 2022-09-02 03:24:41\n","loss: 0.8008, acc: 0.6613\n","E2E-ABSA >>> 2022-09-02 03:24:41\n","loss: 0.7915, acc: 0.6672\n","E2E-ABSA >>> 2022-09-02 03:24:42\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 03:24:42\n","loss: 0.7775, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:24:42\n","loss: 0.7460, acc: 0.6788\n","E2E-ABSA >>> 2022-09-02 03:24:42\n","loss: 0.7561, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:24:42\n","loss: 0.7727, acc: 0.6706\n","E2E-ABSA >>> 2022-09-02 03:24:43\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 03:24:43\n","loss: 0.7852, acc: 0.6449\n","E2E-ABSA >>> 2022-09-02 03:24:43\n","loss: 0.7921, acc: 0.6550\n","E2E-ABSA >>> 2022-09-02 03:24:43\n","loss: 0.7720, acc: 0.6715\n","E2E-ABSA >>> 2022-09-02 03:24:44\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 03:24:44\n","loss: 0.8894, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 03:24:44\n","loss: 0.8015, acc: 0.6579\n","E2E-ABSA >>> 2022-09-02 03:24:44\n","loss: 0.7804, acc: 0.6682\n","E2E-ABSA >>> 2022-09-02 03:24:44\n","loss: 0.7663, acc: 0.6716\n","E2E-ABSA >>> 2022-09-02 03:24:45\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 03:24:45\n","loss: 0.7717, acc: 0.6615\n","E2E-ABSA >>> 2022-09-02 03:24:45\n","loss: 0.7676, acc: 0.6748\n","E2E-ABSA >>> 2022-09-02 03:24:45\n","loss: 0.7744, acc: 0.6629\n","E2E-ABSA >>> 2022-09-02 03:24:46\n",">>> val_acc: 0.6850, val_precision: 0.6850 val_recall: 0.6850, val_f1: 0.6850\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 03:24:46\n","loss: 0.7299, acc: 0.7000\n","E2E-ABSA >>> 2022-09-02 03:24:46\n","loss: 0.7528, acc: 0.6813\n","E2E-ABSA >>> 2022-09-02 03:24:46\n","loss: 0.7580, acc: 0.6723\n","E2E-ABSA >>> 2022-09-02 03:24:46\n","loss: 0.7589, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:24:47\n",">>> val_acc: 0.6850, val_precision: 0.6850 val_recall: 0.6850, val_f1: 0.6850\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 03:24:47\n","loss: 0.7282, acc: 0.7043\n","E2E-ABSA >>> 2022-09-02 03:24:47\n","loss: 0.7163, acc: 0.6987\n","E2E-ABSA >>> 2022-09-02 03:24:47\n","loss: 0.7360, acc: 0.6860\n","E2E-ABSA >>> 2022-09-02 03:24:48\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 03:24:48\n","loss: 0.7022, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:24:48\n","loss: 0.7325, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:24:48\n","loss: 0.7453, acc: 0.6780\n","E2E-ABSA >>> 2022-09-02 03:24:48\n","loss: 0.7496, acc: 0.6783\n","E2E-ABSA >>> 2022-09-02 03:24:49\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 03:24:49\n","loss: 0.7350, acc: 0.6741\n","E2E-ABSA >>> 2022-09-02 03:24:49\n","loss: 0.7310, acc: 0.6778\n","E2E-ABSA >>> 2022-09-02 03:24:49\n","loss: 0.7328, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 03:24:50\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 03:24:50\n","loss: 0.6937, acc: 0.6964\n","E2E-ABSA >>> 2022-09-02 03:24:50\n","loss: 0.7249, acc: 0.6918\n","E2E-ABSA >>> 2022-09-02 03:24:50\n","loss: 0.7338, acc: 0.6833\n","E2E-ABSA >>> 2022-09-02 03:24:50\n","loss: 0.7395, acc: 0.6779\n","E2E-ABSA >>> 2022-09-02 03:24:50\n",">>> val_acc: 0.6897, val_precision: 0.6897 val_recall: 0.6897, val_f1: 0.6897\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 03:24:51\n","loss: 0.7194, acc: 0.6896\n","E2E-ABSA >>> 2022-09-02 03:24:51\n","loss: 0.7426, acc: 0.6781\n","E2E-ABSA >>> 2022-09-02 03:24:51\n","loss: 0.7423, acc: 0.6785\n","E2E-ABSA >>> 2022-09-02 03:24:51\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 03:24:52\n","loss: 0.7297, acc: 0.6680\n","E2E-ABSA >>> 2022-09-02 03:24:52\n","loss: 0.7313, acc: 0.6753\n","E2E-ABSA >>> 2022-09-02 03:24:52\n","loss: 0.7396, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:24:52\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 03:24:52\n","loss: 0.9903, acc: 0.5000\n","E2E-ABSA >>> 2022-09-02 03:24:53\n","loss: 0.7354, acc: 0.6582\n","E2E-ABSA >>> 2022-09-02 03:24:53\n","loss: 0.7269, acc: 0.6784\n","E2E-ABSA >>> 2022-09-02 03:24:53\n","loss: 0.7352, acc: 0.6773\n","E2E-ABSA >>> 2022-09-02 03:24:53\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 03:24:53\n","loss: 0.7338, acc: 0.6701\n","E2E-ABSA >>> 2022-09-02 03:24:54\n","loss: 0.7172, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 03:24:54\n","loss: 0.7261, acc: 0.6859\n","E2E-ABSA >>> 2022-09-02 03:24:54\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 03:24:54\n","loss: 0.8079, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 03:24:54\n","loss: 0.7812, acc: 0.6489\n","E2E-ABSA >>> 2022-09-02 03:24:55\n","loss: 0.7446, acc: 0.6768\n","E2E-ABSA >>> 2022-09-02 03:24:55\n","loss: 0.7213, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:24:55\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 03:24:55\n","loss: 0.7321, acc: 0.6844\n","E2E-ABSA >>> 2022-09-02 03:24:56\n","loss: 0.7181, acc: 0.6800\n","E2E-ABSA >>> 2022-09-02 03:24:56\n","loss: 0.7047, acc: 0.6914\n","E2E-ABSA >>> 2022-09-02 03:24:56\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 03:24:56\n","loss: 0.7287, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:24:56\n","loss: 0.7388, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:24:57\n","loss: 0.7207, acc: 0.6761\n","E2E-ABSA >>> 2022-09-02 03:24:57\n","loss: 0.7214, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 03:24:57\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 03:24:57\n","loss: 0.7471, acc: 0.6648\n","E2E-ABSA >>> 2022-09-02 03:24:57\n","loss: 0.7192, acc: 0.6803\n","E2E-ABSA >>> 2022-09-02 03:24:58\n","loss: 0.7054, acc: 0.6883\n","E2E-ABSA >>> 2022-09-02 03:24:58\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 03:24:58\n","loss: 0.6282, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 03:24:58\n","loss: 0.7356, acc: 0.6628\n","E2E-ABSA >>> 2022-09-02 03:24:59\n","loss: 0.7090, acc: 0.6912\n","E2E-ABSA >>> 2022-09-02 03:24:59\n","loss: 0.7116, acc: 0.6862\n","E2E-ABSA >>> 2022-09-02 03:24:59\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 03:24:59\n","loss: 0.7456, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:24:59\n","loss: 0.7185, acc: 0.6806\n","E2E-ABSA >>> 2022-09-02 03:25:00\n","loss: 0.7124, acc: 0.6830\n","E2E-ABSA >>> 2022-09-02 03:25:00\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 03:25:00\n","loss: 0.6784, acc: 0.7000\n","E2E-ABSA >>> 2022-09-02 03:25:00\n","loss: 0.6874, acc: 0.7078\n","E2E-ABSA >>> 2022-09-02 03:25:00\n","loss: 0.6949, acc: 0.7045\n","E2E-ABSA >>> 2022-09-02 03:25:01\n","loss: 0.7012, acc: 0.6913\n","E2E-ABSA >>> 2022-09-02 03:25:01\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 03:25:01\n","loss: 0.7401, acc: 0.6731\n","E2E-ABSA >>> 2022-09-02 03:25:01\n","loss: 0.7267, acc: 0.6897\n","E2E-ABSA >>> 2022-09-02 03:25:02\n","loss: 0.7082, acc: 0.6977\n","E2E-ABSA >>> 2022-09-02 03:25:02\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 03:25:02\n","loss: 0.6962, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:25:02\n","loss: 0.7008, acc: 0.6935\n","E2E-ABSA >>> 2022-09-02 03:25:02\n","loss: 0.7021, acc: 0.6910\n","E2E-ABSA >>> 2022-09-02 03:25:03\n","loss: 0.6971, acc: 0.6918\n","E2E-ABSA >>> 2022-09-02 03:25:03\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 03:25:03\n","loss: 0.6914, acc: 0.6808\n","E2E-ABSA >>> 2022-09-02 03:25:03\n","loss: 0.7031, acc: 0.6832\n","E2E-ABSA >>> 2022-09-02 03:25:03\n","loss: 0.6840, acc: 0.6982\n","E2E-ABSA >>> 2022-09-02 03:25:04\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 03:25:04\n","loss: 0.6996, acc: 0.6830\n","E2E-ABSA >>> 2022-09-02 03:25:04\n","loss: 0.7139, acc: 0.6790\n","E2E-ABSA >>> 2022-09-02 03:25:04\n","loss: 0.7130, acc: 0.6850\n","E2E-ABSA >>> 2022-09-02 03:25:04\n","loss: 0.6898, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 03:25:05\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 03:25:05\n","loss: 0.6710, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:25:05\n","loss: 0.6929, acc: 0.6969\n","E2E-ABSA >>> 2022-09-02 03:25:05\n","loss: 0.6917, acc: 0.6965\n","E2E-ABSA >>> 2022-09-02 03:25:06\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 03:25:06\n","loss: 0.7309, acc: 0.6602\n","E2E-ABSA >>> 2022-09-02 03:25:06\n","loss: 0.6921, acc: 0.6970\n","E2E-ABSA >>> 2022-09-02 03:25:06\n","loss: 0.7088, acc: 0.6859\n","E2E-ABSA >>> 2022-09-02 03:25:06\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 03:25:06\n","loss: 0.7577, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:25:07\n","loss: 0.7009, acc: 0.6836\n","E2E-ABSA >>> 2022-09-02 03:25:07\n","loss: 0.6786, acc: 0.6956\n","E2E-ABSA >>> 2022-09-02 03:25:07\n","loss: 0.6748, acc: 0.7011\n","E2E-ABSA >>> 2022-09-02 03:25:07\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 03:25:08\n","loss: 0.6985, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:25:08\n","loss: 0.6912, acc: 0.6849\n","E2E-ABSA >>> 2022-09-02 03:25:08\n","loss: 0.6844, acc: 0.6923\n","E2E-ABSA >>> 2022-09-02 03:25:08\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 03:25:08\n","loss: 0.6324, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 03:25:09\n","loss: 0.7055, acc: 0.6746\n","E2E-ABSA >>> 2022-09-02 03:25:09\n","loss: 0.6848, acc: 0.6826\n","E2E-ABSA >>> 2022-09-02 03:25:09\n","loss: 0.6780, acc: 0.6902\n","E2E-ABSA >>> 2022-09-02 03:25:09\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 03:25:09\n","loss: 0.7018, acc: 0.6813\n","E2E-ABSA >>> 2022-09-02 03:25:10\n","loss: 0.6976, acc: 0.6887\n","E2E-ABSA >>> 2022-09-02 03:25:10\n","loss: 0.6816, acc: 0.7023\n","E2E-ABSA >>> 2022-09-02 03:25:10\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 03:25:10\n","loss: 0.6536, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:25:10\n","loss: 0.6580, acc: 0.7101\n","E2E-ABSA >>> 2022-09-02 03:25:11\n","loss: 0.6522, acc: 0.7159\n","E2E-ABSA >>> 2022-09-02 03:25:11\n","loss: 0.6668, acc: 0.7038\n","E2E-ABSA >>> 2022-09-02 03:25:11\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 03:25:11\n","loss: 0.6515, acc: 0.7301\n","E2E-ABSA >>> 2022-09-02 03:25:12\n","loss: 0.6282, acc: 0.7296\n","E2E-ABSA >>> 2022-09-02 03:25:12\n","loss: 0.6573, acc: 0.7073\n","E2E-ABSA >>> 2022-09-02 03:25:12\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 03:25:12\n","loss: 0.7007, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:25:12\n","loss: 0.6652, acc: 0.7105\n","E2E-ABSA >>> 2022-09-02 03:25:13\n","loss: 0.6565, acc: 0.7142\n","E2E-ABSA >>> 2022-09-02 03:25:13\n","loss: 0.6634, acc: 0.7079\n","E2E-ABSA >>> 2022-09-02 03:25:13\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 03:25:13\n","loss: 0.6385, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 03:25:13\n","loss: 0.6569, acc: 0.7141\n","E2E-ABSA >>> 2022-09-02 03:25:14\n","loss: 0.6732, acc: 0.6949\n","E2E-ABSA >>> 2022-09-02 03:25:14\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 03:25:14\n","loss: 0.6383, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 03:25:14\n","loss: 0.6703, acc: 0.7078\n","E2E-ABSA >>> 2022-09-02 03:25:14\n","loss: 0.6532, acc: 0.7116\n","E2E-ABSA >>> 2022-09-02 03:25:15\n","loss: 0.6512, acc: 0.7150\n","E2E-ABSA >>> 2022-09-02 03:25:15\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 03:25:15\n","loss: 0.6046, acc: 0.7356\n","E2E-ABSA >>> 2022-09-02 03:25:15\n","loss: 0.6473, acc: 0.7098\n","E2E-ABSA >>> 2022-09-02 03:25:16\n","loss: 0.6425, acc: 0.7093\n","E2E-ABSA >>> 2022-09-02 03:25:16\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 03:25:16\n","loss: 0.6093, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:25:16\n","loss: 0.6470, acc: 0.7068\n","E2E-ABSA >>> 2022-09-02 03:25:16\n","loss: 0.6420, acc: 0.7179\n","E2E-ABSA >>> 2022-09-02 03:25:17\n","loss: 0.6447, acc: 0.7200\n","E2E-ABSA >>> 2022-09-02 03:25:17\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 03:25:17\n","loss: 0.6463, acc: 0.7143\n","E2E-ABSA >>> 2022-09-02 03:25:17\n","loss: 0.6488, acc: 0.7177\n","E2E-ABSA >>> 2022-09-02 03:25:17\n","loss: 0.6502, acc: 0.7152\n","E2E-ABSA >>> 2022-09-02 03:25:18\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 03:25:18\n","loss: 0.5883, acc: 0.7679\n","E2E-ABSA >>> 2022-09-02 03:25:18\n","loss: 0.6237, acc: 0.7330\n","E2E-ABSA >>> 2022-09-02 03:25:18\n","loss: 0.6357, acc: 0.7264\n","E2E-ABSA >>> 2022-09-02 03:25:19\n","loss: 0.6363, acc: 0.7200\n","E2E-ABSA >>> 2022-09-02 03:25:19\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 03:25:19\n","loss: 0.6432, acc: 0.7250\n","E2E-ABSA >>> 2022-09-02 03:25:19\n","loss: 0.6320, acc: 0.7156\n","E2E-ABSA >>> 2022-09-02 03:25:19\n","loss: 0.6392, acc: 0.7139\n","E2E-ABSA >>> 2022-09-02 03:25:20\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.716\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 03:25:20\n","loss: 0.5663, acc: 0.7734\n","E2E-ABSA >>> 2022-09-02 03:25:20\n","loss: 0.6263, acc: 0.7269\n","E2E-ABSA >>> 2022-09-02 03:25:20\n","loss: 0.6302, acc: 0.7286\n","E2E-ABSA >>> 2022-09-02 03:25:21\n",">>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.7232\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 03:25:21\n","loss: 0.6864, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:25:21\n","loss: 0.6599, acc: 0.7148\n","E2E-ABSA >>> 2022-09-02 03:25:21\n","loss: 0.6350, acc: 0.7238\n","E2E-ABSA >>> 2022-09-02 03:25:22\n","loss: 0.6301, acc: 0.7269\n","E2E-ABSA >>> 2022-09-02 03:25:22\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 03:25:22\n","loss: 0.5904, acc: 0.7431\n","E2E-ABSA >>> 2022-09-02 03:25:22\n","loss: 0.6305, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:25:22\n","loss: 0.6198, acc: 0.7284\n","E2E-ABSA >>> 2022-09-02 03:25:23\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 03:25:23\n","loss: 0.6904, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:25:23\n","loss: 0.6352, acc: 0.7132\n","E2E-ABSA >>> 2022-09-02 03:25:23\n","loss: 0.6219, acc: 0.7178\n","E2E-ABSA >>> 2022-09-02 03:25:23\n","loss: 0.6296, acc: 0.7214\n","E2E-ABSA >>> 2022-09-02 03:25:24\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 03:25:24\n","loss: 0.6445, acc: 0.7250\n","E2E-ABSA >>> 2022-09-02 03:25:24\n","loss: 0.5899, acc: 0.7462\n","E2E-ABSA >>> 2022-09-02 03:25:24\n","loss: 0.6157, acc: 0.7281\n","E2E-ABSA >>> 2022-09-02 03:25:25\n",">>> val_acc: 0.7208, val_precision: 0.7208 val_recall: 0.7208, val_f1: 0.7208\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 03:25:25\n","loss: 0.6711, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:25:25\n","loss: 0.6109, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:25:25\n","loss: 0.6247, acc: 0.7263\n","E2E-ABSA >>> 2022-09-02 03:25:25\n","loss: 0.6241, acc: 0.7233\n","E2E-ABSA >>> 2022-09-02 03:25:26\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 03:25:26\n","loss: 0.6322, acc: 0.7358\n","E2E-ABSA >>> 2022-09-02 03:25:26\n","loss: 0.6164, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:25:26\n","loss: 0.6254, acc: 0.7233\n","E2E-ABSA >>> 2022-09-02 03:25:26\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 03:25:27\n","loss: 0.6184, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 03:25:27\n","loss: 0.6025, acc: 0.7303\n","E2E-ABSA >>> 2022-09-02 03:25:27\n","loss: 0.5989, acc: 0.7279\n","E2E-ABSA >>> 2022-09-02 03:25:27\n","loss: 0.6146, acc: 0.7302\n","E2E-ABSA >>> 2022-09-02 03:25:27\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 03:25:28\n","loss: 0.6218, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 03:25:28\n","loss: 0.6241, acc: 0.7280\n","E2E-ABSA >>> 2022-09-02 03:25:28\n","loss: 0.6169, acc: 0.7336\n","E2E-ABSA >>> 2022-09-02 03:25:28\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 03:25:28\n","loss: 0.5534, acc: 0.7312\n","E2E-ABSA >>> 2022-09-02 03:25:29\n","loss: 0.6269, acc: 0.7141\n","E2E-ABSA >>> 2022-09-02 03:25:29\n","loss: 0.6166, acc: 0.7250\n","E2E-ABSA >>> 2022-09-02 03:25:29\n","loss: 0.6123, acc: 0.7300\n","E2E-ABSA >>> 2022-09-02 03:25:29\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 03:25:29\n","loss: 0.5522, acc: 0.7452\n","E2E-ABSA >>> 2022-09-02 03:25:30\n","loss: 0.5797, acc: 0.7366\n","E2E-ABSA >>> 2022-09-02 03:25:30\n","loss: 0.5914, acc: 0.7406\n","E2E-ABSA >>> 2022-09-02 03:25:30\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 03:25:30\n","loss: 0.6182, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 03:25:31\n","loss: 0.6212, acc: 0.7307\n","E2E-ABSA >>> 2022-09-02 03:25:31\n","loss: 0.6225, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 03:25:31\n","loss: 0.6078, acc: 0.7377\n","E2E-ABSA >>> 2022-09-02 03:25:31\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 03:25:31\n","loss: 0.5678, acc: 0.7455\n","E2E-ABSA >>> 2022-09-02 03:25:32\n","loss: 0.6001, acc: 0.7414\n","E2E-ABSA >>> 2022-09-02 03:25:32\n","loss: 0.6016, acc: 0.7365\n","E2E-ABSA >>> 2022-09-02 03:25:32\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 03:25:32\n","loss: 0.6512, acc: 0.7143\n","E2E-ABSA >>> 2022-09-02 03:25:32\n","loss: 0.5974, acc: 0.7443\n","E2E-ABSA >>> 2022-09-02 03:25:33\n","loss: 0.6087, acc: 0.7348\n","E2E-ABSA >>> 2022-09-02 03:25:33\n","loss: 0.6061, acc: 0.7392\n","E2E-ABSA >>> 2022-09-02 03:25:33\n",">>> val_acc: 0.7208, val_precision: 0.7208 val_recall: 0.7208, val_f1: 0.7208\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 03:25:33\n","loss: 0.6140, acc: 0.7229\n","E2E-ABSA >>> 2022-09-02 03:25:33\n","loss: 0.6090, acc: 0.7281\n","E2E-ABSA >>> 2022-09-02 03:25:34\n","loss: 0.6097, acc: 0.7382\n","E2E-ABSA >>> 2022-09-02 03:25:34\n",">>> val_acc: 0.6850, val_precision: 0.6850 val_recall: 0.6850, val_f1: 0.6850\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 03:25:34\n","loss: 0.5505, acc: 0.7539\n","E2E-ABSA >>> 2022-09-02 03:25:34\n","loss: 0.5920, acc: 0.7378\n","E2E-ABSA >>> 2022-09-02 03:25:35\n","loss: 0.6137, acc: 0.7229\n","E2E-ABSA >>> 2022-09-02 03:25:35\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 03:25:35\n","loss: 0.5811, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 03:25:35\n","loss: 0.6320, acc: 0.7383\n","E2E-ABSA >>> 2022-09-02 03:25:35\n","loss: 0.6120, acc: 0.7399\n","E2E-ABSA >>> 2022-09-02 03:25:36\n","loss: 0.5971, acc: 0.7466\n","E2E-ABSA >>> 2022-09-02 03:25:36\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 03:25:36\n","loss: 0.5709, acc: 0.7986\n","E2E-ABSA >>> 2022-09-02 03:25:36\n","loss: 0.5637, acc: 0.7721\n","E2E-ABSA >>> 2022-09-02 03:25:36\n","loss: 0.5805, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:25:37\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 03:25:37\n","loss: 0.5821, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:25:37\n","loss: 0.5675, acc: 0.7665\n","E2E-ABSA >>> 2022-09-02 03:25:37\n","loss: 0.5938, acc: 0.7451\n","E2E-ABSA >>> 2022-09-02 03:25:37\n","loss: 0.6026, acc: 0.7400\n","E2E-ABSA >>> 2022-09-02 03:25:38\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 03:25:38\n","loss: 0.5923, acc: 0.7406\n","E2E-ABSA >>> 2022-09-02 03:25:38\n","loss: 0.5667, acc: 0.7612\n","E2E-ABSA >>> 2022-09-02 03:25:38\n","loss: 0.5946, acc: 0.7375\n","E2E-ABSA >>> 2022-09-02 03:25:39\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 03:25:39\n","loss: 0.6912, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 03:25:39\n","loss: 0.6049, acc: 0.7431\n","E2E-ABSA >>> 2022-09-02 03:25:39\n","loss: 0.5917, acc: 0.7424\n","E2E-ABSA >>> 2022-09-02 03:25:39\n","loss: 0.6036, acc: 0.7298\n","E2E-ABSA >>> 2022-09-02 03:25:40\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 03:25:40\n","loss: 0.6166, acc: 0.7386\n","E2E-ABSA >>> 2022-09-02 03:25:40\n","loss: 0.6109, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:25:40\n","loss: 0.6057, acc: 0.7332\n","E2E-ABSA >>> 2022-09-02 03:25:41\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","E2E-ABSA >>> 2022-09-02 03:25:41\n","loss: 0.5924, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:25:41\n","loss: 0.5721, acc: 0.7549\n","E2E-ABSA >>> 2022-09-02 03:25:41\n","loss: 0.5860, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:25:41\n","loss: 0.5933, acc: 0.7443\n","E2E-ABSA >>> 2022-09-02 03:25:41\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","E2E-ABSA >>> 2022-09-02 03:25:42\n","loss: 0.5540, acc: 0.7630\n","E2E-ABSA >>> 2022-09-02 03:25:42\n","loss: 0.5825, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:25:42\n","loss: 0.5984, acc: 0.7411\n","E2E-ABSA >>> 2022-09-02 03:25:42\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","E2E-ABSA >>> 2022-09-02 03:25:42\n","loss: 0.6253, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 03:25:43\n","loss: 0.5770, acc: 0.7703\n","E2E-ABSA >>> 2022-09-02 03:25:43\n","loss: 0.5983, acc: 0.7455\n","E2E-ABSA >>> 2022-09-02 03:25:43\n","loss: 0.6021, acc: 0.7431\n","E2E-ABSA >>> 2022-09-02 03:25:43\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","E2E-ABSA >>> 2022-09-02 03:25:44\n","loss: 0.5937, acc: 0.7524\n","E2E-ABSA >>> 2022-09-02 03:25:44\n","loss: 0.6146, acc: 0.7366\n","E2E-ABSA >>> 2022-09-02 03:25:44\n","loss: 0.5932, acc: 0.7471\n","E2E-ABSA >>> 2022-09-02 03:25:44\n",">>> val_acc: 0.6826, val_precision: 0.6826 val_recall: 0.6826, val_f1: 0.6826\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","E2E-ABSA >>> 2022-09-02 03:25:44\n","loss: 0.6282, acc: 0.7448\n","E2E-ABSA >>> 2022-09-02 03:25:45\n","loss: 0.6126, acc: 0.7262\n","E2E-ABSA >>> 2022-09-02 03:25:45\n","loss: 0.5960, acc: 0.7457\n","E2E-ABSA >>> 2022-09-02 03:25:45\n","loss: 0.5947, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 03:25:45\n",">>> val_acc: 0.6897, val_precision: 0.6897 val_recall: 0.6897, val_f1: 0.6897\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","E2E-ABSA >>> 2022-09-02 03:25:45\n","loss: 0.5839, acc: 0.7545\n","E2E-ABSA >>> 2022-09-02 03:25:46\n","loss: 0.5670, acc: 0.7532\n","E2E-ABSA >>> 2022-09-02 03:25:46\n","loss: 0.5840, acc: 0.7429\n","E2E-ABSA >>> 2022-09-02 03:25:46\n",">>> val_acc: 0.6730, val_precision: 0.6730 val_recall: 0.6730, val_f1: 0.6730\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","E2E-ABSA >>> 2022-09-02 03:25:46\n","loss: 0.5716, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:25:47\n","loss: 0.6176, acc: 0.7372\n","E2E-ABSA >>> 2022-09-02 03:25:47\n","loss: 0.5929, acc: 0.7432\n","E2E-ABSA >>> 2022-09-02 03:25:47\n","loss: 0.5913, acc: 0.7482\n","E2E-ABSA >>> 2022-09-02 03:25:47\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","E2E-ABSA >>> 2022-09-02 03:25:47\n","loss: 0.5757, acc: 0.7479\n","E2E-ABSA >>> 2022-09-02 03:25:48\n","loss: 0.5705, acc: 0.7542\n","E2E-ABSA >>> 2022-09-02 03:25:48\n","loss: 0.5904, acc: 0.7472\n","E2E-ABSA >>> 2022-09-02 03:25:48\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","E2E-ABSA >>> 2022-09-02 03:25:48\n","loss: 0.5517, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:25:48\n","loss: 0.5696, acc: 0.7717\n","E2E-ABSA >>> 2022-09-02 03:25:49\n","loss: 0.5768, acc: 0.7640\n","E2E-ABSA >>> 2022-09-02 03:25:49\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","E2E-ABSA >>> 2022-09-02 03:25:49\n","loss: 0.6081, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:25:49\n","loss: 0.5543, acc: 0.7578\n","E2E-ABSA >>> 2022-09-02 03:25:50\n","loss: 0.5897, acc: 0.7339\n","E2E-ABSA >>> 2022-09-02 03:25:50\n","loss: 0.6008, acc: 0.7330\n","E2E-ABSA >>> 2022-09-02 03:25:50\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","E2E-ABSA >>> 2022-09-02 03:25:50\n","loss: 0.5869, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:25:50\n","loss: 0.5955, acc: 0.7448\n","E2E-ABSA >>> 2022-09-02 03:25:51\n","loss: 0.5937, acc: 0.7468\n","E2E-ABSA >>> 2022-09-02 03:25:51\n",">>> val_acc: 0.7208, val_precision: 0.7208 val_recall: 0.7208, val_f1: 0.7208\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","E2E-ABSA >>> 2022-09-02 03:25:51\n","loss: 0.4455, acc: 0.8281\n","E2E-ABSA >>> 2022-09-02 03:25:51\n","loss: 0.5643, acc: 0.7445\n","E2E-ABSA >>> 2022-09-02 03:25:51\n","loss: 0.5680, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:25:52\n","loss: 0.5858, acc: 0.7460\n","E2E-ABSA >>> 2022-09-02 03:25:52\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","E2E-ABSA >>> 2022-09-02 03:25:52\n","loss: 0.5798, acc: 0.7312\n","E2E-ABSA >>> 2022-09-02 03:25:52\n","loss: 0.5826, acc: 0.7312\n","E2E-ABSA >>> 2022-09-02 03:25:53\n","loss: 0.5710, acc: 0.7469\n","E2E-ABSA >>> 2022-09-02 03:25:53\n",">>> val_acc: 0.6802, val_precision: 0.6802 val_recall: 0.6802, val_f1: 0.6802\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","E2E-ABSA >>> 2022-09-02 03:25:53\n","loss: 0.5675, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 03:25:53\n","loss: 0.5907, acc: 0.7274\n","E2E-ABSA >>> 2022-09-02 03:25:53\n","loss: 0.5767, acc: 0.7434\n","E2E-ABSA >>> 2022-09-02 03:25:54\n","loss: 0.5830, acc: 0.7428\n","E2E-ABSA >>> 2022-09-02 03:25:54\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","E2E-ABSA >>> 2022-09-02 03:25:54\n","loss: 0.5371, acc: 0.7699\n","E2E-ABSA >>> 2022-09-02 03:25:54\n","loss: 0.5617, acc: 0.7620\n","E2E-ABSA >>> 2022-09-02 03:25:54\n","loss: 0.5807, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:25:55\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","E2E-ABSA >>> 2022-09-02 03:25:55\n","loss: 0.5924, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 03:25:55\n","loss: 0.6010, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:25:55\n","loss: 0.5987, acc: 0.7463\n","E2E-ABSA >>> 2022-09-02 03:25:56\n","loss: 0.5815, acc: 0.7551\n","E2E-ABSA >>> 2022-09-02 03:25:56\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","E2E-ABSA >>> 2022-09-02 03:25:56\n","loss: 0.5884, acc: 0.7422\n","E2E-ABSA >>> 2022-09-02 03:25:56\n","loss: 0.5762, acc: 0.7488\n","E2E-ABSA >>> 2022-09-02 03:25:56\n","loss: 0.5774, acc: 0.7478\n","E2E-ABSA >>> 2022-09-02 03:25:57\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","E2E-ABSA >>> 2022-09-02 03:25:57\n","loss: 0.5681, acc: 0.7750\n","E2E-ABSA >>> 2022-09-02 03:25:57\n","loss: 0.5902, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 03:25:57\n","loss: 0.5839, acc: 0.7429\n","E2E-ABSA >>> 2022-09-02 03:25:57\n","loss: 0.5777, acc: 0.7531\n","E2E-ABSA >>> 2022-09-02 03:25:58\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","E2E-ABSA >>> 2022-09-02 03:25:58\n","loss: 0.5636, acc: 0.7428\n","E2E-ABSA >>> 2022-09-02 03:25:58\n","loss: 0.5797, acc: 0.7478\n","E2E-ABSA >>> 2022-09-02 03:25:58\n","loss: 0.5699, acc: 0.7551\n","E2E-ABSA >>> 2022-09-02 03:25:59\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","E2E-ABSA >>> 2022-09-02 03:25:59\n","loss: 0.5462, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 03:25:59\n","loss: 0.5642, acc: 0.7589\n","E2E-ABSA >>> 2022-09-02 03:25:59\n","loss: 0.5789, acc: 0.7465\n","E2E-ABSA >>> 2022-09-02 03:25:59\n","loss: 0.5842, acc: 0.7463\n","E2E-ABSA >>> 2022-09-02 03:26:00\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","E2E-ABSA >>> 2022-09-02 03:26:00\n","loss: 0.5665, acc: 0.7545\n","E2E-ABSA >>> 2022-09-02 03:26:00\n","loss: 0.5801, acc: 0.7446\n","E2E-ABSA >>> 2022-09-02 03:26:00\n","loss: 0.5831, acc: 0.7479\n","E2E-ABSA >>> 2022-09-02 03:26:00\n",">>> val_acc: 0.6850, val_precision: 0.6850 val_recall: 0.6850, val_f1: 0.6850\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","E2E-ABSA >>> 2022-09-02 03:26:01\n","loss: 0.5710, acc: 0.7411\n","E2E-ABSA >>> 2022-09-02 03:26:01\n","loss: 0.5594, acc: 0.7599\n","E2E-ABSA >>> 2022-09-02 03:26:01\n","loss: 0.5637, acc: 0.7551\n","E2E-ABSA >>> 2022-09-02 03:26:01\n","loss: 0.5824, acc: 0.7440\n","E2E-ABSA >>> 2022-09-02 03:26:01\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 90.\n","E2E-ABSA >>> 2022-09-02 03:26:02\n","loss: 0.5581, acc: 0.7646\n","E2E-ABSA >>> 2022-09-02 03:26:02\n","loss: 0.5721, acc: 0.7625\n","E2E-ABSA >>> 2022-09-02 03:26:02\n","loss: 0.5691, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:26:02\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 91.\n","E2E-ABSA >>> 2022-09-02 03:26:02\n","loss: 0.5337, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:26:03\n","loss: 0.5703, acc: 0.7514\n","E2E-ABSA >>> 2022-09-02 03:26:03\n","loss: 0.5759, acc: 0.7459\n","E2E-ABSA >>> 2022-09-02 03:26:03\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 92.\n","E2E-ABSA >>> 2022-09-02 03:26:03\n","loss: 0.6741, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:26:04\n","loss: 0.5839, acc: 0.7578\n","E2E-ABSA >>> 2022-09-02 03:26:04\n","loss: 0.5758, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:26:04\n","loss: 0.5736, acc: 0.7507\n","E2E-ABSA >>> 2022-09-02 03:26:04\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 93.\n","E2E-ABSA >>> 2022-09-02 03:26:04\n","loss: 0.5335, acc: 0.7847\n","E2E-ABSA >>> 2022-09-02 03:26:05\n","loss: 0.5719, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:26:05\n","loss: 0.5748, acc: 0.7548\n","E2E-ABSA >>> 2022-09-02 03:26:05\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 94.\n","E2E-ABSA >>> 2022-09-02 03:26:05\n","loss: 0.6196, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 03:26:05\n","loss: 0.6098, acc: 0.7206\n","E2E-ABSA >>> 2022-09-02 03:26:06\n","loss: 0.5746, acc: 0.7451\n","E2E-ABSA >>> 2022-09-02 03:26:06\n","loss: 0.5750, acc: 0.7493\n","E2E-ABSA >>> 2022-09-02 03:26:06\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 95.\n","E2E-ABSA >>> 2022-09-02 03:26:06\n","loss: 0.5476, acc: 0.7594\n","E2E-ABSA >>> 2022-09-02 03:26:07\n","loss: 0.5753, acc: 0.7538\n","E2E-ABSA >>> 2022-09-02 03:26:07\n","loss: 0.5721, acc: 0.7523\n","E2E-ABSA >>> 2022-09-02 03:26:07\n",">>> val_acc: 0.6754, val_precision: 0.6754 val_recall: 0.6754, val_f1: 0.6754\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 96.\n","E2E-ABSA >>> 2022-09-02 03:26:07\n","loss: 0.5189, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 03:26:08\n","loss: 0.5635, acc: 0.7587\n","E2E-ABSA >>> 2022-09-02 03:26:08\n","loss: 0.5747, acc: 0.7566\n","E2E-ABSA >>> 2022-09-02 03:26:08\n","loss: 0.5806, acc: 0.7513\n","E2E-ABSA >>> 2022-09-02 03:26:09\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n","E2E-ABSA >>> 2022-09-02 03:26:09\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n","you can download the best model from state_dict/lstm_twitter_know_val_f1_0.7232\n",">>> test_acc: 0.7232, test_precision: 0.7232, test_recall: 0.7232, test_f1: 0.7232\n"]}]},{"cell_type":"markdown","source":["增加字典知识后：Training **twitter** dataset on model**(td_LSTM)**"],"metadata":{"id":"RaOWTTM19wxo"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name lstm --dataset twitter_know --embed_dim 200 --patience 50 --log_step 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"koFxkweS9xIs","outputId":"0ca8d038-d7e3-4458-e030-789f01f0a51e","executionInfo":{"status":"ok","timestamp":1662089287190,"user_tz":-480,"elapsed":118987,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.twitter.27B.200d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1664.\n","> testing dataset count: 419.\n","cuda memory allocated: 17950720\n","> n_trainable_params: 603303, n_nontrainable_params: 3884000\n","> training arguments:\n",">>> model_name: lstm\n",">>> dataset: twitter_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7fe37109cc20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 30\n",">>> embed_dim: 200\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 50\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.lstm.LSTM'>\n",">>> dataset_file: {'train': './datasets/twitter/output_know_insert/train.tsv', 'test': './datasets/twitter/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 03:26:36\n","loss: 1.1269, acc: 0.1146\n","E2E-ABSA >>> 2022-09-02 03:26:36\n","loss: 1.0989, acc: 0.2948\n","E2E-ABSA >>> 2022-09-02 03:26:36\n","loss: 1.0764, acc: 0.4042\n","E2E-ABSA >>> 2022-09-02 03:26:37\n",">>> val_acc: 0.6802, val_precision: 0.6802 val_recall: 0.6802, val_f1: 0.6802\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.6802\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 03:26:37\n","loss: 0.9578, acc: 0.6602\n","E2E-ABSA >>> 2022-09-02 03:26:37\n","loss: 0.9273, acc: 0.6793\n","E2E-ABSA >>> 2022-09-02 03:26:37\n","loss: 0.9175, acc: 0.6711\n","E2E-ABSA >>> 2022-09-02 03:26:38\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 03:26:38\n","loss: 0.8676, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:26:38\n","loss: 0.8531, acc: 0.6660\n","E2E-ABSA >>> 2022-09-02 03:26:38\n","loss: 0.8329, acc: 0.6784\n","E2E-ABSA >>> 2022-09-02 03:26:38\n","loss: 0.8258, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:26:39\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 03:26:39\n","loss: 0.8281, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:26:39\n","loss: 0.8164, acc: 0.6628\n","E2E-ABSA >>> 2022-09-02 03:26:39\n","loss: 0.8025, acc: 0.6691\n","E2E-ABSA >>> 2022-09-02 03:26:39\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 03:26:39\n","loss: 0.7711, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:26:40\n","loss: 0.7984, acc: 0.6599\n","E2E-ABSA >>> 2022-09-02 03:26:40\n","loss: 0.7758, acc: 0.6846\n","E2E-ABSA >>> 2022-09-02 03:26:40\n","loss: 0.7873, acc: 0.6742\n","E2E-ABSA >>> 2022-09-02 03:26:40\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 03:26:41\n","loss: 0.8090, acc: 0.6500\n","E2E-ABSA >>> 2022-09-02 03:26:41\n","loss: 0.8008, acc: 0.6613\n","E2E-ABSA >>> 2022-09-02 03:26:41\n","loss: 0.7915, acc: 0.6672\n","E2E-ABSA >>> 2022-09-02 03:26:41\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 03:26:41\n","loss: 0.7775, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:26:42\n","loss: 0.7460, acc: 0.6788\n","E2E-ABSA >>> 2022-09-02 03:26:42\n","loss: 0.7561, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:26:42\n","loss: 0.7727, acc: 0.6706\n","E2E-ABSA >>> 2022-09-02 03:26:42\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 03:26:42\n","loss: 0.7852, acc: 0.6449\n","E2E-ABSA >>> 2022-09-02 03:26:43\n","loss: 0.7921, acc: 0.6550\n","E2E-ABSA >>> 2022-09-02 03:26:43\n","loss: 0.7720, acc: 0.6715\n","E2E-ABSA >>> 2022-09-02 03:26:43\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 03:26:43\n","loss: 0.8894, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 03:26:43\n","loss: 0.8015, acc: 0.6579\n","E2E-ABSA >>> 2022-09-02 03:26:44\n","loss: 0.7804, acc: 0.6682\n","E2E-ABSA >>> 2022-09-02 03:26:44\n","loss: 0.7663, acc: 0.6716\n","E2E-ABSA >>> 2022-09-02 03:26:44\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 03:26:44\n","loss: 0.7717, acc: 0.6615\n","E2E-ABSA >>> 2022-09-02 03:26:45\n","loss: 0.7676, acc: 0.6748\n","E2E-ABSA >>> 2022-09-02 03:26:45\n","loss: 0.7744, acc: 0.6629\n","E2E-ABSA >>> 2022-09-02 03:26:45\n",">>> val_acc: 0.6850, val_precision: 0.6850 val_recall: 0.6850, val_f1: 0.6850\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 03:26:45\n","loss: 0.7299, acc: 0.7000\n","E2E-ABSA >>> 2022-09-02 03:26:45\n","loss: 0.7528, acc: 0.6813\n","E2E-ABSA >>> 2022-09-02 03:26:46\n","loss: 0.7580, acc: 0.6723\n","E2E-ABSA >>> 2022-09-02 03:26:46\n","loss: 0.7589, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:26:46\n",">>> val_acc: 0.6850, val_precision: 0.6850 val_recall: 0.6850, val_f1: 0.6850\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 03:26:46\n","loss: 0.7282, acc: 0.7043\n","E2E-ABSA >>> 2022-09-02 03:26:46\n","loss: 0.7163, acc: 0.6987\n","E2E-ABSA >>> 2022-09-02 03:26:47\n","loss: 0.7360, acc: 0.6860\n","E2E-ABSA >>> 2022-09-02 03:26:47\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 03:26:47\n","loss: 0.7022, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:26:47\n","loss: 0.7325, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:26:47\n","loss: 0.7453, acc: 0.6780\n","E2E-ABSA >>> 2022-09-02 03:26:48\n","loss: 0.7496, acc: 0.6783\n","E2E-ABSA >>> 2022-09-02 03:26:48\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 03:26:48\n","loss: 0.7350, acc: 0.6741\n","E2E-ABSA >>> 2022-09-02 03:26:48\n","loss: 0.7310, acc: 0.6778\n","E2E-ABSA >>> 2022-09-02 03:26:49\n","loss: 0.7328, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 03:26:49\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 03:26:49\n","loss: 0.6937, acc: 0.6964\n","E2E-ABSA >>> 2022-09-02 03:26:49\n","loss: 0.7249, acc: 0.6918\n","E2E-ABSA >>> 2022-09-02 03:26:49\n","loss: 0.7338, acc: 0.6833\n","E2E-ABSA >>> 2022-09-02 03:26:50\n","loss: 0.7395, acc: 0.6779\n","E2E-ABSA >>> 2022-09-02 03:26:50\n",">>> val_acc: 0.6897, val_precision: 0.6897 val_recall: 0.6897, val_f1: 0.6897\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 03:26:50\n","loss: 0.7194, acc: 0.6896\n","E2E-ABSA >>> 2022-09-02 03:26:50\n","loss: 0.7426, acc: 0.6781\n","E2E-ABSA >>> 2022-09-02 03:26:50\n","loss: 0.7423, acc: 0.6785\n","E2E-ABSA >>> 2022-09-02 03:26:51\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 03:26:51\n","loss: 0.7297, acc: 0.6680\n","E2E-ABSA >>> 2022-09-02 03:26:51\n","loss: 0.7313, acc: 0.6753\n","E2E-ABSA >>> 2022-09-02 03:26:51\n","loss: 0.7396, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:26:52\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 03:26:52\n","loss: 0.9903, acc: 0.5000\n","E2E-ABSA >>> 2022-09-02 03:26:52\n","loss: 0.7354, acc: 0.6582\n","E2E-ABSA >>> 2022-09-02 03:26:52\n","loss: 0.7269, acc: 0.6784\n","E2E-ABSA >>> 2022-09-02 03:26:52\n","loss: 0.7352, acc: 0.6773\n","E2E-ABSA >>> 2022-09-02 03:26:53\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 03:26:53\n","loss: 0.7338, acc: 0.6701\n","E2E-ABSA >>> 2022-09-02 03:26:53\n","loss: 0.7172, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 03:26:53\n","loss: 0.7261, acc: 0.6859\n","E2E-ABSA >>> 2022-09-02 03:26:53\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 03:26:54\n","loss: 0.8079, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 03:26:54\n","loss: 0.7812, acc: 0.6489\n","E2E-ABSA >>> 2022-09-02 03:26:54\n","loss: 0.7446, acc: 0.6768\n","E2E-ABSA >>> 2022-09-02 03:26:54\n","loss: 0.7213, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:26:54\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 03:26:55\n","loss: 0.7321, acc: 0.6844\n","E2E-ABSA >>> 2022-09-02 03:26:55\n","loss: 0.7181, acc: 0.6800\n","E2E-ABSA >>> 2022-09-02 03:26:55\n","loss: 0.7047, acc: 0.6914\n","E2E-ABSA >>> 2022-09-02 03:26:55\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 03:26:55\n","loss: 0.7287, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:26:56\n","loss: 0.7388, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:26:56\n","loss: 0.7207, acc: 0.6761\n","E2E-ABSA >>> 2022-09-02 03:26:56\n","loss: 0.7214, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 03:26:56\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 03:26:57\n","loss: 0.7471, acc: 0.6648\n","E2E-ABSA >>> 2022-09-02 03:26:57\n","loss: 0.7192, acc: 0.6803\n","E2E-ABSA >>> 2022-09-02 03:26:57\n","loss: 0.7054, acc: 0.6883\n","E2E-ABSA >>> 2022-09-02 03:26:57\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 03:26:57\n","loss: 0.6282, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 03:26:58\n","loss: 0.7356, acc: 0.6628\n","E2E-ABSA >>> 2022-09-02 03:26:58\n","loss: 0.7090, acc: 0.6912\n","E2E-ABSA >>> 2022-09-02 03:26:58\n","loss: 0.7116, acc: 0.6862\n","E2E-ABSA >>> 2022-09-02 03:26:58\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 03:26:58\n","loss: 0.7456, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:26:59\n","loss: 0.7185, acc: 0.6806\n","E2E-ABSA >>> 2022-09-02 03:26:59\n","loss: 0.7124, acc: 0.6830\n","E2E-ABSA >>> 2022-09-02 03:26:59\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 03:26:59\n","loss: 0.6784, acc: 0.7000\n","E2E-ABSA >>> 2022-09-02 03:26:59\n","loss: 0.6874, acc: 0.7078\n","E2E-ABSA >>> 2022-09-02 03:27:00\n","loss: 0.6949, acc: 0.7045\n","E2E-ABSA >>> 2022-09-02 03:27:00\n","loss: 0.7012, acc: 0.6913\n","E2E-ABSA >>> 2022-09-02 03:27:00\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 03:27:00\n","loss: 0.7401, acc: 0.6731\n","E2E-ABSA >>> 2022-09-02 03:27:01\n","loss: 0.7267, acc: 0.6897\n","E2E-ABSA >>> 2022-09-02 03:27:01\n","loss: 0.7082, acc: 0.6977\n","E2E-ABSA >>> 2022-09-02 03:27:01\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 03:27:01\n","loss: 0.6962, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:27:01\n","loss: 0.7008, acc: 0.6935\n","E2E-ABSA >>> 2022-09-02 03:27:02\n","loss: 0.7021, acc: 0.6910\n","E2E-ABSA >>> 2022-09-02 03:27:02\n","loss: 0.6971, acc: 0.6918\n","E2E-ABSA >>> 2022-09-02 03:27:02\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 03:27:02\n","loss: 0.6914, acc: 0.6808\n","E2E-ABSA >>> 2022-09-02 03:27:02\n","loss: 0.7031, acc: 0.6832\n","E2E-ABSA >>> 2022-09-02 03:27:03\n","loss: 0.6840, acc: 0.6982\n","E2E-ABSA >>> 2022-09-02 03:27:03\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 03:27:03\n","loss: 0.6996, acc: 0.6830\n","E2E-ABSA >>> 2022-09-02 03:27:03\n","loss: 0.7139, acc: 0.6790\n","E2E-ABSA >>> 2022-09-02 03:27:04\n","loss: 0.7130, acc: 0.6850\n","E2E-ABSA >>> 2022-09-02 03:27:04\n","loss: 0.6898, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 03:27:04\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 03:27:04\n","loss: 0.6710, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:27:04\n","loss: 0.6929, acc: 0.6969\n","E2E-ABSA >>> 2022-09-02 03:27:05\n","loss: 0.6917, acc: 0.6965\n","E2E-ABSA >>> 2022-09-02 03:27:05\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 03:27:05\n","loss: 0.7309, acc: 0.6602\n","E2E-ABSA >>> 2022-09-02 03:27:05\n","loss: 0.6921, acc: 0.6970\n","E2E-ABSA >>> 2022-09-02 03:27:05\n","loss: 0.7088, acc: 0.6859\n","E2E-ABSA >>> 2022-09-02 03:27:06\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 03:27:06\n","loss: 0.7577, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:27:06\n","loss: 0.7009, acc: 0.6836\n","E2E-ABSA >>> 2022-09-02 03:27:06\n","loss: 0.6786, acc: 0.6956\n","E2E-ABSA >>> 2022-09-02 03:27:06\n","loss: 0.6748, acc: 0.7011\n","E2E-ABSA >>> 2022-09-02 03:27:07\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 03:27:07\n","loss: 0.6985, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:27:07\n","loss: 0.6912, acc: 0.6849\n","E2E-ABSA >>> 2022-09-02 03:27:07\n","loss: 0.6844, acc: 0.6923\n","E2E-ABSA >>> 2022-09-02 03:27:08\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 03:27:08\n","loss: 0.6324, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 03:27:08\n","loss: 0.7055, acc: 0.6746\n","E2E-ABSA >>> 2022-09-02 03:27:08\n","loss: 0.6848, acc: 0.6826\n","E2E-ABSA >>> 2022-09-02 03:27:08\n","loss: 0.6780, acc: 0.6902\n","E2E-ABSA >>> 2022-09-02 03:27:09\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 03:27:09\n","loss: 0.7018, acc: 0.6813\n","E2E-ABSA >>> 2022-09-02 03:27:09\n","loss: 0.6976, acc: 0.6887\n","E2E-ABSA >>> 2022-09-02 03:27:09\n","loss: 0.6816, acc: 0.7023\n","E2E-ABSA >>> 2022-09-02 03:27:10\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 03:27:10\n","loss: 0.6536, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:27:10\n","loss: 0.6580, acc: 0.7101\n","E2E-ABSA >>> 2022-09-02 03:27:10\n","loss: 0.6522, acc: 0.7159\n","E2E-ABSA >>> 2022-09-02 03:27:10\n","loss: 0.6668, acc: 0.7038\n","E2E-ABSA >>> 2022-09-02 03:27:10\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 03:27:11\n","loss: 0.6515, acc: 0.7301\n","E2E-ABSA >>> 2022-09-02 03:27:11\n","loss: 0.6282, acc: 0.7296\n","E2E-ABSA >>> 2022-09-02 03:27:11\n","loss: 0.6573, acc: 0.7073\n","E2E-ABSA >>> 2022-09-02 03:27:11\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 03:27:11\n","loss: 0.7007, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:27:12\n","loss: 0.6652, acc: 0.7105\n","E2E-ABSA >>> 2022-09-02 03:27:12\n","loss: 0.6565, acc: 0.7142\n","E2E-ABSA >>> 2022-09-02 03:27:12\n","loss: 0.6634, acc: 0.7079\n","E2E-ABSA >>> 2022-09-02 03:27:12\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 03:27:13\n","loss: 0.6385, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 03:27:13\n","loss: 0.6569, acc: 0.7141\n","E2E-ABSA >>> 2022-09-02 03:27:13\n","loss: 0.6732, acc: 0.6949\n","E2E-ABSA >>> 2022-09-02 03:27:13\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 03:27:13\n","loss: 0.6383, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 03:27:14\n","loss: 0.6703, acc: 0.7078\n","E2E-ABSA >>> 2022-09-02 03:27:14\n","loss: 0.6532, acc: 0.7116\n","E2E-ABSA >>> 2022-09-02 03:27:14\n","loss: 0.6512, acc: 0.7150\n","E2E-ABSA >>> 2022-09-02 03:27:14\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 03:27:14\n","loss: 0.6046, acc: 0.7356\n","E2E-ABSA >>> 2022-09-02 03:27:15\n","loss: 0.6473, acc: 0.7098\n","E2E-ABSA >>> 2022-09-02 03:27:15\n","loss: 0.6425, acc: 0.7093\n","E2E-ABSA >>> 2022-09-02 03:27:15\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 03:27:15\n","loss: 0.6093, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:27:15\n","loss: 0.6470, acc: 0.7068\n","E2E-ABSA >>> 2022-09-02 03:27:16\n","loss: 0.6420, acc: 0.7179\n","E2E-ABSA >>> 2022-09-02 03:27:16\n","loss: 0.6447, acc: 0.7200\n","E2E-ABSA >>> 2022-09-02 03:27:16\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 03:27:16\n","loss: 0.6463, acc: 0.7143\n","E2E-ABSA >>> 2022-09-02 03:27:17\n","loss: 0.6488, acc: 0.7177\n","E2E-ABSA >>> 2022-09-02 03:27:17\n","loss: 0.6502, acc: 0.7152\n","E2E-ABSA >>> 2022-09-02 03:27:17\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 03:27:17\n","loss: 0.5883, acc: 0.7679\n","E2E-ABSA >>> 2022-09-02 03:27:17\n","loss: 0.6237, acc: 0.7330\n","E2E-ABSA >>> 2022-09-02 03:27:18\n","loss: 0.6357, acc: 0.7264\n","E2E-ABSA >>> 2022-09-02 03:27:18\n","loss: 0.6363, acc: 0.7200\n","E2E-ABSA >>> 2022-09-02 03:27:18\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 03:27:18\n","loss: 0.6432, acc: 0.7250\n","E2E-ABSA >>> 2022-09-02 03:27:19\n","loss: 0.6320, acc: 0.7156\n","E2E-ABSA >>> 2022-09-02 03:27:19\n","loss: 0.6392, acc: 0.7139\n","E2E-ABSA >>> 2022-09-02 03:27:19\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.716\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 03:27:19\n","loss: 0.5663, acc: 0.7734\n","E2E-ABSA >>> 2022-09-02 03:27:19\n","loss: 0.6263, acc: 0.7269\n","E2E-ABSA >>> 2022-09-02 03:27:20\n","loss: 0.6302, acc: 0.7286\n","E2E-ABSA >>> 2022-09-02 03:27:20\n",">>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n",">> saved: state_dict/lstm_twitter_know_val_f1_0.7232\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 03:27:20\n","loss: 0.6864, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:27:20\n","loss: 0.6599, acc: 0.7148\n","E2E-ABSA >>> 2022-09-02 03:27:21\n","loss: 0.6350, acc: 0.7238\n","E2E-ABSA >>> 2022-09-02 03:27:21\n","loss: 0.6301, acc: 0.7269\n","E2E-ABSA >>> 2022-09-02 03:27:21\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 03:27:21\n","loss: 0.5904, acc: 0.7431\n","E2E-ABSA >>> 2022-09-02 03:27:21\n","loss: 0.6305, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:27:22\n","loss: 0.6198, acc: 0.7284\n","E2E-ABSA >>> 2022-09-02 03:27:22\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 03:27:22\n","loss: 0.6904, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:27:22\n","loss: 0.6352, acc: 0.7132\n","E2E-ABSA >>> 2022-09-02 03:27:22\n","loss: 0.6219, acc: 0.7178\n","E2E-ABSA >>> 2022-09-02 03:27:23\n","loss: 0.6296, acc: 0.7214\n","E2E-ABSA >>> 2022-09-02 03:27:23\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 03:27:23\n","loss: 0.6445, acc: 0.7250\n","E2E-ABSA >>> 2022-09-02 03:27:23\n","loss: 0.5899, acc: 0.7462\n","E2E-ABSA >>> 2022-09-02 03:27:24\n","loss: 0.6157, acc: 0.7281\n","E2E-ABSA >>> 2022-09-02 03:27:24\n",">>> val_acc: 0.7208, val_precision: 0.7208 val_recall: 0.7208, val_f1: 0.7208\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 03:27:24\n","loss: 0.6711, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:27:24\n","loss: 0.6109, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:27:24\n","loss: 0.6247, acc: 0.7263\n","E2E-ABSA >>> 2022-09-02 03:27:25\n","loss: 0.6241, acc: 0.7233\n","E2E-ABSA >>> 2022-09-02 03:27:25\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 03:27:25\n","loss: 0.6322, acc: 0.7358\n","E2E-ABSA >>> 2022-09-02 03:27:25\n","loss: 0.6164, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:27:25\n","loss: 0.6254, acc: 0.7233\n","E2E-ABSA >>> 2022-09-02 03:27:26\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 03:27:26\n","loss: 0.6184, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 03:27:26\n","loss: 0.6025, acc: 0.7303\n","E2E-ABSA >>> 2022-09-02 03:27:26\n","loss: 0.5989, acc: 0.7279\n","E2E-ABSA >>> 2022-09-02 03:27:27\n","loss: 0.6146, acc: 0.7302\n","E2E-ABSA >>> 2022-09-02 03:27:27\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 03:27:27\n","loss: 0.6218, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 03:27:27\n","loss: 0.6241, acc: 0.7280\n","E2E-ABSA >>> 2022-09-02 03:27:27\n","loss: 0.6169, acc: 0.7336\n","E2E-ABSA >>> 2022-09-02 03:27:28\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 03:27:28\n","loss: 0.5534, acc: 0.7312\n","E2E-ABSA >>> 2022-09-02 03:27:28\n","loss: 0.6269, acc: 0.7141\n","E2E-ABSA >>> 2022-09-02 03:27:28\n","loss: 0.6166, acc: 0.7250\n","E2E-ABSA >>> 2022-09-02 03:27:28\n","loss: 0.6123, acc: 0.7300\n","E2E-ABSA >>> 2022-09-02 03:27:29\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 03:27:29\n","loss: 0.5522, acc: 0.7452\n","E2E-ABSA >>> 2022-09-02 03:27:29\n","loss: 0.5797, acc: 0.7366\n","E2E-ABSA >>> 2022-09-02 03:27:29\n","loss: 0.5914, acc: 0.7406\n","E2E-ABSA >>> 2022-09-02 03:27:30\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 03:27:30\n","loss: 0.6182, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 03:27:30\n","loss: 0.6212, acc: 0.7307\n","E2E-ABSA >>> 2022-09-02 03:27:30\n","loss: 0.6225, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 03:27:30\n","loss: 0.6078, acc: 0.7377\n","E2E-ABSA >>> 2022-09-02 03:27:30\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 03:27:31\n","loss: 0.5678, acc: 0.7455\n","E2E-ABSA >>> 2022-09-02 03:27:31\n","loss: 0.6001, acc: 0.7414\n","E2E-ABSA >>> 2022-09-02 03:27:31\n","loss: 0.6016, acc: 0.7365\n","E2E-ABSA >>> 2022-09-02 03:27:31\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 03:27:32\n","loss: 0.6512, acc: 0.7143\n","E2E-ABSA >>> 2022-09-02 03:27:32\n","loss: 0.5974, acc: 0.7443\n","E2E-ABSA >>> 2022-09-02 03:27:32\n","loss: 0.6087, acc: 0.7348\n","E2E-ABSA >>> 2022-09-02 03:27:32\n","loss: 0.6061, acc: 0.7392\n","E2E-ABSA >>> 2022-09-02 03:27:32\n",">>> val_acc: 0.7208, val_precision: 0.7208 val_recall: 0.7208, val_f1: 0.7208\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 03:27:33\n","loss: 0.6140, acc: 0.7229\n","E2E-ABSA >>> 2022-09-02 03:27:33\n","loss: 0.6090, acc: 0.7281\n","E2E-ABSA >>> 2022-09-02 03:27:33\n","loss: 0.6097, acc: 0.7382\n","E2E-ABSA >>> 2022-09-02 03:27:33\n",">>> val_acc: 0.6850, val_precision: 0.6850 val_recall: 0.6850, val_f1: 0.6850\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 03:27:33\n","loss: 0.5505, acc: 0.7539\n","E2E-ABSA >>> 2022-09-02 03:27:34\n","loss: 0.5920, acc: 0.7378\n","E2E-ABSA >>> 2022-09-02 03:27:34\n","loss: 0.6137, acc: 0.7229\n","E2E-ABSA >>> 2022-09-02 03:27:34\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 03:27:34\n","loss: 0.5811, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 03:27:34\n","loss: 0.6320, acc: 0.7383\n","E2E-ABSA >>> 2022-09-02 03:27:35\n","loss: 0.6120, acc: 0.7399\n","E2E-ABSA >>> 2022-09-02 03:27:35\n","loss: 0.5971, acc: 0.7466\n","E2E-ABSA >>> 2022-09-02 03:27:35\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 03:27:35\n","loss: 0.5709, acc: 0.7986\n","E2E-ABSA >>> 2022-09-02 03:27:36\n","loss: 0.5637, acc: 0.7721\n","E2E-ABSA >>> 2022-09-02 03:27:36\n","loss: 0.5805, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:27:36\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 03:27:36\n","loss: 0.5821, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:27:36\n","loss: 0.5675, acc: 0.7665\n","E2E-ABSA >>> 2022-09-02 03:27:37\n","loss: 0.5938, acc: 0.7451\n","E2E-ABSA >>> 2022-09-02 03:27:37\n","loss: 0.6026, acc: 0.7400\n","E2E-ABSA >>> 2022-09-02 03:27:37\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 03:27:37\n","loss: 0.5923, acc: 0.7406\n","E2E-ABSA >>> 2022-09-02 03:27:37\n","loss: 0.5667, acc: 0.7612\n","E2E-ABSA >>> 2022-09-02 03:27:38\n","loss: 0.5946, acc: 0.7375\n","E2E-ABSA >>> 2022-09-02 03:27:38\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 03:27:38\n","loss: 0.6912, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 03:27:38\n","loss: 0.6049, acc: 0.7431\n","E2E-ABSA >>> 2022-09-02 03:27:39\n","loss: 0.5917, acc: 0.7424\n","E2E-ABSA >>> 2022-09-02 03:27:39\n","loss: 0.6036, acc: 0.7298\n","E2E-ABSA >>> 2022-09-02 03:27:39\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 03:27:39\n","loss: 0.6166, acc: 0.7386\n","E2E-ABSA >>> 2022-09-02 03:27:39\n","loss: 0.6109, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:27:40\n","loss: 0.6057, acc: 0.7332\n","E2E-ABSA >>> 2022-09-02 03:27:40\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","E2E-ABSA >>> 2022-09-02 03:27:40\n","loss: 0.5924, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:27:40\n","loss: 0.5721, acc: 0.7549\n","E2E-ABSA >>> 2022-09-02 03:27:40\n","loss: 0.5860, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:27:41\n","loss: 0.5933, acc: 0.7443\n","E2E-ABSA >>> 2022-09-02 03:27:41\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","E2E-ABSA >>> 2022-09-02 03:27:41\n","loss: 0.5540, acc: 0.7630\n","E2E-ABSA >>> 2022-09-02 03:27:41\n","loss: 0.5825, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:27:41\n","loss: 0.5984, acc: 0.7411\n","E2E-ABSA >>> 2022-09-02 03:27:42\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","E2E-ABSA >>> 2022-09-02 03:27:42\n","loss: 0.6253, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 03:27:42\n","loss: 0.5770, acc: 0.7703\n","E2E-ABSA >>> 2022-09-02 03:27:42\n","loss: 0.5983, acc: 0.7455\n","E2E-ABSA >>> 2022-09-02 03:27:43\n","loss: 0.6021, acc: 0.7431\n","E2E-ABSA >>> 2022-09-02 03:27:43\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","E2E-ABSA >>> 2022-09-02 03:27:43\n","loss: 0.5937, acc: 0.7524\n","E2E-ABSA >>> 2022-09-02 03:27:43\n","loss: 0.6146, acc: 0.7366\n","E2E-ABSA >>> 2022-09-02 03:27:43\n","loss: 0.5932, acc: 0.7471\n","E2E-ABSA >>> 2022-09-02 03:27:44\n",">>> val_acc: 0.6826, val_precision: 0.6826 val_recall: 0.6826, val_f1: 0.6826\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","E2E-ABSA >>> 2022-09-02 03:27:44\n","loss: 0.6282, acc: 0.7448\n","E2E-ABSA >>> 2022-09-02 03:27:44\n","loss: 0.6126, acc: 0.7262\n","E2E-ABSA >>> 2022-09-02 03:27:44\n","loss: 0.5960, acc: 0.7457\n","E2E-ABSA >>> 2022-09-02 03:27:44\n","loss: 0.5947, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 03:27:45\n",">>> val_acc: 0.6897, val_precision: 0.6897 val_recall: 0.6897, val_f1: 0.6897\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","E2E-ABSA >>> 2022-09-02 03:27:45\n","loss: 0.5839, acc: 0.7545\n","E2E-ABSA >>> 2022-09-02 03:27:45\n","loss: 0.5670, acc: 0.7532\n","E2E-ABSA >>> 2022-09-02 03:27:45\n","loss: 0.5840, acc: 0.7429\n","E2E-ABSA >>> 2022-09-02 03:27:46\n",">>> val_acc: 0.6730, val_precision: 0.6730 val_recall: 0.6730, val_f1: 0.6730\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","E2E-ABSA >>> 2022-09-02 03:27:46\n","loss: 0.5716, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:27:46\n","loss: 0.6176, acc: 0.7372\n","E2E-ABSA >>> 2022-09-02 03:27:46\n","loss: 0.5929, acc: 0.7432\n","E2E-ABSA >>> 2022-09-02 03:27:46\n","loss: 0.5913, acc: 0.7482\n","E2E-ABSA >>> 2022-09-02 03:27:47\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","E2E-ABSA >>> 2022-09-02 03:27:47\n","loss: 0.5757, acc: 0.7479\n","E2E-ABSA >>> 2022-09-02 03:27:47\n","loss: 0.5705, acc: 0.7542\n","E2E-ABSA >>> 2022-09-02 03:27:47\n","loss: 0.5904, acc: 0.7472\n","E2E-ABSA >>> 2022-09-02 03:27:47\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","E2E-ABSA >>> 2022-09-02 03:27:48\n","loss: 0.5517, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:27:48\n","loss: 0.5696, acc: 0.7717\n","E2E-ABSA >>> 2022-09-02 03:27:48\n","loss: 0.5768, acc: 0.7640\n","E2E-ABSA >>> 2022-09-02 03:27:48\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","E2E-ABSA >>> 2022-09-02 03:27:48\n","loss: 0.6081, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:27:49\n","loss: 0.5543, acc: 0.7578\n","E2E-ABSA >>> 2022-09-02 03:27:49\n","loss: 0.5897, acc: 0.7339\n","E2E-ABSA >>> 2022-09-02 03:27:49\n","loss: 0.6008, acc: 0.7330\n","E2E-ABSA >>> 2022-09-02 03:27:49\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","E2E-ABSA >>> 2022-09-02 03:27:49\n","loss: 0.5869, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:27:50\n","loss: 0.5955, acc: 0.7448\n","E2E-ABSA >>> 2022-09-02 03:27:50\n","loss: 0.5937, acc: 0.7468\n","E2E-ABSA >>> 2022-09-02 03:27:50\n",">>> val_acc: 0.7208, val_precision: 0.7208 val_recall: 0.7208, val_f1: 0.7208\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","E2E-ABSA >>> 2022-09-02 03:27:50\n","loss: 0.4455, acc: 0.8281\n","E2E-ABSA >>> 2022-09-02 03:27:51\n","loss: 0.5643, acc: 0.7445\n","E2E-ABSA >>> 2022-09-02 03:27:51\n","loss: 0.5680, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:27:51\n","loss: 0.5858, acc: 0.7460\n","E2E-ABSA >>> 2022-09-02 03:27:51\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","E2E-ABSA >>> 2022-09-02 03:27:51\n","loss: 0.5798, acc: 0.7312\n","E2E-ABSA >>> 2022-09-02 03:27:52\n","loss: 0.5826, acc: 0.7312\n","E2E-ABSA >>> 2022-09-02 03:27:52\n","loss: 0.5710, acc: 0.7469\n","E2E-ABSA >>> 2022-09-02 03:27:52\n",">>> val_acc: 0.6802, val_precision: 0.6802 val_recall: 0.6802, val_f1: 0.6802\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","E2E-ABSA >>> 2022-09-02 03:27:52\n","loss: 0.5675, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 03:27:52\n","loss: 0.5907, acc: 0.7274\n","E2E-ABSA >>> 2022-09-02 03:27:53\n","loss: 0.5767, acc: 0.7434\n","E2E-ABSA >>> 2022-09-02 03:27:53\n","loss: 0.5830, acc: 0.7428\n","E2E-ABSA >>> 2022-09-02 03:27:53\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","E2E-ABSA >>> 2022-09-02 03:27:53\n","loss: 0.5371, acc: 0.7699\n","E2E-ABSA >>> 2022-09-02 03:27:54\n","loss: 0.5617, acc: 0.7620\n","E2E-ABSA >>> 2022-09-02 03:27:54\n","loss: 0.5807, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:27:54\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","E2E-ABSA >>> 2022-09-02 03:27:54\n","loss: 0.5924, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 03:27:54\n","loss: 0.6010, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:27:55\n","loss: 0.5987, acc: 0.7463\n","E2E-ABSA >>> 2022-09-02 03:27:55\n","loss: 0.5815, acc: 0.7551\n","E2E-ABSA >>> 2022-09-02 03:27:55\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","E2E-ABSA >>> 2022-09-02 03:27:55\n","loss: 0.5884, acc: 0.7422\n","E2E-ABSA >>> 2022-09-02 03:27:55\n","loss: 0.5762, acc: 0.7488\n","E2E-ABSA >>> 2022-09-02 03:27:56\n","loss: 0.5774, acc: 0.7478\n","E2E-ABSA >>> 2022-09-02 03:27:56\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","E2E-ABSA >>> 2022-09-02 03:27:56\n","loss: 0.5681, acc: 0.7750\n","E2E-ABSA >>> 2022-09-02 03:27:56\n","loss: 0.5902, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 03:27:56\n","loss: 0.5839, acc: 0.7429\n","E2E-ABSA >>> 2022-09-02 03:27:57\n","loss: 0.5777, acc: 0.7531\n","E2E-ABSA >>> 2022-09-02 03:27:57\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","E2E-ABSA >>> 2022-09-02 03:27:57\n","loss: 0.5636, acc: 0.7428\n","E2E-ABSA >>> 2022-09-02 03:27:57\n","loss: 0.5797, acc: 0.7478\n","E2E-ABSA >>> 2022-09-02 03:27:58\n","loss: 0.5699, acc: 0.7551\n","E2E-ABSA >>> 2022-09-02 03:27:58\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","E2E-ABSA >>> 2022-09-02 03:27:58\n","loss: 0.5462, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 03:27:58\n","loss: 0.5642, acc: 0.7589\n","E2E-ABSA >>> 2022-09-02 03:27:58\n","loss: 0.5789, acc: 0.7465\n","E2E-ABSA >>> 2022-09-02 03:27:59\n","loss: 0.5842, acc: 0.7463\n","E2E-ABSA >>> 2022-09-02 03:27:59\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","E2E-ABSA >>> 2022-09-02 03:27:59\n","loss: 0.5665, acc: 0.7545\n","E2E-ABSA >>> 2022-09-02 03:27:59\n","loss: 0.5801, acc: 0.7446\n","E2E-ABSA >>> 2022-09-02 03:27:59\n","loss: 0.5831, acc: 0.7479\n","E2E-ABSA >>> 2022-09-02 03:28:00\n",">>> val_acc: 0.6850, val_precision: 0.6850 val_recall: 0.6850, val_f1: 0.6850\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","E2E-ABSA >>> 2022-09-02 03:28:00\n","loss: 0.5710, acc: 0.7411\n","E2E-ABSA >>> 2022-09-02 03:28:00\n","loss: 0.5594, acc: 0.7599\n","E2E-ABSA >>> 2022-09-02 03:28:00\n","loss: 0.5637, acc: 0.7551\n","E2E-ABSA >>> 2022-09-02 03:28:01\n","loss: 0.5824, acc: 0.7440\n","E2E-ABSA >>> 2022-09-02 03:28:01\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 90.\n","E2E-ABSA >>> 2022-09-02 03:28:01\n","loss: 0.5581, acc: 0.7646\n","E2E-ABSA >>> 2022-09-02 03:28:01\n","loss: 0.5721, acc: 0.7625\n","E2E-ABSA >>> 2022-09-02 03:28:01\n","loss: 0.5691, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:28:02\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 91.\n","E2E-ABSA >>> 2022-09-02 03:28:02\n","loss: 0.5337, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:28:02\n","loss: 0.5703, acc: 0.7514\n","E2E-ABSA >>> 2022-09-02 03:28:02\n","loss: 0.5759, acc: 0.7459\n","E2E-ABSA >>> 2022-09-02 03:28:03\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 92.\n","E2E-ABSA >>> 2022-09-02 03:28:03\n","loss: 0.6741, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:28:03\n","loss: 0.5839, acc: 0.7578\n","E2E-ABSA >>> 2022-09-02 03:28:03\n","loss: 0.5758, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:28:04\n","loss: 0.5736, acc: 0.7507\n","E2E-ABSA >>> 2022-09-02 03:28:04\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 93.\n","E2E-ABSA >>> 2022-09-02 03:28:04\n","loss: 0.5335, acc: 0.7847\n","E2E-ABSA >>> 2022-09-02 03:28:04\n","loss: 0.5719, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:28:05\n","loss: 0.5748, acc: 0.7548\n","E2E-ABSA >>> 2022-09-02 03:28:05\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 94.\n","E2E-ABSA >>> 2022-09-02 03:28:05\n","loss: 0.6196, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 03:28:05\n","loss: 0.6098, acc: 0.7206\n","E2E-ABSA >>> 2022-09-02 03:28:06\n","loss: 0.5746, acc: 0.7451\n","E2E-ABSA >>> 2022-09-02 03:28:06\n","loss: 0.5750, acc: 0.7493\n","E2E-ABSA >>> 2022-09-02 03:28:06\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 95.\n","E2E-ABSA >>> 2022-09-02 03:28:06\n","loss: 0.5476, acc: 0.7594\n","E2E-ABSA >>> 2022-09-02 03:28:06\n","loss: 0.5753, acc: 0.7538\n","E2E-ABSA >>> 2022-09-02 03:28:07\n","loss: 0.5721, acc: 0.7523\n","E2E-ABSA >>> 2022-09-02 03:28:07\n",">>> val_acc: 0.6754, val_precision: 0.6754 val_recall: 0.6754, val_f1: 0.6754\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 96.\n","E2E-ABSA >>> 2022-09-02 03:28:07\n","loss: 0.5189, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 03:28:07\n","loss: 0.5635, acc: 0.7587\n","E2E-ABSA >>> 2022-09-02 03:28:08\n","loss: 0.5747, acc: 0.7566\n","E2E-ABSA >>> 2022-09-02 03:28:08\n","loss: 0.5806, acc: 0.7513\n","E2E-ABSA >>> 2022-09-02 03:28:08\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n","E2E-ABSA >>> 2022-09-02 03:28:08\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n","you can download the best model from state_dict/lstm_twitter_know_val_f1_0.7232\n",">>> test_acc: 0.7232, test_precision: 0.7232, test_recall: 0.7232, test_f1: 0.7232\n"]}]},{"cell_type":"markdown","source":["增加字典知识后：Training **twitter** dataset on model**(tc_LSTM)**"],"metadata":{"id":"oYlSWV6QHI5N"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name tc_lstm --dataset twitter_know --embed_dim 200 --patience 50 --log_step 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uxCExZUeHK7b","outputId":"a3770bd0-e06f-437a-ce6d-4894c1517f92","executionInfo":{"status":"ok","timestamp":1662089393748,"user_tz":-480,"elapsed":106567,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.twitter.27B.200d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1245.\n","> testing dataset count: 332.\n","cuda memory allocated: 22284288\n","> n_trainable_params: 1686603, n_nontrainable_params: 3884000\n","> training arguments:\n",">>> model_name: tc_lstm\n",">>> dataset: twitter_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f452e2eac20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 30\n",">>> embed_dim: 200\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 50\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.tc_lstm.TC_LSTM'>\n",">>> dataset_file: {'train': './datasets/twitter/output_know_insert/train.tsv', 'test': './datasets/twitter/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['left_with_aspect_indices', 'right_with_aspect_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 03:28:35\n","loss: 0.9878, acc: 0.6521\n","E2E-ABSA >>> 2022-09-02 03:28:35\n","loss: 0.9482, acc: 0.6625\n","E2E-ABSA >>> 2022-09-02 03:28:36\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">> saved: state_dict/tc_lstm_twitter_know_val_f1_0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 03:28:36\n","loss: 0.8586, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:28:36\n","loss: 0.8559, acc: 0.6443\n","E2E-ABSA >>> 2022-09-02 03:28:37\n","loss: 0.8494, acc: 0.6493\n","E2E-ABSA >>> 2022-09-02 03:28:37\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 03:28:37\n","loss: 0.8114, acc: 0.6510\n","E2E-ABSA >>> 2022-09-02 03:28:38\n","loss: 0.8291, acc: 0.6458\n","E2E-ABSA >>> 2022-09-02 03:28:38\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 03:28:38\n","loss: 0.7536, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 03:28:38\n","loss: 0.7975, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:28:39\n","loss: 0.7999, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:28:39\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 03:28:39\n","loss: 0.7688, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:28:40\n","loss: 0.7686, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:28:40\n","loss: 0.7859, acc: 0.6570\n","E2E-ABSA >>> 2022-09-02 03:28:40\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 03:28:40\n","loss: 0.7660, acc: 0.6625\n","E2E-ABSA >>> 2022-09-02 03:28:41\n","loss: 0.7829, acc: 0.6542\n","E2E-ABSA >>> 2022-09-02 03:28:41\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">> saved: state_dict/tc_lstm_twitter_know_val_f1_0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 03:28:41\n","loss: 0.8109, acc: 0.6354\n","E2E-ABSA >>> 2022-09-02 03:28:42\n","loss: 0.7800, acc: 0.6473\n","E2E-ABSA >>> 2022-09-02 03:28:42\n","loss: 0.7684, acc: 0.6649\n","E2E-ABSA >>> 2022-09-02 03:28:42\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 03:28:42\n","loss: 0.7521, acc: 0.6745\n","E2E-ABSA >>> 2022-09-02 03:28:43\n","loss: 0.7638, acc: 0.6678\n","E2E-ABSA >>> 2022-09-02 03:28:43\n",">>> val_acc: 0.6717, val_precision: 0.6717 val_recall: 0.6717, val_f1: 0.6717\n",">> saved: state_dict/tc_lstm_twitter_know_val_f1_0.6717\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 03:28:43\n","loss: 0.7503, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:28:44\n","loss: 0.7444, acc: 0.6788\n","E2E-ABSA >>> 2022-09-02 03:28:44\n","loss: 0.7600, acc: 0.6629\n","E2E-ABSA >>> 2022-09-02 03:28:44\n",">>> val_acc: 0.6837, val_precision: 0.6837 val_recall: 0.6837, val_f1: 0.6837\n",">> saved: state_dict/tc_lstm_twitter_know_val_f1_0.6837\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 03:28:45\n","loss: 0.7417, acc: 0.6701\n","E2E-ABSA >>> 2022-09-02 03:28:45\n","loss: 0.7337, acc: 0.6849\n","E2E-ABSA >>> 2022-09-02 03:28:45\n","loss: 0.7482, acc: 0.6707\n","E2E-ABSA >>> 2022-09-02 03:28:45\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 03:28:46\n","loss: 0.7526, acc: 0.6542\n","E2E-ABSA >>> 2022-09-02 03:28:46\n","loss: 0.7567, acc: 0.6625\n","E2E-ABSA >>> 2022-09-02 03:28:46\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 03:28:47\n","loss: 0.7894, acc: 0.6146\n","E2E-ABSA >>> 2022-09-02 03:28:47\n","loss: 0.7381, acc: 0.6756\n","E2E-ABSA >>> 2022-09-02 03:28:47\n","loss: 0.7328, acc: 0.6753\n","E2E-ABSA >>> 2022-09-02 03:28:47\n",">>> val_acc: 0.6777, val_precision: 0.6777 val_recall: 0.6777, val_f1: 0.6777\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 03:28:48\n","loss: 0.7239, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:28:48\n","loss: 0.7122, acc: 0.6852\n","E2E-ABSA >>> 2022-09-02 03:28:49\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 03:28:49\n","loss: 0.8159, acc: 0.6354\n","E2E-ABSA >>> 2022-09-02 03:28:49\n","loss: 0.7374, acc: 0.6632\n","E2E-ABSA >>> 2022-09-02 03:28:49\n","loss: 0.7161, acc: 0.6818\n","E2E-ABSA >>> 2022-09-02 03:28:50\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 03:28:50\n","loss: 0.7231, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:28:50\n","loss: 0.7387, acc: 0.6641\n","E2E-ABSA >>> 2022-09-02 03:28:50\n","loss: 0.7213, acc: 0.6803\n","E2E-ABSA >>> 2022-09-02 03:28:51\n",">>> val_acc: 0.6898, val_precision: 0.6898 val_recall: 0.6898, val_f1: 0.6898\n",">> saved: state_dict/tc_lstm_twitter_know_val_f1_0.6898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 03:28:51\n","loss: 0.7307, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:28:51\n","loss: 0.7227, acc: 0.6760\n","E2E-ABSA >>> 2022-09-02 03:28:52\n",">>> val_acc: 0.6898, val_precision: 0.6898 val_recall: 0.6898, val_f1: 0.6898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 03:28:52\n","loss: 0.6832, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:28:52\n","loss: 0.7220, acc: 0.6682\n","E2E-ABSA >>> 2022-09-02 03:28:53\n","loss: 0.7091, acc: 0.6840\n","E2E-ABSA >>> 2022-09-02 03:28:53\n",">>> val_acc: 0.6898, val_precision: 0.6898 val_recall: 0.6898, val_f1: 0.6898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 03:28:53\n","loss: 0.7375, acc: 0.6536\n","E2E-ABSA >>> 2022-09-02 03:28:53\n","loss: 0.6966, acc: 0.6817\n","E2E-ABSA >>> 2022-09-02 03:28:54\n",">>> val_acc: 0.6867, val_precision: 0.6867 val_recall: 0.6867, val_f1: 0.6867\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 03:28:54\n","loss: 0.7110, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:28:54\n","loss: 0.7030, acc: 0.6858\n","E2E-ABSA >>> 2022-09-02 03:28:55\n","loss: 0.7070, acc: 0.6799\n","E2E-ABSA >>> 2022-09-02 03:28:55\n",">>> val_acc: 0.6867, val_precision: 0.6867 val_recall: 0.6867, val_f1: 0.6867\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 03:28:55\n","loss: 0.6925, acc: 0.6840\n","E2E-ABSA >>> 2022-09-02 03:28:55\n","loss: 0.6928, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:28:56\n","loss: 0.6979, acc: 0.6859\n","E2E-ABSA >>> 2022-09-02 03:28:56\n",">>> val_acc: 0.6867, val_precision: 0.6867 val_recall: 0.6867, val_f1: 0.6867\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 03:28:56\n","loss: 0.7089, acc: 0.6813\n","E2E-ABSA >>> 2022-09-02 03:28:57\n","loss: 0.6942, acc: 0.6854\n","E2E-ABSA >>> 2022-09-02 03:28:57\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">> saved: state_dict/tc_lstm_twitter_know_val_f1_0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 03:28:57\n","loss: 0.7248, acc: 0.6615\n","E2E-ABSA >>> 2022-09-02 03:28:57\n","loss: 0.7053, acc: 0.6786\n","E2E-ABSA >>> 2022-09-02 03:28:58\n","loss: 0.6847, acc: 0.6910\n","E2E-ABSA >>> 2022-09-02 03:28:58\n",">>> val_acc: 0.6988, val_precision: 0.6988 val_recall: 0.6988, val_f1: 0.6988\n",">> saved: state_dict/tc_lstm_twitter_know_val_f1_0.6988\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 03:28:58\n","loss: 0.6794, acc: 0.6823\n","E2E-ABSA >>> 2022-09-02 03:28:59\n","loss: 0.6914, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:28:59\n",">>> val_acc: 0.6988, val_precision: 0.6988 val_recall: 0.6988, val_f1: 0.6988\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 03:28:59\n","loss: 0.5965, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 03:28:59\n","loss: 0.6658, acc: 0.7049\n","E2E-ABSA >>> 2022-09-02 03:29:00\n","loss: 0.6870, acc: 0.6922\n","E2E-ABSA >>> 2022-09-02 03:29:00\n",">>> val_acc: 0.7018, val_precision: 0.7018 val_recall: 0.7018, val_f1: 0.7018\n",">> saved: state_dict/tc_lstm_twitter_know_val_f1_0.7018\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 03:29:00\n","loss: 0.6927, acc: 0.6701\n","E2E-ABSA >>> 2022-09-02 03:29:01\n","loss: 0.6956, acc: 0.6836\n","E2E-ABSA >>> 2022-09-02 03:29:01\n","loss: 0.6763, acc: 0.6980\n","E2E-ABSA >>> 2022-09-02 03:29:01\n",">>> val_acc: 0.7018, val_precision: 0.7018 val_recall: 0.7018, val_f1: 0.7018\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 03:29:02\n","loss: 0.6637, acc: 0.6854\n","E2E-ABSA >>> 2022-09-02 03:29:02\n","loss: 0.6711, acc: 0.6906\n","E2E-ABSA >>> 2022-09-02 03:29:02\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">> saved: state_dict/tc_lstm_twitter_know_val_f1_0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 03:29:02\n","loss: 0.7031, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:29:03\n","loss: 0.6506, acc: 0.7158\n","E2E-ABSA >>> 2022-09-02 03:29:03\n","loss: 0.6740, acc: 0.6988\n","E2E-ABSA >>> 2022-09-02 03:29:03\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 03:29:04\n","loss: 0.6730, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 03:29:04\n","loss: 0.6532, acc: 0.7095\n","E2E-ABSA >>> 2022-09-02 03:29:04\n",">>> val_acc: 0.6988, val_precision: 0.6988 val_recall: 0.6988, val_f1: 0.6988\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 03:29:04\n","loss: 0.7335, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 03:29:05\n","loss: 0.6706, acc: 0.6997\n","E2E-ABSA >>> 2022-09-02 03:29:05\n","loss: 0.6597, acc: 0.7102\n","E2E-ABSA >>> 2022-09-02 03:29:05\n",">>> val_acc: 0.7018, val_precision: 0.7018 val_recall: 0.7018, val_f1: 0.7018\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 03:29:06\n","loss: 0.6465, acc: 0.7326\n","E2E-ABSA >>> 2022-09-02 03:29:06\n","loss: 0.6535, acc: 0.7174\n","E2E-ABSA >>> 2022-09-02 03:29:06\n","loss: 0.6550, acc: 0.7044\n","E2E-ABSA >>> 2022-09-02 03:29:06\n",">>> val_acc: 0.6867, val_precision: 0.6867 val_recall: 0.6867, val_f1: 0.6867\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 03:29:07\n","loss: 0.6389, acc: 0.7208\n","E2E-ABSA >>> 2022-09-02 03:29:07\n","loss: 0.6467, acc: 0.7177\n","E2E-ABSA >>> 2022-09-02 03:29:08\n",">>> val_acc: 0.6988, val_precision: 0.6988 val_recall: 0.6988, val_f1: 0.6988\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 03:29:08\n","loss: 0.6639, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:29:08\n","loss: 0.6218, acc: 0.7217\n","E2E-ABSA >>> 2022-09-02 03:29:08\n","loss: 0.6374, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 03:29:09\n",">>> val_acc: 0.6867, val_precision: 0.6867 val_recall: 0.6867, val_f1: 0.6867\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 03:29:09\n","loss: 0.6087, acc: 0.7161\n","E2E-ABSA >>> 2022-09-02 03:29:09\n","loss: 0.6423, acc: 0.7153\n","E2E-ABSA >>> 2022-09-02 03:29:10\n",">>> val_acc: 0.6867, val_precision: 0.6867 val_recall: 0.6867, val_f1: 0.6867\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 03:29:10\n","loss: 0.6172, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:29:10\n","loss: 0.6513, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 03:29:10\n","loss: 0.6356, acc: 0.7216\n","E2E-ABSA >>> 2022-09-02 03:29:11\n",">>> val_acc: 0.6898, val_precision: 0.6898 val_recall: 0.6898, val_f1: 0.6898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 03:29:11\n","loss: 0.5998, acc: 0.7465\n","E2E-ABSA >>> 2022-09-02 03:29:11\n","loss: 0.6259, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 03:29:12\n","loss: 0.6327, acc: 0.7261\n","E2E-ABSA >>> 2022-09-02 03:29:12\n",">>> val_acc: 0.6837, val_precision: 0.6837 val_recall: 0.6837, val_f1: 0.6837\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 03:29:12\n","loss: 0.6582, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 03:29:13\n","loss: 0.6265, acc: 0.7271\n","E2E-ABSA >>> 2022-09-02 03:29:13\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 03:29:13\n","loss: 0.6009, acc: 0.7552\n","E2E-ABSA >>> 2022-09-02 03:29:13\n","loss: 0.6529, acc: 0.7217\n","E2E-ABSA >>> 2022-09-02 03:29:14\n","loss: 0.6287, acc: 0.7309\n","E2E-ABSA >>> 2022-09-02 03:29:14\n",">>> val_acc: 0.6867, val_precision: 0.6867 val_recall: 0.6867, val_f1: 0.6867\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 03:29:14\n","loss: 0.6171, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:29:15\n","loss: 0.6260, acc: 0.7338\n","E2E-ABSA >>> 2022-09-02 03:29:15\n",">>> val_acc: 0.6777, val_precision: 0.6777 val_recall: 0.6777, val_f1: 0.6777\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 03:29:15\n","loss: 0.5808, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:29:15\n","loss: 0.6022, acc: 0.7517\n","E2E-ABSA >>> 2022-09-02 03:29:16\n","loss: 0.6073, acc: 0.7462\n","E2E-ABSA >>> 2022-09-02 03:29:16\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 03:29:16\n","loss: 0.5457, acc: 0.7847\n","E2E-ABSA >>> 2022-09-02 03:29:17\n","loss: 0.5971, acc: 0.7448\n","E2E-ABSA >>> 2022-09-02 03:29:17\n","loss: 0.6086, acc: 0.7462\n","E2E-ABSA >>> 2022-09-02 03:29:17\n",">>> val_acc: 0.6717, val_precision: 0.6717 val_recall: 0.6717, val_f1: 0.6717\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 03:29:17\n","loss: 0.6275, acc: 0.7479\n","E2E-ABSA >>> 2022-09-02 03:29:18\n","loss: 0.5989, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:29:18\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 03:29:18\n","loss: 0.5417, acc: 0.8021\n","E2E-ABSA >>> 2022-09-02 03:29:19\n","loss: 0.6230, acc: 0.7411\n","E2E-ABSA >>> 2022-09-02 03:29:19\n","loss: 0.5984, acc: 0.7543\n","E2E-ABSA >>> 2022-09-02 03:29:19\n",">>> val_acc: 0.6898, val_precision: 0.6898 val_recall: 0.6898, val_f1: 0.6898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 03:29:19\n","loss: 0.5976, acc: 0.7448\n","E2E-ABSA >>> 2022-09-02 03:29:20\n","loss: 0.5719, acc: 0.7558\n","E2E-ABSA >>> 2022-09-02 03:29:20\n",">>> val_acc: 0.6747, val_precision: 0.6747 val_recall: 0.6747, val_f1: 0.6747\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 03:29:20\n","loss: 0.5351, acc: 0.7917\n","E2E-ABSA >>> 2022-09-02 03:29:21\n","loss: 0.5848, acc: 0.7535\n","E2E-ABSA >>> 2022-09-02 03:29:21\n","loss: 0.5847, acc: 0.7718\n","E2E-ABSA >>> 2022-09-02 03:29:21\n",">>> val_acc: 0.6958, val_precision: 0.6958 val_recall: 0.6958, val_f1: 0.6958\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 03:29:21\n","loss: 0.5574, acc: 0.7847\n","E2E-ABSA >>> 2022-09-02 03:29:22\n","loss: 0.5684, acc: 0.7721\n","E2E-ABSA >>> 2022-09-02 03:29:22\n","loss: 0.5799, acc: 0.7647\n","E2E-ABSA >>> 2022-09-02 03:29:22\n",">>> val_acc: 0.6777, val_precision: 0.6777 val_recall: 0.6777, val_f1: 0.6777\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 03:29:23\n","loss: 0.5688, acc: 0.7875\n","E2E-ABSA >>> 2022-09-02 03:29:23\n","loss: 0.5588, acc: 0.7875\n","E2E-ABSA >>> 2022-09-02 03:29:23\n",">>> val_acc: 0.6867, val_precision: 0.6867 val_recall: 0.6867, val_f1: 0.6867\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 03:29:23\n","loss: 0.6011, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 03:29:24\n","loss: 0.5698, acc: 0.7649\n","E2E-ABSA >>> 2022-09-02 03:29:24\n","loss: 0.5659, acc: 0.7717\n","E2E-ABSA >>> 2022-09-02 03:29:24\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 03:29:25\n","loss: 0.5359, acc: 0.7865\n","E2E-ABSA >>> 2022-09-02 03:29:25\n","loss: 0.5660, acc: 0.7674\n","E2E-ABSA >>> 2022-09-02 03:29:25\n",">>> val_acc: 0.6867, val_precision: 0.6867 val_recall: 0.6867, val_f1: 0.6867\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 03:29:25\n","loss: 0.4496, acc: 0.8646\n","E2E-ABSA >>> 2022-09-02 03:29:26\n","loss: 0.5438, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:29:26\n","loss: 0.5547, acc: 0.7794\n","E2E-ABSA >>> 2022-09-02 03:29:26\n",">>> val_acc: 0.6837, val_precision: 0.6837 val_recall: 0.6837, val_f1: 0.6837\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 03:29:27\n","loss: 0.5888, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:29:27\n","loss: 0.5530, acc: 0.7917\n","E2E-ABSA >>> 2022-09-02 03:29:27\n","loss: 0.5484, acc: 0.7936\n","E2E-ABSA >>> 2022-09-02 03:29:27\n",">>> val_acc: 0.6898, val_precision: 0.6898 val_recall: 0.6898, val_f1: 0.6898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 03:29:28\n","loss: 0.5069, acc: 0.8000\n","E2E-ABSA >>> 2022-09-02 03:29:28\n","loss: 0.5402, acc: 0.7823\n","E2E-ABSA >>> 2022-09-02 03:29:29\n",">>> val_acc: 0.6898, val_precision: 0.6898 val_recall: 0.6898, val_f1: 0.6898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 03:29:29\n","loss: 0.4999, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 03:29:29\n","loss: 0.5242, acc: 0.8051\n","E2E-ABSA >>> 2022-09-02 03:29:29\n","loss: 0.5335, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 03:29:30\n",">>> val_acc: 0.6777, val_precision: 0.6777 val_recall: 0.6777, val_f1: 0.6777\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 03:29:30\n","loss: 0.5256, acc: 0.8047\n","E2E-ABSA >>> 2022-09-02 03:29:30\n","loss: 0.5359, acc: 0.7963\n","E2E-ABSA >>> 2022-09-02 03:29:31\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 03:29:31\n","loss: 0.6180, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:29:31\n","loss: 0.5148, acc: 0.8073\n","E2E-ABSA >>> 2022-09-02 03:29:31\n","loss: 0.5234, acc: 0.7983\n","E2E-ABSA >>> 2022-09-02 03:29:32\n",">>> val_acc: 0.6777, val_precision: 0.6777 val_recall: 0.6777, val_f1: 0.6777\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 03:29:32\n","loss: 0.5007, acc: 0.8090\n","E2E-ABSA >>> 2022-09-02 03:29:32\n","loss: 0.5083, acc: 0.8034\n","E2E-ABSA >>> 2022-09-02 03:29:33\n","loss: 0.5148, acc: 0.7984\n","E2E-ABSA >>> 2022-09-02 03:29:33\n",">>> val_acc: 0.6747, val_precision: 0.6747 val_recall: 0.6747, val_f1: 0.6747\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 03:29:33\n","loss: 0.4976, acc: 0.8083\n","E2E-ABSA >>> 2022-09-02 03:29:33\n","loss: 0.5040, acc: 0.8094\n","E2E-ABSA >>> 2022-09-02 03:29:34\n",">>> val_acc: 0.6837, val_precision: 0.6837 val_recall: 0.6837, val_f1: 0.6837\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 03:29:34\n","loss: 0.4825, acc: 0.8073\n","E2E-ABSA >>> 2022-09-02 03:29:34\n","loss: 0.5037, acc: 0.7932\n","E2E-ABSA >>> 2022-09-02 03:29:35\n","loss: 0.4967, acc: 0.8012\n","E2E-ABSA >>> 2022-09-02 03:29:35\n",">>> val_acc: 0.6867, val_precision: 0.6867 val_recall: 0.6867, val_f1: 0.6867\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 03:29:35\n","loss: 0.4946, acc: 0.8203\n","E2E-ABSA >>> 2022-09-02 03:29:35\n","loss: 0.4901, acc: 0.8229\n","E2E-ABSA >>> 2022-09-02 03:29:36\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 03:29:36\n","loss: 0.5091, acc: 0.7917\n","E2E-ABSA >>> 2022-09-02 03:29:36\n","loss: 0.4638, acc: 0.8142\n","E2E-ABSA >>> 2022-09-02 03:29:37\n","loss: 0.4824, acc: 0.8106\n","E2E-ABSA >>> 2022-09-02 03:29:37\n",">>> val_acc: 0.6837, val_precision: 0.6837 val_recall: 0.6837, val_f1: 0.6837\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 03:29:37\n","loss: 0.4359, acc: 0.8472\n","E2E-ABSA >>> 2022-09-02 03:29:37\n","loss: 0.4758, acc: 0.8190\n","E2E-ABSA >>> 2022-09-02 03:29:38\n","loss: 0.4791, acc: 0.8145\n","E2E-ABSA >>> 2022-09-02 03:29:38\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 03:29:38\n","loss: 0.4695, acc: 0.8292\n","E2E-ABSA >>> 2022-09-02 03:29:39\n","loss: 0.4806, acc: 0.8177\n","E2E-ABSA >>> 2022-09-02 03:29:39\n",">>> val_acc: 0.6837, val_precision: 0.6837 val_recall: 0.6837, val_f1: 0.6837\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 03:29:39\n","loss: 0.4797, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 03:29:39\n","loss: 0.4709, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 03:29:40\n","loss: 0.4698, acc: 0.8177\n","E2E-ABSA >>> 2022-09-02 03:29:40\n",">>> val_acc: 0.6717, val_precision: 0.6717 val_recall: 0.6717, val_f1: 0.6717\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 03:29:40\n","loss: 0.4450, acc: 0.8281\n","E2E-ABSA >>> 2022-09-02 03:29:41\n","loss: 0.4536, acc: 0.8252\n","E2E-ABSA >>> 2022-09-02 03:29:41\n",">>> val_acc: 0.6627, val_precision: 0.6627 val_recall: 0.6627, val_f1: 0.6627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 03:29:41\n","loss: 0.3668, acc: 0.8750\n","E2E-ABSA >>> 2022-09-02 03:29:42\n","loss: 0.4713, acc: 0.8177\n","E2E-ABSA >>> 2022-09-02 03:29:42\n","loss: 0.4547, acc: 0.8258\n","E2E-ABSA >>> 2022-09-02 03:29:42\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 03:29:42\n","loss: 0.4656, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 03:29:43\n","loss: 0.4459, acc: 0.8216\n","E2E-ABSA >>> 2022-09-02 03:29:43\n","loss: 0.4436, acc: 0.8217\n","E2E-ABSA >>> 2022-09-02 03:29:43\n",">>> val_acc: 0.6867, val_precision: 0.6867 val_recall: 0.6867, val_f1: 0.6867\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 03:29:44\n","loss: 0.4190, acc: 0.8250\n","E2E-ABSA >>> 2022-09-02 03:29:44\n","loss: 0.4448, acc: 0.8240\n","E2E-ABSA >>> 2022-09-02 03:29:44\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 03:29:44\n","loss: 0.3952, acc: 0.8490\n","E2E-ABSA >>> 2022-09-02 03:29:45\n","loss: 0.4163, acc: 0.8378\n","E2E-ABSA >>> 2022-09-02 03:29:45\n","loss: 0.4291, acc: 0.8342\n","E2E-ABSA >>> 2022-09-02 03:29:45\n",">>> val_acc: 0.6325, val_precision: 0.6325 val_recall: 0.6325, val_f1: 0.6325\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 03:29:46\n","loss: 0.4026, acc: 0.8646\n","E2E-ABSA >>> 2022-09-02 03:29:46\n","loss: 0.4247, acc: 0.8414\n","E2E-ABSA >>> 2022-09-02 03:29:46\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","E2E-ABSA >>> 2022-09-02 03:29:46\n","loss: 0.3565, acc: 0.8438\n","E2E-ABSA >>> 2022-09-02 03:29:47\n","loss: 0.3882, acc: 0.8490\n","E2E-ABSA >>> 2022-09-02 03:29:47\n","loss: 0.4122, acc: 0.8409\n","E2E-ABSA >>> 2022-09-02 03:29:47\n",">>> val_acc: 0.6506, val_precision: 0.6506 val_recall: 0.6506, val_f1: 0.6506\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","E2E-ABSA >>> 2022-09-02 03:29:48\n","loss: 0.3923, acc: 0.8646\n","E2E-ABSA >>> 2022-09-02 03:29:48\n","loss: 0.4017, acc: 0.8542\n","E2E-ABSA >>> 2022-09-02 03:29:48\n","loss: 0.4137, acc: 0.8434\n","E2E-ABSA >>> 2022-09-02 03:29:48\n",">>> val_acc: 0.6596, val_precision: 0.6596 val_recall: 0.6596, val_f1: 0.6596\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","E2E-ABSA >>> 2022-09-02 03:29:49\n","loss: 0.3655, acc: 0.8792\n","E2E-ABSA >>> 2022-09-02 03:29:49\n","loss: 0.4057, acc: 0.8510\n","E2E-ABSA >>> 2022-09-02 03:29:49\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","E2E-ABSA >>> 2022-09-02 03:29:50\n","loss: 0.4061, acc: 0.8385\n","E2E-ABSA >>> 2022-09-02 03:29:50\n","loss: 0.3709, acc: 0.8601\n","E2E-ABSA >>> 2022-09-02 03:29:50\n","loss: 0.3992, acc: 0.8472\n","E2E-ABSA >>> 2022-09-02 03:29:50\n",">>> val_acc: 0.6596, val_precision: 0.6596 val_recall: 0.6596, val_f1: 0.6596\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","E2E-ABSA >>> 2022-09-02 03:29:51\n","loss: 0.3456, acc: 0.8750\n","E2E-ABSA >>> 2022-09-02 03:29:51\n","loss: 0.3690, acc: 0.8657\n","E2E-ABSA >>> 2022-09-02 03:29:51\n",">>> val_acc: 0.6536, val_precision: 0.6536 val_recall: 0.6536, val_f1: 0.6536\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","E2E-ABSA >>> 2022-09-02 03:29:52\n","loss: 0.3228, acc: 0.8854\n","E2E-ABSA >>> 2022-09-02 03:29:52\n","loss: 0.3741, acc: 0.8576\n","E2E-ABSA >>> 2022-09-02 03:29:52\n","loss: 0.3792, acc: 0.8542\n","E2E-ABSA >>> 2022-09-02 03:29:52\n",">>> val_acc: 0.6566, val_precision: 0.6566 val_recall: 0.6566, val_f1: 0.6566\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","E2E-ABSA >>> 2022-09-02 03:29:53\n","loss: 0.3832, acc: 0.8611\n","E2E-ABSA >>> 2022-09-02 03:29:53\n","loss: 0.3820, acc: 0.8594\n","E2E-ABSA >>> 2022-09-02 03:29:53\n","loss: 0.3775, acc: 0.8562\n","E2E-ABSA >>> 2022-09-02 03:29:54\n",">>> val_acc: 0.6596, val_precision: 0.6596 val_recall: 0.6596, val_f1: 0.6596\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","E2E-ABSA >>> 2022-09-02 03:29:54\n","loss: 0.4037, acc: 0.8479\n","E2E-ABSA >>> 2022-09-02 03:29:54\n","loss: 0.3754, acc: 0.8594\n","E2E-ABSA >>> 2022-09-02 03:29:55\n",">>> val_acc: 0.6536, val_precision: 0.6536 val_recall: 0.6536, val_f1: 0.6536\n","E2E-ABSA >>> 2022-09-02 03:29:55\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n","you can download the best model from state_dict/tc_lstm_twitter_know_val_f1_0.7078\n",">>> test_acc: 0.7078, test_precision: 0.7078, test_recall: 0.7078, test_f1: 0.7078\n"]}]},{"cell_type":"markdown","source":["增加字典知识后: Training **twitter** dataset on model(**atae_lstm**)"],"metadata":{"id":"Sfm2Aik3hdsw"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name atae_lstm --dataset twitter_know --embed_dim 200 --patience 50 --log_step 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5LG_XXnhd7I","outputId":"22fa6ea0-97d6-434e-ce1c-8d42d7361752","executionInfo":{"status":"ok","timestamp":1662089531478,"user_tz":-480,"elapsed":137733,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.twitter.27B.200d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1664.\n","> testing dataset count: 419.\n","cuda memory allocated: 22920704\n","> n_trainable_params: 1845303, n_nontrainable_params: 3884000\n","> training arguments:\n",">>> model_name: atae_lstm\n",">>> dataset: twitter_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7ff04eb68c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 30\n",">>> embed_dim: 200\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 50\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.atae_lstm.ATAE_LSTM'>\n",">>> dataset_file: {'train': './datasets/twitter/output_know_insert/train.tsv', 'test': './datasets/twitter/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 03:30:23\n","loss: 1.3074, acc: 0.1479\n","E2E-ABSA >>> 2022-09-02 03:30:23\n","loss: 1.2655, acc: 0.1854\n","E2E-ABSA >>> 2022-09-02 03:30:23\n","loss: 1.2333, acc: 0.2132\n","E2E-ABSA >>> 2022-09-02 03:30:24\n",">>> val_acc: 0.4869, val_precision: 0.4869 val_recall: 0.4869, val_f1: 0.4869\n",">> saved: state_dict/atae_lstm_twitter_know_val_f1_0.4869\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 03:30:24\n","loss: 0.9973, acc: 0.5195\n","E2E-ABSA >>> 2022-09-02 03:30:24\n","loss: 0.9514, acc: 0.5802\n","E2E-ABSA >>> 2022-09-02 03:30:25\n","loss: 0.9098, acc: 0.6086\n","E2E-ABSA >>> 2022-09-02 03:30:25\n",">>> val_acc: 0.6850, val_precision: 0.6850 val_recall: 0.6850, val_f1: 0.6850\n",">> saved: state_dict/atae_lstm_twitter_know_val_f1_0.685\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 03:30:25\n","loss: 0.9767, acc: 0.5312\n","E2E-ABSA >>> 2022-09-02 03:30:26\n","loss: 0.8447, acc: 0.6465\n","E2E-ABSA >>> 2022-09-02 03:30:26\n","loss: 0.8094, acc: 0.6663\n","E2E-ABSA >>> 2022-09-02 03:30:26\n","loss: 0.8163, acc: 0.6576\n","E2E-ABSA >>> 2022-09-02 03:30:27\n",">>> val_acc: 0.6850, val_precision: 0.6850 val_recall: 0.6850, val_f1: 0.6850\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 03:30:27\n","loss: 0.7252, acc: 0.7014\n","E2E-ABSA >>> 2022-09-02 03:30:27\n","loss: 0.7692, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:30:28\n","loss: 0.7936, acc: 0.6635\n","E2E-ABSA >>> 2022-09-02 03:30:28\n",">>> val_acc: 0.6850, val_precision: 0.6850 val_recall: 0.6850, val_f1: 0.6850\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 03:30:28\n","loss: 0.7999, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:30:29\n","loss: 0.7609, acc: 0.6838\n","E2E-ABSA >>> 2022-09-02 03:30:29\n","loss: 0.7797, acc: 0.6758\n","E2E-ABSA >>> 2022-09-02 03:30:29\n","loss: 0.7753, acc: 0.6775\n","E2E-ABSA >>> 2022-09-02 03:30:30\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">> saved: state_dict/atae_lstm_twitter_know_val_f1_0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 03:30:30\n","loss: 0.7021, acc: 0.7156\n","E2E-ABSA >>> 2022-09-02 03:30:30\n","loss: 0.7581, acc: 0.6813\n","E2E-ABSA >>> 2022-09-02 03:30:31\n","loss: 0.7595, acc: 0.6789\n","E2E-ABSA >>> 2022-09-02 03:30:31\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">> saved: state_dict/atae_lstm_twitter_know_val_f1_0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 03:30:31\n","loss: 0.7305, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:30:32\n","loss: 0.7678, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:30:32\n","loss: 0.7543, acc: 0.6809\n","E2E-ABSA >>> 2022-09-02 03:30:32\n","loss: 0.7633, acc: 0.6738\n","E2E-ABSA >>> 2022-09-02 03:30:33\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 03:30:33\n","loss: 0.7777, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:30:33\n","loss: 0.7828, acc: 0.6599\n","E2E-ABSA >>> 2022-09-02 03:30:34\n","loss: 0.7646, acc: 0.6753\n","E2E-ABSA >>> 2022-09-02 03:30:34\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 03:30:34\n","loss: 0.8714, acc: 0.5938\n","E2E-ABSA >>> 2022-09-02 03:30:34\n","loss: 0.8003, acc: 0.6645\n","E2E-ABSA >>> 2022-09-02 03:30:35\n","loss: 0.7678, acc: 0.6792\n","E2E-ABSA >>> 2022-09-02 03:30:35\n","loss: 0.7597, acc: 0.6767\n","E2E-ABSA >>> 2022-09-02 03:30:35\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">> saved: state_dict/atae_lstm_twitter_know_val_f1_0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 03:30:36\n","loss: 0.7826, acc: 0.6432\n","E2E-ABSA >>> 2022-09-02 03:30:36\n","loss: 0.7506, acc: 0.6782\n","E2E-ABSA >>> 2022-09-02 03:30:37\n","loss: 0.7484, acc: 0.6815\n","E2E-ABSA >>> 2022-09-02 03:30:37\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 03:30:37\n","loss: 0.7888, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:30:37\n","loss: 0.7667, acc: 0.6594\n","E2E-ABSA >>> 2022-09-02 03:30:38\n","loss: 0.7453, acc: 0.6750\n","E2E-ABSA >>> 2022-09-02 03:30:38\n","loss: 0.7453, acc: 0.6781\n","E2E-ABSA >>> 2022-09-02 03:30:38\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 03:30:39\n","loss: 0.7764, acc: 0.6587\n","E2E-ABSA >>> 2022-09-02 03:30:39\n","loss: 0.7624, acc: 0.6696\n","E2E-ABSA >>> 2022-09-02 03:30:40\n","loss: 0.7413, acc: 0.6781\n","E2E-ABSA >>> 2022-09-02 03:30:40\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">> saved: state_dict/atae_lstm_twitter_know_val_f1_0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 03:30:40\n","loss: 0.7485, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:30:40\n","loss: 0.7727, acc: 0.6548\n","E2E-ABSA >>> 2022-09-02 03:30:41\n","loss: 0.7606, acc: 0.6597\n","E2E-ABSA >>> 2022-09-02 03:30:41\n","loss: 0.7386, acc: 0.6795\n","E2E-ABSA >>> 2022-09-02 03:30:41\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 03:30:42\n","loss: 0.7121, acc: 0.6897\n","E2E-ABSA >>> 2022-09-02 03:30:42\n","loss: 0.7307, acc: 0.6767\n","E2E-ABSA >>> 2022-09-02 03:30:42\n","loss: 0.7361, acc: 0.6761\n","E2E-ABSA >>> 2022-09-02 03:30:43\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">> saved: state_dict/atae_lstm_twitter_know_val_f1_0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 03:30:43\n","loss: 0.7852, acc: 0.6473\n","E2E-ABSA >>> 2022-09-02 03:30:43\n","loss: 0.7231, acc: 0.6832\n","E2E-ABSA >>> 2022-09-02 03:30:44\n","loss: 0.7394, acc: 0.6833\n","E2E-ABSA >>> 2022-09-02 03:30:44\n","loss: 0.7287, acc: 0.6827\n","E2E-ABSA >>> 2022-09-02 03:30:44\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">> saved: state_dict/atae_lstm_twitter_know_val_f1_0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 03:30:45\n","loss: 0.7431, acc: 0.6625\n","E2E-ABSA >>> 2022-09-02 03:30:45\n","loss: 0.7362, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:30:46\n","loss: 0.7208, acc: 0.6868\n","E2E-ABSA >>> 2022-09-02 03:30:46\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 03:30:46\n","loss: 0.7025, acc: 0.6914\n","E2E-ABSA >>> 2022-09-02 03:30:46\n","loss: 0.7211, acc: 0.6780\n","E2E-ABSA >>> 2022-09-02 03:30:47\n","loss: 0.7195, acc: 0.6867\n","E2E-ABSA >>> 2022-09-02 03:30:47\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 03:30:47\n","loss: 0.7563, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:30:48\n","loss: 0.7143, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 03:30:48\n","loss: 0.7189, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:30:48\n","loss: 0.7162, acc: 0.6834\n","E2E-ABSA >>> 2022-09-02 03:30:49\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">> saved: state_dict/atae_lstm_twitter_know_val_f1_0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 03:30:49\n","loss: 0.7389, acc: 0.6632\n","E2E-ABSA >>> 2022-09-02 03:30:50\n","loss: 0.7210, acc: 0.6810\n","E2E-ABSA >>> 2022-09-02 03:30:50\n","loss: 0.7257, acc: 0.6715\n","E2E-ABSA >>> 2022-09-02 03:30:51\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 03:30:51\n","loss: 0.7231, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 03:30:51\n","loss: 0.7200, acc: 0.6746\n","E2E-ABSA >>> 2022-09-02 03:30:51\n","loss: 0.7221, acc: 0.6846\n","E2E-ABSA >>> 2022-09-02 03:30:52\n","loss: 0.7166, acc: 0.6888\n","E2E-ABSA >>> 2022-09-02 03:30:52\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 03:30:52\n","loss: 0.7146, acc: 0.6781\n","E2E-ABSA >>> 2022-09-02 03:30:53\n","loss: 0.6886, acc: 0.6963\n","E2E-ABSA >>> 2022-09-02 03:30:53\n","loss: 0.6924, acc: 0.6977\n","E2E-ABSA >>> 2022-09-02 03:30:54\n",">>> val_acc: 0.7208, val_precision: 0.7208 val_recall: 0.7208, val_f1: 0.7208\n",">> saved: state_dict/atae_lstm_twitter_know_val_f1_0.7208\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 03:30:54\n","loss: 0.8006, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:30:54\n","loss: 0.7024, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 03:30:54\n","loss: 0.6902, acc: 0.7055\n","E2E-ABSA >>> 2022-09-02 03:30:55\n","loss: 0.6971, acc: 0.6992\n","E2E-ABSA >>> 2022-09-02 03:30:55\n",">>> val_acc: 0.7255, val_precision: 0.7255 val_recall: 0.7255, val_f1: 0.7255\n",">> saved: state_dict/atae_lstm_twitter_know_val_f1_0.7255\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 03:30:55\n","loss: 0.6685, acc: 0.7301\n","E2E-ABSA >>> 2022-09-02 03:30:56\n","loss: 0.6762, acc: 0.7127\n","E2E-ABSA >>> 2022-09-02 03:30:56\n","loss: 0.6860, acc: 0.7096\n","E2E-ABSA >>> 2022-09-02 03:30:57\n",">>> val_acc: 0.7208, val_precision: 0.7208 val_recall: 0.7208, val_f1: 0.7208\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 03:30:57\n","loss: 0.6995, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 03:30:57\n","loss: 0.6646, acc: 0.7171\n","E2E-ABSA >>> 2022-09-02 03:30:57\n","loss: 0.6621, acc: 0.7132\n","E2E-ABSA >>> 2022-09-02 03:30:58\n","loss: 0.6759, acc: 0.7079\n","E2E-ABSA >>> 2022-09-02 03:30:58\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 03:30:58\n","loss: 0.6199, acc: 0.7370\n","E2E-ABSA >>> 2022-09-02 03:30:59\n","loss: 0.6399, acc: 0.7211\n","E2E-ABSA >>> 2022-09-02 03:30:59\n","loss: 0.6648, acc: 0.7098\n","E2E-ABSA >>> 2022-09-02 03:31:00\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 03:31:00\n","loss: 0.5838, acc: 0.7625\n","E2E-ABSA >>> 2022-09-02 03:31:00\n","loss: 0.6734, acc: 0.7125\n","E2E-ABSA >>> 2022-09-02 03:31:01\n","loss: 0.6704, acc: 0.7116\n","E2E-ABSA >>> 2022-09-02 03:31:01\n","loss: 0.6701, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:31:01\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 03:31:01\n","loss: 0.6476, acc: 0.7163\n","E2E-ABSA >>> 2022-09-02 03:31:02\n","loss: 0.6531, acc: 0.7299\n","E2E-ABSA >>> 2022-09-02 03:31:02\n","loss: 0.6565, acc: 0.7267\n","E2E-ABSA >>> 2022-09-02 03:31:03\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 03:31:03\n","loss: 0.7345, acc: 0.6823\n","E2E-ABSA >>> 2022-09-02 03:31:03\n","loss: 0.6712, acc: 0.7128\n","E2E-ABSA >>> 2022-09-02 03:31:04\n","loss: 0.6532, acc: 0.7214\n","E2E-ABSA >>> 2022-09-02 03:31:04\n","loss: 0.6532, acc: 0.7224\n","E2E-ABSA >>> 2022-09-02 03:31:04\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 03:31:04\n","loss: 0.6008, acc: 0.7746\n","E2E-ABSA >>> 2022-09-02 03:31:05\n","loss: 0.5985, acc: 0.7597\n","E2E-ABSA >>> 2022-09-02 03:31:05\n","loss: 0.6370, acc: 0.7379\n","E2E-ABSA >>> 2022-09-02 03:31:06\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 03:31:06\n","loss: 0.6263, acc: 0.7232\n","E2E-ABSA >>> 2022-09-02 03:31:06\n","loss: 0.6436, acc: 0.7401\n","E2E-ABSA >>> 2022-09-02 03:31:07\n","loss: 0.6464, acc: 0.7382\n","E2E-ABSA >>> 2022-09-02 03:31:07\n","loss: 0.6403, acc: 0.7368\n","E2E-ABSA >>> 2022-09-02 03:31:07\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 03:31:07\n","loss: 0.6425, acc: 0.7333\n","E2E-ABSA >>> 2022-09-02 03:31:08\n","loss: 0.6374, acc: 0.7375\n","E2E-ABSA >>> 2022-09-02 03:31:08\n","loss: 0.6334, acc: 0.7417\n","E2E-ABSA >>> 2022-09-02 03:31:09\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 03:31:09\n","loss: 0.6250, acc: 0.7461\n","E2E-ABSA >>> 2022-09-02 03:31:09\n","loss: 0.6332, acc: 0.7418\n","E2E-ABSA >>> 2022-09-02 03:31:10\n","loss: 0.6273, acc: 0.7393\n","E2E-ABSA >>> 2022-09-02 03:31:10\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 03:31:10\n","loss: 0.6283, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:31:10\n","loss: 0.6076, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:31:11\n","loss: 0.6058, acc: 0.7530\n","E2E-ABSA >>> 2022-09-02 03:31:11\n","loss: 0.6172, acc: 0.7439\n","E2E-ABSA >>> 2022-09-02 03:31:11\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 03:31:12\n","loss: 0.5943, acc: 0.7431\n","E2E-ABSA >>> 2022-09-02 03:31:12\n","loss: 0.6164, acc: 0.7448\n","E2E-ABSA >>> 2022-09-02 03:31:12\n","loss: 0.6255, acc: 0.7316\n","E2E-ABSA >>> 2022-09-02 03:31:13\n",">>> val_acc: 0.7208, val_precision: 0.7208 val_recall: 0.7208, val_f1: 0.7208\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 03:31:13\n","loss: 0.6345, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:31:13\n","loss: 0.6387, acc: 0.7206\n","E2E-ABSA >>> 2022-09-02 03:31:14\n","loss: 0.6064, acc: 0.7441\n","E2E-ABSA >>> 2022-09-02 03:31:14\n","loss: 0.5994, acc: 0.7473\n","E2E-ABSA >>> 2022-09-02 03:31:14\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 03:31:15\n","loss: 0.5728, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:31:15\n","loss: 0.5653, acc: 0.7750\n","E2E-ABSA >>> 2022-09-02 03:31:15\n","loss: 0.5785, acc: 0.7641\n","E2E-ABSA >>> 2022-09-02 03:31:16\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 03:31:16\n","loss: 0.5840, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:31:16\n","loss: 0.6120, acc: 0.7448\n","E2E-ABSA >>> 2022-09-02 03:31:17\n","loss: 0.5988, acc: 0.7509\n","E2E-ABSA >>> 2022-09-02 03:31:17\n","loss: 0.5812, acc: 0.7559\n","E2E-ABSA >>> 2022-09-02 03:31:17\n",">>> val_acc: 0.7208, val_precision: 0.7208 val_recall: 0.7208, val_f1: 0.7208\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 03:31:18\n","loss: 0.6353, acc: 0.7443\n","E2E-ABSA >>> 2022-09-02 03:31:18\n","loss: 0.5630, acc: 0.7752\n","E2E-ABSA >>> 2022-09-02 03:31:18\n","loss: 0.5670, acc: 0.7668\n","E2E-ABSA >>> 2022-09-02 03:31:19\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 03:31:19\n","loss: 0.4879, acc: 0.7734\n","E2E-ABSA >>> 2022-09-02 03:31:19\n","loss: 0.5411, acc: 0.7747\n","E2E-ABSA >>> 2022-09-02 03:31:20\n","loss: 0.5498, acc: 0.7693\n","E2E-ABSA >>> 2022-09-02 03:31:20\n","loss: 0.5637, acc: 0.7634\n","E2E-ABSA >>> 2022-09-02 03:31:20\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 03:31:21\n","loss: 0.5447, acc: 0.7943\n","E2E-ABSA >>> 2022-09-02 03:31:21\n","loss: 0.5706, acc: 0.7731\n","E2E-ABSA >>> 2022-09-02 03:31:22\n","loss: 0.5653, acc: 0.7649\n","E2E-ABSA >>> 2022-09-02 03:31:22\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 03:31:22\n","loss: 0.6502, acc: 0.6750\n","E2E-ABSA >>> 2022-09-02 03:31:22\n","loss: 0.5953, acc: 0.7453\n","E2E-ABSA >>> 2022-09-02 03:31:23\n","loss: 0.5825, acc: 0.7580\n","E2E-ABSA >>> 2022-09-02 03:31:23\n","loss: 0.5580, acc: 0.7706\n","E2E-ABSA >>> 2022-09-02 03:31:23\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 03:31:24\n","loss: 0.5312, acc: 0.7764\n","E2E-ABSA >>> 2022-09-02 03:31:24\n","loss: 0.5203, acc: 0.7868\n","E2E-ABSA >>> 2022-09-02 03:31:24\n","loss: 0.5276, acc: 0.7827\n","E2E-ABSA >>> 2022-09-02 03:31:25\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 03:31:25\n","loss: 0.5110, acc: 0.7917\n","E2E-ABSA >>> 2022-09-02 03:31:25\n","loss: 0.4958, acc: 0.8006\n","E2E-ABSA >>> 2022-09-02 03:31:26\n","loss: 0.5376, acc: 0.7865\n","E2E-ABSA >>> 2022-09-02 03:31:26\n","loss: 0.5303, acc: 0.7831\n","E2E-ABSA >>> 2022-09-02 03:31:26\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 03:31:27\n","loss: 0.5314, acc: 0.7701\n","E2E-ABSA >>> 2022-09-02 03:31:27\n","loss: 0.5310, acc: 0.7791\n","E2E-ABSA >>> 2022-09-02 03:31:27\n","loss: 0.5268, acc: 0.7855\n","E2E-ABSA >>> 2022-09-02 03:31:28\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 03:31:28\n","loss: 0.5125, acc: 0.8080\n","E2E-ABSA >>> 2022-09-02 03:31:28\n","loss: 0.4995, acc: 0.7884\n","E2E-ABSA >>> 2022-09-02 03:31:29\n","loss: 0.5031, acc: 0.7990\n","E2E-ABSA >>> 2022-09-02 03:31:29\n","loss: 0.5194, acc: 0.7843\n","E2E-ABSA >>> 2022-09-02 03:31:29\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 03:31:30\n","loss: 0.5574, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:31:30\n","loss: 0.5187, acc: 0.7854\n","E2E-ABSA >>> 2022-09-02 03:31:30\n","loss: 0.5194, acc: 0.7875\n","E2E-ABSA >>> 2022-09-02 03:31:31\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 03:31:31\n","loss: 0.4792, acc: 0.8047\n","E2E-ABSA >>> 2022-09-02 03:31:31\n","loss: 0.4875, acc: 0.8003\n","E2E-ABSA >>> 2022-09-02 03:31:32\n","loss: 0.4964, acc: 0.8010\n","E2E-ABSA >>> 2022-09-02 03:31:32\n",">>> val_acc: 0.6826, val_precision: 0.6826 val_recall: 0.6826, val_f1: 0.6826\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 03:31:32\n","loss: 0.4819, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:31:33\n","loss: 0.4767, acc: 0.7930\n","E2E-ABSA >>> 2022-09-02 03:31:33\n","loss: 0.4835, acc: 0.8004\n","E2E-ABSA >>> 2022-09-02 03:31:33\n","loss: 0.4937, acc: 0.7976\n","E2E-ABSA >>> 2022-09-02 03:31:34\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 03:31:34\n","loss: 0.4667, acc: 0.8194\n","E2E-ABSA >>> 2022-09-02 03:31:34\n","loss: 0.4848, acc: 0.8008\n","E2E-ABSA >>> 2022-09-02 03:31:35\n","loss: 0.4761, acc: 0.7997\n","E2E-ABSA >>> 2022-09-02 03:31:35\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 03:31:35\n","loss: 0.5136, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:31:35\n","loss: 0.4627, acc: 0.8033\n","E2E-ABSA >>> 2022-09-02 03:31:36\n","loss: 0.4776, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 03:31:36\n","loss: 0.4809, acc: 0.7965\n","E2E-ABSA >>> 2022-09-02 03:31:37\n",">>> val_acc: 0.6563, val_precision: 0.6563 val_recall: 0.6563, val_f1: 0.6563\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 03:31:37\n","loss: 0.4879, acc: 0.7875\n","E2E-ABSA >>> 2022-09-02 03:31:37\n","loss: 0.4783, acc: 0.8025\n","E2E-ABSA >>> 2022-09-02 03:31:37\n","loss: 0.4876, acc: 0.7922\n","E2E-ABSA >>> 2022-09-02 03:31:38\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 03:31:38\n","loss: 0.3960, acc: 0.8750\n","E2E-ABSA >>> 2022-09-02 03:31:38\n","loss: 0.4207, acc: 0.8420\n","E2E-ABSA >>> 2022-09-02 03:31:39\n","loss: 0.4399, acc: 0.8191\n","E2E-ABSA >>> 2022-09-02 03:31:39\n","loss: 0.4593, acc: 0.8112\n","E2E-ABSA >>> 2022-09-02 03:31:39\n",">>> val_acc: 0.6850, val_precision: 0.6850 val_recall: 0.6850, val_f1: 0.6850\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 03:31:40\n","loss: 0.4704, acc: 0.8011\n","E2E-ABSA >>> 2022-09-02 03:31:40\n","loss: 0.4598, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 03:31:40\n","loss: 0.4570, acc: 0.8155\n","E2E-ABSA >>> 2022-09-02 03:31:41\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 03:31:41\n","loss: 0.4636, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 03:31:41\n","loss: 0.4688, acc: 0.8043\n","E2E-ABSA >>> 2022-09-02 03:31:42\n","loss: 0.4651, acc: 0.8051\n","E2E-ABSA >>> 2022-09-02 03:31:42\n","loss: 0.4581, acc: 0.8099\n","E2E-ABSA >>> 2022-09-02 03:31:42\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 03:31:43\n","loss: 0.4413, acc: 0.8151\n","E2E-ABSA >>> 2022-09-02 03:31:43\n","loss: 0.4524, acc: 0.8218\n","E2E-ABSA >>> 2022-09-02 03:31:43\n","loss: 0.4486, acc: 0.8266\n","E2E-ABSA >>> 2022-09-02 03:31:44\n",">>> val_acc: 0.6754, val_precision: 0.6754 val_recall: 0.6754, val_f1: 0.6754\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 03:31:44\n","loss: 0.3600, acc: 0.8625\n","E2E-ABSA >>> 2022-09-02 03:31:44\n","loss: 0.4272, acc: 0.8234\n","E2E-ABSA >>> 2022-09-02 03:31:45\n","loss: 0.4456, acc: 0.8116\n","E2E-ABSA >>> 2022-09-02 03:31:45\n","loss: 0.4414, acc: 0.8206\n","E2E-ABSA >>> 2022-09-02 03:31:45\n",">>> val_acc: 0.6754, val_precision: 0.6754 val_recall: 0.6754, val_f1: 0.6754\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 03:31:46\n","loss: 0.4178, acc: 0.8341\n","E2E-ABSA >>> 2022-09-02 03:31:46\n","loss: 0.4357, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 03:31:46\n","loss: 0.4439, acc: 0.8140\n","E2E-ABSA >>> 2022-09-02 03:31:47\n",">>> val_acc: 0.6754, val_precision: 0.6754 val_recall: 0.6754, val_f1: 0.6754\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 03:31:47\n","loss: 0.3364, acc: 0.8854\n","E2E-ABSA >>> 2022-09-02 03:31:47\n","loss: 0.4273, acc: 0.8333\n","E2E-ABSA >>> 2022-09-02 03:31:48\n","loss: 0.4347, acc: 0.8247\n","E2E-ABSA >>> 2022-09-02 03:31:48\n","loss: 0.4346, acc: 0.8284\n","E2E-ABSA >>> 2022-09-02 03:31:48\n",">>> val_acc: 0.6730, val_precision: 0.6730 val_recall: 0.6730, val_f1: 0.6730\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 03:31:48\n","loss: 0.4747, acc: 0.8103\n","E2E-ABSA >>> 2022-09-02 03:31:49\n","loss: 0.4492, acc: 0.8190\n","E2E-ABSA >>> 2022-09-02 03:31:49\n","loss: 0.4388, acc: 0.8210\n","E2E-ABSA >>> 2022-09-02 03:31:50\n",">>> val_acc: 0.6468, val_precision: 0.6468 val_recall: 0.6468, val_f1: 0.6468\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 03:31:50\n","loss: 0.4565, acc: 0.8304\n","E2E-ABSA >>> 2022-09-02 03:31:50\n","loss: 0.4275, acc: 0.8281\n","E2E-ABSA >>> 2022-09-02 03:31:51\n","loss: 0.4433, acc: 0.8201\n","E2E-ABSA >>> 2022-09-02 03:31:51\n","loss: 0.4326, acc: 0.8221\n","E2E-ABSA >>> 2022-09-02 03:31:51\n",">>> val_acc: 0.6802, val_precision: 0.6802 val_recall: 0.6802, val_f1: 0.6802\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 03:31:52\n","loss: 0.4087, acc: 0.8229\n","E2E-ABSA >>> 2022-09-02 03:31:52\n","loss: 0.4228, acc: 0.8219\n","E2E-ABSA >>> 2022-09-02 03:31:53\n","loss: 0.4188, acc: 0.8306\n","E2E-ABSA >>> 2022-09-02 03:31:53\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 03:31:53\n","loss: 0.3944, acc: 0.8359\n","E2E-ABSA >>> 2022-09-02 03:31:54\n","loss: 0.3828, acc: 0.8478\n","E2E-ABSA >>> 2022-09-02 03:31:54\n","loss: 0.3884, acc: 0.8479\n","E2E-ABSA >>> 2022-09-02 03:31:55\n",">>> val_acc: 0.6802, val_precision: 0.6802 val_recall: 0.6802, val_f1: 0.6802\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 03:31:55\n","loss: 0.3368, acc: 0.9062\n","E2E-ABSA >>> 2022-09-02 03:31:55\n","loss: 0.3796, acc: 0.8535\n","E2E-ABSA >>> 2022-09-02 03:31:55\n","loss: 0.3924, acc: 0.8407\n","E2E-ABSA >>> 2022-09-02 03:31:56\n","loss: 0.4062, acc: 0.8383\n","E2E-ABSA >>> 2022-09-02 03:31:56\n",">>> val_acc: 0.6516, val_precision: 0.6516 val_recall: 0.6516, val_f1: 0.6516\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 03:31:56\n","loss: 0.3730, acc: 0.8576\n","E2E-ABSA >>> 2022-09-02 03:31:57\n","loss: 0.4227, acc: 0.8216\n","E2E-ABSA >>> 2022-09-02 03:31:57\n","loss: 0.4123, acc: 0.8341\n","E2E-ABSA >>> 2022-09-02 03:31:58\n",">>> val_acc: 0.6802, val_precision: 0.6802 val_recall: 0.6802, val_f1: 0.6802\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 03:31:58\n","loss: 0.3455, acc: 0.8906\n","E2E-ABSA >>> 2022-09-02 03:31:58\n","loss: 0.3744, acc: 0.8548\n","E2E-ABSA >>> 2022-09-02 03:31:58\n","loss: 0.3911, acc: 0.8496\n","E2E-ABSA >>> 2022-09-02 03:31:59\n","loss: 0.3925, acc: 0.8451\n","E2E-ABSA >>> 2022-09-02 03:31:59\n",">>> val_acc: 0.6706, val_precision: 0.6706 val_recall: 0.6706, val_f1: 0.6706\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 03:31:59\n","loss: 0.3555, acc: 0.8688\n","E2E-ABSA >>> 2022-09-02 03:32:00\n","loss: 0.4001, acc: 0.8363\n","E2E-ABSA >>> 2022-09-02 03:32:00\n","loss: 0.4022, acc: 0.8414\n","E2E-ABSA >>> 2022-09-02 03:32:01\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 03:32:01\n","loss: 0.4032, acc: 0.8438\n","E2E-ABSA >>> 2022-09-02 03:32:01\n","loss: 0.3737, acc: 0.8524\n","E2E-ABSA >>> 2022-09-02 03:32:01\n","loss: 0.3713, acc: 0.8428\n","E2E-ABSA >>> 2022-09-02 03:32:02\n","loss: 0.3863, acc: 0.8418\n","E2E-ABSA >>> 2022-09-02 03:32:02\n",">>> val_acc: 0.6802, val_precision: 0.6802 val_recall: 0.6802, val_f1: 0.6802\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 03:32:02\n","loss: 0.3935, acc: 0.8409\n","E2E-ABSA >>> 2022-09-02 03:32:03\n","loss: 0.3962, acc: 0.8438\n","E2E-ABSA >>> 2022-09-02 03:32:03\n","loss: 0.3958, acc: 0.8453\n","E2E-ABSA >>> 2022-09-02 03:32:03\n",">>> val_acc: 0.6659, val_precision: 0.6659 val_recall: 0.6659, val_f1: 0.6659\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","E2E-ABSA >>> 2022-09-02 03:32:04\n","loss: 0.3234, acc: 0.8828\n","E2E-ABSA >>> 2022-09-02 03:32:04\n","loss: 0.3795, acc: 0.8405\n","E2E-ABSA >>> 2022-09-02 03:32:04\n","loss: 0.3815, acc: 0.8438\n","E2E-ABSA >>> 2022-09-02 03:32:05\n","loss: 0.3862, acc: 0.8412\n","E2E-ABSA >>> 2022-09-02 03:32:05\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","E2E-ABSA >>> 2022-09-02 03:32:05\n","loss: 0.4078, acc: 0.8359\n","E2E-ABSA >>> 2022-09-02 03:32:06\n","loss: 0.3705, acc: 0.8588\n","E2E-ABSA >>> 2022-09-02 03:32:06\n","loss: 0.3749, acc: 0.8504\n","E2E-ABSA >>> 2022-09-02 03:32:06\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","E2E-ABSA >>> 2022-09-02 03:32:06\n","loss: 0.3513, acc: 0.8375\n","E2E-ABSA >>> 2022-09-02 03:32:07\n","loss: 0.3785, acc: 0.8391\n","E2E-ABSA >>> 2022-09-02 03:32:07\n","loss: 0.3729, acc: 0.8420\n","E2E-ABSA >>> 2022-09-02 03:32:08\n","loss: 0.3873, acc: 0.8375\n","E2E-ABSA >>> 2022-09-02 03:32:08\n",">>> val_acc: 0.6659, val_precision: 0.6659 val_recall: 0.6659, val_f1: 0.6659\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","E2E-ABSA >>> 2022-09-02 03:32:08\n","loss: 0.3918, acc: 0.8365\n","E2E-ABSA >>> 2022-09-02 03:32:09\n","loss: 0.3863, acc: 0.8516\n","E2E-ABSA >>> 2022-09-02 03:32:09\n","loss: 0.3881, acc: 0.8452\n","E2E-ABSA >>> 2022-09-02 03:32:09\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n","E2E-ABSA >>> 2022-09-02 03:32:09\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7255, val_precision: 0.7255 val_recall: 0.7255, val_f1: 0.7255\n","you can download the best model from state_dict/atae_lstm_twitter_know_val_f1_0.7255\n",">>> test_acc: 0.7255, test_precision: 0.7255, test_recall: 0.7255, test_f1: 0.7255\n"]}]},{"cell_type":"markdown","source":["增加字典知识后: Training **Twitter** dataset on model(**IAN**)"],"metadata":{"id":"ifPtlhzNjO2i"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name ian --dataset twitter_know --embed_dim 200 --patience 50 --log_step 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z56axXpijPDU","outputId":"eb053582-27f4-48cf-8ceb-f18ce7a49ab3","executionInfo":{"status":"ok","timestamp":1662089737800,"user_tz":-480,"elapsed":206328,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.twitter.27B.200d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1664.\n","> testing dataset count: 419.\n","cuda memory allocated: 23257088\n","> n_trainable_params: 1928403, n_nontrainable_params: 3884000\n","> training arguments:\n",">>> model_name: ian\n",">>> dataset: twitter_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f41d36e1c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 30\n",">>> embed_dim: 200\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 50\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.ian.IAN'>\n",">>> dataset_file: {'train': './datasets/twitter/output_know_insert/train.tsv', 'test': './datasets/twitter/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:32:37\n","loss: 1.1749, acc: 0.2708\n","E2E-ABSA >>> 2022-09-02 03:32:37\n","loss: 1.1120, acc: 0.2938\n","E2E-ABSA >>> 2022-09-02 03:32:38\n","loss: 1.0581, acc: 0.3819\n","E2E-ABSA >>> 2022-09-02 03:32:38\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">> saved: state_dict/ian_twitter_know_val_f1_0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:32:39\n","loss: 0.8465, acc: 0.7305\n","E2E-ABSA >>> 2022-09-02 03:32:39\n","loss: 0.8764, acc: 0.6685\n","E2E-ABSA >>> 2022-09-02 03:32:39\n","loss: 0.8679, acc: 0.6686\n","E2E-ABSA >>> 2022-09-02 03:32:40\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:32:40\n","loss: 0.9654, acc: 0.5625\n","E2E-ABSA >>> 2022-09-02 03:32:41\n","loss: 0.8514, acc: 0.6523\n","E2E-ABSA >>> 2022-09-02 03:32:41\n","loss: 0.8262, acc: 0.6744\n","E2E-ABSA >>> 2022-09-02 03:32:42\n","loss: 0.8287, acc: 0.6692\n","E2E-ABSA >>> 2022-09-02 03:32:42\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:32:42\n","loss: 0.8341, acc: 0.6528\n","E2E-ABSA >>> 2022-09-02 03:32:43\n","loss: 0.8252, acc: 0.6589\n","E2E-ABSA >>> 2022-09-02 03:32:43\n","loss: 0.8263, acc: 0.6627\n","E2E-ABSA >>> 2022-09-02 03:32:44\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:32:44\n","loss: 0.7594, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:32:44\n","loss: 0.7844, acc: 0.6838\n","E2E-ABSA >>> 2022-09-02 03:32:45\n","loss: 0.7920, acc: 0.6748\n","E2E-ABSA >>> 2022-09-02 03:32:45\n","loss: 0.8094, acc: 0.6676\n","E2E-ABSA >>> 2022-09-02 03:32:45\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:32:46\n","loss: 0.7965, acc: 0.6937\n","E2E-ABSA >>> 2022-09-02 03:32:46\n","loss: 0.8140, acc: 0.6787\n","E2E-ABSA >>> 2022-09-02 03:32:47\n","loss: 0.8117, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:32:47\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:32:47\n","loss: 0.8368, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:32:48\n","loss: 0.8398, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:32:48\n","loss: 0.8168, acc: 0.6648\n","E2E-ABSA >>> 2022-09-02 03:32:49\n","loss: 0.8067, acc: 0.6699\n","E2E-ABSA >>> 2022-09-02 03:32:49\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:32:49\n","loss: 0.8307, acc: 0.6591\n","E2E-ABSA >>> 2022-09-02 03:32:50\n","loss: 0.7937, acc: 0.6671\n","E2E-ABSA >>> 2022-09-02 03:32:50\n","loss: 0.8077, acc: 0.6662\n","E2E-ABSA >>> 2022-09-02 03:32:51\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:32:51\n","loss: 0.8497, acc: 0.6641\n","E2E-ABSA >>> 2022-09-02 03:32:51\n","loss: 0.7947, acc: 0.6743\n","E2E-ABSA >>> 2022-09-02 03:32:52\n","loss: 0.8007, acc: 0.6710\n","E2E-ABSA >>> 2022-09-02 03:32:52\n","loss: 0.7966, acc: 0.6728\n","E2E-ABSA >>> 2022-09-02 03:32:52\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:32:53\n","loss: 0.8523, acc: 0.6510\n","E2E-ABSA >>> 2022-09-02 03:32:53\n","loss: 0.8186, acc: 0.6609\n","E2E-ABSA >>> 2022-09-02 03:32:54\n","loss: 0.8021, acc: 0.6689\n","E2E-ABSA >>> 2022-09-02 03:32:54\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:32:54\n","loss: 0.9086, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 03:32:55\n","loss: 0.8184, acc: 0.6609\n","E2E-ABSA >>> 2022-09-02 03:32:55\n","loss: 0.8011, acc: 0.6634\n","E2E-ABSA >>> 2022-09-02 03:32:56\n","loss: 0.7971, acc: 0.6687\n","E2E-ABSA >>> 2022-09-02 03:32:56\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:32:56\n","loss: 0.8084, acc: 0.6611\n","E2E-ABSA >>> 2022-09-02 03:32:57\n","loss: 0.7923, acc: 0.6685\n","E2E-ABSA >>> 2022-09-02 03:32:57\n","loss: 0.7809, acc: 0.6766\n","E2E-ABSA >>> 2022-09-02 03:32:58\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:32:58\n","loss: 0.8579, acc: 0.5833\n","E2E-ABSA >>> 2022-09-02 03:32:58\n","loss: 0.8062, acc: 0.6473\n","E2E-ABSA >>> 2022-09-02 03:32:59\n","loss: 0.7876, acc: 0.6727\n","E2E-ABSA >>> 2022-09-02 03:32:59\n","loss: 0.7916, acc: 0.6697\n","E2E-ABSA >>> 2022-09-02 03:33:00\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:00\n","loss: 0.7750, acc: 0.6808\n","E2E-ABSA >>> 2022-09-02 03:33:00\n","loss: 0.7660, acc: 0.6929\n","E2E-ABSA >>> 2022-09-02 03:33:01\n","loss: 0.7789, acc: 0.6740\n","E2E-ABSA >>> 2022-09-02 03:33:01\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:02\n","loss: 0.7648, acc: 0.6830\n","E2E-ABSA >>> 2022-09-02 03:33:02\n","loss: 0.8098, acc: 0.6534\n","E2E-ABSA >>> 2022-09-02 03:33:02\n","loss: 0.8038, acc: 0.6571\n","E2E-ABSA >>> 2022-09-02 03:33:03\n","loss: 0.7882, acc: 0.6701\n","E2E-ABSA >>> 2022-09-02 03:33:03\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:04\n","loss: 0.7337, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:33:04\n","loss: 0.7843, acc: 0.6760\n","E2E-ABSA >>> 2022-09-02 03:33:04\n","loss: 0.7903, acc: 0.6687\n","E2E-ABSA >>> 2022-09-02 03:33:05\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:05\n","loss: 0.7272, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 03:33:06\n","loss: 0.7710, acc: 0.6821\n","E2E-ABSA >>> 2022-09-02 03:33:06\n","loss: 0.7787, acc: 0.6859\n","E2E-ABSA >>> 2022-09-02 03:33:07\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:07\n","loss: 0.8577, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 03:33:07\n","loss: 0.7762, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 03:33:08\n","loss: 0.7751, acc: 0.6774\n","E2E-ABSA >>> 2022-09-02 03:33:08\n","loss: 0.7887, acc: 0.6671\n","E2E-ABSA >>> 2022-09-02 03:33:08\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:09\n","loss: 0.7923, acc: 0.6632\n","E2E-ABSA >>> 2022-09-02 03:33:09\n","loss: 0.8204, acc: 0.6471\n","E2E-ABSA >>> 2022-09-02 03:33:10\n","loss: 0.7941, acc: 0.6659\n","E2E-ABSA >>> 2022-09-02 03:33:10\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:10\n","loss: 0.8844, acc: 0.5781\n","E2E-ABSA >>> 2022-09-02 03:33:11\n","loss: 0.8000, acc: 0.6599\n","E2E-ABSA >>> 2022-09-02 03:33:11\n","loss: 0.7896, acc: 0.6748\n","E2E-ABSA >>> 2022-09-02 03:33:12\n","loss: 0.7801, acc: 0.6722\n","E2E-ABSA >>> 2022-09-02 03:33:12\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:12\n","loss: 0.7415, acc: 0.7000\n","E2E-ABSA >>> 2022-09-02 03:33:13\n","loss: 0.7716, acc: 0.6675\n","E2E-ABSA >>> 2022-09-02 03:33:13\n","loss: 0.7640, acc: 0.6820\n","E2E-ABSA >>> 2022-09-02 03:33:14\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:14\n","loss: 0.7169, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 03:33:14\n","loss: 0.7564, acc: 0.6736\n","E2E-ABSA >>> 2022-09-02 03:33:15\n","loss: 0.7687, acc: 0.6780\n","E2E-ABSA >>> 2022-09-02 03:33:15\n","loss: 0.7758, acc: 0.6751\n","E2E-ABSA >>> 2022-09-02 03:33:15\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:16\n","loss: 0.7834, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:33:16\n","loss: 0.7642, acc: 0.6671\n","E2E-ABSA >>> 2022-09-02 03:33:17\n","loss: 0.7728, acc: 0.6662\n","E2E-ABSA >>> 2022-09-02 03:33:17\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:17\n","loss: 0.7590, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:33:18\n","loss: 0.7939, acc: 0.6694\n","E2E-ABSA >>> 2022-09-02 03:33:18\n","loss: 0.7640, acc: 0.6811\n","E2E-ABSA >>> 2022-09-02 03:33:19\n","loss: 0.7815, acc: 0.6665\n","E2E-ABSA >>> 2022-09-02 03:33:19\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:19\n","loss: 0.7307, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 03:33:20\n","loss: 0.7623, acc: 0.6794\n","E2E-ABSA >>> 2022-09-02 03:33:20\n","loss: 0.7666, acc: 0.6756\n","E2E-ABSA >>> 2022-09-02 03:33:21\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:21\n","loss: 0.7316, acc: 0.6750\n","E2E-ABSA >>> 2022-09-02 03:33:21\n","loss: 0.7525, acc: 0.6813\n","E2E-ABSA >>> 2022-09-02 03:33:22\n","loss: 0.7734, acc: 0.6696\n","E2E-ABSA >>> 2022-09-02 03:33:22\n","loss: 0.7762, acc: 0.6700\n","E2E-ABSA >>> 2022-09-02 03:33:23\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:23\n","loss: 0.7898, acc: 0.6538\n","E2E-ABSA >>> 2022-09-02 03:33:23\n","loss: 0.7828, acc: 0.6663\n","E2E-ABSA >>> 2022-09-02 03:33:24\n","loss: 0.7694, acc: 0.6693\n","E2E-ABSA >>> 2022-09-02 03:33:24\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:25\n","loss: 0.8853, acc: 0.6146\n","E2E-ABSA >>> 2022-09-02 03:33:25\n","loss: 0.8044, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:33:26\n","loss: 0.7817, acc: 0.6649\n","E2E-ABSA >>> 2022-09-02 03:33:26\n","loss: 0.7737, acc: 0.6685\n","E2E-ABSA >>> 2022-09-02 03:33:26\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:27\n","loss: 0.7239, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 03:33:27\n","loss: 0.7575, acc: 0.6810\n","E2E-ABSA >>> 2022-09-02 03:33:28\n","loss: 0.7672, acc: 0.6726\n","E2E-ABSA >>> 2022-09-02 03:33:28\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:28\n","loss: 0.6795, acc: 0.7321\n","E2E-ABSA >>> 2022-09-02 03:33:29\n","loss: 0.7623, acc: 0.6790\n","E2E-ABSA >>> 2022-09-02 03:33:29\n","loss: 0.7593, acc: 0.6731\n","E2E-ABSA >>> 2022-09-02 03:33:30\n","loss: 0.7675, acc: 0.6701\n","E2E-ABSA >>> 2022-09-02 03:33:30\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:30\n","loss: 0.7992, acc: 0.6417\n","E2E-ABSA >>> 2022-09-02 03:33:31\n","loss: 0.7924, acc: 0.6573\n","E2E-ABSA >>> 2022-09-02 03:33:31\n","loss: 0.7783, acc: 0.6625\n","E2E-ABSA >>> 2022-09-02 03:33:31\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:32\n","loss: 0.7442, acc: 0.6836\n","E2E-ABSA >>> 2022-09-02 03:33:32\n","loss: 0.7703, acc: 0.6698\n","E2E-ABSA >>> 2022-09-02 03:33:33\n","loss: 0.7636, acc: 0.6768\n","E2E-ABSA >>> 2022-09-02 03:33:33\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:33\n","loss: 0.7062, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:33:34\n","loss: 0.7788, acc: 0.6504\n","E2E-ABSA >>> 2022-09-02 03:33:34\n","loss: 0.7805, acc: 0.6522\n","E2E-ABSA >>> 2022-09-02 03:33:35\n","loss: 0.7631, acc: 0.6658\n","E2E-ABSA >>> 2022-09-02 03:33:35\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:35\n","loss: 0.7259, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:33:36\n","loss: 0.7706, acc: 0.6641\n","E2E-ABSA >>> 2022-09-02 03:33:36\n","loss: 0.7613, acc: 0.6723\n","E2E-ABSA >>> 2022-09-02 03:33:37\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:37\n","loss: 0.8350, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 03:33:37\n","loss: 0.7779, acc: 0.6526\n","E2E-ABSA >>> 2022-09-02 03:33:38\n","loss: 0.7515, acc: 0.6680\n","E2E-ABSA >>> 2022-09-02 03:33:38\n","loss: 0.7578, acc: 0.6715\n","E2E-ABSA >>> 2022-09-02 03:33:39\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:39\n","loss: 0.7036, acc: 0.7156\n","E2E-ABSA >>> 2022-09-02 03:33:39\n","loss: 0.7045, acc: 0.7013\n","E2E-ABSA >>> 2022-09-02 03:33:40\n","loss: 0.7499, acc: 0.6789\n","E2E-ABSA >>> 2022-09-02 03:33:40\n",">>> val_acc: 0.6850, val_precision: 0.6850 val_recall: 0.6850, val_f1: 0.6850\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:41\n","loss: 0.6997, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:33:41\n","loss: 0.7392, acc: 0.6962\n","E2E-ABSA >>> 2022-09-02 03:33:41\n","loss: 0.7492, acc: 0.6818\n","E2E-ABSA >>> 2022-09-02 03:33:42\n","loss: 0.7643, acc: 0.6693\n","E2E-ABSA >>> 2022-09-02 03:33:42\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:43\n","loss: 0.7547, acc: 0.6790\n","E2E-ABSA >>> 2022-09-02 03:33:43\n","loss: 0.7598, acc: 0.6647\n","E2E-ABSA >>> 2022-09-02 03:33:43\n","loss: 0.7724, acc: 0.6585\n","E2E-ABSA >>> 2022-09-02 03:33:44\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:44\n","loss: 0.7314, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:33:45\n","loss: 0.7547, acc: 0.6842\n","E2E-ABSA >>> 2022-09-02 03:33:45\n","loss: 0.7572, acc: 0.6737\n","E2E-ABSA >>> 2022-09-02 03:33:46\n","loss: 0.7557, acc: 0.6716\n","E2E-ABSA >>> 2022-09-02 03:33:46\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:46\n","loss: 0.7517, acc: 0.6641\n","E2E-ABSA >>> 2022-09-02 03:33:47\n","loss: 0.7502, acc: 0.6644\n","E2E-ABSA >>> 2022-09-02 03:33:47\n","loss: 0.7471, acc: 0.6763\n","E2E-ABSA >>> 2022-09-02 03:33:48\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:48\n","loss: 0.7570, acc: 0.6438\n","E2E-ABSA >>> 2022-09-02 03:33:48\n","loss: 0.7437, acc: 0.6687\n","E2E-ABSA >>> 2022-09-02 03:33:49\n","loss: 0.7574, acc: 0.6687\n","E2E-ABSA >>> 2022-09-02 03:33:49\n","loss: 0.7570, acc: 0.6681\n","E2E-ABSA >>> 2022-09-02 03:33:50\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:50\n","loss: 0.7743, acc: 0.6394\n","E2E-ABSA >>> 2022-09-02 03:33:51\n","loss: 0.7874, acc: 0.6462\n","E2E-ABSA >>> 2022-09-02 03:33:51\n","loss: 0.7583, acc: 0.6621\n","E2E-ABSA >>> 2022-09-02 03:33:52\n",">>> val_acc: 0.6897, val_precision: 0.6897 val_recall: 0.6897, val_f1: 0.6897\n",">> saved: state_dict/ian_twitter_know_val_f1_0.6897\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:52\n","loss: 0.7851, acc: 0.6302\n","E2E-ABSA >>> 2022-09-02 03:33:52\n","loss: 0.7639, acc: 0.6518\n","E2E-ABSA >>> 2022-09-02 03:33:53\n","loss: 0.7543, acc: 0.6606\n","E2E-ABSA >>> 2022-09-02 03:33:53\n","loss: 0.7512, acc: 0.6679\n","E2E-ABSA >>> 2022-09-02 03:33:53\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:54\n","loss: 0.7272, acc: 0.6920\n","E2E-ABSA >>> 2022-09-02 03:33:54\n","loss: 0.7563, acc: 0.6724\n","E2E-ABSA >>> 2022-09-02 03:33:55\n","loss: 0.7473, acc: 0.6726\n","E2E-ABSA >>> 2022-09-02 03:33:55\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:55\n","loss: 0.6997, acc: 0.6830\n","E2E-ABSA >>> 2022-09-02 03:33:56\n","loss: 0.7570, acc: 0.6648\n","E2E-ABSA >>> 2022-09-02 03:33:56\n","loss: 0.7580, acc: 0.6630\n","E2E-ABSA >>> 2022-09-02 03:33:57\n","loss: 0.7483, acc: 0.6671\n","E2E-ABSA >>> 2022-09-02 03:33:57\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">> saved: state_dict/ian_twitter_know_val_f1_0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:58\n","loss: 0.7876, acc: 0.6542\n","E2E-ABSA >>> 2022-09-02 03:33:58\n","loss: 0.7629, acc: 0.6729\n","E2E-ABSA >>> 2022-09-02 03:33:58\n","loss: 0.7536, acc: 0.6681\n","E2E-ABSA >>> 2022-09-02 03:33:59\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:33:59\n","loss: 0.7699, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:34:00\n","loss: 0.7379, acc: 0.6807\n","E2E-ABSA >>> 2022-09-02 03:34:00\n","loss: 0.7486, acc: 0.6669\n","E2E-ABSA >>> 2022-09-02 03:34:01\n",">>> val_acc: 0.6897, val_precision: 0.6897 val_recall: 0.6897, val_f1: 0.6897\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:01\n","loss: 0.6906, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:34:01\n","loss: 0.6859, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 03:34:02\n","loss: 0.7204, acc: 0.6835\n","E2E-ABSA >>> 2022-09-02 03:34:02\n","loss: 0.7309, acc: 0.6739\n","E2E-ABSA >>> 2022-09-02 03:34:02\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:03\n","loss: 0.7002, acc: 0.7118\n","E2E-ABSA >>> 2022-09-02 03:34:03\n","loss: 0.7058, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:34:04\n","loss: 0.7362, acc: 0.6827\n","E2E-ABSA >>> 2022-09-02 03:34:04\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">> saved: state_dict/ian_twitter_know_val_f1_0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:04\n","loss: 0.6206, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:34:05\n","loss: 0.7524, acc: 0.6636\n","E2E-ABSA >>> 2022-09-02 03:34:05\n","loss: 0.7597, acc: 0.6602\n","E2E-ABSA >>> 2022-09-02 03:34:06\n","loss: 0.7511, acc: 0.6649\n","E2E-ABSA >>> 2022-09-02 03:34:06\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:06\n","loss: 0.7489, acc: 0.6781\n","E2E-ABSA >>> 2022-09-02 03:34:07\n","loss: 0.7477, acc: 0.6713\n","E2E-ABSA >>> 2022-09-02 03:34:07\n","loss: 0.7501, acc: 0.6656\n","E2E-ABSA >>> 2022-09-02 03:34:08\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:08\n","loss: 0.7859, acc: 0.6042\n","E2E-ABSA >>> 2022-09-02 03:34:08\n","loss: 0.7423, acc: 0.6580\n","E2E-ABSA >>> 2022-09-02 03:34:09\n","loss: 0.7314, acc: 0.6695\n","E2E-ABSA >>> 2022-09-02 03:34:09\n","loss: 0.7326, acc: 0.6745\n","E2E-ABSA >>> 2022-09-02 03:34:10\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:10\n","loss: 0.7749, acc: 0.6619\n","E2E-ABSA >>> 2022-09-02 03:34:10\n","loss: 0.7642, acc: 0.6575\n","E2E-ABSA >>> 2022-09-02 03:34:11\n","loss: 0.7438, acc: 0.6707\n","E2E-ABSA >>> 2022-09-02 03:34:11\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:12\n","loss: 0.7127, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 03:34:12\n","loss: 0.7436, acc: 0.6579\n","E2E-ABSA >>> 2022-09-02 03:34:12\n","loss: 0.7423, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:34:13\n","loss: 0.7365, acc: 0.6767\n","E2E-ABSA >>> 2022-09-02 03:34:13\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:14\n","loss: 0.7664, acc: 0.6615\n","E2E-ABSA >>> 2022-09-02 03:34:14\n","loss: 0.7298, acc: 0.6759\n","E2E-ABSA >>> 2022-09-02 03:34:14\n","loss: 0.7314, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:34:15\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:15\n","loss: 0.7292, acc: 0.6625\n","E2E-ABSA >>> 2022-09-02 03:34:16\n","loss: 0.7605, acc: 0.6656\n","E2E-ABSA >>> 2022-09-02 03:34:16\n","loss: 0.7506, acc: 0.6705\n","E2E-ABSA >>> 2022-09-02 03:34:16\n","loss: 0.7313, acc: 0.6800\n","E2E-ABSA >>> 2022-09-02 03:34:17\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">> saved: state_dict/ian_twitter_know_val_f1_0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:17\n","loss: 0.7428, acc: 0.6707\n","E2E-ABSA >>> 2022-09-02 03:34:18\n","loss: 0.7214, acc: 0.6775\n","E2E-ABSA >>> 2022-09-02 03:34:18\n","loss: 0.7368, acc: 0.6722\n","E2E-ABSA >>> 2022-09-02 03:34:18\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:19\n","loss: 0.7351, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:34:19\n","loss: 0.7521, acc: 0.6637\n","E2E-ABSA >>> 2022-09-02 03:34:20\n","loss: 0.7379, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:34:20\n","loss: 0.7329, acc: 0.6820\n","E2E-ABSA >>> 2022-09-02 03:34:20\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:21\n","loss: 0.7214, acc: 0.6942\n","E2E-ABSA >>> 2022-09-02 03:34:21\n","loss: 0.7546, acc: 0.6746\n","E2E-ABSA >>> 2022-09-02 03:34:22\n","loss: 0.7234, acc: 0.6896\n","E2E-ABSA >>> 2022-09-02 03:34:22\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:22\n","loss: 0.7372, acc: 0.6607\n","E2E-ABSA >>> 2022-09-02 03:34:23\n","loss: 0.7432, acc: 0.6676\n","E2E-ABSA >>> 2022-09-02 03:34:23\n","loss: 0.7365, acc: 0.6791\n","E2E-ABSA >>> 2022-09-02 03:34:24\n","loss: 0.7258, acc: 0.6821\n","E2E-ABSA >>> 2022-09-02 03:34:24\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:24\n","loss: 0.7028, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:34:25\n","loss: 0.7182, acc: 0.6833\n","E2E-ABSA >>> 2022-09-02 03:34:25\n","loss: 0.7257, acc: 0.6799\n","E2E-ABSA >>> 2022-09-02 03:34:26\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:26\n","loss: 0.6773, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:34:26\n","loss: 0.7196, acc: 0.6834\n","E2E-ABSA >>> 2022-09-02 03:34:27\n","loss: 0.7241, acc: 0.6859\n","E2E-ABSA >>> 2022-09-02 03:34:27\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:27\n","loss: 0.6410, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:34:28\n","loss: 0.7175, acc: 0.6816\n","E2E-ABSA >>> 2022-09-02 03:34:28\n","loss: 0.7199, acc: 0.6845\n","E2E-ABSA >>> 2022-09-02 03:34:29\n","loss: 0.7266, acc: 0.6793\n","E2E-ABSA >>> 2022-09-02 03:34:29\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:29\n","loss: 0.6641, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:34:30\n","loss: 0.7050, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 03:34:30\n","loss: 0.7130, acc: 0.6955\n","E2E-ABSA >>> 2022-09-02 03:34:31\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:31\n","loss: 0.6297, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:34:32\n","loss: 0.7385, acc: 0.6783\n","E2E-ABSA >>> 2022-09-02 03:34:32\n","loss: 0.7171, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:34:32\n","loss: 0.7223, acc: 0.6882\n","E2E-ABSA >>> 2022-09-02 03:34:33\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:33\n","loss: 0.7155, acc: 0.6813\n","E2E-ABSA >>> 2022-09-02 03:34:34\n","loss: 0.7128, acc: 0.6950\n","E2E-ABSA >>> 2022-09-02 03:34:34\n","loss: 0.7077, acc: 0.6961\n","E2E-ABSA >>> 2022-09-02 03:34:35\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:35\n","loss: 0.6545, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:34:35\n","loss: 0.7238, acc: 0.6910\n","E2E-ABSA >>> 2022-09-02 03:34:36\n","loss: 0.7154, acc: 0.6903\n","E2E-ABSA >>> 2022-09-02 03:34:36\n","loss: 0.7202, acc: 0.6908\n","E2E-ABSA >>> 2022-09-02 03:34:36\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:37\n","loss: 0.7498, acc: 0.6705\n","E2E-ABSA >>> 2022-09-02 03:34:37\n","loss: 0.7120, acc: 0.6827\n","E2E-ABSA >>> 2022-09-02 03:34:38\n","loss: 0.7112, acc: 0.6883\n","E2E-ABSA >>> 2022-09-02 03:34:38\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:38\n","loss: 0.7071, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:34:39\n","loss: 0.6942, acc: 0.6891\n","E2E-ABSA >>> 2022-09-02 03:34:39\n","loss: 0.7069, acc: 0.6893\n","E2E-ABSA >>> 2022-09-02 03:34:40\n","loss: 0.7182, acc: 0.6913\n","E2E-ABSA >>> 2022-09-02 03:34:40\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:40\n","loss: 0.6761, acc: 0.7057\n","E2E-ABSA >>> 2022-09-02 03:34:41\n","loss: 0.7061, acc: 0.7002\n","E2E-ABSA >>> 2022-09-02 03:34:41\n","loss: 0.7153, acc: 0.6949\n","E2E-ABSA >>> 2022-09-02 03:34:42\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:42\n","loss: 0.8031, acc: 0.6375\n","E2E-ABSA >>> 2022-09-02 03:34:42\n","loss: 0.7600, acc: 0.6828\n","E2E-ABSA >>> 2022-09-02 03:34:43\n","loss: 0.7263, acc: 0.6937\n","E2E-ABSA >>> 2022-09-02 03:34:43\n","loss: 0.7121, acc: 0.7006\n","E2E-ABSA >>> 2022-09-02 03:34:44\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">> saved: state_dict/ian_twitter_know_val_f1_0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:44\n","loss: 0.7113, acc: 0.6971\n","E2E-ABSA >>> 2022-09-02 03:34:44\n","loss: 0.7018, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 03:34:45\n","loss: 0.7071, acc: 0.6948\n","E2E-ABSA >>> 2022-09-02 03:34:45\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">> saved: state_dict/ian_twitter_know_val_f1_0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:46\n","loss: 0.6213, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:34:46\n","loss: 0.7061, acc: 0.6935\n","E2E-ABSA >>> 2022-09-02 03:34:46\n","loss: 0.6974, acc: 0.7005\n","E2E-ABSA >>> 2022-09-02 03:34:47\n","loss: 0.7076, acc: 0.6936\n","E2E-ABSA >>> 2022-09-02 03:34:47\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:48\n","loss: 0.7275, acc: 0.6830\n","E2E-ABSA >>> 2022-09-02 03:34:48\n","loss: 0.7172, acc: 0.6897\n","E2E-ABSA >>> 2022-09-02 03:34:49\n","loss: 0.7115, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 03:34:49\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:49\n","loss: 0.7174, acc: 0.7009\n","E2E-ABSA >>> 2022-09-02 03:34:50\n","loss: 0.7234, acc: 0.6818\n","E2E-ABSA >>> 2022-09-02 03:34:50\n","loss: 0.7128, acc: 0.6926\n","E2E-ABSA >>> 2022-09-02 03:34:51\n","loss: 0.7031, acc: 0.6989\n","E2E-ABSA >>> 2022-09-02 03:34:51\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:51\n","loss: 0.7225, acc: 0.6896\n","E2E-ABSA >>> 2022-09-02 03:34:52\n","loss: 0.7112, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:34:52\n","loss: 0.7108, acc: 0.6944\n","E2E-ABSA >>> 2022-09-02 03:34:53\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:53\n","loss: 0.6157, acc: 0.7578\n","E2E-ABSA >>> 2022-09-02 03:34:53\n","loss: 0.6983, acc: 0.6957\n","E2E-ABSA >>> 2022-09-02 03:34:54\n","loss: 0.7041, acc: 0.6949\n","E2E-ABSA >>> 2022-09-02 03:34:54\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:54\n","loss: 0.7534, acc: 0.5625\n","E2E-ABSA >>> 2022-09-02 03:34:55\n","loss: 0.6711, acc: 0.6934\n","E2E-ABSA >>> 2022-09-02 03:34:55\n","loss: 0.7140, acc: 0.6623\n","E2E-ABSA >>> 2022-09-02 03:34:56\n","loss: 0.7023, acc: 0.6800\n","E2E-ABSA >>> 2022-09-02 03:34:56\n",">>> val_acc: 0.6969, val_precision: 0.6969 val_recall: 0.6969, val_f1: 0.6969\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:56\n","loss: 0.6925, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:34:57\n","loss: 0.6939, acc: 0.7044\n","E2E-ABSA >>> 2022-09-02 03:34:57\n","loss: 0.7022, acc: 0.7003\n","E2E-ABSA >>> 2022-09-02 03:34:58\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:34:58\n","loss: 0.4663, acc: 0.8281\n","E2E-ABSA >>> 2022-09-02 03:34:58\n","loss: 0.7034, acc: 0.6949\n","E2E-ABSA >>> 2022-09-02 03:34:59\n","loss: 0.6849, acc: 0.7051\n","E2E-ABSA >>> 2022-09-02 03:34:59\n","loss: 0.6891, acc: 0.6955\n","E2E-ABSA >>> 2022-09-02 03:35:00\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:00\n","loss: 0.6815, acc: 0.6750\n","E2E-ABSA >>> 2022-09-02 03:35:00\n","loss: 0.6821, acc: 0.6937\n","E2E-ABSA >>> 2022-09-02 03:35:01\n","loss: 0.6963, acc: 0.6969\n","E2E-ABSA >>> 2022-09-02 03:35:01\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:02\n","loss: 0.6775, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:35:02\n","loss: 0.6947, acc: 0.7066\n","E2E-ABSA >>> 2022-09-02 03:35:02\n","loss: 0.6923, acc: 0.7008\n","E2E-ABSA >>> 2022-09-02 03:35:03\n","loss: 0.6898, acc: 0.7025\n","E2E-ABSA >>> 2022-09-02 03:35:03\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:04\n","loss: 0.7117, acc: 0.6818\n","E2E-ABSA >>> 2022-09-02 03:35:04\n","loss: 0.6820, acc: 0.7091\n","E2E-ABSA >>> 2022-09-02 03:35:05\n","loss: 0.6871, acc: 0.7027\n","E2E-ABSA >>> 2022-09-02 03:35:05\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:05\n","loss: 0.6509, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 03:35:06\n","loss: 0.6494, acc: 0.7155\n","E2E-ABSA >>> 2022-09-02 03:35:06\n","loss: 0.6883, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 03:35:07\n","loss: 0.6911, acc: 0.7034\n","E2E-ABSA >>> 2022-09-02 03:35:07\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:07\n","loss: 0.6525, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:35:08\n","loss: 0.6710, acc: 0.7118\n","E2E-ABSA >>> 2022-09-02 03:35:08\n","loss: 0.6738, acc: 0.7054\n","E2E-ABSA >>> 2022-09-02 03:35:09\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:09\n","loss: 0.6102, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:35:09\n","loss: 0.6468, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:35:10\n","loss: 0.6797, acc: 0.7080\n","E2E-ABSA >>> 2022-09-02 03:35:10\n","loss: 0.6808, acc: 0.7113\n","E2E-ABSA >>> 2022-09-02 03:35:10\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:11\n","loss: 0.7006, acc: 0.7212\n","E2E-ABSA >>> 2022-09-02 03:35:11\n","loss: 0.6891, acc: 0.7121\n","E2E-ABSA >>> 2022-09-02 03:35:12\n","loss: 0.6896, acc: 0.7057\n","E2E-ABSA >>> 2022-09-02 03:35:12\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:12\n","loss: 0.7297, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:35:13\n","loss: 0.7118, acc: 0.7068\n","E2E-ABSA >>> 2022-09-02 03:35:13\n","loss: 0.6929, acc: 0.7127\n","E2E-ABSA >>> 2022-09-02 03:35:14\n","loss: 0.6877, acc: 0.7138\n","E2E-ABSA >>> 2022-09-02 03:35:14\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:14\n","loss: 0.6464, acc: 0.7254\n","E2E-ABSA >>> 2022-09-02 03:35:15\n","loss: 0.6757, acc: 0.7144\n","E2E-ABSA >>> 2022-09-02 03:35:15\n","loss: 0.6857, acc: 0.7145\n","E2E-ABSA >>> 2022-09-02 03:35:16\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:16\n","loss: 0.6897, acc: 0.7277\n","E2E-ABSA >>> 2022-09-02 03:35:16\n","loss: 0.6954, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 03:35:17\n","loss: 0.6735, acc: 0.7128\n","E2E-ABSA >>> 2022-09-02 03:35:17\n","loss: 0.6792, acc: 0.7145\n","E2E-ABSA >>> 2022-09-02 03:35:18\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 90.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:18\n","loss: 0.6681, acc: 0.6937\n","E2E-ABSA >>> 2022-09-02 03:35:18\n","loss: 0.6762, acc: 0.7146\n","E2E-ABSA >>> 2022-09-02 03:35:19\n","loss: 0.6646, acc: 0.7194\n","E2E-ABSA >>> 2022-09-02 03:35:19\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 91.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:20\n","loss: 0.5955, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 03:35:20\n","loss: 0.6520, acc: 0.7337\n","E2E-ABSA >>> 2022-09-02 03:35:21\n","loss: 0.6786, acc: 0.7155\n","E2E-ABSA >>> 2022-09-02 03:35:21\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 92.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:21\n","loss: 0.5908, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:35:22\n","loss: 0.6939, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 03:35:22\n","loss: 0.6817, acc: 0.7036\n","E2E-ABSA >>> 2022-09-02 03:35:23\n","loss: 0.6764, acc: 0.7120\n","E2E-ABSA >>> 2022-09-02 03:35:23\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 93.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:23\n","loss: 0.6109, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:35:24\n","loss: 0.6354, acc: 0.7422\n","E2E-ABSA >>> 2022-09-02 03:35:24\n","loss: 0.6583, acc: 0.7252\n","E2E-ABSA >>> 2022-09-02 03:35:25\n",">>> val_acc: 0.7041, val_precision: 0.7041 val_recall: 0.7041, val_f1: 0.7041\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 94.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:25\n","loss: 0.7685, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 03:35:25\n","loss: 0.6743, acc: 0.7132\n","E2E-ABSA >>> 2022-09-02 03:35:26\n","loss: 0.6860, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 03:35:26\n","loss: 0.6683, acc: 0.7181\n","E2E-ABSA >>> 2022-09-02 03:35:26\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 95.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:27\n","loss: 0.7332, acc: 0.6844\n","E2E-ABSA >>> 2022-09-02 03:35:27\n","loss: 0.6958, acc: 0.7050\n","E2E-ABSA >>> 2022-09-02 03:35:28\n","loss: 0.6775, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:35:28\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 96.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:28\n","loss: 0.7341, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:35:29\n","loss: 0.7119, acc: 0.6892\n","E2E-ABSA >>> 2022-09-02 03:35:29\n","loss: 0.6769, acc: 0.7131\n","E2E-ABSA >>> 2022-09-02 03:35:30\n","loss: 0.6685, acc: 0.7161\n","E2E-ABSA >>> 2022-09-02 03:35:30\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 97.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:30\n","loss: 0.6681, acc: 0.7216\n","E2E-ABSA >>> 2022-09-02 03:35:31\n","loss: 0.6735, acc: 0.7248\n","E2E-ABSA >>> 2022-09-02 03:35:31\n","loss: 0.6632, acc: 0.7317\n","E2E-ABSA >>> 2022-09-02 03:35:32\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 98.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:32\n","loss: 0.6117, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:35:32\n","loss: 0.6452, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:35:33\n","loss: 0.6513, acc: 0.7316\n","E2E-ABSA >>> 2022-09-02 03:35:33\n","loss: 0.6641, acc: 0.7168\n","E2E-ABSA >>> 2022-09-02 03:35:34\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 99.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 03:35:34\n","loss: 0.6998, acc: 0.6849\n","E2E-ABSA >>> 2022-09-02 03:35:35\n","loss: 0.6820, acc: 0.7176\n","E2E-ABSA >>> 2022-09-02 03:35:35\n","loss: 0.6747, acc: 0.7202\n","E2E-ABSA >>> 2022-09-02 03:35:35\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n","you can download the best model from state_dict/ian_twitter_know_val_f1_0.7136\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n",">>> test_acc: 0.7136, test_precision: 0.7136, test_recall: 0.7136, test_f1: 0.7136\n"]}]},{"cell_type":"markdown","source":["增加字典知识后: Training **Twitter** dataset on model(**memnet**)"],"metadata":{"id":"s-n19o_2mkKf"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name memnet --dataset twitter_know --embed_dim 200 --patience 50 --log_step 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GxT7MPn-mkYB","outputId":"c44f6f44-0e7c-4ec8-9e02-4151af6a8cce","executionInfo":{"status":"ok","timestamp":1662089858553,"user_tz":-480,"elapsed":120760,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.twitter.27B.200d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1664.\n","> testing dataset count: 419.\n","cuda memory allocated: 16186368\n","> n_trainable_params: 161803, n_nontrainable_params: 3884000\n","> training arguments:\n",">>> model_name: memnet\n",">>> dataset: twitter_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7fdbb9449c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 30\n",">>> embed_dim: 200\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 50\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.memnet.MemNet'>\n",">>> dataset_file: {'train': './datasets/twitter/output_know_insert/train.tsv', 'test': './datasets/twitter/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['context_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:04\n","loss: 1.0001, acc: 0.4188\n","E2E-ABSA >>> 2022-09-02 03:36:04\n","loss: 0.9537, acc: 0.5292\n","E2E-ABSA >>> 2022-09-02 03:36:04\n","loss: 0.9226, acc: 0.5715\n","E2E-ABSA >>> 2022-09-02 03:36:04\n",">>> val_acc: 0.6420, val_precision: 0.6420 val_recall: 0.6420, val_f1: 0.6420\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.642\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:04\n","loss: 0.8173, acc: 0.6680\n","E2E-ABSA >>> 2022-09-02 03:36:05\n","loss: 0.8370, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:36:05\n","loss: 0.8303, acc: 0.6546\n","E2E-ABSA >>> 2022-09-02 03:36:05\n",">>> val_acc: 0.6587, val_precision: 0.6587 val_recall: 0.6587, val_f1: 0.6587\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.6587\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:05\n","loss: 0.9307, acc: 0.5312\n","E2E-ABSA >>> 2022-09-02 03:36:05\n","loss: 0.8075, acc: 0.6406\n","E2E-ABSA >>> 2022-09-02 03:36:06\n","loss: 0.8219, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:36:06\n","loss: 0.8211, acc: 0.6535\n","E2E-ABSA >>> 2022-09-02 03:36:06\n",">>> val_acc: 0.6587, val_precision: 0.6587 val_recall: 0.6587, val_f1: 0.6587\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:06\n","loss: 0.7495, acc: 0.6910\n","E2E-ABSA >>> 2022-09-02 03:36:07\n","loss: 0.7812, acc: 0.6693\n","E2E-ABSA >>> 2022-09-02 03:36:07\n","loss: 0.7947, acc: 0.6675\n","E2E-ABSA >>> 2022-09-02 03:36:07\n",">>> val_acc: 0.6635, val_precision: 0.6635 val_recall: 0.6635, val_f1: 0.6635\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.6635\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:07\n","loss: 0.7705, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:36:07\n","loss: 0.7858, acc: 0.6710\n","E2E-ABSA >>> 2022-09-02 03:36:08\n","loss: 0.7857, acc: 0.6670\n","E2E-ABSA >>> 2022-09-02 03:36:08\n","loss: 0.7897, acc: 0.6709\n","E2E-ABSA >>> 2022-09-02 03:36:08\n",">>> val_acc: 0.6683, val_precision: 0.6683 val_recall: 0.6683, val_f1: 0.6683\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.6683\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:08\n","loss: 0.7578, acc: 0.6844\n","E2E-ABSA >>> 2022-09-02 03:36:08\n","loss: 0.7814, acc: 0.6737\n","E2E-ABSA >>> 2022-09-02 03:36:09\n","loss: 0.7866, acc: 0.6695\n","E2E-ABSA >>> 2022-09-02 03:36:09\n",">>> val_acc: 0.6706, val_precision: 0.6706 val_recall: 0.6706, val_f1: 0.6706\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.6706\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:09\n","loss: 0.7647, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:36:09\n","loss: 0.7865, acc: 0.6597\n","E2E-ABSA >>> 2022-09-02 03:36:09\n","loss: 0.7847, acc: 0.6695\n","E2E-ABSA >>> 2022-09-02 03:36:10\n","loss: 0.7774, acc: 0.6693\n","E2E-ABSA >>> 2022-09-02 03:36:10\n",">>> val_acc: 0.6659, val_precision: 0.6659 val_recall: 0.6659, val_f1: 0.6659\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:10\n","loss: 0.7071, acc: 0.7244\n","E2E-ABSA >>> 2022-09-02 03:36:10\n","loss: 0.7729, acc: 0.6671\n","E2E-ABSA >>> 2022-09-02 03:36:11\n","loss: 0.7763, acc: 0.6707\n","E2E-ABSA >>> 2022-09-02 03:36:11\n",">>> val_acc: 0.6754, val_precision: 0.6754 val_recall: 0.6754, val_f1: 0.6754\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.6754\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:11\n","loss: 0.7516, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 03:36:11\n","loss: 0.7232, acc: 0.7072\n","E2E-ABSA >>> 2022-09-02 03:36:11\n","loss: 0.7610, acc: 0.6756\n","E2E-ABSA >>> 2022-09-02 03:36:12\n","loss: 0.7565, acc: 0.6805\n","E2E-ABSA >>> 2022-09-02 03:36:12\n",">>> val_acc: 0.6730, val_precision: 0.6730 val_recall: 0.6730, val_f1: 0.6730\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:12\n","loss: 0.7300, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:36:12\n","loss: 0.7483, acc: 0.6748\n","E2E-ABSA >>> 2022-09-02 03:36:13\n","loss: 0.7527, acc: 0.6726\n","E2E-ABSA >>> 2022-09-02 03:36:13\n",">>> val_acc: 0.6802, val_precision: 0.6802 val_recall: 0.6802, val_f1: 0.6802\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.6802\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:13\n","loss: 0.7885, acc: 0.6750\n","E2E-ABSA >>> 2022-09-02 03:36:13\n","loss: 0.7722, acc: 0.6625\n","E2E-ABSA >>> 2022-09-02 03:36:13\n","loss: 0.7606, acc: 0.6634\n","E2E-ABSA >>> 2022-09-02 03:36:14\n","loss: 0.7565, acc: 0.6725\n","E2E-ABSA >>> 2022-09-02 03:36:14\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:14\n","loss: 0.7311, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:36:14\n","loss: 0.7348, acc: 0.6853\n","E2E-ABSA >>> 2022-09-02 03:36:14\n","loss: 0.7556, acc: 0.6751\n","E2E-ABSA >>> 2022-09-02 03:36:15\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:15\n","loss: 0.7361, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:36:15\n","loss: 0.7080, acc: 0.6920\n","E2E-ABSA >>> 2022-09-02 03:36:15\n","loss: 0.7365, acc: 0.6780\n","E2E-ABSA >>> 2022-09-02 03:36:15\n","loss: 0.7451, acc: 0.6746\n","E2E-ABSA >>> 2022-09-02 03:36:16\n",">>> val_acc: 0.6802, val_precision: 0.6802 val_recall: 0.6802, val_f1: 0.6802\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:16\n","loss: 0.7626, acc: 0.6629\n","E2E-ABSA >>> 2022-09-02 03:36:16\n","loss: 0.7426, acc: 0.6810\n","E2E-ABSA >>> 2022-09-02 03:36:16\n","loss: 0.7393, acc: 0.6811\n","E2E-ABSA >>> 2022-09-02 03:36:17\n",">>> val_acc: 0.6802, val_precision: 0.6802 val_recall: 0.6802, val_f1: 0.6802\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:17\n","loss: 0.7156, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:36:17\n","loss: 0.7335, acc: 0.6903\n","E2E-ABSA >>> 2022-09-02 03:36:17\n","loss: 0.7360, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:36:17\n","loss: 0.7345, acc: 0.6863\n","E2E-ABSA >>> 2022-09-02 03:36:18\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:18\n","loss: 0.7462, acc: 0.6833\n","E2E-ABSA >>> 2022-09-02 03:36:18\n","loss: 0.7589, acc: 0.6740\n","E2E-ABSA >>> 2022-09-02 03:36:18\n","loss: 0.7436, acc: 0.6806\n","E2E-ABSA >>> 2022-09-02 03:36:18\n",">>> val_acc: 0.6921, val_precision: 0.6921 val_recall: 0.6921, val_f1: 0.6921\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.6921\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:19\n","loss: 0.7335, acc: 0.6602\n","E2E-ABSA >>> 2022-09-02 03:36:19\n","loss: 0.7232, acc: 0.6834\n","E2E-ABSA >>> 2022-09-02 03:36:19\n","loss: 0.7326, acc: 0.6842\n","E2E-ABSA >>> 2022-09-02 03:36:19\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:19\n","loss: 0.7345, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 03:36:20\n","loss: 0.6962, acc: 0.7090\n","E2E-ABSA >>> 2022-09-02 03:36:20\n","loss: 0.7058, acc: 0.6996\n","E2E-ABSA >>> 2022-09-02 03:36:20\n","loss: 0.7162, acc: 0.6943\n","E2E-ABSA >>> 2022-09-02 03:36:20\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:21\n","loss: 0.7399, acc: 0.6736\n","E2E-ABSA >>> 2022-09-02 03:36:21\n","loss: 0.7334, acc: 0.6914\n","E2E-ABSA >>> 2022-09-02 03:36:21\n","loss: 0.7250, acc: 0.6939\n","E2E-ABSA >>> 2022-09-02 03:36:21\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:21\n","loss: 0.7434, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 03:36:22\n","loss: 0.6803, acc: 0.7206\n","E2E-ABSA >>> 2022-09-02 03:36:22\n","loss: 0.7082, acc: 0.7021\n","E2E-ABSA >>> 2022-09-02 03:36:22\n","loss: 0.7092, acc: 0.6988\n","E2E-ABSA >>> 2022-09-02 03:36:22\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:22\n","loss: 0.7156, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:36:23\n","loss: 0.6991, acc: 0.7050\n","E2E-ABSA >>> 2022-09-02 03:36:23\n","loss: 0.6982, acc: 0.7008\n","E2E-ABSA >>> 2022-09-02 03:36:23\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:23\n","loss: 0.6763, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 03:36:23\n","loss: 0.6842, acc: 0.7153\n","E2E-ABSA >>> 2022-09-02 03:36:24\n","loss: 0.7131, acc: 0.6941\n","E2E-ABSA >>> 2022-09-02 03:36:24\n","loss: 0.6990, acc: 0.7038\n","E2E-ABSA >>> 2022-09-02 03:36:24\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:24\n","loss: 0.7599, acc: 0.6733\n","E2E-ABSA >>> 2022-09-02 03:36:25\n","loss: 0.7230, acc: 0.6971\n","E2E-ABSA >>> 2022-09-02 03:36:25\n","loss: 0.7121, acc: 0.6974\n","E2E-ABSA >>> 2022-09-02 03:36:25\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:25\n","loss: 0.7041, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:36:25\n","loss: 0.6740, acc: 0.7171\n","E2E-ABSA >>> 2022-09-02 03:36:26\n","loss: 0.6950, acc: 0.6976\n","E2E-ABSA >>> 2022-09-02 03:36:26\n","loss: 0.7009, acc: 0.6990\n","E2E-ABSA >>> 2022-09-02 03:36:26\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:26\n","loss: 0.7189, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 03:36:26\n","loss: 0.7040, acc: 0.7060\n","E2E-ABSA >>> 2022-09-02 03:36:27\n","loss: 0.6995, acc: 0.7061\n","E2E-ABSA >>> 2022-09-02 03:36:27\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:27\n","loss: 0.7189, acc: 0.6937\n","E2E-ABSA >>> 2022-09-02 03:36:27\n","loss: 0.6828, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:36:28\n","loss: 0.6952, acc: 0.7080\n","E2E-ABSA >>> 2022-09-02 03:36:28\n","loss: 0.6972, acc: 0.7056\n","E2E-ABSA >>> 2022-09-02 03:36:28\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:28\n","loss: 0.7156, acc: 0.7163\n","E2E-ABSA >>> 2022-09-02 03:36:28\n","loss: 0.7007, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 03:36:29\n","loss: 0.6959, acc: 0.7093\n","E2E-ABSA >>> 2022-09-02 03:36:29\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:29\n","loss: 0.7455, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:36:29\n","loss: 0.6803, acc: 0.7158\n","E2E-ABSA >>> 2022-09-02 03:36:29\n","loss: 0.6736, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:36:30\n","loss: 0.6870, acc: 0.7108\n","E2E-ABSA >>> 2022-09-02 03:36:30\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:30\n","loss: 0.6819, acc: 0.7254\n","E2E-ABSA >>> 2022-09-02 03:36:30\n","loss: 0.6749, acc: 0.7231\n","E2E-ABSA >>> 2022-09-02 03:36:30\n","loss: 0.6960, acc: 0.7095\n","E2E-ABSA >>> 2022-09-02 03:36:31\n",">>> val_acc: 0.7255, val_precision: 0.7255 val_recall: 0.7255, val_f1: 0.7255\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.7255\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:31\n","loss: 0.6558, acc: 0.7232\n","E2E-ABSA >>> 2022-09-02 03:36:31\n","loss: 0.6910, acc: 0.7003\n","E2E-ABSA >>> 2022-09-02 03:36:31\n","loss: 0.6906, acc: 0.7095\n","E2E-ABSA >>> 2022-09-02 03:36:32\n","loss: 0.6821, acc: 0.7133\n","E2E-ABSA >>> 2022-09-02 03:36:32\n",">>> val_acc: 0.7255, val_precision: 0.7255 val_recall: 0.7255, val_f1: 0.7255\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:32\n","loss: 0.6729, acc: 0.7104\n","E2E-ABSA >>> 2022-09-02 03:36:32\n","loss: 0.6679, acc: 0.7104\n","E2E-ABSA >>> 2022-09-02 03:36:32\n","loss: 0.6754, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 03:36:33\n",">>> val_acc: 0.7279, val_precision: 0.7279 val_recall: 0.7279, val_f1: 0.7279\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.7279\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:33\n","loss: 0.6638, acc: 0.7305\n","E2E-ABSA >>> 2022-09-02 03:36:33\n","loss: 0.7034, acc: 0.7120\n","E2E-ABSA >>> 2022-09-02 03:36:33\n","loss: 0.6848, acc: 0.7196\n","E2E-ABSA >>> 2022-09-02 03:36:34\n",">>> val_acc: 0.7279, val_precision: 0.7279 val_recall: 0.7279, val_f1: 0.7279\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:34\n","loss: 0.8540, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 03:36:34\n","loss: 0.6734, acc: 0.7168\n","E2E-ABSA >>> 2022-09-02 03:36:34\n","loss: 0.6931, acc: 0.6986\n","E2E-ABSA >>> 2022-09-02 03:36:34\n","loss: 0.6694, acc: 0.7160\n","E2E-ABSA >>> 2022-09-02 03:36:34\n",">>> val_acc: 0.7255, val_precision: 0.7255 val_recall: 0.7255, val_f1: 0.7255\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:35\n","loss: 0.6728, acc: 0.7049\n","E2E-ABSA >>> 2022-09-02 03:36:35\n","loss: 0.6810, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 03:36:35\n","loss: 0.6709, acc: 0.7228\n","E2E-ABSA >>> 2022-09-02 03:36:35\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:36\n","loss: 0.6092, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:36:36\n","loss: 0.6685, acc: 0.7224\n","E2E-ABSA >>> 2022-09-02 03:36:36\n","loss: 0.6723, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:36:36\n","loss: 0.6667, acc: 0.7254\n","E2E-ABSA >>> 2022-09-02 03:36:36\n",">>> val_acc: 0.7255, val_precision: 0.7255 val_recall: 0.7255, val_f1: 0.7255\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:37\n","loss: 0.6701, acc: 0.7312\n","E2E-ABSA >>> 2022-09-02 03:36:37\n","loss: 0.6949, acc: 0.7037\n","E2E-ABSA >>> 2022-09-02 03:36:37\n","loss: 0.6781, acc: 0.7125\n","E2E-ABSA >>> 2022-09-02 03:36:37\n",">>> val_acc: 0.7375, val_precision: 0.7375 val_recall: 0.7375, val_f1: 0.7375\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.7375\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:37\n","loss: 0.7385, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:36:38\n","loss: 0.6625, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 03:36:38\n","loss: 0.6729, acc: 0.7159\n","E2E-ABSA >>> 2022-09-02 03:36:38\n","loss: 0.6656, acc: 0.7194\n","E2E-ABSA >>> 2022-09-02 03:36:38\n",">>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:38\n","loss: 0.6792, acc: 0.6932\n","E2E-ABSA >>> 2022-09-02 03:36:39\n","loss: 0.6830, acc: 0.7007\n","E2E-ABSA >>> 2022-09-02 03:36:39\n","loss: 0.6614, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:36:39\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:39\n","loss: 0.6893, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:36:39\n","loss: 0.6707, acc: 0.7089\n","E2E-ABSA >>> 2022-09-02 03:36:40\n","loss: 0.6682, acc: 0.7206\n","E2E-ABSA >>> 2022-09-02 03:36:40\n","loss: 0.6569, acc: 0.7270\n","E2E-ABSA >>> 2022-09-02 03:36:40\n",">>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:40\n","loss: 0.6497, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 03:36:41\n","loss: 0.6485, acc: 0.7245\n","E2E-ABSA >>> 2022-09-02 03:36:41\n","loss: 0.6479, acc: 0.7359\n","E2E-ABSA >>> 2022-09-02 03:36:41\n",">>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:41\n","loss: 0.6216, acc: 0.7125\n","E2E-ABSA >>> 2022-09-02 03:36:41\n","loss: 0.6384, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 03:36:42\n","loss: 0.6469, acc: 0.7330\n","E2E-ABSA >>> 2022-09-02 03:36:42\n","loss: 0.6509, acc: 0.7225\n","E2E-ABSA >>> 2022-09-02 03:36:42\n",">>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:42\n","loss: 0.6234, acc: 0.7332\n","E2E-ABSA >>> 2022-09-02 03:36:42\n","loss: 0.6320, acc: 0.7321\n","E2E-ABSA >>> 2022-09-02 03:36:43\n","loss: 0.6386, acc: 0.7340\n","E2E-ABSA >>> 2022-09-02 03:36:43\n",">>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:43\n","loss: 0.6310, acc: 0.7552\n","E2E-ABSA >>> 2022-09-02 03:36:43\n","loss: 0.6473, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 03:36:43\n","loss: 0.6585, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 03:36:44\n","loss: 0.6484, acc: 0.7304\n","E2E-ABSA >>> 2022-09-02 03:36:44\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:44\n","loss: 0.6501, acc: 0.7165\n","E2E-ABSA >>> 2022-09-02 03:36:44\n","loss: 0.6372, acc: 0.7328\n","E2E-ABSA >>> 2022-09-02 03:36:44\n","loss: 0.6474, acc: 0.7301\n","E2E-ABSA >>> 2022-09-02 03:36:45\n",">>> val_acc: 0.7327, val_precision: 0.7327 val_recall: 0.7327, val_f1: 0.7327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:45\n","loss: 0.6367, acc: 0.7411\n","E2E-ABSA >>> 2022-09-02 03:36:45\n","loss: 0.6600, acc: 0.7131\n","E2E-ABSA >>> 2022-09-02 03:36:45\n","loss: 0.6485, acc: 0.7196\n","E2E-ABSA >>> 2022-09-02 03:36:46\n","loss: 0.6427, acc: 0.7302\n","E2E-ABSA >>> 2022-09-02 03:36:46\n",">>> val_acc: 0.7303, val_precision: 0.7303 val_recall: 0.7303, val_f1: 0.7303\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:46\n","loss: 0.6234, acc: 0.7417\n","E2E-ABSA >>> 2022-09-02 03:36:46\n","loss: 0.6416, acc: 0.7302\n","E2E-ABSA >>> 2022-09-02 03:36:46\n","loss: 0.6393, acc: 0.7319\n","E2E-ABSA >>> 2022-09-02 03:36:47\n",">>> val_acc: 0.7327, val_precision: 0.7327 val_recall: 0.7327, val_f1: 0.7327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:47\n","loss: 0.7155, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:36:47\n","loss: 0.6494, acc: 0.7147\n","E2E-ABSA >>> 2022-09-02 03:36:47\n","loss: 0.6375, acc: 0.7311\n","E2E-ABSA >>> 2022-09-02 03:36:48\n",">>> val_acc: 0.7279, val_precision: 0.7279 val_recall: 0.7279, val_f1: 0.7279\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:48\n","loss: 0.5826, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 03:36:48\n","loss: 0.6441, acc: 0.7305\n","E2E-ABSA >>> 2022-09-02 03:36:48\n","loss: 0.6296, acc: 0.7389\n","E2E-ABSA >>> 2022-09-02 03:36:48\n","loss: 0.6328, acc: 0.7385\n","E2E-ABSA >>> 2022-09-02 03:36:49\n",">>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:49\n","loss: 0.6842, acc: 0.7222\n","E2E-ABSA >>> 2022-09-02 03:36:49\n","loss: 0.6385, acc: 0.7214\n","E2E-ABSA >>> 2022-09-02 03:36:49\n","loss: 0.6298, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 03:36:49\n",">>> val_acc: 0.7255, val_precision: 0.7255 val_recall: 0.7255, val_f1: 0.7255\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:49\n","loss: 0.5690, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 03:36:50\n","loss: 0.6332, acc: 0.7261\n","E2E-ABSA >>> 2022-09-02 03:36:50\n","loss: 0.6272, acc: 0.7324\n","E2E-ABSA >>> 2022-09-02 03:36:50\n","loss: 0.6317, acc: 0.7347\n","E2E-ABSA >>> 2022-09-02 03:36:50\n",">>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:50\n","loss: 0.6187, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:36:51\n","loss: 0.6207, acc: 0.7412\n","E2E-ABSA >>> 2022-09-02 03:36:51\n","loss: 0.6301, acc: 0.7367\n","E2E-ABSA >>> 2022-09-02 03:36:51\n",">>> val_acc: 0.7303, val_precision: 0.7303 val_recall: 0.7303, val_f1: 0.7303\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:51\n","loss: 0.5265, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:36:52\n","loss: 0.6338, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 03:36:52\n","loss: 0.6317, acc: 0.7263\n","E2E-ABSA >>> 2022-09-02 03:36:52\n","loss: 0.6297, acc: 0.7311\n","E2E-ABSA >>> 2022-09-02 03:36:52\n",">>> val_acc: 0.7208, val_precision: 0.7208 val_recall: 0.7208, val_f1: 0.7208\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:52\n","loss: 0.5625, acc: 0.7841\n","E2E-ABSA >>> 2022-09-02 03:36:53\n","loss: 0.5961, acc: 0.7596\n","E2E-ABSA >>> 2022-09-02 03:36:53\n","loss: 0.6304, acc: 0.7363\n","E2E-ABSA >>> 2022-09-02 03:36:53\n",">>> val_acc: 0.7399, val_precision: 0.7399 val_recall: 0.7399, val_f1: 0.7399\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.7399\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:53\n","loss: 0.6732, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:36:53\n","loss: 0.6271, acc: 0.7385\n","E2E-ABSA >>> 2022-09-02 03:36:54\n","loss: 0.6156, acc: 0.7491\n","E2E-ABSA >>> 2022-09-02 03:36:54\n","loss: 0.6255, acc: 0.7411\n","E2E-ABSA >>> 2022-09-02 03:36:54\n",">>> val_acc: 0.7375, val_precision: 0.7375 val_recall: 0.7375, val_f1: 0.7375\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:54\n","loss: 0.5960, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:36:54\n","loss: 0.6064, acc: 0.7465\n","E2E-ABSA >>> 2022-09-02 03:36:55\n","loss: 0.6143, acc: 0.7440\n","E2E-ABSA >>> 2022-09-02 03:36:55\n",">>> val_acc: 0.7399, val_precision: 0.7399 val_recall: 0.7399, val_f1: 0.7399\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:55\n","loss: 0.5531, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:36:55\n","loss: 0.5901, acc: 0.7562\n","E2E-ABSA >>> 2022-09-02 03:36:55\n","loss: 0.6090, acc: 0.7545\n","E2E-ABSA >>> 2022-09-02 03:36:56\n","loss: 0.6130, acc: 0.7488\n","E2E-ABSA >>> 2022-09-02 03:36:56\n",">>> val_acc: 0.7399, val_precision: 0.7399 val_recall: 0.7399, val_f1: 0.7399\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:56\n","loss: 0.5985, acc: 0.7548\n","E2E-ABSA >>> 2022-09-02 03:36:56\n","loss: 0.6201, acc: 0.7388\n","E2E-ABSA >>> 2022-09-02 03:36:56\n","loss: 0.6177, acc: 0.7456\n","E2E-ABSA >>> 2022-09-02 03:36:57\n",">>> val_acc: 0.7422, val_precision: 0.7422 val_recall: 0.7422, val_f1: 0.7422\n",">> saved: state_dict/memnet_twitter_know_val_f1_0.7422\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:57\n","loss: 0.6408, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 03:36:57\n","loss: 0.5961, acc: 0.7455\n","E2E-ABSA >>> 2022-09-02 03:36:57\n","loss: 0.5925, acc: 0.7517\n","E2E-ABSA >>> 2022-09-02 03:36:58\n","loss: 0.6164, acc: 0.7420\n","E2E-ABSA >>> 2022-09-02 03:36:58\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:58\n","loss: 0.5757, acc: 0.7679\n","E2E-ABSA >>> 2022-09-02 03:36:58\n","loss: 0.5953, acc: 0.7532\n","E2E-ABSA >>> 2022-09-02 03:36:58\n","loss: 0.6206, acc: 0.7372\n","E2E-ABSA >>> 2022-09-02 03:36:59\n",">>> val_acc: 0.7255, val_precision: 0.7255 val_recall: 0.7255, val_f1: 0.7255\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:36:59\n","loss: 0.5471, acc: 0.7723\n","E2E-ABSA >>> 2022-09-02 03:36:59\n","loss: 0.5962, acc: 0.7486\n","E2E-ABSA >>> 2022-09-02 03:36:59\n","loss: 0.5957, acc: 0.7551\n","E2E-ABSA >>> 2022-09-02 03:36:59\n","loss: 0.6122, acc: 0.7470\n","E2E-ABSA >>> 2022-09-02 03:37:00\n",">>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:00\n","loss: 0.5992, acc: 0.7667\n","E2E-ABSA >>> 2022-09-02 03:37:00\n","loss: 0.5895, acc: 0.7635\n","E2E-ABSA >>> 2022-09-02 03:37:00\n","loss: 0.6133, acc: 0.7472\n","E2E-ABSA >>> 2022-09-02 03:37:00\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:01\n","loss: 0.6076, acc: 0.7383\n","E2E-ABSA >>> 2022-09-02 03:37:01\n","loss: 0.5932, acc: 0.7582\n","E2E-ABSA >>> 2022-09-02 03:37:01\n","loss: 0.6022, acc: 0.7442\n","E2E-ABSA >>> 2022-09-02 03:37:01\n",">>> val_acc: 0.7422, val_precision: 0.7422 val_recall: 0.7422, val_f1: 0.7422\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:01\n","loss: 0.7138, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:37:02\n","loss: 0.6225, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:37:02\n","loss: 0.6032, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:37:02\n","loss: 0.6128, acc: 0.7385\n","E2E-ABSA >>> 2022-09-02 03:37:02\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:02\n","loss: 0.6398, acc: 0.7257\n","E2E-ABSA >>> 2022-09-02 03:37:03\n","loss: 0.6292, acc: 0.7448\n","E2E-ABSA >>> 2022-09-02 03:37:03\n","loss: 0.6074, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:37:03\n",">>> val_acc: 0.7399, val_precision: 0.7399 val_recall: 0.7399, val_f1: 0.7399\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:03\n","loss: 0.6189, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:37:03\n","loss: 0.5851, acc: 0.7426\n","E2E-ABSA >>> 2022-09-02 03:37:04\n","loss: 0.6217, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:37:04\n","loss: 0.6034, acc: 0.7480\n","E2E-ABSA >>> 2022-09-02 03:37:04\n",">>> val_acc: 0.7375, val_precision: 0.7375 val_recall: 0.7375, val_f1: 0.7375\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:04\n","loss: 0.6306, acc: 0.7250\n","E2E-ABSA >>> 2022-09-02 03:37:04\n","loss: 0.6153, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 03:37:05\n","loss: 0.5949, acc: 0.7570\n","E2E-ABSA >>> 2022-09-02 03:37:05\n",">>> val_acc: 0.7255, val_precision: 0.7255 val_recall: 0.7255, val_f1: 0.7255\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:05\n","loss: 0.5941, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 03:37:05\n","loss: 0.6089, acc: 0.7552\n","E2E-ABSA >>> 2022-09-02 03:37:06\n","loss: 0.5989, acc: 0.7576\n","E2E-ABSA >>> 2022-09-02 03:37:06\n","loss: 0.5969, acc: 0.7572\n","E2E-ABSA >>> 2022-09-02 03:37:06\n",">>> val_acc: 0.7303, val_precision: 0.7303 val_recall: 0.7303, val_f1: 0.7303\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:06\n","loss: 0.6850, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:37:06\n","loss: 0.6016, acc: 0.7596\n","E2E-ABSA >>> 2022-09-02 03:37:07\n","loss: 0.5936, acc: 0.7584\n","E2E-ABSA >>> 2022-09-02 03:37:07\n",">>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:07\n","loss: 0.5494, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 03:37:07\n","loss: 0.5933, acc: 0.7467\n","E2E-ABSA >>> 2022-09-02 03:37:07\n","loss: 0.5977, acc: 0.7546\n","E2E-ABSA >>> 2022-09-02 03:37:08\n","loss: 0.5922, acc: 0.7526\n","E2E-ABSA >>> 2022-09-02 03:37:08\n",">>> val_acc: 0.7375, val_precision: 0.7375 val_recall: 0.7375, val_f1: 0.7375\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:08\n","loss: 0.6134, acc: 0.7370\n","E2E-ABSA >>> 2022-09-02 03:37:08\n","loss: 0.6213, acc: 0.7442\n","E2E-ABSA >>> 2022-09-02 03:37:08\n","loss: 0.5995, acc: 0.7530\n","E2E-ABSA >>> 2022-09-02 03:37:09\n",">>> val_acc: 0.7399, val_precision: 0.7399 val_recall: 0.7399, val_f1: 0.7399\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:09\n","loss: 0.5566, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 03:37:09\n","loss: 0.6195, acc: 0.7391\n","E2E-ABSA >>> 2022-09-02 03:37:09\n","loss: 0.5846, acc: 0.7571\n","E2E-ABSA >>> 2022-09-02 03:37:09\n","loss: 0.5918, acc: 0.7588\n","E2E-ABSA >>> 2022-09-02 03:37:10\n",">>> val_acc: 0.7208, val_precision: 0.7208 val_recall: 0.7208, val_f1: 0.7208\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:10\n","loss: 0.5949, acc: 0.7404\n","E2E-ABSA >>> 2022-09-02 03:37:10\n","loss: 0.5934, acc: 0.7467\n","E2E-ABSA >>> 2022-09-02 03:37:10\n","loss: 0.6011, acc: 0.7507\n","E2E-ABSA >>> 2022-09-02 03:37:11\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:11\n","loss: 0.6121, acc: 0.7552\n","E2E-ABSA >>> 2022-09-02 03:37:11\n","loss: 0.5683, acc: 0.7783\n","E2E-ABSA >>> 2022-09-02 03:37:11\n","loss: 0.6083, acc: 0.7526\n","E2E-ABSA >>> 2022-09-02 03:37:11\n","loss: 0.5906, acc: 0.7665\n","E2E-ABSA >>> 2022-09-02 03:37:12\n",">>> val_acc: 0.7375, val_precision: 0.7375 val_recall: 0.7375, val_f1: 0.7375\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:12\n","loss: 0.5826, acc: 0.7746\n","E2E-ABSA >>> 2022-09-02 03:37:12\n","loss: 0.5836, acc: 0.7651\n","E2E-ABSA >>> 2022-09-02 03:37:12\n","loss: 0.5793, acc: 0.7649\n","E2E-ABSA >>> 2022-09-02 03:37:12\n",">>> val_acc: 0.7327, val_precision: 0.7327 val_recall: 0.7327, val_f1: 0.7327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:13\n","loss: 0.5365, acc: 0.7857\n","E2E-ABSA >>> 2022-09-02 03:37:13\n","loss: 0.5740, acc: 0.7699\n","E2E-ABSA >>> 2022-09-02 03:37:13\n","loss: 0.5781, acc: 0.7694\n","E2E-ABSA >>> 2022-09-02 03:37:13\n","loss: 0.5847, acc: 0.7620\n","E2E-ABSA >>> 2022-09-02 03:37:13\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:14\n","loss: 0.5652, acc: 0.7688\n","E2E-ABSA >>> 2022-09-02 03:37:14\n","loss: 0.5869, acc: 0.7542\n","E2E-ABSA >>> 2022-09-02 03:37:14\n","loss: 0.5848, acc: 0.7597\n","E2E-ABSA >>> 2022-09-02 03:37:14\n",">>> val_acc: 0.7279, val_precision: 0.7279 val_recall: 0.7279, val_f1: 0.7279\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:14\n","loss: 0.6134, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:37:15\n","loss: 0.6111, acc: 0.7418\n","E2E-ABSA >>> 2022-09-02 03:37:15\n","loss: 0.6010, acc: 0.7508\n","E2E-ABSA >>> 2022-09-02 03:37:15\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:15\n","loss: 0.6017, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:37:16\n","loss: 0.5820, acc: 0.7559\n","E2E-ABSA >>> 2022-09-02 03:37:16\n","loss: 0.5870, acc: 0.7560\n","E2E-ABSA >>> 2022-09-02 03:37:16\n","loss: 0.5857, acc: 0.7568\n","E2E-ABSA >>> 2022-09-02 03:37:16\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:16\n","loss: 0.5556, acc: 0.7674\n","E2E-ABSA >>> 2022-09-02 03:37:17\n","loss: 0.5710, acc: 0.7747\n","E2E-ABSA >>> 2022-09-02 03:37:17\n","loss: 0.5760, acc: 0.7620\n","E2E-ABSA >>> 2022-09-02 03:37:17\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:17\n","loss: 0.6851, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:37:17\n","loss: 0.6146, acc: 0.7445\n","E2E-ABSA >>> 2022-09-02 03:37:18\n","loss: 0.5861, acc: 0.7598\n","E2E-ABSA >>> 2022-09-02 03:37:18\n","loss: 0.5810, acc: 0.7573\n","E2E-ABSA >>> 2022-09-02 03:37:18\n",">>> val_acc: 0.7399, val_precision: 0.7399 val_recall: 0.7399, val_f1: 0.7399\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:18\n","loss: 0.6437, acc: 0.7094\n","E2E-ABSA >>> 2022-09-02 03:37:18\n","loss: 0.6009, acc: 0.7512\n","E2E-ABSA >>> 2022-09-02 03:37:19\n","loss: 0.5776, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 03:37:19\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:19\n","loss: 0.7019, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:37:19\n","loss: 0.5735, acc: 0.7691\n","E2E-ABSA >>> 2022-09-02 03:37:19\n","loss: 0.5887, acc: 0.7595\n","E2E-ABSA >>> 2022-09-02 03:37:20\n","loss: 0.5736, acc: 0.7715\n","E2E-ABSA >>> 2022-09-02 03:37:20\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:20\n","loss: 0.5956, acc: 0.7557\n","E2E-ABSA >>> 2022-09-02 03:37:20\n","loss: 0.5703, acc: 0.7704\n","E2E-ABSA >>> 2022-09-02 03:37:21\n","loss: 0.5723, acc: 0.7668\n","E2E-ABSA >>> 2022-09-02 03:37:21\n",">>> val_acc: 0.7327, val_precision: 0.7327 val_recall: 0.7327, val_f1: 0.7327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:21\n","loss: 0.5764, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:37:21\n","loss: 0.6183, acc: 0.7467\n","E2E-ABSA >>> 2022-09-02 03:37:21\n","loss: 0.5871, acc: 0.7564\n","E2E-ABSA >>> 2022-09-02 03:37:22\n","loss: 0.5793, acc: 0.7602\n","E2E-ABSA >>> 2022-09-02 03:37:22\n",">>> val_acc: 0.7375, val_precision: 0.7375 val_recall: 0.7375, val_f1: 0.7375\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:22\n","loss: 0.5603, acc: 0.7422\n","E2E-ABSA >>> 2022-09-02 03:37:22\n","loss: 0.5824, acc: 0.7546\n","E2E-ABSA >>> 2022-09-02 03:37:22\n","loss: 0.5716, acc: 0.7664\n","E2E-ABSA >>> 2022-09-02 03:37:23\n",">>> val_acc: 0.7422, val_precision: 0.7422 val_recall: 0.7422, val_f1: 0.7422\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:23\n","loss: 0.5460, acc: 0.7750\n","E2E-ABSA >>> 2022-09-02 03:37:23\n","loss: 0.5493, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:37:23\n","loss: 0.5642, acc: 0.7705\n","E2E-ABSA >>> 2022-09-02 03:37:24\n","loss: 0.5716, acc: 0.7675\n","E2E-ABSA >>> 2022-09-02 03:37:24\n",">>> val_acc: 0.7232, val_precision: 0.7232 val_recall: 0.7232, val_f1: 0.7232\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:24\n","loss: 0.5267, acc: 0.7933\n","E2E-ABSA >>> 2022-09-02 03:37:24\n","loss: 0.5650, acc: 0.7589\n","E2E-ABSA >>> 2022-09-02 03:37:24\n","loss: 0.5689, acc: 0.7638\n","E2E-ABSA >>> 2022-09-02 03:37:25\n",">>> val_acc: 0.7327, val_precision: 0.7327 val_recall: 0.7327, val_f1: 0.7327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:25\n","loss: 0.5341, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:37:25\n","loss: 0.5624, acc: 0.7679\n","E2E-ABSA >>> 2022-09-02 03:37:25\n","loss: 0.5648, acc: 0.7734\n","E2E-ABSA >>> 2022-09-02 03:37:25\n","loss: 0.5681, acc: 0.7690\n","E2E-ABSA >>> 2022-09-02 03:37:26\n",">>> val_acc: 0.7422, val_precision: 0.7422 val_recall: 0.7422, val_f1: 0.7422\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:26\n","loss: 0.5773, acc: 0.7545\n","E2E-ABSA >>> 2022-09-02 03:37:26\n","loss: 0.5754, acc: 0.7640\n","E2E-ABSA >>> 2022-09-02 03:37:26\n","loss: 0.5722, acc: 0.7670\n","E2E-ABSA >>> 2022-09-02 03:37:26\n",">>> val_acc: 0.7375, val_precision: 0.7375 val_recall: 0.7375, val_f1: 0.7375\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:27\n","loss: 0.5669, acc: 0.7723\n","E2E-ABSA >>> 2022-09-02 03:37:27\n","loss: 0.5681, acc: 0.7685\n","E2E-ABSA >>> 2022-09-02 03:37:27\n","loss: 0.5580, acc: 0.7770\n","E2E-ABSA >>> 2022-09-02 03:37:27\n","loss: 0.5655, acc: 0.7698\n","E2E-ABSA >>> 2022-09-02 03:37:27\n",">>> val_acc: 0.7422, val_precision: 0.7422 val_recall: 0.7422, val_f1: 0.7422\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 90.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:28\n","loss: 0.5484, acc: 0.7771\n","E2E-ABSA >>> 2022-09-02 03:37:28\n","loss: 0.5494, acc: 0.7740\n","E2E-ABSA >>> 2022-09-02 03:37:28\n","loss: 0.5598, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 03:37:28\n",">>> val_acc: 0.7279, val_precision: 0.7279 val_recall: 0.7279, val_f1: 0.7279\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 91.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:28\n","loss: 0.5480, acc: 0.7891\n","E2E-ABSA >>> 2022-09-02 03:37:29\n","loss: 0.5512, acc: 0.7704\n","E2E-ABSA >>> 2022-09-02 03:37:29\n","loss: 0.5638, acc: 0.7681\n","E2E-ABSA >>> 2022-09-02 03:37:29\n",">>> val_acc: 0.7327, val_precision: 0.7327 val_recall: 0.7327, val_f1: 0.7327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 92.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:29\n","loss: 0.5695, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:37:30\n","loss: 0.5917, acc: 0.7559\n","E2E-ABSA >>> 2022-09-02 03:37:30\n","loss: 0.5618, acc: 0.7722\n","E2E-ABSA >>> 2022-09-02 03:37:30\n","loss: 0.5511, acc: 0.7758\n","E2E-ABSA >>> 2022-09-02 03:37:30\n",">>> val_acc: 0.7303, val_precision: 0.7303 val_recall: 0.7303, val_f1: 0.7303\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 93.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:30\n","loss: 0.6298, acc: 0.7431\n","E2E-ABSA >>> 2022-09-02 03:37:31\n","loss: 0.5979, acc: 0.7591\n","E2E-ABSA >>> 2022-09-02 03:37:31\n","loss: 0.5752, acc: 0.7628\n","E2E-ABSA >>> 2022-09-02 03:37:31\n",">>> val_acc: 0.7303, val_precision: 0.7303 val_recall: 0.7303, val_f1: 0.7303\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 94.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:31\n","loss: 0.6087, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 03:37:31\n","loss: 0.5541, acc: 0.7757\n","E2E-ABSA >>> 2022-09-02 03:37:32\n","loss: 0.5537, acc: 0.7754\n","E2E-ABSA >>> 2022-09-02 03:37:32\n","loss: 0.5676, acc: 0.7673\n","E2E-ABSA >>> 2022-09-02 03:37:32\n",">>> val_acc: 0.7399, val_precision: 0.7399 val_recall: 0.7399, val_f1: 0.7399\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 95.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:32\n","loss: 0.5585, acc: 0.7469\n","E2E-ABSA >>> 2022-09-02 03:37:32\n","loss: 0.5299, acc: 0.7775\n","E2E-ABSA >>> 2022-09-02 03:37:33\n","loss: 0.5486, acc: 0.7641\n","E2E-ABSA >>> 2022-09-02 03:37:33\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 96.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:33\n","loss: 0.5598, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 03:37:33\n","loss: 0.5438, acc: 0.7743\n","E2E-ABSA >>> 2022-09-02 03:37:33\n","loss: 0.5583, acc: 0.7699\n","E2E-ABSA >>> 2022-09-02 03:37:34\n","loss: 0.5564, acc: 0.7721\n","E2E-ABSA >>> 2022-09-02 03:37:34\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 97.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:34\n","loss: 0.5446, acc: 0.7898\n","E2E-ABSA >>> 2022-09-02 03:37:34\n","loss: 0.5469, acc: 0.7788\n","E2E-ABSA >>> 2022-09-02 03:37:35\n","loss: 0.5508, acc: 0.7713\n","E2E-ABSA >>> 2022-09-02 03:37:35\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 98.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:35\n","loss: 0.5198, acc: 0.7891\n","E2E-ABSA >>> 2022-09-02 03:37:35\n","loss: 0.5605, acc: 0.7599\n","E2E-ABSA >>> 2022-09-02 03:37:35\n","loss: 0.5345, acc: 0.7840\n","E2E-ABSA >>> 2022-09-02 03:37:36\n","loss: 0.5569, acc: 0.7691\n","E2E-ABSA >>> 2022-09-02 03:37:36\n",">>> val_acc: 0.7303, val_precision: 0.7303 val_recall: 0.7303, val_f1: 0.7303\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 99.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 03:37:36\n","loss: 0.5280, acc: 0.7839\n","E2E-ABSA >>> 2022-09-02 03:37:36\n","loss: 0.5415, acc: 0.7766\n","E2E-ABSA >>> 2022-09-02 03:37:36\n","loss: 0.5462, acc: 0.7783\n","E2E-ABSA >>> 2022-09-02 03:37:37\n",">>> val_acc: 0.7303, val_precision: 0.7303 val_recall: 0.7303, val_f1: 0.7303\n","you can download the best model from state_dict/memnet_twitter_know_val_f1_0.7422\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",">>> test_acc: 0.7422, test_precision: 0.7422, test_recall: 0.7422, test_f1: 0.7422\n"]}]},{"cell_type":"markdown","source":["增加字典知识后: Training **Twitter** dataset on model(**cabasc**)"],"metadata":{"id":"3eOyBSFOnC9T"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name cabasc --dataset twitter_know --embed_dim 200 --patience 50 --log_step 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtVmB55KnDKW","outputId":"d67a7fd5-a313-4fe9-c60d-e9353ad6e714","executionInfo":{"status":"ok","timestamp":1662090469039,"user_tz":-480,"elapsed":610497,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.twitter.27B.200d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1245.\n","> testing dataset count: 332.\n","cuda memory allocated: 19801600\n","> n_trainable_params: 1065405, n_nontrainable_params: 3884000\n","> training arguments:\n",">>> model_name: cabasc\n",">>> dataset: twitter_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f05b8dcec20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 30\n",">>> embed_dim: 200\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 50\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.cabasc.Cabasc'>\n",">>> dataset_file: {'train': './datasets/twitter/output_know_insert/train.tsv', 'test': './datasets/twitter/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices', 'left_with_aspect_indices', 'right_with_aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 03:38:06\n","loss: 1.2934, acc: 0.2021\n","E2E-ABSA >>> 2022-09-02 03:38:08\n","loss: 1.2392, acc: 0.2271\n","E2E-ABSA >>> 2022-09-02 03:38:10\n",">>> val_acc: 0.3102, val_precision: 0.3102 val_recall: 0.3102, val_f1: 0.3102\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.3102\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 03:38:11\n","loss: 1.0934, acc: 0.3594\n","E2E-ABSA >>> 2022-09-02 03:38:12\n","loss: 1.0674, acc: 0.4345\n","E2E-ABSA >>> 2022-09-02 03:38:14\n","loss: 1.0383, acc: 0.4974\n","E2E-ABSA >>> 2022-09-02 03:38:16\n",">>> val_acc: 0.6265, val_precision: 0.6265 val_recall: 0.6265, val_f1: 0.6265\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.6265\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 03:38:17\n","loss: 0.9525, acc: 0.6354\n","E2E-ABSA >>> 2022-09-02 03:38:19\n","loss: 0.9364, acc: 0.6424\n","E2E-ABSA >>> 2022-09-02 03:38:21\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 03:38:22\n","loss: 0.8902, acc: 0.6146\n","E2E-ABSA >>> 2022-09-02 03:38:24\n","loss: 0.8598, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:38:25\n","loss: 0.8663, acc: 0.6572\n","E2E-ABSA >>> 2022-09-02 03:38:27\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 03:38:28\n","loss: 0.8619, acc: 0.6389\n","E2E-ABSA >>> 2022-09-02 03:38:30\n","loss: 0.8560, acc: 0.6458\n","E2E-ABSA >>> 2022-09-02 03:38:32\n","loss: 0.8365, acc: 0.6546\n","E2E-ABSA >>> 2022-09-02 03:38:33\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 03:38:35\n","loss: 0.8161, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:38:37\n","loss: 0.8287, acc: 0.6500\n","E2E-ABSA >>> 2022-09-02 03:38:39\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 03:38:40\n","loss: 0.7768, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:38:42\n","loss: 0.7962, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:38:43\n","loss: 0.8135, acc: 0.6571\n","E2E-ABSA >>> 2022-09-02 03:38:45\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 03:38:46\n","loss: 0.7859, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:38:48\n","loss: 0.7978, acc: 0.6609\n","E2E-ABSA >>> 2022-09-02 03:38:51\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 03:38:51\n","loss: 0.8098, acc: 0.6458\n","E2E-ABSA >>> 2022-09-02 03:38:53\n","loss: 0.7793, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:38:55\n","loss: 0.7884, acc: 0.6638\n","E2E-ABSA >>> 2022-09-02 03:38:56\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 03:38:58\n","loss: 0.7880, acc: 0.6632\n","E2E-ABSA >>> 2022-09-02 03:38:59\n","loss: 0.8175, acc: 0.6445\n","E2E-ABSA >>> 2022-09-02 03:39:01\n","loss: 0.8012, acc: 0.6554\n","E2E-ABSA >>> 2022-09-02 03:39:02\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 03:39:04\n","loss: 0.7730, acc: 0.6854\n","E2E-ABSA >>> 2022-09-02 03:39:06\n","loss: 0.7799, acc: 0.6729\n","E2E-ABSA >>> 2022-09-02 03:39:08\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 03:39:09\n","loss: 0.8353, acc: 0.6198\n","E2E-ABSA >>> 2022-09-02 03:39:11\n","loss: 0.8123, acc: 0.6503\n","E2E-ABSA >>> 2022-09-02 03:39:13\n","loss: 0.7948, acc: 0.6597\n","E2E-ABSA >>> 2022-09-02 03:39:14\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 03:39:15\n","loss: 0.7617, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:39:17\n","loss: 0.7780, acc: 0.6701\n","E2E-ABSA >>> 2022-09-02 03:39:20\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 03:39:20\n","loss: 0.7048, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:39:22\n","loss: 0.7760, acc: 0.6753\n","E2E-ABSA >>> 2022-09-02 03:39:24\n","loss: 0.7970, acc: 0.6534\n","E2E-ABSA >>> 2022-09-02 03:39:25\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 03:39:26\n","loss: 0.8083, acc: 0.6424\n","E2E-ABSA >>> 2022-09-02 03:39:28\n","loss: 0.8045, acc: 0.6523\n","E2E-ABSA >>> 2022-09-02 03:39:30\n","loss: 0.7900, acc: 0.6578\n","E2E-ABSA >>> 2022-09-02 03:39:31\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 03:39:33\n","loss: 0.7816, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:39:35\n","loss: 0.7850, acc: 0.6521\n","E2E-ABSA >>> 2022-09-02 03:39:37\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 03:39:38\n","loss: 0.8361, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 03:39:40\n","loss: 0.7722, acc: 0.6711\n","E2E-ABSA >>> 2022-09-02 03:39:42\n","loss: 0.7819, acc: 0.6597\n","E2E-ABSA >>> 2022-09-02 03:39:43\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 03:39:45\n","loss: 0.7717, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:39:46\n","loss: 0.7849, acc: 0.6493\n","E2E-ABSA >>> 2022-09-02 03:39:49\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 03:39:49\n","loss: 0.7500, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:39:51\n","loss: 0.7731, acc: 0.6684\n","E2E-ABSA >>> 2022-09-02 03:39:53\n","loss: 0.7863, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:39:55\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 03:39:56\n","loss: 0.8192, acc: 0.6458\n","E2E-ABSA >>> 2022-09-02 03:39:58\n","loss: 0.7950, acc: 0.6536\n","E2E-ABSA >>> 2022-09-02 03:39:59\n","loss: 0.7792, acc: 0.6602\n","E2E-ABSA >>> 2022-09-02 03:40:00\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 03:40:02\n","loss: 0.7675, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:40:04\n","loss: 0.7750, acc: 0.6615\n","E2E-ABSA >>> 2022-09-02 03:40:06\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 03:40:07\n","loss: 0.7672, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:40:09\n","loss: 0.7799, acc: 0.6458\n","E2E-ABSA >>> 2022-09-02 03:40:11\n","loss: 0.7686, acc: 0.6589\n","E2E-ABSA >>> 2022-09-02 03:40:12\n",">>> val_acc: 0.6717, val_precision: 0.6717 val_recall: 0.6717, val_f1: 0.6717\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.6717\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 03:40:14\n","loss: 0.7444, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:40:15\n","loss: 0.7848, acc: 0.6470\n","E2E-ABSA >>> 2022-09-02 03:40:18\n",">>> val_acc: 0.6717, val_precision: 0.6717 val_recall: 0.6717, val_f1: 0.6717\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 03:40:18\n","loss: 0.7575, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 03:40:20\n","loss: 0.8041, acc: 0.6441\n","E2E-ABSA >>> 2022-09-02 03:40:22\n","loss: 0.7705, acc: 0.6676\n","E2E-ABSA >>> 2022-09-02 03:40:24\n",">>> val_acc: 0.6717, val_precision: 0.6717 val_recall: 0.6717, val_f1: 0.6717\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 03:40:25\n","loss: 0.7351, acc: 0.7014\n","E2E-ABSA >>> 2022-09-02 03:40:27\n","loss: 0.7648, acc: 0.6693\n","E2E-ABSA >>> 2022-09-02 03:40:28\n","loss: 0.7618, acc: 0.6683\n","E2E-ABSA >>> 2022-09-02 03:40:29\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 03:40:31\n","loss: 0.7584, acc: 0.6729\n","E2E-ABSA >>> 2022-09-02 03:40:33\n","loss: 0.7482, acc: 0.6708\n","E2E-ABSA >>> 2022-09-02 03:40:35\n",">>> val_acc: 0.6777, val_precision: 0.6777 val_recall: 0.6777, val_f1: 0.6777\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.6777\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 03:40:36\n","loss: 0.7899, acc: 0.6615\n","E2E-ABSA >>> 2022-09-02 03:40:38\n","loss: 0.7394, acc: 0.6905\n","E2E-ABSA >>> 2022-09-02 03:40:40\n","loss: 0.7418, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:40:41\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 03:40:42\n","loss: 0.7579, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:40:44\n","loss: 0.7475, acc: 0.6852\n","E2E-ABSA >>> 2022-09-02 03:40:47\n",">>> val_acc: 0.6807, val_precision: 0.6807 val_recall: 0.6807, val_f1: 0.6807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 03:40:47\n","loss: 0.7866, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:40:49\n","loss: 0.7278, acc: 0.6910\n","E2E-ABSA >>> 2022-09-02 03:40:51\n","loss: 0.7278, acc: 0.6932\n","E2E-ABSA >>> 2022-09-02 03:40:53\n",">>> val_acc: 0.6777, val_precision: 0.6777 val_recall: 0.6777, val_f1: 0.6777\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 03:40:54\n","loss: 0.7323, acc: 0.6840\n","E2E-ABSA >>> 2022-09-02 03:40:55\n","loss: 0.7326, acc: 0.6888\n","E2E-ABSA >>> 2022-09-02 03:40:57\n","loss: 0.7421, acc: 0.6932\n","E2E-ABSA >>> 2022-09-02 03:40:58\n",">>> val_acc: 0.6777, val_precision: 0.6777 val_recall: 0.6777, val_f1: 0.6777\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 03:41:00\n","loss: 0.7398, acc: 0.6854\n","E2E-ABSA >>> 2022-09-02 03:41:02\n","loss: 0.7435, acc: 0.6844\n","E2E-ABSA >>> 2022-09-02 03:41:04\n",">>> val_acc: 0.6837, val_precision: 0.6837 val_recall: 0.6837, val_f1: 0.6837\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.6837\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 03:41:05\n","loss: 0.7067, acc: 0.6823\n","E2E-ABSA >>> 2022-09-02 03:41:07\n","loss: 0.7371, acc: 0.6815\n","E2E-ABSA >>> 2022-09-02 03:41:08\n","loss: 0.7436, acc: 0.6901\n","E2E-ABSA >>> 2022-09-02 03:41:10\n",">>> val_acc: 0.6837, val_precision: 0.6837 val_recall: 0.6837, val_f1: 0.6837\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 03:41:11\n","loss: 0.7052, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 03:41:13\n","loss: 0.7147, acc: 0.7060\n","E2E-ABSA >>> 2022-09-02 03:41:15\n",">>> val_acc: 0.6898, val_precision: 0.6898 val_recall: 0.6898, val_f1: 0.6898\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.6898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 03:41:16\n","loss: 0.7116, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:41:18\n","loss: 0.7560, acc: 0.6840\n","E2E-ABSA >>> 2022-09-02 03:41:20\n","loss: 0.7293, acc: 0.7027\n","E2E-ABSA >>> 2022-09-02 03:41:21\n",">>> val_acc: 0.6898, val_precision: 0.6898 val_recall: 0.6898, val_f1: 0.6898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 03:41:22\n","loss: 0.7180, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:41:24\n","loss: 0.7338, acc: 0.6992\n","E2E-ABSA >>> 2022-09-02 03:41:26\n","loss: 0.7269, acc: 0.6980\n","E2E-ABSA >>> 2022-09-02 03:41:27\n",">>> val_acc: 0.6898, val_precision: 0.6898 val_recall: 0.6898, val_f1: 0.6898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 03:41:29\n","loss: 0.7231, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 03:41:31\n","loss: 0.7238, acc: 0.7010\n","E2E-ABSA >>> 2022-09-02 03:41:34\n",">>> val_acc: 0.6988, val_precision: 0.6988 val_recall: 0.6988, val_f1: 0.6988\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.6988\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 03:41:35\n","loss: 0.6214, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:41:36\n","loss: 0.7094, acc: 0.7098\n","E2E-ABSA >>> 2022-09-02 03:41:38\n","loss: 0.7249, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 03:41:40\n",">>> val_acc: 0.6988, val_precision: 0.6988 val_recall: 0.6988, val_f1: 0.6988\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 03:41:41\n","loss: 0.6953, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 03:41:43\n","loss: 0.7002, acc: 0.7130\n","E2E-ABSA >>> 2022-09-02 03:41:45\n",">>> val_acc: 0.6988, val_precision: 0.6988 val_recall: 0.6988, val_f1: 0.6988\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 03:41:46\n","loss: 0.7116, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:41:47\n","loss: 0.7211, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 03:41:49\n","loss: 0.7159, acc: 0.7064\n","E2E-ABSA >>> 2022-09-02 03:41:51\n",">>> val_acc: 0.6988, val_precision: 0.6988 val_recall: 0.6988, val_f1: 0.6988\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 03:41:52\n","loss: 0.7283, acc: 0.6806\n","E2E-ABSA >>> 2022-09-02 03:41:54\n","loss: 0.7381, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 03:41:56\n","loss: 0.7183, acc: 0.6980\n","E2E-ABSA >>> 2022-09-02 03:41:57\n",">>> val_acc: 0.6988, val_precision: 0.6988 val_recall: 0.6988, val_f1: 0.6988\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 03:41:59\n","loss: 0.7415, acc: 0.6813\n","E2E-ABSA >>> 2022-09-02 03:42:01\n","loss: 0.7093, acc: 0.7125\n","E2E-ABSA >>> 2022-09-02 03:42:03\n",">>> val_acc: 0.7018, val_precision: 0.7018 val_recall: 0.7018, val_f1: 0.7018\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.7018\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 03:42:03\n","loss: 0.7114, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 03:42:05\n","loss: 0.6958, acc: 0.7202\n","E2E-ABSA >>> 2022-09-02 03:42:07\n","loss: 0.7169, acc: 0.7005\n","E2E-ABSA >>> 2022-09-02 03:42:08\n",">>> val_acc: 0.7018, val_precision: 0.7018 val_recall: 0.7018, val_f1: 0.7018\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 03:42:10\n","loss: 0.7266, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:42:12\n","loss: 0.7275, acc: 0.6968\n","E2E-ABSA >>> 2022-09-02 03:42:14\n",">>> val_acc: 0.7018, val_precision: 0.7018 val_recall: 0.7018, val_f1: 0.7018\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 03:42:15\n","loss: 0.6070, acc: 0.8021\n","E2E-ABSA >>> 2022-09-02 03:42:16\n","loss: 0.6802, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 03:42:18\n","loss: 0.7132, acc: 0.6989\n","E2E-ABSA >>> 2022-09-02 03:42:20\n",">>> val_acc: 0.7018, val_precision: 0.7018 val_recall: 0.7018, val_f1: 0.7018\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 03:42:21\n","loss: 0.7262, acc: 0.7049\n","E2E-ABSA >>> 2022-09-02 03:42:23\n","loss: 0.7267, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 03:42:25\n","loss: 0.7107, acc: 0.7028\n","E2E-ABSA >>> 2022-09-02 03:42:26\n",">>> val_acc: 0.7018, val_precision: 0.7018 val_recall: 0.7018, val_f1: 0.7018\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 03:42:28\n","loss: 0.7157, acc: 0.6937\n","E2E-ABSA >>> 2022-09-02 03:42:29\n","loss: 0.7206, acc: 0.6948\n","E2E-ABSA >>> 2022-09-02 03:42:31\n",">>> val_acc: 0.7018, val_precision: 0.7018 val_recall: 0.7018, val_f1: 0.7018\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 03:42:32\n","loss: 0.6901, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 03:42:34\n","loss: 0.6953, acc: 0.7128\n","E2E-ABSA >>> 2022-09-02 03:42:36\n","loss: 0.7117, acc: 0.6988\n","E2E-ABSA >>> 2022-09-02 03:42:37\n",">>> val_acc: 0.7018, val_precision: 0.7018 val_recall: 0.7018, val_f1: 0.7018\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 03:42:39\n","loss: 0.6919, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 03:42:40\n","loss: 0.7090, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:42:43\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 03:42:43\n","loss: 0.7858, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:42:45\n","loss: 0.6897, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:42:47\n","loss: 0.7022, acc: 0.7045\n","E2E-ABSA >>> 2022-09-02 03:42:49\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 03:42:50\n","loss: 0.6961, acc: 0.7153\n","E2E-ABSA >>> 2022-09-02 03:42:52\n","loss: 0.6846, acc: 0.7357\n","E2E-ABSA >>> 2022-09-02 03:42:53\n","loss: 0.7049, acc: 0.7052\n","E2E-ABSA >>> 2022-09-02 03:42:54\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 03:42:56\n","loss: 0.7074, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 03:42:58\n","loss: 0.7063, acc: 0.7073\n","E2E-ABSA >>> 2022-09-02 03:43:00\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 03:43:01\n","loss: 0.6927, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 03:43:03\n","loss: 0.7069, acc: 0.7098\n","E2E-ABSA >>> 2022-09-02 03:43:05\n","loss: 0.7018, acc: 0.7057\n","E2E-ABSA >>> 2022-09-02 03:43:06\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 03:43:08\n","loss: 0.7557, acc: 0.6641\n","E2E-ABSA >>> 2022-09-02 03:43:09\n","loss: 0.7214, acc: 0.6887\n","E2E-ABSA >>> 2022-09-02 03:43:12\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 03:43:12\n","loss: 0.6975, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 03:43:14\n","loss: 0.6721, acc: 0.7274\n","E2E-ABSA >>> 2022-09-02 03:43:16\n","loss: 0.6906, acc: 0.7112\n","E2E-ABSA >>> 2022-09-02 03:43:18\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 03:43:19\n","loss: 0.7182, acc: 0.6910\n","E2E-ABSA >>> 2022-09-02 03:43:21\n","loss: 0.7148, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:43:22\n","loss: 0.6987, acc: 0.7060\n","E2E-ABSA >>> 2022-09-02 03:43:23\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 03:43:25\n","loss: 0.6842, acc: 0.7229\n","E2E-ABSA >>> 2022-09-02 03:43:28\n","loss: 0.7048, acc: 0.6948\n","E2E-ABSA >>> 2022-09-02 03:43:30\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 03:43:31\n","loss: 0.7249, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:43:33\n","loss: 0.6799, acc: 0.7173\n","E2E-ABSA >>> 2022-09-02 03:43:34\n","loss: 0.7002, acc: 0.7014\n","E2E-ABSA >>> 2022-09-02 03:43:36\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 03:43:37\n","loss: 0.7165, acc: 0.6901\n","E2E-ABSA >>> 2022-09-02 03:43:39\n","loss: 0.6912, acc: 0.7072\n","E2E-ABSA >>> 2022-09-02 03:43:42\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 03:43:42\n","loss: 0.7186, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:43:44\n","loss: 0.7066, acc: 0.6997\n","E2E-ABSA >>> 2022-09-02 03:43:46\n","loss: 0.6977, acc: 0.7074\n","E2E-ABSA >>> 2022-09-02 03:43:48\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 03:43:49\n","loss: 0.7461, acc: 0.6701\n","E2E-ABSA >>> 2022-09-02 03:43:51\n","loss: 0.6957, acc: 0.7057\n","E2E-ABSA >>> 2022-09-02 03:43:52\n","loss: 0.6937, acc: 0.7076\n","E2E-ABSA >>> 2022-09-02 03:43:53\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 03:43:55\n","loss: 0.6734, acc: 0.7146\n","E2E-ABSA >>> 2022-09-02 03:43:57\n","loss: 0.6984, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 03:43:59\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 03:44:00\n","loss: 0.7237, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:44:02\n","loss: 0.6785, acc: 0.7068\n","E2E-ABSA >>> 2022-09-02 03:44:04\n","loss: 0.6899, acc: 0.7075\n","E2E-ABSA >>> 2022-09-02 03:44:05\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 03:44:07\n","loss: 0.6735, acc: 0.7214\n","E2E-ABSA >>> 2022-09-02 03:44:08\n","loss: 0.6829, acc: 0.7130\n","E2E-ABSA >>> 2022-09-02 03:44:11\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 03:44:11\n","loss: 0.7463, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 03:44:13\n","loss: 0.7406, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:44:15\n","loss: 0.6976, acc: 0.6998\n","E2E-ABSA >>> 2022-09-02 03:44:17\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 03:44:18\n","loss: 0.6775, acc: 0.7222\n","E2E-ABSA >>> 2022-09-02 03:44:20\n","loss: 0.7084, acc: 0.6992\n","E2E-ABSA >>> 2022-09-02 03:44:22\n","loss: 0.6887, acc: 0.7092\n","E2E-ABSA >>> 2022-09-02 03:44:22\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 03:44:24\n","loss: 0.6816, acc: 0.7167\n","E2E-ABSA >>> 2022-09-02 03:44:26\n","loss: 0.6826, acc: 0.7156\n","E2E-ABSA >>> 2022-09-02 03:44:28\n",">>> val_acc: 0.7108, val_precision: 0.7108 val_recall: 0.7108, val_f1: 0.7108\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.7108\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 03:44:29\n","loss: 0.7103, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:44:31\n","loss: 0.6904, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 03:44:33\n","loss: 0.6843, acc: 0.7127\n","E2E-ABSA >>> 2022-09-02 03:44:34\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 03:44:36\n","loss: 0.6305, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:44:38\n","loss: 0.6696, acc: 0.7211\n","E2E-ABSA >>> 2022-09-02 03:44:40\n",">>> val_acc: 0.7048, val_precision: 0.7048 val_recall: 0.7048, val_f1: 0.7048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","E2E-ABSA >>> 2022-09-02 03:44:40\n","loss: 0.6885, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 03:44:42\n","loss: 0.6684, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:44:44\n","loss: 0.6773, acc: 0.7159\n","E2E-ABSA >>> 2022-09-02 03:44:46\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","E2E-ABSA >>> 2022-09-02 03:44:47\n","loss: 0.6706, acc: 0.7222\n","E2E-ABSA >>> 2022-09-02 03:44:49\n","loss: 0.6935, acc: 0.7148\n","E2E-ABSA >>> 2022-09-02 03:44:51\n","loss: 0.6840, acc: 0.7108\n","E2E-ABSA >>> 2022-09-02 03:44:52\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","E2E-ABSA >>> 2022-09-02 03:44:54\n","loss: 0.6442, acc: 0.7417\n","E2E-ABSA >>> 2022-09-02 03:44:56\n","loss: 0.6883, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 03:44:58\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","E2E-ABSA >>> 2022-09-02 03:44:58\n","loss: 0.6636, acc: 0.7552\n","E2E-ABSA >>> 2022-09-02 03:45:00\n","loss: 0.6771, acc: 0.7113\n","E2E-ABSA >>> 2022-09-02 03:45:02\n","loss: 0.6802, acc: 0.7118\n","E2E-ABSA >>> 2022-09-02 03:45:03\n",">>> val_acc: 0.7108, val_precision: 0.7108 val_recall: 0.7108, val_f1: 0.7108\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","E2E-ABSA >>> 2022-09-02 03:45:05\n","loss: 0.7203, acc: 0.7005\n","E2E-ABSA >>> 2022-09-02 03:45:07\n","loss: 0.6889, acc: 0.7106\n","E2E-ABSA >>> 2022-09-02 03:45:09\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","E2E-ABSA >>> 2022-09-02 03:45:10\n","loss: 0.5878, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 03:45:11\n","loss: 0.6327, acc: 0.7448\n","E2E-ABSA >>> 2022-09-02 03:45:13\n","loss: 0.6693, acc: 0.7216\n","E2E-ABSA >>> 2022-09-02 03:45:15\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","E2E-ABSA >>> 2022-09-02 03:45:16\n","loss: 0.6643, acc: 0.7257\n","E2E-ABSA >>> 2022-09-02 03:45:18\n","loss: 0.6654, acc: 0.7253\n","E2E-ABSA >>> 2022-09-02 03:45:20\n","loss: 0.6795, acc: 0.7108\n","E2E-ABSA >>> 2022-09-02 03:45:21\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","E2E-ABSA >>> 2022-09-02 03:45:23\n","loss: 0.7180, acc: 0.6937\n","E2E-ABSA >>> 2022-09-02 03:45:25\n","loss: 0.7024, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 03:45:27\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","E2E-ABSA >>> 2022-09-02 03:45:28\n","loss: 0.6896, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 03:45:30\n","loss: 0.6724, acc: 0.7202\n","E2E-ABSA >>> 2022-09-02 03:45:32\n","loss: 0.6744, acc: 0.7127\n","E2E-ABSA >>> 2022-09-02 03:45:33\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","E2E-ABSA >>> 2022-09-02 03:45:34\n","loss: 0.7418, acc: 0.6849\n","E2E-ABSA >>> 2022-09-02 03:45:36\n","loss: 0.6993, acc: 0.6991\n","E2E-ABSA >>> 2022-09-02 03:45:39\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","E2E-ABSA >>> 2022-09-02 03:45:39\n","loss: 0.6020, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 03:45:41\n","loss: 0.6452, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 03:45:43\n","loss: 0.6774, acc: 0.7140\n","E2E-ABSA >>> 2022-09-02 03:45:44\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","E2E-ABSA >>> 2022-09-02 03:45:46\n","loss: 0.6547, acc: 0.7222\n","E2E-ABSA >>> 2022-09-02 03:45:47\n","loss: 0.6812, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:45:49\n","loss: 0.6739, acc: 0.7157\n","E2E-ABSA >>> 2022-09-02 03:45:50\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","E2E-ABSA >>> 2022-09-02 03:45:52\n","loss: 0.6660, acc: 0.7333\n","E2E-ABSA >>> 2022-09-02 03:45:54\n","loss: 0.6645, acc: 0.7208\n","E2E-ABSA >>> 2022-09-02 03:45:56\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","E2E-ABSA >>> 2022-09-02 03:45:57\n","loss: 0.7241, acc: 0.6823\n","E2E-ABSA >>> 2022-09-02 03:45:59\n","loss: 0.6757, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:46:00\n","loss: 0.6721, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:46:02\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","E2E-ABSA >>> 2022-09-02 03:46:03\n","loss: 0.6953, acc: 0.7057\n","E2E-ABSA >>> 2022-09-02 03:46:05\n","loss: 0.6610, acc: 0.7118\n","E2E-ABSA >>> 2022-09-02 03:46:07\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","E2E-ABSA >>> 2022-09-02 03:46:08\n","loss: 0.8449, acc: 0.6146\n","E2E-ABSA >>> 2022-09-02 03:46:10\n","loss: 0.6654, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 03:46:11\n","loss: 0.6618, acc: 0.7235\n","E2E-ABSA >>> 2022-09-02 03:46:13\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","E2E-ABSA >>> 2022-09-02 03:46:14\n","loss: 0.6450, acc: 0.7326\n","E2E-ABSA >>> 2022-09-02 03:46:16\n","loss: 0.6490, acc: 0.7201\n","E2E-ABSA >>> 2022-09-02 03:46:18\n","loss: 0.6706, acc: 0.7149\n","E2E-ABSA >>> 2022-09-02 03:46:19\n",">>> val_acc: 0.7078, val_precision: 0.7078 val_recall: 0.7078, val_f1: 0.7078\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","E2E-ABSA >>> 2022-09-02 03:46:21\n","loss: 0.7078, acc: 0.6958\n","E2E-ABSA >>> 2022-09-02 03:46:23\n","loss: 0.6734, acc: 0.7104\n","E2E-ABSA >>> 2022-09-02 03:46:25\n",">>> val_acc: 0.7108, val_precision: 0.7108 val_recall: 0.7108, val_f1: 0.7108\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","E2E-ABSA >>> 2022-09-02 03:46:25\n","loss: 0.7072, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 03:46:27\n","loss: 0.6793, acc: 0.6964\n","E2E-ABSA >>> 2022-09-02 03:46:29\n","loss: 0.6733, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 03:46:30\n",">>> val_acc: 0.7108, val_precision: 0.7108 val_recall: 0.7108, val_f1: 0.7108\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","E2E-ABSA >>> 2022-09-02 03:46:32\n","loss: 0.6698, acc: 0.7370\n","E2E-ABSA >>> 2022-09-02 03:46:34\n","loss: 0.6723, acc: 0.7222\n","E2E-ABSA >>> 2022-09-02 03:46:36\n",">>> val_acc: 0.7108, val_precision: 0.7108 val_recall: 0.7108, val_f1: 0.7108\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","E2E-ABSA >>> 2022-09-02 03:46:37\n","loss: 0.5642, acc: 0.7917\n","E2E-ABSA >>> 2022-09-02 03:46:38\n","loss: 0.6697, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 03:46:40\n","loss: 0.6557, acc: 0.7273\n","E2E-ABSA >>> 2022-09-02 03:46:42\n",">>> val_acc: 0.7108, val_precision: 0.7108 val_recall: 0.7108, val_f1: 0.7108\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","E2E-ABSA >>> 2022-09-02 03:46:43\n","loss: 0.6531, acc: 0.7257\n","E2E-ABSA >>> 2022-09-02 03:46:45\n","loss: 0.6674, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 03:46:47\n","loss: 0.6660, acc: 0.7181\n","E2E-ABSA >>> 2022-09-02 03:46:48\n",">>> val_acc: 0.7108, val_precision: 0.7108 val_recall: 0.7108, val_f1: 0.7108\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 90.\n","E2E-ABSA >>> 2022-09-02 03:46:50\n","loss: 0.6806, acc: 0.7146\n","E2E-ABSA >>> 2022-09-02 03:46:52\n","loss: 0.6650, acc: 0.7167\n","E2E-ABSA >>> 2022-09-02 03:46:54\n",">>> val_acc: 0.7139, val_precision: 0.7139 val_recall: 0.7139, val_f1: 0.7139\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.7139\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 91.\n","E2E-ABSA >>> 2022-09-02 03:46:54\n","loss: 0.6610, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 03:46:56\n","loss: 0.6524, acc: 0.7202\n","E2E-ABSA >>> 2022-09-02 03:46:58\n","loss: 0.6643, acc: 0.7161\n","E2E-ABSA >>> 2022-09-02 03:46:59\n",">>> val_acc: 0.7139, val_precision: 0.7139 val_recall: 0.7139, val_f1: 0.7139\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 92.\n","E2E-ABSA >>> 2022-09-02 03:47:01\n","loss: 0.6982, acc: 0.6849\n","E2E-ABSA >>> 2022-09-02 03:47:03\n","loss: 0.6653, acc: 0.7141\n","E2E-ABSA >>> 2022-09-02 03:47:05\n",">>> val_acc: 0.7139, val_precision: 0.7139 val_recall: 0.7139, val_f1: 0.7139\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 93.\n","E2E-ABSA >>> 2022-09-02 03:47:06\n","loss: 0.7282, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 03:47:07\n","loss: 0.6664, acc: 0.7309\n","E2E-ABSA >>> 2022-09-02 03:47:09\n","loss: 0.6633, acc: 0.7263\n","E2E-ABSA >>> 2022-09-02 03:47:11\n",">>> val_acc: 0.7139, val_precision: 0.7139 val_recall: 0.7139, val_f1: 0.7139\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 94.\n","E2E-ABSA >>> 2022-09-02 03:47:12\n","loss: 0.6702, acc: 0.7118\n","E2E-ABSA >>> 2022-09-02 03:47:14\n","loss: 0.6688, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 03:47:16\n","loss: 0.6616, acc: 0.7165\n","E2E-ABSA >>> 2022-09-02 03:47:17\n",">>> val_acc: 0.7169, val_precision: 0.7169 val_recall: 0.7169, val_f1: 0.7169\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.7169\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 95.\n","E2E-ABSA >>> 2022-09-02 03:47:19\n","loss: 0.6956, acc: 0.6958\n","E2E-ABSA >>> 2022-09-02 03:47:21\n","loss: 0.6689, acc: 0.7146\n","E2E-ABSA >>> 2022-09-02 03:47:23\n",">>> val_acc: 0.7169, val_precision: 0.7169 val_recall: 0.7169, val_f1: 0.7169\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 96.\n","E2E-ABSA >>> 2022-09-02 03:47:24\n","loss: 0.6964, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 03:47:26\n","loss: 0.6793, acc: 0.7054\n","E2E-ABSA >>> 2022-09-02 03:47:28\n","loss: 0.6564, acc: 0.7161\n","E2E-ABSA >>> 2022-09-02 03:47:29\n",">>> val_acc: 0.7169, val_precision: 0.7169 val_recall: 0.7169, val_f1: 0.7169\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 97.\n","E2E-ABSA >>> 2022-09-02 03:47:30\n","loss: 0.6584, acc: 0.7318\n","E2E-ABSA >>> 2022-09-02 03:47:32\n","loss: 0.6631, acc: 0.7245\n","E2E-ABSA >>> 2022-09-02 03:47:35\n",">>> val_acc: 0.7169, val_precision: 0.7169 val_recall: 0.7169, val_f1: 0.7169\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 98.\n","E2E-ABSA >>> 2022-09-02 03:47:35\n","loss: 0.5856, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 03:47:37\n","loss: 0.6516, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 03:47:39\n","loss: 0.6404, acc: 0.7330\n","E2E-ABSA >>> 2022-09-02 03:47:40\n",">>> val_acc: 0.7169, val_precision: 0.7169 val_recall: 0.7169, val_f1: 0.7169\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 99.\n","E2E-ABSA >>> 2022-09-02 03:47:42\n","loss: 0.6743, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:47:43\n","loss: 0.6510, acc: 0.7214\n","E2E-ABSA >>> 2022-09-02 03:47:45\n","loss: 0.6572, acc: 0.7189\n","E2E-ABSA >>> 2022-09-02 03:47:46\n",">>> val_acc: 0.7199, val_precision: 0.7199 val_recall: 0.7199, val_f1: 0.7199\n",">> saved: state_dict/cabasc_twitter_know_val_f1_0.7199\n","you can download the best model from state_dict/cabasc_twitter_know_val_f1_0.7199\n",">>> test_acc: 0.7199, test_precision: 0.7199, test_recall: 0.7199, test_f1: 0.7199\n"]}]},{"cell_type":"markdown","source":["# 针对SemEval201X以及acl2014data的notebook上实验"],"metadata":{"id":"zkHL4QNxR_tQ"}},{"cell_type":"markdown","source":["lstm\n","tdlstm  \n","tclstm  \n","ataelstm  \n","ian \n","memnet  \n","cabasc "],"metadata":{"id":"hxg2FWc_E5Io"}},{"cell_type":"code","source":["# train.py embed_size == 300 则需要下载\n","!wget https://huggingface.co/stanfordnlp/glove/resolve/main/glove.42B.300d.zip #Common Crawl数据集,不区分大小写\n","!unzip glove.42B.300d.zip -d /content/DictionaryFused-E2E-ABSA/glove_embeddings"],"metadata":{"id":"xlLB1-mkg6uI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"41cf13f1-5fbc-43e3-e864-753abfc6ee35","executionInfo":{"status":"ok","timestamp":1662090564959,"user_tz":-480,"elapsed":95925,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-09-02 03:47:48--  https://huggingface.co/stanfordnlp/glove/resolve/main/glove.42B.300d.zip\n","Resolving huggingface.co (huggingface.co)... 52.202.207.64, 52.6.16.131, 2600:1f18:147f:e850:db35:e0c7:187b:c770, ...\n","Connecting to huggingface.co (huggingface.co)|52.202.207.64|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs.huggingface.co/stanfordnlp/glove/357baac33090f645e71e253b3295ee1b767c98a0336e9a1d99c77e9e33b43c4a?response-content-disposition=attachment%3B%20filename%3D%22glove.42B.300d.zip%22 [following]\n","--2022-09-02 03:47:48--  https://cdn-lfs.huggingface.co/stanfordnlp/glove/357baac33090f645e71e253b3295ee1b767c98a0336e9a1d99c77e9e33b43c4a?response-content-disposition=attachment%3B%20filename%3D%22glove.42B.300d.zip%22\n","Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 65.9.86.70, 65.9.86.14, 65.9.86.11, ...\n","Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|65.9.86.70|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1877802108 (1.7G) [application/zip]\n","Saving to: ‘glove.42B.300d.zip’\n","\n","glove.42B.300d.zip  100%[===================>]   1.75G  41.7MB/s    in 45s     \n","\n","2022-09-02 03:48:34 (40.2 MB/s) - ‘glove.42B.300d.zip’ saved [1877802108/1877802108]\n","\n","Archive:  glove.42B.300d.zip\n","  inflating: /content/DictionaryFused-E2E-ABSA/glove_embeddings/glove.42B.300d.txt  \n"]}]},{"cell_type":"markdown","source":["增加字典知识后：Training **SemEval2014** dataset on model(**LSTM**)"],"metadata":{"id":"aLdGitf1R-1H"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name lstm --dataset SemEval2014_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oa4Li_RLR1Uv","outputId":"5c232396-9e0f-4118-a937-142e9d4180cb","executionInfo":{"status":"ok","timestamp":1662090729331,"user_tz":-480,"elapsed":164379,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 3093.\n","> testing dataset count: 329.\n","cuda memory allocated: 18574848\n","> n_trainable_params: 723303, n_nontrainable_params: 3920100\n","> training arguments:\n",">>> model_name: lstm\n",">>> dataset: SemEval2014_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f8aa75e6c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.lstm.LSTM'>\n",">>> dataset_file: {'train': './datasets/laprest14/output_know_insert/train.tsv', 'test': './datasets/laprest14/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 03:50:10\n","loss: 1.0035, acc: 0.5487\n","E2E-ABSA >>> 2022-09-02 03:50:11\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 03:50:11\n","loss: 0.9269, acc: 0.5938\n","E2E-ABSA >>> 2022-09-02 03:50:12\n","loss: 0.9619, acc: 0.5678\n","E2E-ABSA >>> 2022-09-02 03:50:13\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 03:50:13\n","loss: 0.9100, acc: 0.6198\n","E2E-ABSA >>> 2022-09-02 03:50:14\n","loss: 0.9472, acc: 0.5731\n","E2E-ABSA >>> 2022-09-02 03:50:14\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 03:50:15\n","loss: 1.0035, acc: 0.5208\n","E2E-ABSA >>> 2022-09-02 03:50:15\n","loss: 0.9526, acc: 0.5593\n","E2E-ABSA >>> 2022-09-02 03:50:16\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 03:50:16\n","loss: 0.9253, acc: 0.5677\n","E2E-ABSA >>> 2022-09-02 03:50:17\n","loss: 0.9301, acc: 0.5716\n","E2E-ABSA >>> 2022-09-02 03:50:18\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 03:50:18\n","loss: 0.9092, acc: 0.5813\n","E2E-ABSA >>> 2022-09-02 03:50:19\n","loss: 0.9104, acc: 0.5793\n","E2E-ABSA >>> 2022-09-02 03:50:19\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 03:50:20\n","loss: 0.9115, acc: 0.5625\n","E2E-ABSA >>> 2022-09-02 03:50:21\n","loss: 0.9084, acc: 0.5712\n","E2E-ABSA >>> 2022-09-02 03:50:21\n",">>> val_acc: 0.5836, val_precision: 0.5836 val_recall: 0.5836, val_f1: 0.5836\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.5836\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 03:50:22\n","loss: 0.8999, acc: 0.5521\n","E2E-ABSA >>> 2022-09-02 03:50:22\n","loss: 0.8881, acc: 0.5797\n","E2E-ABSA >>> 2022-09-02 03:50:23\n",">>> val_acc: 0.5957, val_precision: 0.5957 val_recall: 0.5957, val_f1: 0.5957\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.5957\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 03:50:23\n","loss: 0.8493, acc: 0.6107\n","E2E-ABSA >>> 2022-09-02 03:50:24\n","loss: 0.8690, acc: 0.6056\n","E2E-ABSA >>> 2022-09-02 03:50:25\n",">>> val_acc: 0.6322, val_precision: 0.6322 val_recall: 0.6322, val_f1: 0.6322\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.6322\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 03:50:25\n","loss: 0.8646, acc: 0.6053\n","E2E-ABSA >>> 2022-09-02 03:50:26\n","loss: 0.8432, acc: 0.6270\n","E2E-ABSA >>> 2022-09-02 03:50:26\n",">>> val_acc: 0.6261, val_precision: 0.6261 val_recall: 0.6261, val_f1: 0.6261\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 03:50:27\n","loss: 0.8617, acc: 0.6125\n","E2E-ABSA >>> 2022-09-02 03:50:28\n","loss: 0.8406, acc: 0.6332\n","E2E-ABSA >>> 2022-09-02 03:50:28\n",">>> val_acc: 0.6383, val_precision: 0.6383 val_recall: 0.6383, val_f1: 0.6383\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.6383\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 03:50:29\n","loss: 0.8317, acc: 0.6241\n","E2E-ABSA >>> 2022-09-02 03:50:30\n","loss: 0.8298, acc: 0.6325\n","E2E-ABSA >>> 2022-09-02 03:50:30\n",">>> val_acc: 0.6505, val_precision: 0.6505 val_recall: 0.6505, val_f1: 0.6505\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.6505\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 03:50:30\n","loss: 0.8009, acc: 0.6424\n","E2E-ABSA >>> 2022-09-02 03:50:31\n","loss: 0.8139, acc: 0.6421\n","E2E-ABSA >>> 2022-09-02 03:50:32\n",">>> val_acc: 0.6444, val_precision: 0.6444 val_recall: 0.6444, val_f1: 0.6444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 03:50:32\n","loss: 0.8111, acc: 0.6386\n","E2E-ABSA >>> 2022-09-02 03:50:33\n","loss: 0.8072, acc: 0.6450\n","E2E-ABSA >>> 2022-09-02 03:50:33\n",">>> val_acc: 0.6626, val_precision: 0.6626 val_recall: 0.6626, val_f1: 0.6626\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.6626\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 03:50:34\n","loss: 0.8146, acc: 0.6332\n","E2E-ABSA >>> 2022-09-02 03:50:35\n","loss: 0.7960, acc: 0.6433\n","E2E-ABSA >>> 2022-09-02 03:50:35\n",">>> val_acc: 0.6626, val_precision: 0.6626 val_recall: 0.6626, val_f1: 0.6626\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 03:50:36\n","loss: 0.8072, acc: 0.6236\n","E2E-ABSA >>> 2022-09-02 03:50:37\n","loss: 0.7852, acc: 0.6490\n","E2E-ABSA >>> 2022-09-02 03:50:37\n",">>> val_acc: 0.6717, val_precision: 0.6717 val_recall: 0.6717, val_f1: 0.6717\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.6717\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 03:50:38\n","loss: 0.7835, acc: 0.6393\n","E2E-ABSA >>> 2022-09-02 03:50:38\n",">>> val_acc: 0.6596, val_precision: 0.6596 val_recall: 0.6596, val_f1: 0.6596\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 03:50:38\n","loss: 0.8182, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:50:39\n","loss: 0.7632, acc: 0.6618\n","E2E-ABSA >>> 2022-09-02 03:50:40\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 03:50:40\n","loss: 0.7693, acc: 0.6484\n","E2E-ABSA >>> 2022-09-02 03:50:41\n","loss: 0.7467, acc: 0.6725\n","E2E-ABSA >>> 2022-09-02 03:50:42\n",">>> val_acc: 0.6809, val_precision: 0.6809 val_recall: 0.6809, val_f1: 0.6809\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.6809\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 03:50:42\n","loss: 0.7508, acc: 0.6607\n","E2E-ABSA >>> 2022-09-02 03:50:43\n","loss: 0.7615, acc: 0.6650\n","E2E-ABSA >>> 2022-09-02 03:50:44\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 03:50:44\n","loss: 0.7439, acc: 0.6625\n","E2E-ABSA >>> 2022-09-02 03:50:45\n","loss: 0.7718, acc: 0.6510\n","E2E-ABSA >>> 2022-09-02 03:50:45\n",">>> val_acc: 0.6809, val_precision: 0.6809 val_recall: 0.6809, val_f1: 0.6809\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 03:50:46\n","loss: 0.7482, acc: 0.6803\n","E2E-ABSA >>> 2022-09-02 03:50:46\n","loss: 0.7594, acc: 0.6612\n","E2E-ABSA >>> 2022-09-02 03:50:47\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 03:50:47\n","loss: 0.7079, acc: 0.6992\n","E2E-ABSA >>> 2022-09-02 03:50:48\n","loss: 0.7311, acc: 0.6809\n","E2E-ABSA >>> 2022-09-02 03:50:49\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 03:50:49\n","loss: 0.7550, acc: 0.6398\n","E2E-ABSA >>> 2022-09-02 03:50:50\n","loss: 0.7341, acc: 0.6766\n","E2E-ABSA >>> 2022-09-02 03:50:50\n",">>> val_acc: 0.6869, val_precision: 0.6869 val_recall: 0.6869, val_f1: 0.6869\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.6869\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 03:50:51\n","loss: 0.7507, acc: 0.6761\n","E2E-ABSA >>> 2022-09-02 03:50:52\n","loss: 0.7406, acc: 0.6753\n","E2E-ABSA >>> 2022-09-02 03:50:52\n",">>> val_acc: 0.6900, val_precision: 0.6900 val_recall: 0.6900, val_f1: 0.6900\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.69\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 03:50:53\n","loss: 0.6712, acc: 0.7225\n","E2E-ABSA >>> 2022-09-02 03:50:54\n","loss: 0.7125, acc: 0.6900\n","E2E-ABSA >>> 2022-09-02 03:50:54\n",">>> val_acc: 0.6809, val_precision: 0.6809 val_recall: 0.6809, val_f1: 0.6809\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 03:50:54\n","loss: 0.7128, acc: 0.6931\n","E2E-ABSA >>> 2022-09-02 03:50:55\n","loss: 0.7323, acc: 0.6783\n","E2E-ABSA >>> 2022-09-02 03:50:56\n",">>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.696\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 03:50:56\n","loss: 0.7021, acc: 0.6946\n","E2E-ABSA >>> 2022-09-02 03:50:57\n","loss: 0.7231, acc: 0.6806\n","E2E-ABSA >>> 2022-09-02 03:50:57\n",">>> val_acc: 0.6930, val_precision: 0.6930 val_recall: 0.6930, val_f1: 0.6930\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 03:50:58\n","loss: 0.7125, acc: 0.6930\n","E2E-ABSA >>> 2022-09-02 03:50:59\n","loss: 0.7073, acc: 0.6894\n","E2E-ABSA >>> 2022-09-02 03:50:59\n",">>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 03:51:00\n","loss: 0.7246, acc: 0.6791\n","E2E-ABSA >>> 2022-09-02 03:51:01\n","loss: 0.7217, acc: 0.6800\n","E2E-ABSA >>> 2022-09-02 03:51:01\n",">>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 03:51:02\n","loss: 0.7262, acc: 0.6805\n","E2E-ABSA >>> 2022-09-02 03:51:02\n","loss: 0.7179, acc: 0.6819\n","E2E-ABSA >>> 2022-09-02 03:51:03\n",">>> val_acc: 0.6383, val_precision: 0.6383 val_recall: 0.6383, val_f1: 0.6383\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 03:51:03\n","loss: 0.7045, acc: 0.6999\n","E2E-ABSA >>> 2022-09-02 03:51:04\n","loss: 0.7172, acc: 0.6855\n","E2E-ABSA >>> 2022-09-02 03:51:04\n",">>> val_acc: 0.6991, val_precision: 0.6991 val_recall: 0.6991, val_f1: 0.6991\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.6991\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 03:51:05\n","loss: 0.7064, acc: 0.6909\n","E2E-ABSA >>> 2022-09-02 03:51:06\n","loss: 0.7116, acc: 0.6885\n","E2E-ABSA >>> 2022-09-02 03:51:06\n",">>> val_acc: 0.6809, val_precision: 0.6809 val_recall: 0.6809, val_f1: 0.6809\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 03:51:07\n","loss: 0.7077, acc: 0.6894\n","E2E-ABSA >>> 2022-09-02 03:51:08\n",">>> val_acc: 0.7082, val_precision: 0.7082 val_recall: 0.7082, val_f1: 0.7082\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.7082\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 03:51:08\n","loss: 0.7559, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 03:51:09\n","loss: 0.7121, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 03:51:10\n",">>> val_acc: 0.7082, val_precision: 0.7082 val_recall: 0.7082, val_f1: 0.7082\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 03:51:10\n","loss: 0.6875, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 03:51:11\n","loss: 0.7049, acc: 0.6903\n","E2E-ABSA >>> 2022-09-02 03:51:12\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 03:51:12\n","loss: 0.6779, acc: 0.6758\n","E2E-ABSA >>> 2022-09-02 03:51:13\n","loss: 0.6688, acc: 0.7193\n","E2E-ABSA >>> 2022-09-02 03:51:14\n",">>> val_acc: 0.6900, val_precision: 0.6900 val_recall: 0.6900, val_f1: 0.6900\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 03:51:14\n","loss: 0.7580, acc: 0.6506\n","E2E-ABSA >>> 2022-09-02 03:51:15\n","loss: 0.7041, acc: 0.6880\n","E2E-ABSA >>> 2022-09-02 03:51:15\n",">>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n",">> saved: state_dict/lstm_SemEval2014_know_val_f1_0.7112\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 03:51:16\n","loss: 0.6653, acc: 0.7098\n","E2E-ABSA >>> 2022-09-02 03:51:16\n","loss: 0.7055, acc: 0.6816\n","E2E-ABSA >>> 2022-09-02 03:51:17\n",">>> val_acc: 0.6930, val_precision: 0.6930 val_recall: 0.6930, val_f1: 0.6930\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 03:51:17\n","loss: 0.7012, acc: 0.7004\n","E2E-ABSA >>> 2022-09-02 03:51:18\n","loss: 0.7011, acc: 0.7001\n","E2E-ABSA >>> 2022-09-02 03:51:19\n",">>> val_acc: 0.6900, val_precision: 0.6900 val_recall: 0.6900, val_f1: 0.6900\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 03:51:19\n","loss: 0.7119, acc: 0.6828\n","E2E-ABSA >>> 2022-09-02 03:51:20\n","loss: 0.7096, acc: 0.6897\n","E2E-ABSA >>> 2022-09-02 03:51:20\n",">>> val_acc: 0.7082, val_precision: 0.7082 val_recall: 0.7082, val_f1: 0.7082\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 03:51:21\n","loss: 0.6670, acc: 0.7106\n","E2E-ABSA >>> 2022-09-02 03:51:22\n","loss: 0.6745, acc: 0.7025\n","E2E-ABSA >>> 2022-09-02 03:51:22\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 03:51:23\n","loss: 0.7095, acc: 0.7055\n","E2E-ABSA >>> 2022-09-02 03:51:23\n","loss: 0.6998, acc: 0.7007\n","E2E-ABSA >>> 2022-09-02 03:51:24\n",">>> val_acc: 0.6930, val_precision: 0.6930 val_recall: 0.6930, val_f1: 0.6930\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 03:51:24\n","loss: 0.6840, acc: 0.6918\n","E2E-ABSA >>> 2022-09-02 03:51:25\n","loss: 0.6846, acc: 0.6966\n","E2E-ABSA >>> 2022-09-02 03:51:26\n",">>> val_acc: 0.6565, val_precision: 0.6565 val_recall: 0.6565, val_f1: 0.6565\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 03:51:26\n","loss: 0.6892, acc: 0.6934\n","E2E-ABSA >>> 2022-09-02 03:51:27\n","loss: 0.7023, acc: 0.6898\n","E2E-ABSA >>> 2022-09-02 03:51:27\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 03:51:28\n","loss: 0.6794, acc: 0.7054\n","E2E-ABSA >>> 2022-09-02 03:51:29\n","loss: 0.6848, acc: 0.7037\n","E2E-ABSA >>> 2022-09-02 03:51:29\n",">>> val_acc: 0.7052, val_precision: 0.7052 val_recall: 0.7052, val_f1: 0.7052\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 03:51:30\n","loss: 0.6769, acc: 0.7138\n","E2E-ABSA >>> 2022-09-02 03:51:30\n","loss: 0.6869, acc: 0.6992\n","E2E-ABSA >>> 2022-09-02 03:51:31\n",">>> val_acc: 0.6900, val_precision: 0.6900 val_recall: 0.6900, val_f1: 0.6900\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 03:51:31\n","loss: 0.7180, acc: 0.6860\n","E2E-ABSA >>> 2022-09-02 03:51:32\n","loss: 0.7113, acc: 0.6902\n","E2E-ABSA >>> 2022-09-02 03:51:32\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 03:51:33\n","loss: 0.7026, acc: 0.6889\n","E2E-ABSA >>> 2022-09-02 03:51:34\n","loss: 0.6912, acc: 0.6971\n","E2E-ABSA >>> 2022-09-02 03:51:34\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 03:51:35\n","loss: 0.6595, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:51:36\n","loss: 0.6866, acc: 0.6993\n","E2E-ABSA >>> 2022-09-02 03:51:36\n",">>> val_acc: 0.6991, val_precision: 0.6991 val_recall: 0.6991, val_f1: 0.6991\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 03:51:37\n","loss: 0.6932, acc: 0.6900\n","E2E-ABSA >>> 2022-09-02 03:51:37\n",">>> val_acc: 0.6717, val_precision: 0.6717 val_recall: 0.6717, val_f1: 0.6717\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 03:51:38\n","loss: 0.6379, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:51:38\n","loss: 0.6672, acc: 0.7129\n","E2E-ABSA >>> 2022-09-02 03:51:39\n",">>> val_acc: 0.6900, val_precision: 0.6900 val_recall: 0.6900, val_f1: 0.6900\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 03:51:39\n","loss: 0.6339, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:51:40\n","loss: 0.6760, acc: 0.7098\n","E2E-ABSA >>> 2022-09-02 03:51:41\n",">>> val_acc: 0.7082, val_precision: 0.7082 val_recall: 0.7082, val_f1: 0.7082\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 03:51:41\n","loss: 0.6988, acc: 0.6910\n","E2E-ABSA >>> 2022-09-02 03:51:42\n","loss: 0.6950, acc: 0.6981\n","E2E-ABSA >>> 2022-09-02 03:51:43\n",">>> val_acc: 0.7021, val_precision: 0.7021 val_recall: 0.7021, val_f1: 0.7021\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 03:51:43\n","loss: 0.6907, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 03:51:44\n","loss: 0.6708, acc: 0.7082\n","E2E-ABSA >>> 2022-09-02 03:51:44\n",">>> val_acc: 0.7082, val_precision: 0.7082 val_recall: 0.7082, val_f1: 0.7082\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 03:51:45\n","loss: 0.7123, acc: 0.6833\n","E2E-ABSA >>> 2022-09-02 03:51:45\n","loss: 0.6682, acc: 0.7058\n","E2E-ABSA >>> 2022-09-02 03:51:46\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 03:51:46\n","loss: 0.6859, acc: 0.6962\n","E2E-ABSA >>> 2022-09-02 03:51:47\n","loss: 0.6997, acc: 0.6847\n","E2E-ABSA >>> 2022-09-02 03:51:48\n",">>> val_acc: 0.6869, val_precision: 0.6869 val_recall: 0.6869, val_f1: 0.6869\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 03:51:48\n","loss: 0.7075, acc: 0.6964\n","E2E-ABSA >>> 2022-09-02 03:51:49\n","loss: 0.6853, acc: 0.7038\n","E2E-ABSA >>> 2022-09-02 03:51:49\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 03:51:50\n","loss: 0.6553, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:51:51\n","loss: 0.6749, acc: 0.7107\n","E2E-ABSA >>> 2022-09-02 03:51:51\n",">>> val_acc: 0.6717, val_precision: 0.6717 val_recall: 0.6717, val_f1: 0.6717\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 03:51:52\n","loss: 0.6667, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 03:51:52\n","loss: 0.6617, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 03:51:53\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 03:51:53\n","loss: 0.6639, acc: 0.7177\n","E2E-ABSA >>> 2022-09-02 03:51:54\n","loss: 0.6720, acc: 0.7094\n","E2E-ABSA >>> 2022-09-02 03:51:55\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 03:51:55\n","loss: 0.6815, acc: 0.7017\n","E2E-ABSA >>> 2022-09-02 03:51:56\n","loss: 0.6809, acc: 0.7014\n","E2E-ABSA >>> 2022-09-02 03:51:56\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 03:51:57\n","loss: 0.6728, acc: 0.7118\n","E2E-ABSA >>> 2022-09-02 03:51:58\n","loss: 0.6662, acc: 0.7122\n","E2E-ABSA >>> 2022-09-02 03:51:58\n",">>> val_acc: 0.6717, val_precision: 0.6717 val_recall: 0.6717, val_f1: 0.6717\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 03:51:59\n","loss: 0.6699, acc: 0.7107\n","E2E-ABSA >>> 2022-09-02 03:52:00\n","loss: 0.6760, acc: 0.7058\n","E2E-ABSA >>> 2022-09-02 03:52:00\n",">>> val_acc: 0.6930, val_precision: 0.6930 val_recall: 0.6930, val_f1: 0.6930\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 03:52:00\n","loss: 0.6675, acc: 0.7098\n","E2E-ABSA >>> 2022-09-02 03:52:01\n","loss: 0.6683, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 03:52:01\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 03:52:02\n","loss: 0.6872, acc: 0.7021\n","E2E-ABSA >>> 2022-09-02 03:52:03\n","loss: 0.6724, acc: 0.7122\n","E2E-ABSA >>> 2022-09-02 03:52:03\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 03:52:04\n","loss: 0.6999, acc: 0.6829\n","E2E-ABSA >>> 2022-09-02 03:52:05\n",">>> val_acc: 0.6900, val_precision: 0.6900 val_recall: 0.6900, val_f1: 0.6900\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 03:52:05\n","loss: 0.6001, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:52:06\n","loss: 0.6744, acc: 0.7016\n","E2E-ABSA >>> 2022-09-02 03:52:07\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n","E2E-ABSA >>> 2022-09-02 03:52:07\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7112, val_precision: 0.7112 val_recall: 0.7112, val_f1: 0.7112\n","you can download the best model from state_dict/lstm_SemEval2014_know_val_f1_0.7112\n",">>> test_acc: 0.7112, test_precision: 0.7112, test_recall: 0.7112, test_f1: 0.7112\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2014** dataset on model(**TDLSTM**)"],"metadata":{"id":"Uqmjs0O_E5V_"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name td_lstm --dataset SemEval2014_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l_Ip6UjOE5cL","outputId":"dc721671-e6f5-4d31-fd0d-42eb54903da0","executionInfo":{"status":"ok","timestamp":1662090994464,"user_tz":-480,"elapsed":265139,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 2913.\n","> testing dataset count: 311.\n","cuda memory allocated: 21468160\n","> n_trainable_params: 1446603, n_nontrainable_params: 3920100\n","> training arguments:\n",">>> model_name: td_lstm\n",">>> dataset: SemEval2014_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f70bd039c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.td_lstm.TD_LSTM'>\n",">>> dataset_file: {'train': './datasets/laprest14/output_know_insert/train.tsv', 'test': './datasets/laprest14/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['left_with_aspect_indices', 'right_with_aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 03:52:51\n","loss: 1.0971, acc: 0.4163\n","E2E-ABSA >>> 2022-09-02 03:52:52\n",">>> val_acc: 0.5659, val_precision: 0.5659 val_recall: 0.5659, val_f1: 0.5659\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.5659\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 03:52:52\n","loss: 0.9603, acc: 0.5699\n","E2E-ABSA >>> 2022-09-02 03:52:53\n","loss: 0.9396, acc: 0.5678\n","E2E-ABSA >>> 2022-09-02 03:52:54\n",">>> val_acc: 0.5756, val_precision: 0.5756 val_recall: 0.5756, val_f1: 0.5756\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.5756\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 03:52:55\n","loss: 0.9513, acc: 0.5680\n","E2E-ABSA >>> 2022-09-02 03:52:56\n","loss: 0.9358, acc: 0.5779\n","E2E-ABSA >>> 2022-09-02 03:52:57\n",">>> val_acc: 0.5852, val_precision: 0.5852 val_recall: 0.5852, val_f1: 0.5852\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.5852\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 03:52:57\n","loss: 0.9291, acc: 0.5772\n","E2E-ABSA >>> 2022-09-02 03:52:58\n","loss: 0.9155, acc: 0.5857\n","E2E-ABSA >>> 2022-09-02 03:52:59\n",">>> val_acc: 0.6206, val_precision: 0.6206 val_recall: 0.6206, val_f1: 0.6206\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.6206\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 03:53:00\n","loss: 0.9141, acc: 0.5836\n","E2E-ABSA >>> 2022-09-02 03:53:01\n","loss: 0.9080, acc: 0.5941\n","E2E-ABSA >>> 2022-09-02 03:53:01\n",">>> val_acc: 0.6238, val_precision: 0.6238 val_recall: 0.6238, val_f1: 0.6238\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.6238\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 03:53:03\n","loss: 0.8902, acc: 0.6088\n","E2E-ABSA >>> 2022-09-02 03:53:04\n",">>> val_acc: 0.6399, val_precision: 0.6399 val_recall: 0.6399, val_f1: 0.6399\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.6399\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 03:53:04\n","loss: 0.8714, acc: 0.5938\n","E2E-ABSA >>> 2022-09-02 03:53:05\n","loss: 0.8886, acc: 0.6054\n","E2E-ABSA >>> 2022-09-02 03:53:06\n",">>> val_acc: 0.6367, val_precision: 0.6367 val_recall: 0.6367, val_f1: 0.6367\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 03:53:06\n","loss: 0.8020, acc: 0.6645\n","E2E-ABSA >>> 2022-09-02 03:53:08\n","loss: 0.8692, acc: 0.6124\n","E2E-ABSA >>> 2022-09-02 03:53:08\n",">>> val_acc: 0.6463, val_precision: 0.6463 val_recall: 0.6463, val_f1: 0.6463\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.6463\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 03:53:09\n","loss: 0.8544, acc: 0.6458\n","E2E-ABSA >>> 2022-09-02 03:53:10\n","loss: 0.8565, acc: 0.6328\n","E2E-ABSA >>> 2022-09-02 03:53:11\n",">>> val_acc: 0.6495, val_precision: 0.6495 val_recall: 0.6495, val_f1: 0.6495\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.6495\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 03:53:11\n","loss: 0.8613, acc: 0.6203\n","E2E-ABSA >>> 2022-09-02 03:53:12\n","loss: 0.8569, acc: 0.6246\n","E2E-ABSA >>> 2022-09-02 03:53:13\n",">>> val_acc: 0.6399, val_precision: 0.6399 val_recall: 0.6399, val_f1: 0.6399\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 03:53:14\n","loss: 0.8366, acc: 0.6348\n","E2E-ABSA >>> 2022-09-02 03:53:15\n","loss: 0.8374, acc: 0.6346\n","E2E-ABSA >>> 2022-09-02 03:53:15\n",">>> val_acc: 0.6399, val_precision: 0.6399 val_recall: 0.6399, val_f1: 0.6399\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 03:53:16\n","loss: 0.8376, acc: 0.6329\n","E2E-ABSA >>> 2022-09-02 03:53:17\n",">>> val_acc: 0.6463, val_precision: 0.6463 val_recall: 0.6463, val_f1: 0.6463\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 03:53:17\n","loss: 1.0220, acc: 0.5156\n","E2E-ABSA >>> 2022-09-02 03:53:19\n","loss: 0.8213, acc: 0.6364\n","E2E-ABSA >>> 2022-09-02 03:53:20\n",">>> val_acc: 0.6527, val_precision: 0.6527 val_recall: 0.6527, val_f1: 0.6527\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.6527\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 03:53:20\n","loss: 0.8048, acc: 0.6518\n","E2E-ABSA >>> 2022-09-02 03:53:21\n","loss: 0.8031, acc: 0.6441\n","E2E-ABSA >>> 2022-09-02 03:53:22\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.672\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 03:53:22\n","loss: 0.8117, acc: 0.6612\n","E2E-ABSA >>> 2022-09-02 03:53:23\n","loss: 0.7978, acc: 0.6508\n","E2E-ABSA >>> 2022-09-02 03:53:24\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 03:53:25\n","loss: 0.7871, acc: 0.6568\n","E2E-ABSA >>> 2022-09-02 03:53:26\n","loss: 0.7848, acc: 0.6629\n","E2E-ABSA >>> 2022-09-02 03:53:26\n",">>> val_acc: 0.6817, val_precision: 0.6817 val_recall: 0.6817, val_f1: 0.6817\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.6817\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 03:53:27\n","loss: 0.7950, acc: 0.6476\n","E2E-ABSA >>> 2022-09-02 03:53:28\n","loss: 0.7899, acc: 0.6548\n","E2E-ABSA >>> 2022-09-02 03:53:29\n",">>> val_acc: 0.6849, val_precision: 0.6849 val_recall: 0.6849, val_f1: 0.6849\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.6849\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 03:53:30\n","loss: 0.7757, acc: 0.6580\n","E2E-ABSA >>> 2022-09-02 03:53:31\n",">>> val_acc: 0.6849, val_precision: 0.6849 val_recall: 0.6849, val_f1: 0.6849\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 03:53:31\n","loss: 0.8015, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 03:53:32\n","loss: 0.7675, acc: 0.6663\n","E2E-ABSA >>> 2022-09-02 03:53:33\n",">>> val_acc: 0.6849, val_precision: 0.6849 val_recall: 0.6849, val_f1: 0.6849\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 03:53:33\n","loss: 0.7705, acc: 0.6413\n","E2E-ABSA >>> 2022-09-02 03:53:34\n","loss: 0.7848, acc: 0.6463\n","E2E-ABSA >>> 2022-09-02 03:53:35\n",">>> val_acc: 0.6849, val_precision: 0.6849 val_recall: 0.6849, val_f1: 0.6849\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 03:53:36\n","loss: 0.7627, acc: 0.6906\n","E2E-ABSA >>> 2022-09-02 03:53:37\n","loss: 0.7632, acc: 0.6674\n","E2E-ABSA >>> 2022-09-02 03:53:37\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 03:53:38\n","loss: 0.7656, acc: 0.6579\n","E2E-ABSA >>> 2022-09-02 03:53:39\n","loss: 0.7696, acc: 0.6616\n","E2E-ABSA >>> 2022-09-02 03:53:40\n",">>> val_acc: 0.6817, val_precision: 0.6817 val_recall: 0.6817, val_f1: 0.6817\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 03:53:40\n","loss: 0.7531, acc: 0.6757\n","E2E-ABSA >>> 2022-09-02 03:53:42\n","loss: 0.7637, acc: 0.6692\n","E2E-ABSA >>> 2022-09-02 03:53:42\n",">>> val_acc: 0.6817, val_precision: 0.6817 val_recall: 0.6817, val_f1: 0.6817\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 03:53:43\n","loss: 0.7817, acc: 0.6573\n","E2E-ABSA >>> 2022-09-02 03:53:44\n",">>> val_acc: 0.6849, val_precision: 0.6849 val_recall: 0.6849, val_f1: 0.6849\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 03:53:44\n","loss: 0.7220, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:53:45\n","loss: 0.7468, acc: 0.6817\n","E2E-ABSA >>> 2022-09-02 03:53:46\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 03:53:47\n","loss: 0.7840, acc: 0.6400\n","E2E-ABSA >>> 2022-09-02 03:53:48\n","loss: 0.7569, acc: 0.6710\n","E2E-ABSA >>> 2022-09-02 03:53:48\n",">>> val_acc: 0.6913, val_precision: 0.6913 val_recall: 0.6913, val_f1: 0.6913\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 03:53:49\n","loss: 0.7774, acc: 0.6533\n","E2E-ABSA >>> 2022-09-02 03:53:50\n","loss: 0.7594, acc: 0.6695\n","E2E-ABSA >>> 2022-09-02 03:53:51\n",">>> val_acc: 0.6913, val_precision: 0.6913 val_recall: 0.6913, val_f1: 0.6913\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 03:53:51\n","loss: 0.7519, acc: 0.6610\n","E2E-ABSA >>> 2022-09-02 03:53:53\n","loss: 0.7511, acc: 0.6690\n","E2E-ABSA >>> 2022-09-02 03:53:53\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 03:53:54\n","loss: 0.7485, acc: 0.6752\n","E2E-ABSA >>> 2022-09-02 03:53:55\n","loss: 0.7504, acc: 0.6747\n","E2E-ABSA >>> 2022-09-02 03:53:55\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 03:53:56\n","loss: 0.7417, acc: 0.6761\n","E2E-ABSA >>> 2022-09-02 03:53:57\n",">>> val_acc: 0.6817, val_precision: 0.6817 val_recall: 0.6817, val_f1: 0.6817\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 03:53:58\n","loss: 0.7688, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:53:59\n","loss: 0.7410, acc: 0.6852\n","E2E-ABSA >>> 2022-09-02 03:54:00\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 03:54:00\n","loss: 0.7650, acc: 0.6551\n","E2E-ABSA >>> 2022-09-02 03:54:01\n","loss: 0.7512, acc: 0.6742\n","E2E-ABSA >>> 2022-09-02 03:54:02\n",">>> val_acc: 0.6849, val_precision: 0.6849 val_recall: 0.6849, val_f1: 0.6849\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 03:54:02\n","loss: 0.7287, acc: 0.6861\n","E2E-ABSA >>> 2022-09-02 03:54:03\n","loss: 0.7436, acc: 0.6740\n","E2E-ABSA >>> 2022-09-02 03:54:04\n",">>> val_acc: 0.6977, val_precision: 0.6977 val_recall: 0.6977, val_f1: 0.6977\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.6977\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 03:54:05\n","loss: 0.7573, acc: 0.6691\n","E2E-ABSA >>> 2022-09-02 03:54:06\n","loss: 0.7416, acc: 0.6755\n","E2E-ABSA >>> 2022-09-02 03:54:06\n",">>> val_acc: 0.6881, val_precision: 0.6881 val_recall: 0.6881, val_f1: 0.6881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 03:54:07\n","loss: 0.7205, acc: 0.6899\n","E2E-ABSA >>> 2022-09-02 03:54:08\n","loss: 0.7349, acc: 0.6815\n","E2E-ABSA >>> 2022-09-02 03:54:08\n",">>> val_acc: 0.6785, val_precision: 0.6785 val_recall: 0.6785, val_f1: 0.6785\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 03:54:10\n","loss: 0.7283, acc: 0.6888\n","E2E-ABSA >>> 2022-09-02 03:54:11\n",">>> val_acc: 0.6881, val_precision: 0.6881 val_recall: 0.6881, val_f1: 0.6881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 03:54:11\n","loss: 0.8063, acc: 0.6510\n","E2E-ABSA >>> 2022-09-02 03:54:12\n","loss: 0.7274, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:54:13\n",">>> val_acc: 0.7010, val_precision: 0.7010 val_recall: 0.7010, val_f1: 0.7010\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.701\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 03:54:13\n","loss: 0.7229, acc: 0.6810\n","E2E-ABSA >>> 2022-09-02 03:54:14\n","loss: 0.7213, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:54:15\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 03:54:16\n","loss: 0.7335, acc: 0.6793\n","E2E-ABSA >>> 2022-09-02 03:54:17\n","loss: 0.7246, acc: 0.6811\n","E2E-ABSA >>> 2022-09-02 03:54:17\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 03:54:18\n","loss: 0.7280, acc: 0.6815\n","E2E-ABSA >>> 2022-09-02 03:54:19\n","loss: 0.7196, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:54:19\n",">>> val_acc: 0.6785, val_precision: 0.6785 val_recall: 0.6785, val_f1: 0.6785\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 03:54:20\n","loss: 0.7156, acc: 0.6930\n","E2E-ABSA >>> 2022-09-02 03:54:22\n","loss: 0.7216, acc: 0.6840\n","E2E-ABSA >>> 2022-09-02 03:54:22\n",">>> val_acc: 0.6817, val_precision: 0.6817 val_recall: 0.6817, val_f1: 0.6817\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 03:54:23\n","loss: 0.7321, acc: 0.6778\n","E2E-ABSA >>> 2022-09-02 03:54:24\n",">>> val_acc: 0.6785, val_precision: 0.6785 val_recall: 0.6785, val_f1: 0.6785\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 03:54:24\n","loss: 0.6832, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:54:25\n","loss: 0.7230, acc: 0.6820\n","E2E-ABSA >>> 2022-09-02 03:54:26\n",">>> val_acc: 0.6785, val_precision: 0.6785 val_recall: 0.6785, val_f1: 0.6785\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 03:54:26\n","loss: 0.6982, acc: 0.6935\n","E2E-ABSA >>> 2022-09-02 03:54:28\n","loss: 0.7054, acc: 0.6942\n","E2E-ABSA >>> 2022-09-02 03:54:28\n",">>> val_acc: 0.6913, val_precision: 0.6913 val_recall: 0.6913, val_f1: 0.6913\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 03:54:29\n","loss: 0.6769, acc: 0.7018\n","E2E-ABSA >>> 2022-09-02 03:54:30\n","loss: 0.7072, acc: 0.6896\n","E2E-ABSA >>> 2022-09-02 03:54:30\n",">>> val_acc: 0.6913, val_precision: 0.6913 val_recall: 0.6913, val_f1: 0.6913\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 03:54:31\n","loss: 0.7171, acc: 0.6769\n","E2E-ABSA >>> 2022-09-02 03:54:32\n","loss: 0.7058, acc: 0.6848\n","E2E-ABSA >>> 2022-09-02 03:54:33\n",">>> val_acc: 0.6977, val_precision: 0.6977 val_recall: 0.6977, val_f1: 0.6977\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 03:54:34\n","loss: 0.6837, acc: 0.7149\n","E2E-ABSA >>> 2022-09-02 03:54:35\n","loss: 0.6956, acc: 0.6968\n","E2E-ABSA >>> 2022-09-02 03:54:35\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 03:54:36\n","loss: 0.6940, acc: 0.6894\n","E2E-ABSA >>> 2022-09-02 03:54:37\n",">>> val_acc: 0.6913, val_precision: 0.6913 val_recall: 0.6913, val_f1: 0.6913\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 03:54:37\n","loss: 0.7214, acc: 0.6992\n","E2E-ABSA >>> 2022-09-02 03:54:38\n","loss: 0.6811, acc: 0.7096\n","E2E-ABSA >>> 2022-09-02 03:54:39\n",">>> val_acc: 0.6849, val_precision: 0.6849 val_recall: 0.6849, val_f1: 0.6849\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 03:54:40\n","loss: 0.6385, acc: 0.7273\n","E2E-ABSA >>> 2022-09-02 03:54:41\n","loss: 0.6801, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 03:54:41\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 03:54:42\n","loss: 0.6868, acc: 0.7013\n","E2E-ABSA >>> 2022-09-02 03:54:43\n","loss: 0.6813, acc: 0.7037\n","E2E-ABSA >>> 2022-09-02 03:54:44\n",">>> val_acc: 0.6913, val_precision: 0.6913 val_recall: 0.6913, val_f1: 0.6913\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 03:54:44\n","loss: 0.6665, acc: 0.7108\n","E2E-ABSA >>> 2022-09-02 03:54:46\n","loss: 0.6715, acc: 0.7070\n","E2E-ABSA >>> 2022-09-02 03:54:46\n",">>> val_acc: 0.6977, val_precision: 0.6977 val_recall: 0.6977, val_f1: 0.6977\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 03:54:47\n","loss: 0.6488, acc: 0.7269\n","E2E-ABSA >>> 2022-09-02 03:54:48\n",">>> val_acc: 0.6977, val_precision: 0.6977 val_recall: 0.6977, val_f1: 0.6977\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 03:54:48\n","loss: 0.7672, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:54:49\n","loss: 0.6432, acc: 0.7184\n","E2E-ABSA >>> 2022-09-02 03:54:50\n",">>> val_acc: 0.6913, val_precision: 0.6913 val_recall: 0.6913, val_f1: 0.6913\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 03:54:50\n","loss: 0.6323, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:54:52\n","loss: 0.6578, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:54:52\n",">>> val_acc: 0.6817, val_precision: 0.6817 val_recall: 0.6817, val_f1: 0.6817\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 03:54:53\n","loss: 0.6689, acc: 0.7125\n","E2E-ABSA >>> 2022-09-02 03:54:54\n","loss: 0.6381, acc: 0.7273\n","E2E-ABSA >>> 2022-09-02 03:54:55\n",">>> val_acc: 0.6785, val_precision: 0.6785 val_recall: 0.6785, val_f1: 0.6785\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 03:54:55\n","loss: 0.6889, acc: 0.6959\n","E2E-ABSA >>> 2022-09-02 03:54:56\n","loss: 0.6631, acc: 0.7171\n","E2E-ABSA >>> 2022-09-02 03:54:57\n",">>> val_acc: 0.7042, val_precision: 0.7042 val_recall: 0.7042, val_f1: 0.7042\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.7042\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 03:54:58\n","loss: 0.6756, acc: 0.7074\n","E2E-ABSA >>> 2022-09-02 03:54:59\n","loss: 0.6542, acc: 0.7208\n","E2E-ABSA >>> 2022-09-02 03:55:00\n",">>> val_acc: 0.6913, val_precision: 0.6913 val_recall: 0.6913, val_f1: 0.6913\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 03:55:01\n","loss: 0.6379, acc: 0.7224\n","E2E-ABSA >>> 2022-09-02 03:55:02\n",">>> val_acc: 0.6817, val_precision: 0.6817 val_recall: 0.6817, val_f1: 0.6817\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 03:55:02\n","loss: 0.6240, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:55:03\n","loss: 0.6326, acc: 0.7275\n","E2E-ABSA >>> 2022-09-02 03:55:04\n",">>> val_acc: 0.7010, val_precision: 0.7010 val_recall: 0.7010, val_f1: 0.7010\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 03:55:04\n","loss: 0.6270, acc: 0.7375\n","E2E-ABSA >>> 2022-09-02 03:55:05\n","loss: 0.6377, acc: 0.7307\n","E2E-ABSA >>> 2022-09-02 03:55:06\n",">>> val_acc: 0.6849, val_precision: 0.6849 val_recall: 0.6849, val_f1: 0.6849\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 03:55:07\n","loss: 0.6331, acc: 0.7128\n","E2E-ABSA >>> 2022-09-02 03:55:08\n","loss: 0.6316, acc: 0.7276\n","E2E-ABSA >>> 2022-09-02 03:55:09\n",">>> val_acc: 0.6977, val_precision: 0.6977 val_recall: 0.6977, val_f1: 0.6977\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 03:55:09\n","loss: 0.6144, acc: 0.7350\n","E2E-ABSA >>> 2022-09-02 03:55:10\n","loss: 0.6346, acc: 0.7248\n","E2E-ABSA >>> 2022-09-02 03:55:11\n",">>> val_acc: 0.6849, val_precision: 0.6849 val_recall: 0.6849, val_f1: 0.6849\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 03:55:12\n","loss: 0.6130, acc: 0.7306\n","E2E-ABSA >>> 2022-09-02 03:55:13\n","loss: 0.6282, acc: 0.7284\n","E2E-ABSA >>> 2022-09-02 03:55:13\n",">>> val_acc: 0.6817, val_precision: 0.6817 val_recall: 0.6817, val_f1: 0.6817\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 03:55:14\n","loss: 0.6317, acc: 0.7280\n","E2E-ABSA >>> 2022-09-02 03:55:15\n",">>> val_acc: 0.6495, val_precision: 0.6495 val_recall: 0.6495, val_f1: 0.6495\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 03:55:15\n","loss: 0.5647, acc: 0.7875\n","E2E-ABSA >>> 2022-09-02 03:55:16\n","loss: 0.6319, acc: 0.7274\n","E2E-ABSA >>> 2022-09-02 03:55:17\n",">>> val_acc: 0.6881, val_precision: 0.6881 val_recall: 0.6881, val_f1: 0.6881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 03:55:18\n","loss: 0.6080, acc: 0.7472\n","E2E-ABSA >>> 2022-09-02 03:55:19\n","loss: 0.6106, acc: 0.7362\n","E2E-ABSA >>> 2022-09-02 03:55:20\n",">>> val_acc: 0.6977, val_precision: 0.6977 val_recall: 0.6977, val_f1: 0.6977\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 03:55:20\n","loss: 0.6423, acc: 0.7131\n","E2E-ABSA >>> 2022-09-02 03:55:21\n","loss: 0.6151, acc: 0.7248\n","E2E-ABSA >>> 2022-09-02 03:55:22\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","E2E-ABSA >>> 2022-09-02 03:55:23\n","loss: 0.6229, acc: 0.7277\n","E2E-ABSA >>> 2022-09-02 03:55:24\n","loss: 0.6218, acc: 0.7260\n","E2E-ABSA >>> 2022-09-02 03:55:24\n",">>> val_acc: 0.6977, val_precision: 0.6977 val_recall: 0.6977, val_f1: 0.6977\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","E2E-ABSA >>> 2022-09-02 03:55:25\n","loss: 0.6299, acc: 0.7363\n","E2E-ABSA >>> 2022-09-02 03:55:26\n","loss: 0.6106, acc: 0.7392\n","E2E-ABSA >>> 2022-09-02 03:55:26\n",">>> val_acc: 0.6977, val_precision: 0.6977 val_recall: 0.6977, val_f1: 0.6977\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","E2E-ABSA >>> 2022-09-02 03:55:27\n","loss: 0.6185, acc: 0.7431\n","E2E-ABSA >>> 2022-09-02 03:55:28\n",">>> val_acc: 0.6334, val_precision: 0.6334 val_recall: 0.6334, val_f1: 0.6334\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","E2E-ABSA >>> 2022-09-02 03:55:29\n","loss: 0.6946, acc: 0.7857\n","E2E-ABSA >>> 2022-09-02 03:55:30\n","loss: 0.6313, acc: 0.7360\n","E2E-ABSA >>> 2022-09-02 03:55:31\n",">>> val_acc: 0.6977, val_precision: 0.6977 val_recall: 0.6977, val_f1: 0.6977\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","E2E-ABSA >>> 2022-09-02 03:55:31\n","loss: 0.5974, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:55:32\n","loss: 0.6251, acc: 0.7445\n","E2E-ABSA >>> 2022-09-02 03:55:33\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","E2E-ABSA >>> 2022-09-02 03:55:33\n","loss: 0.6212, acc: 0.7439\n","E2E-ABSA >>> 2022-09-02 03:55:34\n","loss: 0.6175, acc: 0.7416\n","E2E-ABSA >>> 2022-09-02 03:55:35\n",">>> val_acc: 0.7042, val_precision: 0.7042 val_recall: 0.7042, val_f1: 0.7042\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","E2E-ABSA >>> 2022-09-02 03:55:36\n","loss: 0.6093, acc: 0.7328\n","E2E-ABSA >>> 2022-09-02 03:55:37\n","loss: 0.5936, acc: 0.7456\n","E2E-ABSA >>> 2022-09-02 03:55:37\n",">>> val_acc: 0.6913, val_precision: 0.6913 val_recall: 0.6913, val_f1: 0.6913\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","E2E-ABSA >>> 2022-09-02 03:55:38\n","loss: 0.6270, acc: 0.7258\n","E2E-ABSA >>> 2022-09-02 03:55:39\n","loss: 0.6026, acc: 0.7393\n","E2E-ABSA >>> 2022-09-02 03:55:39\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","E2E-ABSA >>> 2022-09-02 03:55:41\n","loss: 0.6014, acc: 0.7405\n","E2E-ABSA >>> 2022-09-02 03:55:42\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","E2E-ABSA >>> 2022-09-02 03:55:42\n","loss: 0.5793, acc: 0.7778\n","E2E-ABSA >>> 2022-09-02 03:55:43\n","loss: 0.6006, acc: 0.7466\n","E2E-ABSA >>> 2022-09-02 03:55:44\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","E2E-ABSA >>> 2022-09-02 03:55:44\n","loss: 0.5770, acc: 0.7524\n","E2E-ABSA >>> 2022-09-02 03:55:45\n","loss: 0.5992, acc: 0.7406\n","E2E-ABSA >>> 2022-09-02 03:55:46\n",">>> val_acc: 0.6785, val_precision: 0.6785 val_recall: 0.6785, val_f1: 0.6785\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","E2E-ABSA >>> 2022-09-02 03:55:47\n","loss: 0.5722, acc: 0.7485\n","E2E-ABSA >>> 2022-09-02 03:55:48\n","loss: 0.6100, acc: 0.7474\n","E2E-ABSA >>> 2022-09-02 03:55:48\n",">>> val_acc: 0.7042, val_precision: 0.7042 val_recall: 0.7042, val_f1: 0.7042\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","E2E-ABSA >>> 2022-09-02 03:55:49\n","loss: 0.5768, acc: 0.7688\n","E2E-ABSA >>> 2022-09-02 03:55:50\n","loss: 0.5827, acc: 0.7594\n","E2E-ABSA >>> 2022-09-02 03:55:51\n",">>> val_acc: 0.7042, val_precision: 0.7042 val_recall: 0.7042, val_f1: 0.7042\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","E2E-ABSA >>> 2022-09-02 03:55:51\n","loss: 0.5880, acc: 0.7581\n","E2E-ABSA >>> 2022-09-02 03:55:53\n","loss: 0.5946, acc: 0.7514\n","E2E-ABSA >>> 2022-09-02 03:55:53\n",">>> val_acc: 0.7010, val_precision: 0.7010 val_recall: 0.7010, val_f1: 0.7010\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","E2E-ABSA >>> 2022-09-02 03:55:54\n","loss: 0.6056, acc: 0.7547\n","E2E-ABSA >>> 2022-09-02 03:55:55\n",">>> val_acc: 0.6881, val_precision: 0.6881 val_recall: 0.6881, val_f1: 0.6881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","E2E-ABSA >>> 2022-09-02 03:55:55\n","loss: 0.5844, acc: 0.7443\n","E2E-ABSA >>> 2022-09-02 03:55:56\n","loss: 0.6125, acc: 0.7376\n","E2E-ABSA >>> 2022-09-02 03:55:57\n",">>> val_acc: 0.7042, val_precision: 0.7042 val_recall: 0.7042, val_f1: 0.7042\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","E2E-ABSA >>> 2022-09-02 03:55:57\n","loss: 0.6069, acc: 0.7634\n","E2E-ABSA >>> 2022-09-02 03:55:59\n","loss: 0.6035, acc: 0.7466\n","E2E-ABSA >>> 2022-09-02 03:55:59\n",">>> val_acc: 0.7042, val_precision: 0.7042 val_recall: 0.7042, val_f1: 0.7042\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","E2E-ABSA >>> 2022-09-02 03:56:00\n","loss: 0.5737, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 03:56:01\n","loss: 0.5785, acc: 0.7621\n","E2E-ABSA >>> 2022-09-02 03:56:02\n",">>> val_acc: 0.7106, val_precision: 0.7106 val_recall: 0.7106, val_f1: 0.7106\n",">> saved: state_dict/td_lstm_SemEval2014_know_val_f1_0.7106\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","E2E-ABSA >>> 2022-09-02 03:56:02\n","loss: 0.5797, acc: 0.7450\n","E2E-ABSA >>> 2022-09-02 03:56:03\n","loss: 0.5931, acc: 0.7442\n","E2E-ABSA >>> 2022-09-02 03:56:04\n",">>> val_acc: 0.7042, val_precision: 0.7042 val_recall: 0.7042, val_f1: 0.7042\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","E2E-ABSA >>> 2022-09-02 03:56:05\n","loss: 0.5578, acc: 0.7650\n","E2E-ABSA >>> 2022-09-02 03:56:06\n","loss: 0.5823, acc: 0.7570\n","E2E-ABSA >>> 2022-09-02 03:56:06\n",">>> val_acc: 0.6977, val_precision: 0.6977 val_recall: 0.6977, val_f1: 0.6977\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","E2E-ABSA >>> 2022-09-02 03:56:07\n","loss: 0.5846, acc: 0.7617\n","E2E-ABSA >>> 2022-09-02 03:56:08\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","E2E-ABSA >>> 2022-09-02 03:56:08\n","loss: 0.5705, acc: 0.7644\n","E2E-ABSA >>> 2022-09-02 03:56:10\n","loss: 0.6065, acc: 0.7423\n","E2E-ABSA >>> 2022-09-02 03:56:10\n",">>> val_acc: 0.6945, val_precision: 0.6945 val_recall: 0.6945, val_f1: 0.6945\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 90.\n","E2E-ABSA >>> 2022-09-02 03:56:11\n","loss: 0.6010, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 03:56:12\n","loss: 0.5922, acc: 0.7433\n","E2E-ABSA >>> 2022-09-02 03:56:13\n",">>> val_acc: 0.6977, val_precision: 0.6977 val_recall: 0.6977, val_f1: 0.6977\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 91.\n","E2E-ABSA >>> 2022-09-02 03:56:13\n","loss: 0.5747, acc: 0.7673\n","E2E-ABSA >>> 2022-09-02 03:56:14\n","loss: 0.5669, acc: 0.7649\n","E2E-ABSA >>> 2022-09-02 03:56:15\n",">>> val_acc: 0.7042, val_precision: 0.7042 val_recall: 0.7042, val_f1: 0.7042\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 92.\n","E2E-ABSA >>> 2022-09-02 03:56:16\n","loss: 0.5889, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 03:56:17\n","loss: 0.5843, acc: 0.7595\n","E2E-ABSA >>> 2022-09-02 03:56:17\n",">>> val_acc: 0.7010, val_precision: 0.7010 val_recall: 0.7010, val_f1: 0.7010\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 93.\n","E2E-ABSA >>> 2022-09-02 03:56:18\n","loss: 0.5696, acc: 0.7585\n","E2E-ABSA >>> 2022-09-02 03:56:19\n","loss: 0.6181, acc: 0.7424\n","E2E-ABSA >>> 2022-09-02 03:56:19\n",">>> val_acc: 0.6881, val_precision: 0.6881 val_recall: 0.6881, val_f1: 0.6881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 94.\n","E2E-ABSA >>> 2022-09-02 03:56:20\n","loss: 0.6160, acc: 0.7417\n","E2E-ABSA >>> 2022-09-02 03:56:21\n",">>> val_acc: 0.7106, val_precision: 0.7106 val_recall: 0.7106, val_f1: 0.7106\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 95.\n","E2E-ABSA >>> 2022-09-02 03:56:22\n","loss: 0.6237, acc: 0.7333\n","E2E-ABSA >>> 2022-09-02 03:56:23\n","loss: 0.5738, acc: 0.7565\n","E2E-ABSA >>> 2022-09-02 03:56:24\n",">>> val_acc: 0.7106, val_precision: 0.7106 val_recall: 0.7106, val_f1: 0.7106\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 96.\n","E2E-ABSA >>> 2022-09-02 03:56:24\n","loss: 0.5507, acc: 0.7754\n","E2E-ABSA >>> 2022-09-02 03:56:25\n","loss: 0.5681, acc: 0.7642\n","E2E-ABSA >>> 2022-09-02 03:56:26\n",">>> val_acc: 0.7074, val_precision: 0.7074 val_recall: 0.7074, val_f1: 0.7074\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 97.\n","E2E-ABSA >>> 2022-09-02 03:56:26\n","loss: 0.5249, acc: 0.7934\n","E2E-ABSA >>> 2022-09-02 03:56:28\n","loss: 0.5738, acc: 0.7601\n","E2E-ABSA >>> 2022-09-02 03:56:28\n",">>> val_acc: 0.6913, val_precision: 0.6913 val_recall: 0.6913, val_f1: 0.6913\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 98.\n","E2E-ABSA >>> 2022-09-02 03:56:29\n","loss: 0.5831, acc: 0.7481\n","E2E-ABSA >>> 2022-09-02 03:56:30\n","loss: 0.5712, acc: 0.7568\n","E2E-ABSA >>> 2022-09-02 03:56:30\n",">>> val_acc: 0.7074, val_precision: 0.7074 val_recall: 0.7074, val_f1: 0.7074\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 99.\n","E2E-ABSA >>> 2022-09-02 03:56:31\n","loss: 0.5832, acc: 0.7470\n","E2E-ABSA >>> 2022-09-02 03:56:32\n","loss: 0.5725, acc: 0.7573\n","E2E-ABSA >>> 2022-09-02 03:56:32\n",">>> val_acc: 0.7042, val_precision: 0.7042 val_recall: 0.7042, val_f1: 0.7042\n","you can download the best model from state_dict/td_lstm_SemEval2014_know_val_f1_0.7106\n",">>> test_acc: 0.7106, test_precision: 0.7106, test_recall: 0.7106, test_f1: 0.7106\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2014** dataset on model(**TCLSTM**)"],"metadata":{"id":"wA8T_VonE_6x"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name tc_lstm --dataset SemEval2014_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"czQaYUYdFABu","outputId":"f564d981-be15-492e-f51e-74493ae2e6a6","executionInfo":{"status":"ok","timestamp":1662091257072,"user_tz":-480,"elapsed":262614,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 2913.\n","> testing dataset count: 311.\n","cuda memory allocated: 24348672\n","> n_trainable_params: 2166603, n_nontrainable_params: 3920100\n","> training arguments:\n",">>> model_name: tc_lstm\n",">>> dataset: SemEval2014_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7fe355766c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.tc_lstm.TC_LSTM'>\n",">>> dataset_file: {'train': './datasets/laprest14/output_know_insert/train.tsv', 'test': './datasets/laprest14/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['left_with_aspect_indices', 'right_with_aspect_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 03:57:14\n","loss: 0.9877, acc: 0.5387\n","E2E-ABSA >>> 2022-09-02 03:57:15\n",">>> val_acc: 0.6045, val_precision: 0.6045 val_recall: 0.6045, val_f1: 0.6045\n",">> saved: state_dict/tc_lstm_SemEval2014_know_val_f1_0.6045\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 03:57:16\n","loss: 0.9661, acc: 0.5772\n","E2E-ABSA >>> 2022-09-02 03:57:17\n","loss: 0.9220, acc: 0.5972\n","E2E-ABSA >>> 2022-09-02 03:57:18\n",">>> val_acc: 0.6367, val_precision: 0.6367 val_recall: 0.6367, val_f1: 0.6367\n",">> saved: state_dict/tc_lstm_SemEval2014_know_val_f1_0.6367\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 03:57:18\n","loss: 0.8831, acc: 0.6232\n","E2E-ABSA >>> 2022-09-02 03:57:19\n","loss: 0.8978, acc: 0.6017\n","E2E-ABSA >>> 2022-09-02 03:57:20\n",">>> val_acc: 0.6399, val_precision: 0.6399 val_recall: 0.6399, val_f1: 0.6399\n",">> saved: state_dict/tc_lstm_SemEval2014_know_val_f1_0.6399\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 03:57:21\n","loss: 0.8897, acc: 0.6164\n","E2E-ABSA >>> 2022-09-02 03:57:22\n","loss: 0.8881, acc: 0.6039\n","E2E-ABSA >>> 2022-09-02 03:57:23\n",">>> val_acc: 0.6495, val_precision: 0.6495 val_recall: 0.6495, val_f1: 0.6495\n",">> saved: state_dict/tc_lstm_SemEval2014_know_val_f1_0.6495\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 03:57:23\n","loss: 0.8881, acc: 0.5910\n","E2E-ABSA >>> 2022-09-02 03:57:25\n","loss: 0.8723, acc: 0.6034\n","E2E-ABSA >>> 2022-09-02 03:57:25\n",">>> val_acc: 0.6559, val_precision: 0.6559 val_recall: 0.6559, val_f1: 0.6559\n",">> saved: state_dict/tc_lstm_SemEval2014_know_val_f1_0.6559\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 03:57:26\n","loss: 0.8404, acc: 0.6324\n","E2E-ABSA >>> 2022-09-02 03:57:27\n",">>> val_acc: 0.6495, val_precision: 0.6495 val_recall: 0.6495, val_f1: 0.6495\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 03:57:27\n","loss: 0.8185, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 03:57:29\n","loss: 0.8562, acc: 0.6225\n","E2E-ABSA >>> 2022-09-02 03:57:30\n",">>> val_acc: 0.6559, val_precision: 0.6559 val_recall: 0.6559, val_f1: 0.6559\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 03:57:30\n","loss: 0.8673, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 03:57:31\n","loss: 0.8475, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 03:57:32\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">> saved: state_dict/tc_lstm_SemEval2014_know_val_f1_0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 03:57:33\n","loss: 0.8330, acc: 0.6441\n","E2E-ABSA >>> 2022-09-02 03:57:34\n","loss: 0.8382, acc: 0.6374\n","E2E-ABSA >>> 2022-09-02 03:57:35\n",">>> val_acc: 0.6559, val_precision: 0.6559 val_recall: 0.6559, val_f1: 0.6559\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 03:57:35\n","loss: 0.7916, acc: 0.6627\n","E2E-ABSA >>> 2022-09-02 03:57:36\n","loss: 0.8172, acc: 0.6487\n","E2E-ABSA >>> 2022-09-02 03:57:37\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 03:57:38\n","loss: 0.8218, acc: 0.6527\n","E2E-ABSA >>> 2022-09-02 03:57:39\n","loss: 0.8088, acc: 0.6540\n","E2E-ABSA >>> 2022-09-02 03:57:39\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">> saved: state_dict/tc_lstm_SemEval2014_know_val_f1_0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 03:57:40\n","loss: 0.8020, acc: 0.6530\n","E2E-ABSA >>> 2022-09-02 03:57:42\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 03:57:42\n","loss: 0.6832, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 03:57:43\n","loss: 0.8054, acc: 0.6575\n","E2E-ABSA >>> 2022-09-02 03:57:44\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 03:57:44\n","loss: 0.7738, acc: 0.6607\n","E2E-ABSA >>> 2022-09-02 03:57:46\n","loss: 0.7706, acc: 0.6736\n","E2E-ABSA >>> 2022-09-02 03:57:46\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 03:57:47\n","loss: 0.7622, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:57:48\n","loss: 0.7685, acc: 0.6721\n","E2E-ABSA >>> 2022-09-02 03:57:49\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">> saved: state_dict/tc_lstm_SemEval2014_know_val_f1_0.672\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 03:57:50\n","loss: 0.7632, acc: 0.6761\n","E2E-ABSA >>> 2022-09-02 03:57:51\n","loss: 0.7596, acc: 0.6758\n","E2E-ABSA >>> 2022-09-02 03:57:51\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 03:57:52\n","loss: 0.7460, acc: 0.6858\n","E2E-ABSA >>> 2022-09-02 03:57:53\n","loss: 0.7591, acc: 0.6784\n","E2E-ABSA >>> 2022-09-02 03:57:54\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 03:57:55\n","loss: 0.7380, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:57:56\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 03:57:56\n","loss: 0.7111, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:57:57\n","loss: 0.7492, acc: 0.6822\n","E2E-ABSA >>> 2022-09-02 03:57:58\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 03:57:59\n","loss: 0.7078, acc: 0.7011\n","E2E-ABSA >>> 2022-09-02 03:58:00\n","loss: 0.7348, acc: 0.6905\n","E2E-ABSA >>> 2022-09-02 03:58:01\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 03:58:01\n","loss: 0.7314, acc: 0.6813\n","E2E-ABSA >>> 2022-09-02 03:58:02\n","loss: 0.7463, acc: 0.6839\n","E2E-ABSA >>> 2022-09-02 03:58:03\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 03:58:04\n","loss: 0.7453, acc: 0.6798\n","E2E-ABSA >>> 2022-09-02 03:58:05\n","loss: 0.7220, acc: 0.6971\n","E2E-ABSA >>> 2022-09-02 03:58:06\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 03:58:06\n","loss: 0.7230, acc: 0.7002\n","E2E-ABSA >>> 2022-09-02 03:58:08\n","loss: 0.7224, acc: 0.6965\n","E2E-ABSA >>> 2022-09-02 03:58:08\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 03:58:09\n","loss: 0.7230, acc: 0.6978\n","E2E-ABSA >>> 2022-09-02 03:58:10\n",">>> val_acc: 0.6495, val_precision: 0.6495 val_recall: 0.6495, val_f1: 0.6495\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 03:58:10\n","loss: 0.7221, acc: 0.7266\n","E2E-ABSA >>> 2022-09-02 03:58:12\n","loss: 0.6821, acc: 0.7211\n","E2E-ABSA >>> 2022-09-02 03:58:13\n",">>> val_acc: 0.6527, val_precision: 0.6527 val_recall: 0.6527, val_f1: 0.6527\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 03:58:13\n","loss: 0.6856, acc: 0.7300\n","E2E-ABSA >>> 2022-09-02 03:58:14\n","loss: 0.6979, acc: 0.7080\n","E2E-ABSA >>> 2022-09-02 03:58:15\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 03:58:16\n","loss: 0.7174, acc: 0.7009\n","E2E-ABSA >>> 2022-09-02 03:58:17\n","loss: 0.7008, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 03:58:17\n",">>> val_acc: 0.6559, val_precision: 0.6559 val_recall: 0.6559, val_f1: 0.6559\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 03:58:18\n","loss: 0.7089, acc: 0.7044\n","E2E-ABSA >>> 2022-09-02 03:58:19\n","loss: 0.6990, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 03:58:20\n",">>> val_acc: 0.6559, val_precision: 0.6559 val_recall: 0.6559, val_f1: 0.6559\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 03:58:21\n","loss: 0.7038, acc: 0.6974\n","E2E-ABSA >>> 2022-09-02 03:58:22\n","loss: 0.6972, acc: 0.7035\n","E2E-ABSA >>> 2022-09-02 03:58:22\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 03:58:23\n","loss: 0.6750, acc: 0.7238\n","E2E-ABSA >>> 2022-09-02 03:58:25\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 03:58:25\n","loss: 0.6354, acc: 0.7562\n","E2E-ABSA >>> 2022-09-02 03:58:26\n","loss: 0.6669, acc: 0.7159\n","E2E-ABSA >>> 2022-09-02 03:58:27\n",">>> val_acc: 0.6527, val_precision: 0.6527 val_recall: 0.6527, val_f1: 0.6527\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 03:58:27\n","loss: 0.6760, acc: 0.7060\n","E2E-ABSA >>> 2022-09-02 03:58:28\n","loss: 0.6692, acc: 0.7195\n","E2E-ABSA >>> 2022-09-02 03:58:29\n",">>> val_acc: 0.6527, val_precision: 0.6527 val_recall: 0.6527, val_f1: 0.6527\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 03:58:30\n","loss: 0.6825, acc: 0.7159\n","E2E-ABSA >>> 2022-09-02 03:58:31\n","loss: 0.6669, acc: 0.7201\n","E2E-ABSA >>> 2022-09-02 03:58:32\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 03:58:32\n","loss: 0.6826, acc: 0.7223\n","E2E-ABSA >>> 2022-09-02 03:58:34\n","loss: 0.6750, acc: 0.7236\n","E2E-ABSA >>> 2022-09-02 03:58:34\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 03:58:35\n","loss: 0.6876, acc: 0.7220\n","E2E-ABSA >>> 2022-09-02 03:58:36\n","loss: 0.6700, acc: 0.7212\n","E2E-ABSA >>> 2022-09-02 03:58:36\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">> saved: state_dict/tc_lstm_SemEval2014_know_val_f1_0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 03:58:38\n","loss: 0.6574, acc: 0.7329\n","E2E-ABSA >>> 2022-09-02 03:58:39\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 03:58:39\n","loss: 0.6451, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 03:58:40\n","loss: 0.6501, acc: 0.7305\n","E2E-ABSA >>> 2022-09-02 03:58:41\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 03:58:42\n","loss: 0.6631, acc: 0.7069\n","E2E-ABSA >>> 2022-09-02 03:58:43\n","loss: 0.6467, acc: 0.7282\n","E2E-ABSA >>> 2022-09-02 03:58:44\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 03:58:44\n","loss: 0.6607, acc: 0.7364\n","E2E-ABSA >>> 2022-09-02 03:58:45\n","loss: 0.6325, acc: 0.7372\n","E2E-ABSA >>> 2022-09-02 03:58:46\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 03:58:47\n","loss: 0.6527, acc: 0.7282\n","E2E-ABSA >>> 2022-09-02 03:58:48\n","loss: 0.6498, acc: 0.7304\n","E2E-ABSA >>> 2022-09-02 03:58:49\n",">>> val_acc: 0.6495, val_precision: 0.6495 val_recall: 0.6495, val_f1: 0.6495\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 03:58:50\n","loss: 0.6691, acc: 0.7211\n","E2E-ABSA >>> 2022-09-02 03:58:51\n","loss: 0.6439, acc: 0.7326\n","E2E-ABSA >>> 2022-09-02 03:58:51\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 03:58:52\n","loss: 0.6367, acc: 0.7371\n","E2E-ABSA >>> 2022-09-02 03:58:54\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 03:58:54\n","loss: 0.6541, acc: 0.7411\n","E2E-ABSA >>> 2022-09-02 03:58:55\n","loss: 0.6314, acc: 0.7368\n","E2E-ABSA >>> 2022-09-02 03:58:56\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 03:58:56\n","loss: 0.6379, acc: 0.7319\n","E2E-ABSA >>> 2022-09-02 03:58:58\n","loss: 0.6222, acc: 0.7400\n","E2E-ABSA >>> 2022-09-02 03:58:58\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 03:58:59\n","loss: 0.6214, acc: 0.7448\n","E2E-ABSA >>> 2022-09-02 03:59:00\n","loss: 0.6231, acc: 0.7428\n","E2E-ABSA >>> 2022-09-02 03:59:01\n",">>> val_acc: 0.6559, val_precision: 0.6559 val_recall: 0.6559, val_f1: 0.6559\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 03:59:02\n","loss: 0.6244, acc: 0.7356\n","E2E-ABSA >>> 2022-09-02 03:59:03\n","loss: 0.6146, acc: 0.7420\n","E2E-ABSA >>> 2022-09-02 03:59:03\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 03:59:04\n","loss: 0.6082, acc: 0.7409\n","E2E-ABSA >>> 2022-09-02 03:59:05\n","loss: 0.6131, acc: 0.7445\n","E2E-ABSA >>> 2022-09-02 03:59:05\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 03:59:07\n","loss: 0.6023, acc: 0.7456\n","E2E-ABSA >>> 2022-09-02 03:59:08\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 03:59:08\n","loss: 0.6021, acc: 0.7539\n","E2E-ABSA >>> 2022-09-02 03:59:09\n","loss: 0.6085, acc: 0.7462\n","E2E-ABSA >>> 2022-09-02 03:59:10\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 03:59:11\n","loss: 0.5691, acc: 0.7689\n","E2E-ABSA >>> 2022-09-02 03:59:12\n","loss: 0.5995, acc: 0.7462\n","E2E-ABSA >>> 2022-09-02 03:59:13\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 03:59:13\n","loss: 0.5953, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 03:59:14\n","loss: 0.5963, acc: 0.7479\n","E2E-ABSA >>> 2022-09-02 03:59:15\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 03:59:16\n","loss: 0.5774, acc: 0.7743\n","E2E-ABSA >>> 2022-09-02 03:59:17\n","loss: 0.5910, acc: 0.7534\n","E2E-ABSA >>> 2022-09-02 03:59:17\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 03:59:18\n","loss: 0.5657, acc: 0.7716\n","E2E-ABSA >>> 2022-09-02 03:59:20\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 03:59:20\n","loss: 0.5662, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 03:59:21\n","loss: 0.5662, acc: 0.7580\n","E2E-ABSA >>> 2022-09-02 03:59:22\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 03:59:22\n","loss: 0.5470, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 03:59:23\n","loss: 0.5686, acc: 0.7680\n","E2E-ABSA >>> 2022-09-02 03:59:24\n",">>> val_acc: 0.6495, val_precision: 0.6495 val_recall: 0.6495, val_f1: 0.6495\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 03:59:25\n","loss: 0.5888, acc: 0.7518\n","E2E-ABSA >>> 2022-09-02 03:59:26\n","loss: 0.5735, acc: 0.7648\n","E2E-ABSA >>> 2022-09-02 03:59:27\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 03:59:27\n","loss: 0.5436, acc: 0.7752\n","E2E-ABSA >>> 2022-09-02 03:59:29\n","loss: 0.5686, acc: 0.7652\n","E2E-ABSA >>> 2022-09-02 03:59:29\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 03:59:30\n","loss: 0.5598, acc: 0.7690\n","E2E-ABSA >>> 2022-09-02 03:59:31\n","loss: 0.5572, acc: 0.7763\n","E2E-ABSA >>> 2022-09-02 03:59:32\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 03:59:33\n","loss: 0.5840, acc: 0.7616\n","E2E-ABSA >>> 2022-09-02 03:59:34\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 03:59:34\n","loss: 0.4373, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 03:59:35\n","loss: 0.5412, acc: 0.7718\n","E2E-ABSA >>> 2022-09-02 03:59:36\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 03:59:37\n","loss: 0.4888, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 03:59:38\n","loss: 0.5406, acc: 0.7766\n","E2E-ABSA >>> 2022-09-02 03:59:39\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 03:59:39\n","loss: 0.5701, acc: 0.7652\n","E2E-ABSA >>> 2022-09-02 03:59:40\n","loss: 0.5319, acc: 0.7847\n","E2E-ABSA >>> 2022-09-02 03:59:41\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 03:59:42\n","loss: 0.5172, acc: 0.7882\n","E2E-ABSA >>> 2022-09-02 03:59:43\n","loss: 0.5205, acc: 0.7898\n","E2E-ABSA >>> 2022-09-02 03:59:43\n",">>> val_acc: 0.6817, val_precision: 0.6817 val_recall: 0.6817, val_f1: 0.6817\n",">> saved: state_dict/tc_lstm_SemEval2014_know_val_f1_0.6817\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 03:59:44\n","loss: 0.5322, acc: 0.7931\n","E2E-ABSA >>> 2022-09-02 03:59:46\n","loss: 0.5288, acc: 0.7836\n","E2E-ABSA >>> 2022-09-02 03:59:46\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 03:59:47\n","loss: 0.5210, acc: 0.7820\n","E2E-ABSA >>> 2022-09-02 03:59:48\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 03:59:48\n","loss: 0.4506, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 03:59:49\n","loss: 0.5064, acc: 0.8000\n","E2E-ABSA >>> 2022-09-02 03:59:51\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 03:59:51\n","loss: 0.4740, acc: 0.8068\n","E2E-ABSA >>> 2022-09-02 03:59:52\n","loss: 0.5118, acc: 0.8007\n","E2E-ABSA >>> 2022-09-02 03:59:53\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 03:59:53\n","loss: 0.5173, acc: 0.7933\n","E2E-ABSA >>> 2022-09-02 03:59:55\n","loss: 0.5093, acc: 0.7972\n","E2E-ABSA >>> 2022-09-02 03:59:55\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","E2E-ABSA >>> 2022-09-02 03:59:56\n","loss: 0.5217, acc: 0.7946\n","E2E-ABSA >>> 2022-09-02 03:59:57\n","loss: 0.5070, acc: 0.7965\n","E2E-ABSA >>> 2022-09-02 03:59:58\n",">>> val_acc: 0.6785, val_precision: 0.6785 val_recall: 0.6785, val_f1: 0.6785\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","E2E-ABSA >>> 2022-09-02 03:59:59\n","loss: 0.5105, acc: 0.8005\n","E2E-ABSA >>> 2022-09-02 04:00:00\n","loss: 0.5054, acc: 0.7966\n","E2E-ABSA >>> 2022-09-02 04:00:00\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","E2E-ABSA >>> 2022-09-02 04:00:01\n","loss: 0.4865, acc: 0.8090\n","E2E-ABSA >>> 2022-09-02 04:00:02\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","E2E-ABSA >>> 2022-09-02 04:00:02\n","loss: 0.5294, acc: 0.8036\n","E2E-ABSA >>> 2022-09-02 04:00:04\n","loss: 0.5012, acc: 0.7868\n","E2E-ABSA >>> 2022-09-02 04:00:05\n",">>> val_acc: 0.6559, val_precision: 0.6559 val_recall: 0.6559, val_f1: 0.6559\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","E2E-ABSA >>> 2022-09-02 04:00:05\n","loss: 0.5105, acc: 0.8021\n","E2E-ABSA >>> 2022-09-02 04:00:06\n","loss: 0.4987, acc: 0.8009\n","E2E-ABSA >>> 2022-09-02 04:00:07\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","E2E-ABSA >>> 2022-09-02 04:00:08\n","loss: 0.4651, acc: 0.8201\n","E2E-ABSA >>> 2022-09-02 04:00:09\n","loss: 0.4859, acc: 0.7992\n","E2E-ABSA >>> 2022-09-02 04:00:09\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","E2E-ABSA >>> 2022-09-02 04:00:10\n","loss: 0.4887, acc: 0.8017\n","E2E-ABSA >>> 2022-09-02 04:00:11\n","loss: 0.4946, acc: 0.8014\n","E2E-ABSA >>> 2022-09-02 04:00:12\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","E2E-ABSA >>> 2022-09-02 04:00:13\n","loss: 0.4618, acc: 0.8225\n","E2E-ABSA >>> 2022-09-02 04:00:14\n","loss: 0.4807, acc: 0.8086\n","E2E-ABSA >>> 2022-09-02 04:00:14\n",">>> val_acc: 0.6463, val_precision: 0.6463 val_recall: 0.6463, val_f1: 0.6463\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","E2E-ABSA >>> 2022-09-02 04:00:15\n","loss: 0.4754, acc: 0.8166\n","E2E-ABSA >>> 2022-09-02 04:00:17\n",">>> val_acc: 0.6785, val_precision: 0.6785 val_recall: 0.6785, val_f1: 0.6785\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","E2E-ABSA >>> 2022-09-02 04:00:17\n","loss: 0.3959, acc: 0.8681\n","E2E-ABSA >>> 2022-09-02 04:00:18\n","loss: 0.4857, acc: 0.8096\n","E2E-ABSA >>> 2022-09-02 04:00:19\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","E2E-ABSA >>> 2022-09-02 04:00:19\n","loss: 0.4710, acc: 0.8053\n","E2E-ABSA >>> 2022-09-02 04:00:21\n","loss: 0.4698, acc: 0.8046\n","E2E-ABSA >>> 2022-09-02 04:00:21\n",">>> val_acc: 0.6785, val_precision: 0.6785 val_recall: 0.6785, val_f1: 0.6785\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","E2E-ABSA >>> 2022-09-02 04:00:22\n","loss: 0.4842, acc: 0.8183\n","E2E-ABSA >>> 2022-09-02 04:00:23\n","loss: 0.4742, acc: 0.8121\n","E2E-ABSA >>> 2022-09-02 04:00:24\n",">>> val_acc: 0.6785, val_precision: 0.6785 val_recall: 0.6785, val_f1: 0.6785\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","E2E-ABSA >>> 2022-09-02 04:00:24\n","loss: 0.4675, acc: 0.7990\n","E2E-ABSA >>> 2022-09-02 04:00:26\n","loss: 0.4644, acc: 0.8109\n","E2E-ABSA >>> 2022-09-02 04:00:26\n",">>> val_acc: 0.6206, val_precision: 0.6206 val_recall: 0.6206, val_f1: 0.6206\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","E2E-ABSA >>> 2022-09-02 04:00:27\n","loss: 0.4821, acc: 0.7955\n","E2E-ABSA >>> 2022-09-02 04:00:28\n","loss: 0.4649, acc: 0.8132\n","E2E-ABSA >>> 2022-09-02 04:00:28\n",">>> val_acc: 0.6367, val_precision: 0.6367 val_recall: 0.6367, val_f1: 0.6367\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","E2E-ABSA >>> 2022-09-02 04:00:30\n","loss: 0.4515, acc: 0.8178\n","E2E-ABSA >>> 2022-09-02 04:00:31\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","E2E-ABSA >>> 2022-09-02 04:00:31\n","loss: 0.4998, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 04:00:32\n","loss: 0.4602, acc: 0.8131\n","E2E-ABSA >>> 2022-09-02 04:00:33\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","E2E-ABSA >>> 2022-09-02 04:00:34\n","loss: 0.4343, acc: 0.8326\n","E2E-ABSA >>> 2022-09-02 04:00:35\n","loss: 0.4422, acc: 0.8247\n","E2E-ABSA >>> 2022-09-02 04:00:36\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","E2E-ABSA >>> 2022-09-02 04:00:36\n","loss: 0.4486, acc: 0.8167\n","E2E-ABSA >>> 2022-09-02 04:00:37\n","loss: 0.4539, acc: 0.8164\n","E2E-ABSA >>> 2022-09-02 04:00:38\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","E2E-ABSA >>> 2022-09-02 04:00:39\n","loss: 0.4493, acc: 0.8236\n","E2E-ABSA >>> 2022-09-02 04:00:40\n","loss: 0.4431, acc: 0.8167\n","E2E-ABSA >>> 2022-09-02 04:00:40\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","E2E-ABSA >>> 2022-09-02 04:00:41\n","loss: 0.4393, acc: 0.8402\n","E2E-ABSA >>> 2022-09-02 04:00:43\n","loss: 0.4428, acc: 0.8233\n","E2E-ABSA >>> 2022-09-02 04:00:43\n",">>> val_acc: 0.6559, val_precision: 0.6559 val_recall: 0.6559, val_f1: 0.6559\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","E2E-ABSA >>> 2022-09-02 04:00:44\n","loss: 0.4420, acc: 0.8366\n","E2E-ABSA >>> 2022-09-02 04:00:46\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","E2E-ABSA >>> 2022-09-02 04:00:46\n","loss: 0.4222, acc: 0.8317\n","E2E-ABSA >>> 2022-09-02 04:00:47\n","loss: 0.4367, acc: 0.8274\n","E2E-ABSA >>> 2022-09-02 04:00:48\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 90.\n","E2E-ABSA >>> 2022-09-02 04:00:48\n","loss: 0.4183, acc: 0.8417\n","E2E-ABSA >>> 2022-09-02 04:00:50\n","loss: 0.4349, acc: 0.8327\n","E2E-ABSA >>> 2022-09-02 04:00:50\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 91.\n","E2E-ABSA >>> 2022-09-02 04:00:51\n","loss: 0.4292, acc: 0.8298\n","E2E-ABSA >>> 2022-09-02 04:00:52\n","loss: 0.4371, acc: 0.8270\n","E2E-ABSA >>> 2022-09-02 04:00:53\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 92.\n","E2E-ABSA >>> 2022-09-02 04:00:53\n","loss: 0.4432, acc: 0.8232\n","E2E-ABSA >>> 2022-09-02 04:00:55\n","loss: 0.4265, acc: 0.8308\n","E2E-ABSA >>> 2022-09-02 04:00:55\n",">>> val_acc: 0.6559, val_precision: 0.6559 val_recall: 0.6559, val_f1: 0.6559\n","E2E-ABSA >>> 2022-09-02 04:00:55\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6817, val_precision: 0.6817 val_recall: 0.6817, val_f1: 0.6817\n","you can download the best model from state_dict/tc_lstm_SemEval2014_know_val_f1_0.6817\n",">>> test_acc: 0.6817, test_precision: 0.6817, test_recall: 0.6817, test_f1: 0.6817\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2014** dataset on model(**ATAELSTM**)"],"metadata":{"id":"s-iO7yDyFA7D"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name atae_lstm --dataset SemEval2014_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cLcZcCTBFBEL","outputId":"24fc6579-6fb2-463c-e5da-ac5e34799938","executionInfo":{"status":"ok","timestamp":1662091409953,"user_tz":-480,"elapsed":152887,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 3093.\n","> testing dataset count: 329.\n","cuda memory allocated: 25786368\n","> n_trainable_params: 2525703, n_nontrainable_params: 3920100\n","> training arguments:\n",">>> model_name: atae_lstm\n",">>> dataset: SemEval2014_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f6c42cc0c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.atae_lstm.ATAE_LSTM'>\n",">>> dataset_file: {'train': './datasets/laprest14/output_know_insert/train.tsv', 'test': './datasets/laprest14/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:01:36\n","loss: 1.0331, acc: 0.4537\n","E2E-ABSA >>> 2022-09-02 04:01:37\n",">>> val_acc: 0.5897, val_precision: 0.5897 val_recall: 0.5897, val_f1: 0.5897\n",">> saved: state_dict/atae_lstm_SemEval2014_know_val_f1_0.5897\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:01:37\n","loss: 0.9260, acc: 0.5417\n","E2E-ABSA >>> 2022-09-02 04:01:39\n","loss: 0.9444, acc: 0.5837\n","E2E-ABSA >>> 2022-09-02 04:01:40\n",">>> val_acc: 0.6109, val_precision: 0.6109 val_recall: 0.6109, val_f1: 0.6109\n",">> saved: state_dict/atae_lstm_SemEval2014_know_val_f1_0.6109\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:01:40\n","loss: 0.9598, acc: 0.5885\n","E2E-ABSA >>> 2022-09-02 04:01:41\n","loss: 0.9124, acc: 0.5988\n","E2E-ABSA >>> 2022-09-02 04:01:43\n",">>> val_acc: 0.6322, val_precision: 0.6322 val_recall: 0.6322, val_f1: 0.6322\n",">> saved: state_dict/atae_lstm_SemEval2014_know_val_f1_0.6322\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:01:43\n","loss: 0.8951, acc: 0.6111\n","E2E-ABSA >>> 2022-09-02 04:01:44\n","loss: 0.8902, acc: 0.6118\n","E2E-ABSA >>> 2022-09-02 04:01:45\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">> saved: state_dict/atae_lstm_SemEval2014_know_val_f1_0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:01:46\n","loss: 0.8734, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 04:01:47\n","loss: 0.8846, acc: 0.6144\n","E2E-ABSA >>> 2022-09-02 04:01:48\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:01:48\n","loss: 0.9248, acc: 0.5792\n","E2E-ABSA >>> 2022-09-02 04:01:50\n","loss: 0.8879, acc: 0.6038\n","E2E-ABSA >>> 2022-09-02 04:01:51\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:01:51\n","loss: 0.8826, acc: 0.6042\n","E2E-ABSA >>> 2022-09-02 04:01:52\n","loss: 0.8691, acc: 0.6103\n","E2E-ABSA >>> 2022-09-02 04:01:53\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">> saved: state_dict/atae_lstm_SemEval2014_know_val_f1_0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:01:54\n","loss: 0.8643, acc: 0.6295\n","E2E-ABSA >>> 2022-09-02 04:01:55\n","loss: 0.8605, acc: 0.6268\n","E2E-ABSA >>> 2022-09-02 04:01:56\n",">>> val_acc: 0.6596, val_precision: 0.6596 val_recall: 0.6596, val_f1: 0.6596\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:01:57\n","loss: 0.8246, acc: 0.6471\n","E2E-ABSA >>> 2022-09-02 04:01:58\n","loss: 0.8411, acc: 0.6318\n","E2E-ABSA >>> 2022-09-02 04:01:59\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:01:59\n","loss: 0.8019, acc: 0.6551\n","E2E-ABSA >>> 2022-09-02 04:02:01\n","loss: 0.8043, acc: 0.6542\n","E2E-ABSA >>> 2022-09-02 04:02:01\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:02:02\n","loss: 0.7822, acc: 0.6615\n","E2E-ABSA >>> 2022-09-02 04:02:03\n","loss: 0.7610, acc: 0.6758\n","E2E-ABSA >>> 2022-09-02 04:02:04\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">> saved: state_dict/atae_lstm_SemEval2014_know_val_f1_0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:02:05\n","loss: 0.7512, acc: 0.6714\n","E2E-ABSA >>> 2022-09-02 04:02:06\n","loss: 0.7464, acc: 0.6736\n","E2E-ABSA >>> 2022-09-02 04:02:07\n",">>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n",">> saved: state_dict/atae_lstm_SemEval2014_know_val_f1_0.696\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:02:08\n","loss: 0.7230, acc: 0.6970\n","E2E-ABSA >>> 2022-09-02 04:02:09\n","loss: 0.7274, acc: 0.6871\n","E2E-ABSA >>> 2022-09-02 04:02:10\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:02:11\n","loss: 0.7165, acc: 0.6899\n","E2E-ABSA >>> 2022-09-02 04:02:12\n","loss: 0.7067, acc: 0.6973\n","E2E-ABSA >>> 2022-09-02 04:02:12\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:02:13\n","loss: 0.6935, acc: 0.7113\n","E2E-ABSA >>> 2022-09-02 04:02:15\n","loss: 0.6946, acc: 0.7096\n","E2E-ABSA >>> 2022-09-02 04:02:15\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:02:16\n","loss: 0.6896, acc: 0.7014\n","E2E-ABSA >>> 2022-09-02 04:02:17\n","loss: 0.6896, acc: 0.7020\n","E2E-ABSA >>> 2022-09-02 04:02:18\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:02:19\n","loss: 0.6786, acc: 0.7129\n","E2E-ABSA >>> 2022-09-02 04:02:20\n",">>> val_acc: 0.6626, val_precision: 0.6626 val_recall: 0.6626, val_f1: 0.6626\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:02:20\n","loss: 0.6328, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:02:22\n","loss: 0.6773, acc: 0.7077\n","E2E-ABSA >>> 2022-09-02 04:02:23\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:02:23\n","loss: 0.7446, acc: 0.6641\n","E2E-ABSA >>> 2022-09-02 04:02:24\n","loss: 0.6762, acc: 0.7147\n","E2E-ABSA >>> 2022-09-02 04:02:26\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:02:26\n","loss: 0.6314, acc: 0.7545\n","E2E-ABSA >>> 2022-09-02 04:02:27\n","loss: 0.6480, acc: 0.7270\n","E2E-ABSA >>> 2022-09-02 04:02:28\n",">>> val_acc: 0.6596, val_precision: 0.6596 val_recall: 0.6596, val_f1: 0.6596\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:02:29\n","loss: 0.6077, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 04:02:30\n","loss: 0.6488, acc: 0.7266\n","E2E-ABSA >>> 2022-09-02 04:02:31\n",">>> val_acc: 0.6505, val_precision: 0.6505 val_recall: 0.6505, val_f1: 0.6505\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:02:31\n","loss: 0.6301, acc: 0.7620\n","E2E-ABSA >>> 2022-09-02 04:02:33\n","loss: 0.6505, acc: 0.7272\n","E2E-ABSA >>> 2022-09-02 04:02:34\n",">>> val_acc: 0.6626, val_precision: 0.6626 val_recall: 0.6626, val_f1: 0.6626\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:02:34\n","loss: 0.6229, acc: 0.7285\n","E2E-ABSA >>> 2022-09-02 04:02:35\n","loss: 0.6372, acc: 0.7382\n","E2E-ABSA >>> 2022-09-02 04:02:36\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:02:37\n","loss: 0.6244, acc: 0.7467\n","E2E-ABSA >>> 2022-09-02 04:02:39\n","loss: 0.6283, acc: 0.7391\n","E2E-ABSA >>> 2022-09-02 04:02:40\n",">>> val_acc: 0.6626, val_precision: 0.6626 val_recall: 0.6626, val_f1: 0.6626\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:02:40\n","loss: 0.6285, acc: 0.7514\n","E2E-ABSA >>> 2022-09-02 04:02:41\n","loss: 0.6222, acc: 0.7470\n","E2E-ABSA >>> 2022-09-02 04:02:42\n",">>> val_acc: 0.6809, val_precision: 0.6809 val_recall: 0.6809, val_f1: 0.6809\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:02:43\n","loss: 0.6157, acc: 0.7462\n","E2E-ABSA >>> 2022-09-02 04:02:44\n","loss: 0.6171, acc: 0.7479\n","E2E-ABSA >>> 2022-09-02 04:02:45\n",">>> val_acc: 0.6626, val_precision: 0.6626 val_recall: 0.6626, val_f1: 0.6626\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:02:46\n","loss: 0.6353, acc: 0.7444\n","E2E-ABSA >>> 2022-09-02 04:02:47\n","loss: 0.6079, acc: 0.7548\n","E2E-ABSA >>> 2022-09-02 04:02:48\n",">>> val_acc: 0.6869, val_precision: 0.6869 val_recall: 0.6869, val_f1: 0.6869\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:02:48\n","loss: 0.6301, acc: 0.7480\n","E2E-ABSA >>> 2022-09-02 04:02:50\n","loss: 0.6117, acc: 0.7542\n","E2E-ABSA >>> 2022-09-02 04:02:50\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:02:51\n","loss: 0.5993, acc: 0.7785\n","E2E-ABSA >>> 2022-09-02 04:02:52\n","loss: 0.6062, acc: 0.7533\n","E2E-ABSA >>> 2022-09-02 04:02:53\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:02:54\n","loss: 0.6059, acc: 0.7627\n","E2E-ABSA >>> 2022-09-02 04:02:55\n","loss: 0.5949, acc: 0.7640\n","E2E-ABSA >>> 2022-09-02 04:02:56\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:02:57\n","loss: 0.5900, acc: 0.7680\n","E2E-ABSA >>> 2022-09-02 04:02:58\n","loss: 0.5919, acc: 0.7625\n","E2E-ABSA >>> 2022-09-02 04:02:58\n",">>> val_acc: 0.6809, val_precision: 0.6809 val_recall: 0.6809, val_f1: 0.6809\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 04:02:59\n","loss: 0.5907, acc: 0.7609\n","E2E-ABSA >>> 2022-09-02 04:03:01\n","loss: 0.5899, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 04:03:01\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 04:03:02\n","loss: 0.5696, acc: 0.7806\n","E2E-ABSA >>> 2022-09-02 04:03:03\n","loss: 0.5866, acc: 0.7643\n","E2E-ABSA >>> 2022-09-02 04:03:04\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 04:03:05\n","loss: 0.5893, acc: 0.7608\n","E2E-ABSA >>> 2022-09-02 04:03:06\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 04:03:06\n","loss: 0.6864, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:03:08\n","loss: 0.5786, acc: 0.7752\n","E2E-ABSA >>> 2022-09-02 04:03:09\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 04:03:09\n","loss: 0.6256, acc: 0.7250\n","E2E-ABSA >>> 2022-09-02 04:03:10\n","loss: 0.5765, acc: 0.7750\n","E2E-ABSA >>> 2022-09-02 04:03:12\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 04:03:12\n","loss: 0.5826, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:03:13\n","loss: 0.5684, acc: 0.7732\n","E2E-ABSA >>> 2022-09-02 04:03:14\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 04:03:15\n","loss: 0.5191, acc: 0.7983\n","E2E-ABSA >>> 2022-09-02 04:03:16\n","loss: 0.5614, acc: 0.7741\n","E2E-ABSA >>> 2022-09-02 04:03:17\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 04:03:17\n","loss: 0.5390, acc: 0.7946\n","E2E-ABSA >>> 2022-09-02 04:03:19\n","loss: 0.5524, acc: 0.7871\n","E2E-ABSA >>> 2022-09-02 04:03:20\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 04:03:20\n","loss: 0.5509, acc: 0.7886\n","E2E-ABSA >>> 2022-09-02 04:03:22\n","loss: 0.5655, acc: 0.7729\n","E2E-ABSA >>> 2022-09-02 04:03:23\n",">>> val_acc: 0.6809, val_precision: 0.6809 val_recall: 0.6809, val_f1: 0.6809\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 04:03:23\n","loss: 0.5064, acc: 0.8234\n","E2E-ABSA >>> 2022-09-02 04:03:24\n","loss: 0.5324, acc: 0.7924\n","E2E-ABSA >>> 2022-09-02 04:03:25\n",">>> val_acc: 0.6900, val_precision: 0.6900 val_recall: 0.6900, val_f1: 0.6900\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 04:03:26\n","loss: 0.5393, acc: 0.7799\n","E2E-ABSA >>> 2022-09-02 04:03:27\n","loss: 0.5403, acc: 0.7808\n","E2E-ABSA >>> 2022-09-02 04:03:28\n",">>> val_acc: 0.6900, val_precision: 0.6900 val_recall: 0.6900, val_f1: 0.6900\n","E2E-ABSA >>> 2022-09-02 04:03:28\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n","you can download the best model from state_dict/atae_lstm_SemEval2014_know_val_f1_0.696\n",">>> test_acc: 0.6960, test_precision: 0.6960, test_recall: 0.6960, test_f1: 0.6960\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2014** dataset on model(**IAN**)"],"metadata":{"id":"nqgXCCOoGtQs"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name ian --dataset SemEval2014_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9z-EMWpGtXk","outputId":"267dbb9b-39e9-44c9-942a-da5230ac0401","executionInfo":{"status":"ok","timestamp":1662091721867,"user_tz":-480,"elapsed":311918,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 3093.\n","> testing dataset count: 329.\n","cuda memory allocated: 24360960\n","> n_trainable_params: 2168403, n_nontrainable_params: 3920100\n","> training arguments:\n",">>> model_name: ian\n",">>> dataset: SemEval2014_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f7b5ab90c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.ian.IAN'>\n",">>> dataset_file: {'train': './datasets/laprest14/output_know_insert/train.tsv', 'test': './datasets/laprest14/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:10\n","loss: 1.0084, acc: 0.5575\n","E2E-ABSA >>> 2022-09-02 04:04:11\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:11\n","loss: 0.9721, acc: 0.5729\n","E2E-ABSA >>> 2022-09-02 04:04:13\n","loss: 0.9858, acc: 0.5501\n","E2E-ABSA >>> 2022-09-02 04:04:14\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:15\n","loss: 0.9603, acc: 0.5625\n","E2E-ABSA >>> 2022-09-02 04:04:16\n","loss: 0.9529, acc: 0.5714\n","E2E-ABSA >>> 2022-09-02 04:04:18\n",">>> val_acc: 0.5775, val_precision: 0.5775 val_recall: 0.5775, val_f1: 0.5775\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.5775\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:18\n","loss: 0.9388, acc: 0.5694\n","E2E-ABSA >>> 2022-09-02 04:04:19\n","loss: 0.9556, acc: 0.5614\n","E2E-ABSA >>> 2022-09-02 04:04:21\n",">>> val_acc: 0.5775, val_precision: 0.5775 val_recall: 0.5775, val_f1: 0.5775\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:21\n","loss: 0.9547, acc: 0.5625\n","E2E-ABSA >>> 2022-09-02 04:04:23\n","loss: 0.9454, acc: 0.5696\n","E2E-ABSA >>> 2022-09-02 04:04:24\n",">>> val_acc: 0.5836, val_precision: 0.5836 val_recall: 0.5836, val_f1: 0.5836\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.5836\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:25\n","loss: 0.9280, acc: 0.5813\n","E2E-ABSA >>> 2022-09-02 04:04:26\n","loss: 0.9312, acc: 0.5769\n","E2E-ABSA >>> 2022-09-02 04:04:27\n",">>> val_acc: 0.5775, val_precision: 0.5775 val_recall: 0.5775, val_f1: 0.5775\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:28\n","loss: 0.9512, acc: 0.5677\n","E2E-ABSA >>> 2022-09-02 04:04:29\n","loss: 0.9307, acc: 0.5818\n","E2E-ABSA >>> 2022-09-02 04:04:30\n",">>> val_acc: 0.5836, val_precision: 0.5836 val_recall: 0.5836, val_f1: 0.5836\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:31\n","loss: 0.9453, acc: 0.5655\n","E2E-ABSA >>> 2022-09-02 04:04:33\n","loss: 0.9420, acc: 0.5717\n","E2E-ABSA >>> 2022-09-02 04:04:34\n",">>> val_acc: 0.5866, val_precision: 0.5866 val_recall: 0.5866, val_f1: 0.5866\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.5866\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:35\n","loss: 0.9239, acc: 0.5768\n","E2E-ABSA >>> 2022-09-02 04:04:37\n","loss: 0.9264, acc: 0.5823\n","E2E-ABSA >>> 2022-09-02 04:04:38\n",">>> val_acc: 0.5866, val_precision: 0.5866 val_recall: 0.5866, val_f1: 0.5866\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:38\n","loss: 0.9212, acc: 0.5972\n","E2E-ABSA >>> 2022-09-02 04:04:40\n","loss: 0.9339, acc: 0.5844\n","E2E-ABSA >>> 2022-09-02 04:04:41\n",">>> val_acc: 0.5927, val_precision: 0.5927 val_recall: 0.5927, val_f1: 0.5927\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.5927\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:42\n","loss: 0.9314, acc: 0.5948\n","E2E-ABSA >>> 2022-09-02 04:04:43\n","loss: 0.9276, acc: 0.5906\n","E2E-ABSA >>> 2022-09-02 04:04:44\n",">>> val_acc: 0.5927, val_precision: 0.5927 val_recall: 0.5927, val_f1: 0.5927\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:45\n","loss: 0.9382, acc: 0.5824\n","E2E-ABSA >>> 2022-09-02 04:04:47\n","loss: 0.9286, acc: 0.5866\n","E2E-ABSA >>> 2022-09-02 04:04:47\n",">>> val_acc: 0.5927, val_precision: 0.5927 val_recall: 0.5927, val_f1: 0.5927\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:48\n","loss: 0.9231, acc: 0.5903\n","E2E-ABSA >>> 2022-09-02 04:04:50\n","loss: 0.9219, acc: 0.5890\n","E2E-ABSA >>> 2022-09-02 04:04:50\n",">>> val_acc: 0.5988, val_precision: 0.5988 val_recall: 0.5988, val_f1: 0.5988\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.5988\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:52\n","loss: 0.9104, acc: 0.6050\n","E2E-ABSA >>> 2022-09-02 04:04:53\n","loss: 0.9236, acc: 0.5941\n","E2E-ABSA >>> 2022-09-02 04:04:54\n",">>> val_acc: 0.6079, val_precision: 0.6079 val_recall: 0.6079, val_f1: 0.6079\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.6079\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:55\n","loss: 0.9151, acc: 0.5923\n","E2E-ABSA >>> 2022-09-02 04:04:57\n","loss: 0.9200, acc: 0.5931\n","E2E-ABSA >>> 2022-09-02 04:04:57\n",">>> val_acc: 0.6079, val_precision: 0.6079 val_recall: 0.6079, val_f1: 0.6079\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:04:58\n","loss: 0.9224, acc: 0.5903\n","E2E-ABSA >>> 2022-09-02 04:05:00\n","loss: 0.9224, acc: 0.5941\n","E2E-ABSA >>> 2022-09-02 04:05:00\n",">>> val_acc: 0.6079, val_precision: 0.6079 val_recall: 0.6079, val_f1: 0.6079\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:02\n","loss: 0.9140, acc: 0.5983\n","E2E-ABSA >>> 2022-09-02 04:05:03\n",">>> val_acc: 0.6140, val_precision: 0.6140 val_recall: 0.6140, val_f1: 0.6140\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.614\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:03\n","loss: 0.8550, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:05:05\n","loss: 0.9303, acc: 0.5895\n","E2E-ABSA >>> 2022-09-02 04:05:07\n",">>> val_acc: 0.6170, val_precision: 0.6170 val_recall: 0.6170, val_f1: 0.6170\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.617\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:07\n","loss: 0.9520, acc: 0.5859\n","E2E-ABSA >>> 2022-09-02 04:05:08\n","loss: 0.9219, acc: 0.6019\n","E2E-ABSA >>> 2022-09-02 04:05:10\n",">>> val_acc: 0.6140, val_precision: 0.6140 val_recall: 0.6140, val_f1: 0.6140\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:10\n","loss: 0.8554, acc: 0.6429\n","E2E-ABSA >>> 2022-09-02 04:05:12\n","loss: 0.9136, acc: 0.6058\n","E2E-ABSA >>> 2022-09-02 04:05:13\n",">>> val_acc: 0.6201, val_precision: 0.6201 val_recall: 0.6201, val_f1: 0.6201\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.6201\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:13\n","loss: 0.9087, acc: 0.6125\n","E2E-ABSA >>> 2022-09-02 04:05:15\n","loss: 0.9046, acc: 0.6036\n","E2E-ABSA >>> 2022-09-02 04:05:16\n",">>> val_acc: 0.6292, val_precision: 0.6292 val_recall: 0.6292, val_f1: 0.6292\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.6292\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:17\n","loss: 0.9166, acc: 0.5913\n","E2E-ABSA >>> 2022-09-02 04:05:18\n","loss: 0.9240, acc: 0.5987\n","E2E-ABSA >>> 2022-09-02 04:05:19\n",">>> val_acc: 0.6170, val_precision: 0.6170 val_recall: 0.6170, val_f1: 0.6170\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:20\n","loss: 0.9376, acc: 0.5840\n","E2E-ABSA >>> 2022-09-02 04:05:21\n","loss: 0.9145, acc: 0.5999\n","E2E-ABSA >>> 2022-09-02 04:05:23\n",">>> val_acc: 0.6231, val_precision: 0.6231 val_recall: 0.6231, val_f1: 0.6231\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:23\n","loss: 0.9003, acc: 0.6102\n","E2E-ABSA >>> 2022-09-02 04:05:25\n","loss: 0.9005, acc: 0.6110\n","E2E-ABSA >>> 2022-09-02 04:05:26\n",">>> val_acc: 0.6201, val_precision: 0.6201 val_recall: 0.6201, val_f1: 0.6201\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:27\n","loss: 0.9064, acc: 0.6108\n","E2E-ABSA >>> 2022-09-02 04:05:28\n","loss: 0.9084, acc: 0.6033\n","E2E-ABSA >>> 2022-09-02 04:05:29\n",">>> val_acc: 0.6231, val_precision: 0.6231 val_recall: 0.6231, val_f1: 0.6231\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:30\n","loss: 0.9211, acc: 0.6025\n","E2E-ABSA >>> 2022-09-02 04:05:31\n","loss: 0.9152, acc: 0.6025\n","E2E-ABSA >>> 2022-09-02 04:05:32\n",">>> val_acc: 0.6322, val_precision: 0.6322 val_recall: 0.6322, val_f1: 0.6322\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.6322\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:33\n","loss: 0.8821, acc: 0.6317\n","E2E-ABSA >>> 2022-09-02 04:05:35\n","loss: 0.9082, acc: 0.6074\n","E2E-ABSA >>> 2022-09-02 04:05:35\n",">>> val_acc: 0.6322, val_precision: 0.6322 val_recall: 0.6322, val_f1: 0.6322\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:36\n","loss: 0.8906, acc: 0.6190\n","E2E-ABSA >>> 2022-09-02 04:05:38\n","loss: 0.9057, acc: 0.6080\n","E2E-ABSA >>> 2022-09-02 04:05:39\n",">>> val_acc: 0.6383, val_precision: 0.6383 val_recall: 0.6383, val_f1: 0.6383\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.6383\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:40\n","loss: 0.8935, acc: 0.6213\n","E2E-ABSA >>> 2022-09-02 04:05:41\n","loss: 0.9022, acc: 0.6101\n","E2E-ABSA >>> 2022-09-02 04:05:42\n",">>> val_acc: 0.6383, val_precision: 0.6383 val_recall: 0.6383, val_f1: 0.6383\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:43\n","loss: 0.8947, acc: 0.6115\n","E2E-ABSA >>> 2022-09-02 04:05:45\n","loss: 0.9017, acc: 0.6078\n","E2E-ABSA >>> 2022-09-02 04:05:45\n",">>> val_acc: 0.6383, val_precision: 0.6383 val_recall: 0.6383, val_f1: 0.6383\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:46\n","loss: 0.9058, acc: 0.6062\n","E2E-ABSA >>> 2022-09-02 04:05:48\n","loss: 0.9045, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 04:05:48\n",">>> val_acc: 0.6322, val_precision: 0.6322 val_recall: 0.6322, val_f1: 0.6322\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:50\n","loss: 0.9098, acc: 0.6003\n","E2E-ABSA >>> 2022-09-02 04:05:51\n","loss: 0.9064, acc: 0.6055\n","E2E-ABSA >>> 2022-09-02 04:05:51\n",">>> val_acc: 0.6353, val_precision: 0.6353 val_recall: 0.6353, val_f1: 0.6353\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:53\n","loss: 0.9177, acc: 0.6033\n","E2E-ABSA >>> 2022-09-02 04:05:54\n","loss: 0.9054, acc: 0.6130\n","E2E-ABSA >>> 2022-09-02 04:05:55\n",">>> val_acc: 0.6292, val_precision: 0.6292 val_recall: 0.6292, val_f1: 0.6292\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:56\n","loss: 0.9133, acc: 0.5976\n","E2E-ABSA >>> 2022-09-02 04:05:58\n",">>> val_acc: 0.6444, val_precision: 0.6444 val_recall: 0.6444, val_f1: 0.6444\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.6444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:05:58\n","loss: 0.9043, acc: 0.5938\n","E2E-ABSA >>> 2022-09-02 04:05:59\n","loss: 0.9239, acc: 0.5895\n","E2E-ABSA >>> 2022-09-02 04:06:01\n",">>> val_acc: 0.6444, val_precision: 0.6444 val_recall: 0.6444, val_f1: 0.6444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:01\n","loss: 0.9748, acc: 0.5625\n","E2E-ABSA >>> 2022-09-02 04:06:03\n","loss: 0.9181, acc: 0.6011\n","E2E-ABSA >>> 2022-09-02 04:06:04\n",">>> val_acc: 0.6353, val_precision: 0.6353 val_recall: 0.6353, val_f1: 0.6353\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:04\n","loss: 0.9865, acc: 0.5391\n","E2E-ABSA >>> 2022-09-02 04:06:06\n","loss: 0.9248, acc: 0.5905\n","E2E-ABSA >>> 2022-09-02 04:06:07\n",">>> val_acc: 0.6231, val_precision: 0.6231 val_recall: 0.6231, val_f1: 0.6231\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:08\n","loss: 0.8695, acc: 0.6364\n","E2E-ABSA >>> 2022-09-02 04:06:09\n","loss: 0.8972, acc: 0.6112\n","E2E-ABSA >>> 2022-09-02 04:06:10\n",">>> val_acc: 0.6383, val_precision: 0.6383 val_recall: 0.6383, val_f1: 0.6383\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:11\n","loss: 0.8986, acc: 0.6205\n","E2E-ABSA >>> 2022-09-02 04:06:12\n","loss: 0.9007, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 04:06:14\n",">>> val_acc: 0.6413, val_precision: 0.6413 val_recall: 0.6413, val_f1: 0.6413\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:14\n","loss: 0.8663, acc: 0.6121\n","E2E-ABSA >>> 2022-09-02 04:06:16\n","loss: 0.8879, acc: 0.6138\n","E2E-ABSA >>> 2022-09-02 04:06:17\n",">>> val_acc: 0.6444, val_precision: 0.6444 val_recall: 0.6444, val_f1: 0.6444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:17\n","loss: 0.8836, acc: 0.6312\n","E2E-ABSA >>> 2022-09-02 04:06:19\n","loss: 0.8984, acc: 0.6076\n","E2E-ABSA >>> 2022-09-02 04:06:20\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:21\n","loss: 0.9188, acc: 0.5883\n","E2E-ABSA >>> 2022-09-02 04:06:22\n","loss: 0.9022, acc: 0.6040\n","E2E-ABSA >>> 2022-09-02 04:06:23\n",">>> val_acc: 0.6444, val_precision: 0.6444 val_recall: 0.6444, val_f1: 0.6444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:24\n","loss: 0.8961, acc: 0.6202\n","E2E-ABSA >>> 2022-09-02 04:06:25\n","loss: 0.9040, acc: 0.6102\n","E2E-ABSA >>> 2022-09-02 04:06:26\n",">>> val_acc: 0.6413, val_precision: 0.6413 val_recall: 0.6413, val_f1: 0.6413\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:27\n","loss: 0.8735, acc: 0.6390\n","E2E-ABSA >>> 2022-09-02 04:06:29\n","loss: 0.8975, acc: 0.6171\n","E2E-ABSA >>> 2022-09-02 04:06:30\n",">>> val_acc: 0.6444, val_precision: 0.6444 val_recall: 0.6444, val_f1: 0.6444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:31\n","loss: 0.9042, acc: 0.6152\n","E2E-ABSA >>> 2022-09-02 04:06:32\n","loss: 0.8928, acc: 0.6181\n","E2E-ABSA >>> 2022-09-02 04:06:33\n",">>> val_acc: 0.6413, val_precision: 0.6413 val_recall: 0.6413, val_f1: 0.6413\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:34\n","loss: 0.9094, acc: 0.6089\n","E2E-ABSA >>> 2022-09-02 04:06:36\n","loss: 0.8953, acc: 0.6176\n","E2E-ABSA >>> 2022-09-02 04:06:36\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:37\n","loss: 0.8984, acc: 0.6077\n","E2E-ABSA >>> 2022-09-02 04:06:39\n","loss: 0.8964, acc: 0.6101\n","E2E-ABSA >>> 2022-09-02 04:06:39\n",">>> val_acc: 0.6444, val_precision: 0.6444 val_recall: 0.6444, val_f1: 0.6444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:41\n","loss: 0.9028, acc: 0.6166\n","E2E-ABSA >>> 2022-09-02 04:06:42\n","loss: 0.8973, acc: 0.6164\n","E2E-ABSA >>> 2022-09-02 04:06:42\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:44\n","loss: 0.9026, acc: 0.6072\n","E2E-ABSA >>> 2022-09-02 04:06:45\n","loss: 0.8955, acc: 0.6164\n","E2E-ABSA >>> 2022-09-02 04:06:46\n",">>> val_acc: 0.6444, val_precision: 0.6444 val_recall: 0.6444, val_f1: 0.6444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:47\n","loss: 0.9098, acc: 0.6051\n","E2E-ABSA >>> 2022-09-02 04:06:49\n","loss: 0.8967, acc: 0.6146\n","E2E-ABSA >>> 2022-09-02 04:06:49\n",">>> val_acc: 0.6413, val_precision: 0.6413 val_recall: 0.6413, val_f1: 0.6413\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:50\n","loss: 0.8962, acc: 0.6131\n","E2E-ABSA >>> 2022-09-02 04:06:52\n",">>> val_acc: 0.6413, val_precision: 0.6413 val_recall: 0.6413, val_f1: 0.6413\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:52\n","loss: 0.9260, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 04:06:54\n","loss: 0.9070, acc: 0.6055\n","E2E-ABSA >>> 2022-09-02 04:06:55\n",">>> val_acc: 0.6413, val_precision: 0.6413 val_recall: 0.6413, val_f1: 0.6413\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:55\n","loss: 0.8519, acc: 0.6406\n","E2E-ABSA >>> 2022-09-02 04:06:57\n","loss: 0.9093, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 04:06:58\n",">>> val_acc: 0.6444, val_precision: 0.6444 val_recall: 0.6444, val_f1: 0.6444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:06:58\n","loss: 0.8626, acc: 0.6354\n","E2E-ABSA >>> 2022-09-02 04:07:00\n","loss: 0.8766, acc: 0.6308\n","E2E-ABSA >>> 2022-09-02 04:07:01\n",">>> val_acc: 0.6383, val_precision: 0.6383 val_recall: 0.6383, val_f1: 0.6383\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:02\n","loss: 0.9135, acc: 0.6042\n","E2E-ABSA >>> 2022-09-02 04:07:03\n","loss: 0.8927, acc: 0.6220\n","E2E-ABSA >>> 2022-09-02 04:07:05\n",">>> val_acc: 0.6535, val_precision: 0.6535 val_recall: 0.6535, val_f1: 0.6535\n",">> saved: state_dict/ian_SemEval2014_know_val_f1_0.6535\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:05\n","loss: 0.9045, acc: 0.6062\n","E2E-ABSA >>> 2022-09-02 04:07:07\n","loss: 0.8940, acc: 0.6178\n","E2E-ABSA >>> 2022-09-02 04:07:08\n",">>> val_acc: 0.6413, val_precision: 0.6413 val_recall: 0.6413, val_f1: 0.6413\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:08\n","loss: 0.9031, acc: 0.6007\n","E2E-ABSA >>> 2022-09-02 04:07:10\n","loss: 0.8936, acc: 0.6195\n","E2E-ABSA >>> 2022-09-02 04:07:11\n",">>> val_acc: 0.6413, val_precision: 0.6413 val_recall: 0.6413, val_f1: 0.6413\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:12\n","loss: 0.8989, acc: 0.6161\n","E2E-ABSA >>> 2022-09-02 04:07:13\n","loss: 0.8839, acc: 0.6241\n","E2E-ABSA >>> 2022-09-02 04:07:14\n",">>> val_acc: 0.6535, val_precision: 0.6535 val_recall: 0.6535, val_f1: 0.6535\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:15\n","loss: 0.9032, acc: 0.6146\n","E2E-ABSA >>> 2022-09-02 04:07:16\n","loss: 0.8813, acc: 0.6326\n","E2E-ABSA >>> 2022-09-02 04:07:17\n",">>> val_acc: 0.6444, val_precision: 0.6444 val_recall: 0.6444, val_f1: 0.6444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:18\n","loss: 0.8792, acc: 0.6296\n","E2E-ABSA >>> 2022-09-02 04:07:20\n","loss: 0.8907, acc: 0.6193\n","E2E-ABSA >>> 2022-09-02 04:07:21\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:22\n","loss: 0.8792, acc: 0.6292\n","E2E-ABSA >>> 2022-09-02 04:07:23\n","loss: 0.8844, acc: 0.6238\n","E2E-ABSA >>> 2022-09-02 04:07:24\n",">>> val_acc: 0.6413, val_precision: 0.6413 val_recall: 0.6413, val_f1: 0.6413\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:25\n","loss: 0.8712, acc: 0.6345\n","E2E-ABSA >>> 2022-09-02 04:07:26\n","loss: 0.8885, acc: 0.6235\n","E2E-ABSA >>> 2022-09-02 04:07:27\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:28\n","loss: 0.8436, acc: 0.6623\n","E2E-ABSA >>> 2022-09-02 04:07:30\n","loss: 0.8838, acc: 0.6283\n","E2E-ABSA >>> 2022-09-02 04:07:30\n",">>> val_acc: 0.6505, val_precision: 0.6505 val_recall: 0.6505, val_f1: 0.6505\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:31\n","loss: 0.8890, acc: 0.6178\n","E2E-ABSA >>> 2022-09-02 04:07:33\n","loss: 0.8880, acc: 0.6187\n","E2E-ABSA >>> 2022-09-02 04:07:33\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:35\n","loss: 0.8860, acc: 0.6369\n","E2E-ABSA >>> 2022-09-02 04:07:36\n","loss: 0.8861, acc: 0.6247\n","E2E-ABSA >>> 2022-09-02 04:07:36\n",">>> val_acc: 0.6505, val_precision: 0.6505 val_recall: 0.6505, val_f1: 0.6505\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:38\n","loss: 0.8735, acc: 0.6382\n","E2E-ABSA >>> 2022-09-02 04:07:39\n","loss: 0.8879, acc: 0.6237\n","E2E-ABSA >>> 2022-09-02 04:07:40\n",">>> val_acc: 0.6444, val_precision: 0.6444 val_recall: 0.6444, val_f1: 0.6444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:41\n","loss: 0.8718, acc: 0.6289\n","E2E-ABSA >>> 2022-09-02 04:07:43\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:43\n","loss: 0.7904, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:07:44\n","loss: 0.8786, acc: 0.6360\n","E2E-ABSA >>> 2022-09-02 04:07:46\n",">>> val_acc: 0.6505, val_precision: 0.6505 val_recall: 0.6505, val_f1: 0.6505\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:46\n","loss: 0.8509, acc: 0.6484\n","E2E-ABSA >>> 2022-09-02 04:07:47\n","loss: 0.8825, acc: 0.6209\n","E2E-ABSA >>> 2022-09-02 04:07:49\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:49\n","loss: 0.8380, acc: 0.6652\n","E2E-ABSA >>> 2022-09-02 04:07:51\n","loss: 0.8687, acc: 0.6382\n","E2E-ABSA >>> 2022-09-02 04:07:52\n",">>> val_acc: 0.6505, val_precision: 0.6505 val_recall: 0.6505, val_f1: 0.6505\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:52\n","loss: 0.8511, acc: 0.6469\n","E2E-ABSA >>> 2022-09-02 04:07:54\n","loss: 0.8853, acc: 0.6234\n","E2E-ABSA >>> 2022-09-02 04:07:55\n",">>> val_acc: 0.6444, val_precision: 0.6444 val_recall: 0.6444, val_f1: 0.6444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:56\n","loss: 0.8770, acc: 0.6154\n","E2E-ABSA >>> 2022-09-02 04:07:57\n","loss: 0.8843, acc: 0.6280\n","E2E-ABSA >>> 2022-09-02 04:07:58\n",">>> val_acc: 0.6505, val_precision: 0.6505 val_recall: 0.6505, val_f1: 0.6505\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:07:59\n","loss: 0.9211, acc: 0.5898\n","E2E-ABSA >>> 2022-09-02 04:08:00\n","loss: 0.8977, acc: 0.6184\n","E2E-ABSA >>> 2022-09-02 04:08:01\n",">>> val_acc: 0.6413, val_precision: 0.6413 val_recall: 0.6413, val_f1: 0.6413\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:08:02\n","loss: 0.8712, acc: 0.6414\n","E2E-ABSA >>> 2022-09-02 04:08:04\n","loss: 0.8859, acc: 0.6259\n","E2E-ABSA >>> 2022-09-02 04:08:05\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:08:05\n","loss: 0.8853, acc: 0.6264\n","E2E-ABSA >>> 2022-09-02 04:08:07\n","loss: 0.8871, acc: 0.6237\n","E2E-ABSA >>> 2022-09-02 04:08:08\n",">>> val_acc: 0.6505, val_precision: 0.6505 val_recall: 0.6505, val_f1: 0.6505\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:08:09\n","loss: 0.8738, acc: 0.6375\n","E2E-ABSA >>> 2022-09-02 04:08:10\n","loss: 0.8839, acc: 0.6275\n","E2E-ABSA >>> 2022-09-02 04:08:11\n",">>> val_acc: 0.6535, val_precision: 0.6535 val_recall: 0.6535, val_f1: 0.6535\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:08:12\n","loss: 0.8913, acc: 0.6150\n","E2E-ABSA >>> 2022-09-02 04:08:13\n","loss: 0.8836, acc: 0.6246\n","E2E-ABSA >>> 2022-09-02 04:08:14\n",">>> val_acc: 0.6505, val_precision: 0.6505 val_recall: 0.6505, val_f1: 0.6505\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:08:15\n","loss: 0.8964, acc: 0.6210\n","E2E-ABSA >>> 2022-09-02 04:08:17\n","loss: 0.8861, acc: 0.6235\n","E2E-ABSA >>> 2022-09-02 04:08:17\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:08:18\n","loss: 0.8808, acc: 0.6351\n","E2E-ABSA >>> 2022-09-02 04:08:20\n","loss: 0.8830, acc: 0.6310\n","E2E-ABSA >>> 2022-09-02 04:08:20\n",">>> val_acc: 0.6505, val_precision: 0.6505 val_recall: 0.6505, val_f1: 0.6505\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:08:22\n","loss: 0.8684, acc: 0.6470\n","E2E-ABSA >>> 2022-09-02 04:08:23\n","loss: 0.8802, acc: 0.6329\n","E2E-ABSA >>> 2022-09-02 04:08:24\n",">>> val_acc: 0.6505, val_precision: 0.6505 val_recall: 0.6505, val_f1: 0.6505\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:08:25\n","loss: 0.8861, acc: 0.6258\n","E2E-ABSA >>> 2022-09-02 04:08:27\n","loss: 0.8791, acc: 0.6309\n","E2E-ABSA >>> 2022-09-02 04:08:27\n",">>> val_acc: 0.6505, val_precision: 0.6505 val_recall: 0.6505, val_f1: 0.6505\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:08:29\n","loss: 0.8831, acc: 0.6235\n","E2E-ABSA >>> 2022-09-02 04:08:30\n","loss: 0.8862, acc: 0.6237\n","E2E-ABSA >>> 2022-09-02 04:08:30\n",">>> val_acc: 0.6505, val_precision: 0.6505 val_recall: 0.6505, val_f1: 0.6505\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:08:32\n","loss: 0.9022, acc: 0.6101\n","E2E-ABSA >>> 2022-09-02 04:08:33\n","loss: 0.8813, acc: 0.6279\n","E2E-ABSA >>> 2022-09-02 04:08:34\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:08:35\n","loss: 0.8773, acc: 0.6295\n","E2E-ABSA >>> 2022-09-02 04:08:37\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:08:37\n","loss: 0.8383, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 04:08:38\n","loss: 0.8812, acc: 0.6268\n","E2E-ABSA >>> 2022-09-02 04:08:40\n",">>> val_acc: 0.6474, val_precision: 0.6474 val_recall: 0.6474, val_f1: 0.6474\n","E2E-ABSA >>> 2022-09-02 04:08:40\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6535, val_precision: 0.6535 val_recall: 0.6535, val_f1: 0.6535\n","you can download the best model from state_dict/ian_SemEval2014_know_val_f1_0.6535\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n",">>> test_acc: 0.6535, test_precision: 0.6535, test_recall: 0.6535, test_f1: 0.6535\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2014** dataset on model(**MEMNET**)"],"metadata":{"id":"6X6qwUSxGtqQ"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name memnet --dataset SemEval2014_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N_npoh6iGtxV","outputId":"4e10acca-7469-4516-cae2-79af24148cb2","executionInfo":{"status":"ok","timestamp":1662091838625,"user_tz":-480,"elapsed":116764,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 3093.\n","> testing dataset count: 329.\n","cuda memory allocated: 17135616\n","> n_trainable_params: 362703, n_nontrainable_params: 3920100\n","> training arguments:\n",">>> model_name: memnet\n",">>> dataset: SemEval2014_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f384f788c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.memnet.MemNet'>\n",">>> dataset_file: {'train': './datasets/laprest14/output_know_insert/train.tsv', 'test': './datasets/laprest14/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['context_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:20\n","loss: 1.0410, acc: 0.5006\n","E2E-ABSA >>> 2022-09-02 04:09:20\n",">>> val_acc: 0.5988, val_precision: 0.5988 val_recall: 0.5988, val_f1: 0.5988\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.5988\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:21\n","loss: 0.9633, acc: 0.5938\n","E2E-ABSA >>> 2022-09-02 04:09:21\n","loss: 0.9503, acc: 0.5696\n","E2E-ABSA >>> 2022-09-02 04:09:22\n",">>> val_acc: 0.6079, val_precision: 0.6079 val_recall: 0.6079, val_f1: 0.6079\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.6079\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:22\n","loss: 0.9073, acc: 0.5990\n","E2E-ABSA >>> 2022-09-02 04:09:23\n","loss: 0.9174, acc: 0.5915\n","E2E-ABSA >>> 2022-09-02 04:09:24\n",">>> val_acc: 0.6140, val_precision: 0.6140 val_recall: 0.6140, val_f1: 0.6140\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.614\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:24\n","loss: 0.8827, acc: 0.6076\n","E2E-ABSA >>> 2022-09-02 04:09:24\n","loss: 0.8848, acc: 0.6192\n","E2E-ABSA >>> 2022-09-02 04:09:25\n",">>> val_acc: 0.6322, val_precision: 0.6322 val_recall: 0.6322, val_f1: 0.6322\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.6322\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:25\n","loss: 0.9283, acc: 0.5964\n","E2E-ABSA >>> 2022-09-02 04:09:26\n","loss: 0.8857, acc: 0.6169\n","E2E-ABSA >>> 2022-09-02 04:09:27\n",">>> val_acc: 0.6322, val_precision: 0.6322 val_recall: 0.6322, val_f1: 0.6322\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:27\n","loss: 0.8193, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 04:09:28\n","loss: 0.8560, acc: 0.6337\n","E2E-ABSA >>> 2022-09-02 04:09:28\n",">>> val_acc: 0.6383, val_precision: 0.6383 val_recall: 0.6383, val_f1: 0.6383\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.6383\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:28\n","loss: 0.8598, acc: 0.6267\n","E2E-ABSA >>> 2022-09-02 04:09:29\n","loss: 0.8583, acc: 0.6291\n","E2E-ABSA >>> 2022-09-02 04:09:30\n",">>> val_acc: 0.6444, val_precision: 0.6444 val_recall: 0.6444, val_f1: 0.6444\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.6444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:30\n","loss: 0.8286, acc: 0.6592\n","E2E-ABSA >>> 2022-09-02 04:09:31\n","loss: 0.8456, acc: 0.6400\n","E2E-ABSA >>> 2022-09-02 04:09:31\n",">>> val_acc: 0.6596, val_precision: 0.6596 val_recall: 0.6596, val_f1: 0.6596\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.6596\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:32\n","loss: 0.8085, acc: 0.6471\n","E2E-ABSA >>> 2022-09-02 04:09:32\n","loss: 0.8351, acc: 0.6410\n","E2E-ABSA >>> 2022-09-02 04:09:33\n",">>> val_acc: 0.6565, val_precision: 0.6565 val_recall: 0.6565, val_f1: 0.6565\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:33\n","loss: 0.8290, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 04:09:34\n","loss: 0.8329, acc: 0.6518\n","E2E-ABSA >>> 2022-09-02 04:09:34\n",">>> val_acc: 0.6596, val_precision: 0.6596 val_recall: 0.6596, val_f1: 0.6596\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:35\n","loss: 0.8246, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 04:09:36\n","loss: 0.8250, acc: 0.6512\n","E2E-ABSA >>> 2022-09-02 04:09:36\n",">>> val_acc: 0.6596, val_precision: 0.6596 val_recall: 0.6596, val_f1: 0.6596\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:36\n","loss: 0.8189, acc: 0.6477\n","E2E-ABSA >>> 2022-09-02 04:09:37\n","loss: 0.8086, acc: 0.6525\n","E2E-ABSA >>> 2022-09-02 04:09:37\n",">>> val_acc: 0.6657, val_precision: 0.6657 val_recall: 0.6657, val_f1: 0.6657\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.6657\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:38\n","loss: 0.8245, acc: 0.6328\n","E2E-ABSA >>> 2022-09-02 04:09:39\n","loss: 0.8040, acc: 0.6530\n","E2E-ABSA >>> 2022-09-02 04:09:39\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:40\n","loss: 0.7798, acc: 0.6723\n","E2E-ABSA >>> 2022-09-02 04:09:40\n","loss: 0.7929, acc: 0.6626\n","E2E-ABSA >>> 2022-09-02 04:09:41\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:41\n","loss: 0.7668, acc: 0.6786\n","E2E-ABSA >>> 2022-09-02 04:09:42\n","loss: 0.7781, acc: 0.6729\n","E2E-ABSA >>> 2022-09-02 04:09:42\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:43\n","loss: 0.7559, acc: 0.6840\n","E2E-ABSA >>> 2022-09-02 04:09:44\n","loss: 0.7650, acc: 0.6763\n","E2E-ABSA >>> 2022-09-02 04:09:44\n",">>> val_acc: 0.6809, val_precision: 0.6809 val_recall: 0.6809, val_f1: 0.6809\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.6809\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:44\n","loss: 0.7426, acc: 0.6921\n","E2E-ABSA >>> 2022-09-02 04:09:45\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:45\n","loss: 0.7827, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 04:09:46\n","loss: 0.7636, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:09:47\n",">>> val_acc: 0.6900, val_precision: 0.6900 val_recall: 0.6900, val_f1: 0.6900\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.69\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:47\n","loss: 0.6813, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 04:09:48\n","loss: 0.7403, acc: 0.6834\n","E2E-ABSA >>> 2022-09-02 04:09:48\n",">>> val_acc: 0.6930, val_precision: 0.6930 val_recall: 0.6930, val_f1: 0.6930\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.693\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:49\n","loss: 0.6930, acc: 0.7009\n","E2E-ABSA >>> 2022-09-02 04:09:49\n","loss: 0.7136, acc: 0.7001\n","E2E-ABSA >>> 2022-09-02 04:09:50\n",">>> val_acc: 0.6991, val_precision: 0.6991 val_recall: 0.6991, val_f1: 0.6991\n",">> saved: state_dict/memnet_SemEval2014_know_val_f1_0.6991\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:50\n","loss: 0.7315, acc: 0.7000\n","E2E-ABSA >>> 2022-09-02 04:09:51\n","loss: 0.7286, acc: 0.6932\n","E2E-ABSA >>> 2022-09-02 04:09:52\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:52\n","loss: 0.7340, acc: 0.6827\n","E2E-ABSA >>> 2022-09-02 04:09:52\n","loss: 0.7086, acc: 0.6910\n","E2E-ABSA >>> 2022-09-02 04:09:53\n",">>> val_acc: 0.6869, val_precision: 0.6869 val_recall: 0.6869, val_f1: 0.6869\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:53\n","loss: 0.7409, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 04:09:54\n","loss: 0.6982, acc: 0.7093\n","E2E-ABSA >>> 2022-09-02 04:09:55\n",">>> val_acc: 0.6991, val_precision: 0.6991 val_recall: 0.6991, val_f1: 0.6991\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:55\n","loss: 0.6799, acc: 0.7072\n","E2E-ABSA >>> 2022-09-02 04:09:56\n","loss: 0.7023, acc: 0.7061\n","E2E-ABSA >>> 2022-09-02 04:09:56\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:57\n","loss: 0.6934, acc: 0.7116\n","E2E-ABSA >>> 2022-09-02 04:09:57\n","loss: 0.6941, acc: 0.7096\n","E2E-ABSA >>> 2022-09-02 04:09:58\n",">>> val_acc: 0.6900, val_precision: 0.6900 val_recall: 0.6900, val_f1: 0.6900\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:09:58\n","loss: 0.7119, acc: 0.7050\n","E2E-ABSA >>> 2022-09-02 04:09:59\n","loss: 0.6980, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 04:09:59\n",">>> val_acc: 0.6991, val_precision: 0.6991 val_recall: 0.6991, val_f1: 0.6991\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:00\n","loss: 0.6860, acc: 0.7087\n","E2E-ABSA >>> 2022-09-02 04:10:00\n","loss: 0.6798, acc: 0.7123\n","E2E-ABSA >>> 2022-09-02 04:10:01\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:01\n","loss: 0.6715, acc: 0.7107\n","E2E-ABSA >>> 2022-09-02 04:10:02\n","loss: 0.6836, acc: 0.7118\n","E2E-ABSA >>> 2022-09-02 04:10:02\n",">>> val_acc: 0.6687, val_precision: 0.6687 val_recall: 0.6687, val_f1: 0.6687\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:03\n","loss: 0.6922, acc: 0.7022\n","E2E-ABSA >>> 2022-09-02 04:10:04\n","loss: 0.6813, acc: 0.7165\n","E2E-ABSA >>> 2022-09-02 04:10:04\n",">>> val_acc: 0.6900, val_precision: 0.6900 val_recall: 0.6900, val_f1: 0.6900\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:05\n","loss: 0.6730, acc: 0.7154\n","E2E-ABSA >>> 2022-09-02 04:10:05\n","loss: 0.6728, acc: 0.7184\n","E2E-ABSA >>> 2022-09-02 04:10:06\n",">>> val_acc: 0.6869, val_precision: 0.6869 val_recall: 0.6869, val_f1: 0.6869\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:06\n","loss: 0.6536, acc: 0.7305\n","E2E-ABSA >>> 2022-09-02 04:10:07\n","loss: 0.6665, acc: 0.7191\n","E2E-ABSA >>> 2022-09-02 04:10:07\n",">>> val_acc: 0.6717, val_precision: 0.6717 val_recall: 0.6717, val_f1: 0.6717\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:08\n","loss: 0.6752, acc: 0.7144\n","E2E-ABSA >>> 2022-09-02 04:10:09\n","loss: 0.6686, acc: 0.7144\n","E2E-ABSA >>> 2022-09-02 04:10:09\n",">>> val_acc: 0.6809, val_precision: 0.6809 val_recall: 0.6809, val_f1: 0.6809\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:09\n","loss: 0.6613, acc: 0.7194\n","E2E-ABSA >>> 2022-09-02 04:10:10\n","loss: 0.6632, acc: 0.7165\n","E2E-ABSA >>> 2022-09-02 04:10:10\n",">>> val_acc: 0.6809, val_precision: 0.6809 val_recall: 0.6809, val_f1: 0.6809\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:11\n","loss: 0.6510, acc: 0.7270\n","E2E-ABSA >>> 2022-09-02 04:10:12\n",">>> val_acc: 0.6869, val_precision: 0.6869 val_recall: 0.6869, val_f1: 0.6869\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:12\n","loss: 0.5958, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 04:10:13\n","loss: 0.6677, acc: 0.7224\n","E2E-ABSA >>> 2022-09-02 04:10:13\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:13\n","loss: 0.7319, acc: 0.6937\n","E2E-ABSA >>> 2022-09-02 04:10:14\n","loss: 0.6478, acc: 0.7250\n","E2E-ABSA >>> 2022-09-02 04:10:15\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:15\n","loss: 0.6780, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:10:16\n","loss: 0.6554, acc: 0.7274\n","E2E-ABSA >>> 2022-09-02 04:10:16\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:17\n","loss: 0.6105, acc: 0.7670\n","E2E-ABSA >>> 2022-09-02 04:10:17\n","loss: 0.6574, acc: 0.7331\n","E2E-ABSA >>> 2022-09-02 04:10:18\n",">>> val_acc: 0.6869, val_precision: 0.6869 val_recall: 0.6869, val_f1: 0.6869\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:18\n","loss: 0.6579, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:10:19\n","loss: 0.6458, acc: 0.7300\n","E2E-ABSA >>> 2022-09-02 04:10:20\n",">>> val_acc: 0.6869, val_precision: 0.6869 val_recall: 0.6869, val_f1: 0.6869\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:20\n","loss: 0.6472, acc: 0.7298\n","E2E-ABSA >>> 2022-09-02 04:10:21\n","loss: 0.6553, acc: 0.7304\n","E2E-ABSA >>> 2022-09-02 04:10:21\n",">>> val_acc: 0.6869, val_precision: 0.6869 val_recall: 0.6869, val_f1: 0.6869\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:22\n","loss: 0.6140, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 04:10:23\n","loss: 0.6325, acc: 0.7357\n","E2E-ABSA >>> 2022-09-02 04:10:23\n",">>> val_acc: 0.6809, val_precision: 0.6809 val_recall: 0.6809, val_f1: 0.6809\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:23\n","loss: 0.6115, acc: 0.7283\n","E2E-ABSA >>> 2022-09-02 04:10:24\n","loss: 0.6305, acc: 0.7324\n","E2E-ABSA >>> 2022-09-02 04:10:25\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:25\n","loss: 0.6597, acc: 0.7416\n","E2E-ABSA >>> 2022-09-02 04:10:26\n","loss: 0.6388, acc: 0.7368\n","E2E-ABSA >>> 2022-09-02 04:10:26\n",">>> val_acc: 0.6900, val_precision: 0.6900 val_recall: 0.6900, val_f1: 0.6900\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:27\n","loss: 0.6412, acc: 0.7360\n","E2E-ABSA >>> 2022-09-02 04:10:27\n","loss: 0.6301, acc: 0.7401\n","E2E-ABSA >>> 2022-09-02 04:10:28\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:28\n","loss: 0.6054, acc: 0.7422\n","E2E-ABSA >>> 2022-09-02 04:10:29\n","loss: 0.6211, acc: 0.7443\n","E2E-ABSA >>> 2022-09-02 04:10:29\n",">>> val_acc: 0.6900, val_precision: 0.6900 val_recall: 0.6900, val_f1: 0.6900\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:30\n","loss: 0.6479, acc: 0.7250\n","E2E-ABSA >>> 2022-09-02 04:10:30\n","loss: 0.6321, acc: 0.7368\n","E2E-ABSA >>> 2022-09-02 04:10:31\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:31\n","loss: 0.6049, acc: 0.7574\n","E2E-ABSA >>> 2022-09-02 04:10:32\n","loss: 0.6294, acc: 0.7379\n","E2E-ABSA >>> 2022-09-02 04:10:32\n",">>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:33\n","loss: 0.6266, acc: 0.7363\n","E2E-ABSA >>> 2022-09-02 04:10:34\n","loss: 0.6239, acc: 0.7387\n","E2E-ABSA >>> 2022-09-02 04:10:34\n",">>> val_acc: 0.6839, val_precision: 0.6839 val_recall: 0.6839, val_f1: 0.6839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:34\n","loss: 0.6197, acc: 0.7408\n","E2E-ABSA >>> 2022-09-02 04:10:35\n","loss: 0.6213, acc: 0.7427\n","E2E-ABSA >>> 2022-09-02 04:10:35\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:10:36\n","loss: 0.6103, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:10:37\n","loss: 0.6185, acc: 0.7420\n","E2E-ABSA >>> 2022-09-02 04:10:37\n",">>> val_acc: 0.6748, val_precision: 0.6748 val_recall: 0.6748, val_f1: 0.6748\n","E2E-ABSA >>> 2022-09-02 04:10:37\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6991, val_precision: 0.6991 val_recall: 0.6991, val_f1: 0.6991\n","you can download the best model from state_dict/memnet_SemEval2014_know_val_f1_0.6991\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",">>> test_acc: 0.6991, test_precision: 0.6991, test_recall: 0.6991, test_f1: 0.6991\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2014** dataset on model(**CABASC**)"],"metadata":{"id":"FDUTdFkUGumI"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name cabasc --dataset SemEval2014_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KX9Pa13uGusR","outputId":"b09d7aa0-e79a-4103-d0d8-0a6c0e146b78","executionInfo":{"status":"ok","timestamp":1662092613421,"user_tz":-480,"elapsed":774373,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 2913.\n","> testing dataset count: 311.\n","cuda memory allocated: 21485568\n","> n_trainable_params: 1446005, n_nontrainable_params: 3920100\n","> training arguments:\n",">>> model_name: cabasc\n",">>> dataset: SemEval2014_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f34677c3c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.cabasc.Cabasc'>\n",">>> dataset_file: {'train': './datasets/laprest14/output_know_insert/train.tsv', 'test': './datasets/laprest14/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices', 'left_with_aspect_indices', 'right_with_aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:11:23\n","loss: 1.0061, acc: 0.4944\n","E2E-ABSA >>> 2022-09-02 04:11:29\n",">>> val_acc: 0.5659, val_precision: 0.5659 val_recall: 0.5659, val_f1: 0.5659\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.5659\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:11:31\n","loss: 0.8666, acc: 0.6434\n","E2E-ABSA >>> 2022-09-02 04:11:37\n","loss: 0.9507, acc: 0.5641\n","E2E-ABSA >>> 2022-09-02 04:11:43\n",">>> val_acc: 0.5659, val_precision: 0.5659 val_recall: 0.5659, val_f1: 0.5659\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:11:45\n","loss: 0.9590, acc: 0.5423\n","E2E-ABSA >>> 2022-09-02 04:11:52\n","loss: 0.9453, acc: 0.5574\n","E2E-ABSA >>> 2022-09-02 04:11:56\n",">>> val_acc: 0.5756, val_precision: 0.5756 val_recall: 0.5756, val_f1: 0.5756\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.5756\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:11:59\n","loss: 0.9106, acc: 0.5784\n","E2E-ABSA >>> 2022-09-02 04:12:06\n","loss: 0.9244, acc: 0.5716\n","E2E-ABSA >>> 2022-09-02 04:12:09\n",">>> val_acc: 0.5852, val_precision: 0.5852 val_recall: 0.5852, val_f1: 0.5852\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.5852\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:12:14\n","loss: 0.9169, acc: 0.5671\n","E2E-ABSA >>> 2022-09-02 04:12:21\n","loss: 0.9104, acc: 0.5781\n","E2E-ABSA >>> 2022-09-02 04:12:23\n",">>> val_acc: 0.5820, val_precision: 0.5820 val_recall: 0.5820, val_f1: 0.5820\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:12:29\n","loss: 0.9046, acc: 0.5890\n","E2E-ABSA >>> 2022-09-02 04:12:36\n",">>> val_acc: 0.5884, val_precision: 0.5884 val_recall: 0.5884, val_f1: 0.5884\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.5884\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:12:36\n","loss: 0.7408, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 04:12:43\n","loss: 0.8957, acc: 0.5980\n","E2E-ABSA >>> 2022-09-02 04:12:50\n",">>> val_acc: 0.5949, val_precision: 0.5949 val_recall: 0.5949, val_f1: 0.5949\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.5949\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:12:51\n","loss: 0.8264, acc: 0.6546\n","E2E-ABSA >>> 2022-09-02 04:12:58\n","loss: 0.8890, acc: 0.5961\n","E2E-ABSA >>> 2022-09-02 04:13:03\n",">>> val_acc: 0.6109, val_precision: 0.6109 val_recall: 0.6109, val_f1: 0.6109\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.6109\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:13:05\n","loss: 0.8555, acc: 0.5955\n","E2E-ABSA >>> 2022-09-02 04:13:12\n","loss: 0.8460, acc: 0.6199\n","E2E-ABSA >>> 2022-09-02 04:13:16\n",">>> val_acc: 0.6270, val_precision: 0.6270 val_recall: 0.6270, val_f1: 0.6270\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:13:20\n","loss: 0.8453, acc: 0.6167\n","E2E-ABSA >>> 2022-09-02 04:13:27\n","loss: 0.8319, acc: 0.6287\n","E2E-ABSA >>> 2022-09-02 04:13:30\n",">>> val_acc: 0.6367, val_precision: 0.6367 val_recall: 0.6367, val_f1: 0.6367\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.6367\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:13:34\n","loss: 0.8223, acc: 0.6304\n","E2E-ABSA >>> 2022-09-02 04:13:41\n","loss: 0.8218, acc: 0.6342\n","E2E-ABSA >>> 2022-09-02 04:13:43\n",">>> val_acc: 0.6495, val_precision: 0.6495 val_recall: 0.6495, val_f1: 0.6495\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.6495\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:13:49\n","loss: 0.8395, acc: 0.6351\n","E2E-ABSA >>> 2022-09-02 04:13:56\n",">>> val_acc: 0.6527, val_precision: 0.6527 val_recall: 0.6527, val_f1: 0.6527\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.6527\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:13:57\n","loss: 0.8104, acc: 0.5781\n","E2E-ABSA >>> 2022-09-02 04:14:04\n","loss: 0.7990, acc: 0.6430\n","E2E-ABSA >>> 2022-09-02 04:14:10\n",">>> val_acc: 0.6463, val_precision: 0.6463 val_recall: 0.6463, val_f1: 0.6463\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:14:12\n","loss: 0.7865, acc: 0.6399\n","E2E-ABSA >>> 2022-09-02 04:14:18\n","loss: 0.8026, acc: 0.6493\n","E2E-ABSA >>> 2022-09-02 04:14:24\n",">>> val_acc: 0.6431, val_precision: 0.6431 val_recall: 0.6431, val_f1: 0.6431\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:14:26\n","loss: 0.7963, acc: 0.6513\n","E2E-ABSA >>> 2022-09-02 04:14:33\n","loss: 0.8049, acc: 0.6445\n","E2E-ABSA >>> 2022-09-02 04:14:37\n",">>> val_acc: 0.6527, val_precision: 0.6527 val_recall: 0.6527, val_f1: 0.6527\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:14:40\n","loss: 0.7987, acc: 0.6568\n","E2E-ABSA >>> 2022-09-02 04:14:47\n","loss: 0.7915, acc: 0.6508\n","E2E-ABSA >>> 2022-09-02 04:14:50\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:14:55\n","loss: 0.7890, acc: 0.6545\n","E2E-ABSA >>> 2022-09-02 04:15:02\n","loss: 0.7935, acc: 0.6504\n","E2E-ABSA >>> 2022-09-02 04:15:03\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:15:09\n","loss: 0.7765, acc: 0.6503\n","E2E-ABSA >>> 2022-09-02 04:15:17\n",">>> val_acc: 0.6559, val_precision: 0.6559 val_recall: 0.6559, val_f1: 0.6559\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:15:17\n","loss: 0.7889, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 04:15:24\n","loss: 0.7790, acc: 0.6527\n","E2E-ABSA >>> 2022-09-02 04:15:30\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:15:32\n","loss: 0.7887, acc: 0.6522\n","E2E-ABSA >>> 2022-09-02 04:15:38\n","loss: 0.7851, acc: 0.6565\n","E2E-ABSA >>> 2022-09-02 04:15:43\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:15:46\n","loss: 0.7934, acc: 0.6547\n","E2E-ABSA >>> 2022-09-02 04:15:53\n","loss: 0.7738, acc: 0.6612\n","E2E-ABSA >>> 2022-09-02 04:15:57\n",">>> val_acc: 0.6463, val_precision: 0.6463 val_recall: 0.6463, val_f1: 0.6463\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:16:01\n","loss: 0.7681, acc: 0.6601\n","E2E-ABSA >>> 2022-09-02 04:16:08\n","loss: 0.7766, acc: 0.6596\n","E2E-ABSA >>> 2022-09-02 04:16:11\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:16:16\n","loss: 0.7649, acc: 0.6639\n","E2E-ABSA >>> 2022-09-02 04:16:22\n","loss: 0.7777, acc: 0.6580\n","E2E-ABSA >>> 2022-09-02 04:16:24\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.672\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:16:30\n","loss: 0.7738, acc: 0.6587\n","E2E-ABSA >>> 2022-09-02 04:16:37\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:16:38\n","loss: 0.6749, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 04:16:45\n","loss: 0.7770, acc: 0.6655\n","E2E-ABSA >>> 2022-09-02 04:16:51\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">> saved: state_dict/cabasc_SemEval2014_know_val_f1_0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:16:52\n","loss: 0.7284, acc: 0.6775\n","E2E-ABSA >>> 2022-09-02 04:16:59\n","loss: 0.7835, acc: 0.6550\n","E2E-ABSA >>> 2022-09-02 04:17:04\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:17:07\n","loss: 0.7496, acc: 0.6935\n","E2E-ABSA >>> 2022-09-02 04:17:13\n","loss: 0.7692, acc: 0.6695\n","E2E-ABSA >>> 2022-09-02 04:17:17\n",">>> val_acc: 0.6527, val_precision: 0.6527 val_recall: 0.6527, val_f1: 0.6527\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:17:21\n","loss: 0.7704, acc: 0.6674\n","E2E-ABSA >>> 2022-09-02 04:17:28\n","loss: 0.7671, acc: 0.6627\n","E2E-ABSA >>> 2022-09-02 04:17:30\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:17:36\n","loss: 0.7673, acc: 0.6637\n","E2E-ABSA >>> 2022-09-02 04:17:42\n","loss: 0.7673, acc: 0.6662\n","E2E-ABSA >>> 2022-09-02 04:17:44\n",">>> val_acc: 0.6495, val_precision: 0.6495 val_recall: 0.6495, val_f1: 0.6495\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:17:50\n","loss: 0.7520, acc: 0.6707\n","E2E-ABSA >>> 2022-09-02 04:17:57\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:17:58\n","loss: 0.8123, acc: 0.6500\n","E2E-ABSA >>> 2022-09-02 04:18:05\n","loss: 0.7470, acc: 0.6824\n","E2E-ABSA >>> 2022-09-02 04:18:11\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 04:18:13\n","loss: 0.7320, acc: 0.6944\n","E2E-ABSA >>> 2022-09-02 04:18:19\n","loss: 0.7505, acc: 0.6816\n","E2E-ABSA >>> 2022-09-02 04:18:24\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 04:18:27\n","loss: 0.7665, acc: 0.6634\n","E2E-ABSA >>> 2022-09-02 04:18:34\n","loss: 0.7610, acc: 0.6710\n","E2E-ABSA >>> 2022-09-02 04:18:37\n",">>> val_acc: 0.6495, val_precision: 0.6495 val_recall: 0.6495, val_f1: 0.6495\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 04:18:41\n","loss: 0.7496, acc: 0.6557\n","E2E-ABSA >>> 2022-09-02 04:18:48\n","loss: 0.7566, acc: 0.6716\n","E2E-ABSA >>> 2022-09-02 04:18:51\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 04:18:56\n","loss: 0.7515, acc: 0.6803\n","E2E-ABSA >>> 2022-09-02 04:19:03\n","loss: 0.7531, acc: 0.6710\n","E2E-ABSA >>> 2022-09-02 04:19:04\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 04:19:10\n","loss: 0.7626, acc: 0.6704\n","E2E-ABSA >>> 2022-09-02 04:19:17\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 04:19:18\n","loss: 0.7859, acc: 0.6354\n","E2E-ABSA >>> 2022-09-02 04:19:25\n","loss: 0.7450, acc: 0.6808\n","E2E-ABSA >>> 2022-09-02 04:19:31\n",">>> val_acc: 0.6559, val_precision: 0.6559 val_recall: 0.6559, val_f1: 0.6559\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 04:19:33\n","loss: 0.7411, acc: 0.6810\n","E2E-ABSA >>> 2022-09-02 04:19:39\n","loss: 0.7413, acc: 0.6778\n","E2E-ABSA >>> 2022-09-02 04:19:44\n",">>> val_acc: 0.6495, val_precision: 0.6495 val_recall: 0.6495, val_f1: 0.6495\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 04:19:47\n","loss: 0.7425, acc: 0.6766\n","E2E-ABSA >>> 2022-09-02 04:19:54\n","loss: 0.7583, acc: 0.6721\n","E2E-ABSA >>> 2022-09-02 04:19:57\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 04:20:02\n","loss: 0.7452, acc: 0.6855\n","E2E-ABSA >>> 2022-09-02 04:20:09\n","loss: 0.7464, acc: 0.6783\n","E2E-ABSA >>> 2022-09-02 04:20:11\n",">>> val_acc: 0.6495, val_precision: 0.6495 val_recall: 0.6495, val_f1: 0.6495\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 04:20:16\n","loss: 0.7513, acc: 0.6789\n","E2E-ABSA >>> 2022-09-02 04:20:23\n","loss: 0.7472, acc: 0.6795\n","E2E-ABSA >>> 2022-09-02 04:20:24\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 04:20:31\n","loss: 0.7531, acc: 0.6695\n","E2E-ABSA >>> 2022-09-02 04:20:38\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 04:20:39\n","loss: 0.7874, acc: 0.6741\n","E2E-ABSA >>> 2022-09-02 04:20:45\n","loss: 0.7316, acc: 0.6930\n","E2E-ABSA >>> 2022-09-02 04:20:51\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 04:20:53\n","loss: 0.7413, acc: 0.6815\n","E2E-ABSA >>> 2022-09-02 04:21:00\n","loss: 0.7404, acc: 0.6885\n","E2E-ABSA >>> 2022-09-02 04:21:04\n",">>> val_acc: 0.6527, val_precision: 0.6527 val_recall: 0.6527, val_f1: 0.6527\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 04:21:07\n","loss: 0.7782, acc: 0.6432\n","E2E-ABSA >>> 2022-09-02 04:21:14\n","loss: 0.7583, acc: 0.6736\n","E2E-ABSA >>> 2022-09-02 04:21:17\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 04:21:22\n","loss: 0.7615, acc: 0.6712\n","E2E-ABSA >>> 2022-09-02 04:21:28\n","loss: 0.7430, acc: 0.6803\n","E2E-ABSA >>> 2022-09-02 04:21:30\n",">>> val_acc: 0.6431, val_precision: 0.6431 val_recall: 0.6431, val_f1: 0.6431\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 04:21:36\n","loss: 0.7272, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:21:43\n","loss: 0.7385, acc: 0.6827\n","E2E-ABSA >>> 2022-09-02 04:21:44\n",">>> val_acc: 0.6559, val_precision: 0.6559 val_recall: 0.6559, val_f1: 0.6559\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 04:21:50\n","loss: 0.7514, acc: 0.6730\n","E2E-ABSA >>> 2022-09-02 04:21:57\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 04:21:59\n","loss: 0.7551, acc: 0.6641\n","E2E-ABSA >>> 2022-09-02 04:22:05\n","loss: 0.7448, acc: 0.6762\n","E2E-ABSA >>> 2022-09-02 04:22:11\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 04:22:13\n","loss: 0.7624, acc: 0.6970\n","E2E-ABSA >>> 2022-09-02 04:22:20\n","loss: 0.7422, acc: 0.6814\n","E2E-ABSA >>> 2022-09-02 04:22:24\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 04:22:27\n","loss: 0.7220, acc: 0.6887\n","E2E-ABSA >>> 2022-09-02 04:22:34\n","loss: 0.7385, acc: 0.6792\n","E2E-ABSA >>> 2022-09-02 04:22:37\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 04:22:42\n","loss: 0.7376, acc: 0.6866\n","E2E-ABSA >>> 2022-09-02 04:22:49\n","loss: 0.7323, acc: 0.6864\n","E2E-ABSA >>> 2022-09-02 04:22:51\n",">>> val_acc: 0.6463, val_precision: 0.6463 val_recall: 0.6463, val_f1: 0.6463\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 04:22:56\n","loss: 0.7109, acc: 0.6949\n","E2E-ABSA >>> 2022-09-02 04:23:04\n",">>> val_acc: 0.6431, val_precision: 0.6431 val_recall: 0.6431, val_f1: 0.6431\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 04:23:04\n","loss: 0.7777, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 04:23:11\n","loss: 0.7447, acc: 0.6745\n","E2E-ABSA >>> 2022-09-02 04:23:17\n",">>> val_acc: 0.6367, val_precision: 0.6367 val_recall: 0.6367, val_f1: 0.6367\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 04:23:19\n","loss: 0.6986, acc: 0.7153\n","E2E-ABSA >>> 2022-09-02 04:23:25\n","loss: 0.7340, acc: 0.6864\n","E2E-ABSA >>> 2022-09-02 04:23:31\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n","E2E-ABSA >>> 2022-09-02 04:23:31\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n","you can download the best model from state_dict/cabasc_SemEval2014_know_val_f1_0.6752\n",">>> test_acc: 0.6752, test_precision: 0.6752, test_recall: 0.6752, test_f1: 0.6752\n"]}]},{"cell_type":"markdown","source":["# 针对SemEval201X以及acl2014data的notebook上实验"],"metadata":{"id":"w9s7x6OCJLyc"}},{"cell_type":"markdown","source":["# SemEval2015 数据集"],"metadata":{"id":"3CLfC7UPIxRO"}},{"cell_type":"markdown","source":["lstm\n","\n","tdlstm  \n","tclstm  \n","ataelstm  \n","ian \n","memnet  \n","cabasc \n"],"metadata":{"id":"180yPbjWQJjE"}},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2015** dataset on model(**LSTM**)"],"metadata":{"id":"hUhN-KCtSx4i"}},{"cell_type":"code","source":["!pwd\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name lstm --dataset SemEval2015_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zeYin41YSyRY","outputId":"8f4bd5f5-7719-456d-f6c0-d854bceadf18","executionInfo":{"status":"ok","timestamp":1662092665781,"user_tz":-480,"elapsed":52368,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train_insert.py\n","data_utils.py\t    layers\t\t   README.md\t     train.py\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   state_dict\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 750.\n","> testing dataset count: 82.\n","cuda memory allocated: 9015808\n","> n_trainable_params: 723303, n_nontrainable_params: 1530300\n","> training arguments:\n",">>> model_name: lstm\n",">>> dataset: SemEval2015_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7fc0320b3c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.lstm.LSTM'>\n",">>> dataset_file: {'train': './datasets/rest15/output_know_insert/train.tsv', 'test': './datasets/rest15/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:24:11\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">> saved: state_dict/lstm_SemEval2015_know_val_f1_0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:24:12\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:24:12\n","loss: 0.6808, acc: 0.8021\n","E2E-ABSA >>> 2022-09-02 04:24:12\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:24:12\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:24:13\n","loss: 0.6993, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:24:13\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:24:13\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:24:13\n","loss: 0.5982, acc: 0.7917\n","E2E-ABSA >>> 2022-09-02 04:24:14\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:24:14\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:24:14\n","loss: 0.6254, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 04:24:15\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:24:15\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:24:15\n","loss: 0.5864, acc: 0.7917\n","E2E-ABSA >>> 2022-09-02 04:24:15\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:24:16\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:24:16\n","loss: 0.6304, acc: 0.7622\n","E2E-ABSA >>> 2022-09-02 04:24:16\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:24:17\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:24:17\n","loss: 0.6256, acc: 0.7664\n","E2E-ABSA >>> 2022-09-02 04:24:17\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:24:18\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:24:18\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:24:18\n","loss: 0.5018, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 04:24:18\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:24:19\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:24:19\n","loss: 0.5640, acc: 0.7857\n","E2E-ABSA >>> 2022-09-02 04:24:19\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:24:20\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:24:20\n","loss: 0.5522, acc: 0.7885\n","E2E-ABSA >>> 2022-09-02 04:24:20\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:24:21\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:24:21\n","loss: 0.6377, acc: 0.7599\n","E2E-ABSA >>> 2022-09-02 04:24:21\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:24:21\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:24:22\n","loss: 0.5683, acc: 0.7850\n","E2E-ABSA >>> 2022-09-02 04:24:22\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:24:22\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:24:22\n","loss: 0.5761, acc: 0.7722\n","E2E-ABSA >>> 2022-09-02 04:24:23\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:24:23\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:24:23\n","loss: 0.5744, acc: 0.7703\n","E2E-ABSA >>> 2022-09-02 04:24:23\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:24:24\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n","E2E-ABSA >>> 2022-09-02 04:24:24\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n","you can download the best model from state_dict/lstm_SemEval2015_know_val_f1_0.8293\n",">>> test_acc: 0.8293, test_precision: 0.8293, test_recall: 0.8293, test_f1: 0.8293\n"]}]},{"cell_type":"markdown","source":["\n","# 增加字典知识后：Training **SemEval2015** dataset on model(**TDLSTM**)"],"metadata":{"id":"YrqsLvCCQJxE"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name td_lstm --dataset SemEval2015_know --embed_dim 300 --patience 30\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qiJ_pb78QJ3Z","outputId":"fa2509ab-9f61-4771-a1a0-11f4bf661c45","executionInfo":{"status":"ok","timestamp":1662092720128,"user_tz":-480,"elapsed":54358,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 658.\n","> testing dataset count: 79.\n","cuda memory allocated: 11909120\n","> n_trainable_params: 1446603, n_nontrainable_params: 1530300\n","> training arguments:\n",">>> model_name: td_lstm\n",">>> dataset: SemEval2015_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f7ea8867c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.td_lstm.TD_LSTM'>\n",">>> dataset_file: {'train': './datasets/rest15/output_know_insert/train.tsv', 'test': './datasets/rest15/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['left_with_aspect_indices', 'right_with_aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:25:03\n",">>> val_acc: 0.4810, val_precision: 0.4810 val_recall: 0.4810, val_f1: 0.4810\n",">> saved: state_dict/td_lstm_SemEval2015_know_val_f1_0.481\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:25:03\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">> saved: state_dict/td_lstm_SemEval2015_know_val_f1_0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:25:03\n","loss: 0.8329, acc: 0.7461\n","E2E-ABSA >>> 2022-09-02 04:25:04\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:25:04\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:25:05\n","loss: 0.7044, acc: 0.7461\n","E2E-ABSA >>> 2022-09-02 04:25:05\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:25:05\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:25:06\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:25:06\n","loss: 0.6279, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 04:25:06\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:25:07\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:25:07\n","loss: 0.6202, acc: 0.7727\n","E2E-ABSA >>> 2022-09-02 04:25:07\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:25:08\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:25:08\n","loss: 0.6132, acc: 0.7648\n","E2E-ABSA >>> 2022-09-02 04:25:08\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:25:09\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:25:09\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:25:09\n","loss: 0.5922, acc: 0.7552\n","E2E-ABSA >>> 2022-09-02 04:25:10\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:25:10\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:25:11\n","loss: 0.5931, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 04:25:11\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:25:11\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:25:12\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:25:12\n","loss: 0.5745, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 04:25:12\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:25:13\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:25:13\n","loss: 0.5783, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 04:25:13\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:25:14\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:25:14\n","loss: 0.6068, acc: 0.7463\n","E2E-ABSA >>> 2022-09-02 04:25:14\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:25:15\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:25:15\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:25:15\n","loss: 0.5727, acc: 0.7578\n","E2E-ABSA >>> 2022-09-02 04:25:16\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:25:16\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:25:17\n","loss: 0.5460, acc: 0.7891\n","E2E-ABSA >>> 2022-09-02 04:25:17\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:25:17\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:25:18\n","loss: 0.5733, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 04:25:18\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 04:25:18\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n","E2E-ABSA >>> 2022-09-02 04:25:18\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n","you can download the best model from state_dict/td_lstm_SemEval2015_know_val_f1_0.8354\n",">>> test_acc: 0.8354, test_precision: 0.8354, test_recall: 0.8354, test_f1: 0.8354\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2015** dataset on model(**TCLSTM**)"],"metadata":{"id":"6tHpJfEyQKJP"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name tc_lstm --dataset SemEval2015_know --embed_dim 300 --patience 30\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C3wg6HobQKPG","outputId":"d8d48424-3d20-4f67-a10e-0ebaabf3c495","executionInfo":{"status":"ok","timestamp":1662092775997,"user_tz":-480,"elapsed":55880,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 658.\n","> testing dataset count: 79.\n","cuda memory allocated: 14789632\n","> n_trainable_params: 2166603, n_nontrainable_params: 1530300\n","> training arguments:\n",">>> model_name: tc_lstm\n",">>> dataset: SemEval2015_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7fd235725c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.tc_lstm.TC_LSTM'>\n",">>> dataset_file: {'train': './datasets/rest15/output_know_insert/train.tsv', 'test': './datasets/rest15/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['left_with_aspect_indices', 'right_with_aspect_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:25:58\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">> saved: state_dict/tc_lstm_SemEval2015_know_val_f1_0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:25:58\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:25:59\n","loss: 0.6653, acc: 0.7695\n","E2E-ABSA >>> 2022-09-02 04:25:59\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:26:00\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:26:00\n","loss: 0.6171, acc: 0.7734\n","E2E-ABSA >>> 2022-09-02 04:26:00\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:26:01\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:26:01\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:26:01\n","loss: 0.6006, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 04:26:02\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:26:02\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:26:03\n","loss: 0.6426, acc: 0.7330\n","E2E-ABSA >>> 2022-09-02 04:26:03\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:26:03\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:26:04\n","loss: 0.5808, acc: 0.7648\n","E2E-ABSA >>> 2022-09-02 04:26:04\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:26:04\n",">>> val_acc: 0.8228, val_precision: 0.8228 val_recall: 0.8228, val_f1: 0.8228\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:26:05\n",">>> val_acc: 0.8228, val_precision: 0.8228 val_recall: 0.8228, val_f1: 0.8228\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:26:05\n","loss: 0.6318, acc: 0.7448\n","E2E-ABSA >>> 2022-09-02 04:26:05\n",">>> val_acc: 0.8228, val_precision: 0.8228 val_recall: 0.8228, val_f1: 0.8228\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:26:06\n",">>> val_acc: 0.8228, val_precision: 0.8228 val_recall: 0.8228, val_f1: 0.8228\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:26:06\n","loss: 0.5798, acc: 0.7679\n","E2E-ABSA >>> 2022-09-02 04:26:07\n",">>> val_acc: 0.8228, val_precision: 0.8228 val_recall: 0.8228, val_f1: 0.8228\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:26:07\n",">>> val_acc: 0.8101, val_precision: 0.8101 val_recall: 0.8101, val_f1: 0.8101\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:26:08\n",">>> val_acc: 0.8228, val_precision: 0.8228 val_recall: 0.8228, val_f1: 0.8228\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:26:08\n","loss: 0.5343, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 04:26:08\n",">>> val_acc: 0.8228, val_precision: 0.8228 val_recall: 0.8228, val_f1: 0.8228\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:26:09\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:26:09\n","loss: 0.5158, acc: 0.7951\n","E2E-ABSA >>> 2022-09-02 04:26:09\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:26:10\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:26:10\n","loss: 0.5479, acc: 0.7757\n","E2E-ABSA >>> 2022-09-02 04:26:10\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:26:11\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:26:11\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:26:12\n","loss: 0.5190, acc: 0.8047\n","E2E-ABSA >>> 2022-09-02 04:26:12\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:26:13\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:26:13\n","loss: 0.5111, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 04:26:13\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:26:14\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:26:14\n","loss: 0.5310, acc: 0.7766\n","E2E-ABSA >>> 2022-09-02 04:26:14\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n","E2E-ABSA >>> 2022-09-02 04:26:14\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n","you can download the best model from state_dict/tc_lstm_SemEval2015_know_val_f1_0.8354\n",">>> test_acc: 0.8354, test_precision: 0.8354, test_recall: 0.8354, test_f1: 0.8354\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2015** dataset on model(**ATAELSTM**)"],"metadata":{"id":"8aeGtDrMQKf2"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name atae_lstm --dataset SemEval2015_know --embed_dim 300 --patience 30\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4IPyME5kQKme","outputId":"ff3f017e-d81b-40fe-d489-f89cd8f55191","executionInfo":{"status":"ok","timestamp":1662092853593,"user_tz":-480,"elapsed":77606,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 750.\n","> testing dataset count: 82.\n","cuda memory allocated: 16227328\n","> n_trainable_params: 2525703, n_nontrainable_params: 1530300\n","> training arguments:\n",">>> model_name: atae_lstm\n",">>> dataset: SemEval2015_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7fd802857c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.atae_lstm.ATAE_LSTM'>\n",">>> dataset_file: {'train': './datasets/rest15/output_know_insert/train.tsv', 'test': './datasets/rest15/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:26:53\n",">>> val_acc: 0.7683, val_precision: 0.7683 val_recall: 0.7683, val_f1: 0.7683\n",">> saved: state_dict/atae_lstm_SemEval2015_know_val_f1_0.7683\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:26:54\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">> saved: state_dict/atae_lstm_SemEval2015_know_val_f1_0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:26:54\n","loss: 0.7593, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 04:26:54\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:26:55\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:26:55\n","loss: 0.6830, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 04:26:56\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:26:56\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:26:57\n","loss: 0.6972, acc: 0.7431\n","E2E-ABSA >>> 2022-09-02 04:26:57\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:26:58\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:26:58\n","loss: 0.6491, acc: 0.7630\n","E2E-ABSA >>> 2022-09-02 04:26:58\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:26:59\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:26:59\n","loss: 0.6149, acc: 0.7667\n","E2E-ABSA >>> 2022-09-02 04:27:00\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:27:00\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:27:01\n","loss: 0.5835, acc: 0.7778\n","E2E-ABSA >>> 2022-09-02 04:27:01\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:27:02\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:27:02\n","loss: 0.6195, acc: 0.7530\n","E2E-ABSA >>> 2022-09-02 04:27:02\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:27:03\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:27:03\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:27:03\n","loss: 0.7611, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 04:27:04\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:27:05\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:27:05\n","loss: 0.5348, acc: 0.8036\n","E2E-ABSA >>> 2022-09-02 04:27:05\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:27:06\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:27:06\n","loss: 0.6068, acc: 0.7452\n","E2E-ABSA >>> 2022-09-02 04:27:07\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:27:07\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:27:07\n","loss: 0.5071, acc: 0.8026\n","E2E-ABSA >>> 2022-09-02 04:27:08\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:27:09\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:27:09\n","loss: 0.5841, acc: 0.7700\n","E2E-ABSA >>> 2022-09-02 04:27:09\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:27:10\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:27:10\n","loss: 0.5467, acc: 0.7782\n","E2E-ABSA >>> 2022-09-02 04:27:10\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:27:11\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:27:12\n","loss: 0.5552, acc: 0.7821\n","E2E-ABSA >>> 2022-09-02 04:27:12\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:27:12\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">> saved: state_dict/atae_lstm_SemEval2015_know_val_f1_0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 04:27:13\n","loss: 0.5525, acc: 0.7805\n","E2E-ABSA >>> 2022-09-02 04:27:13\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 04:27:14\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 04:27:14\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 04:27:14\n","loss: 0.6369, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:27:15\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 04:27:16\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 04:27:16\n","loss: 0.4862, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 04:27:16\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 04:27:17\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 04:27:17\n","loss: 0.5267, acc: 0.8036\n","E2E-ABSA >>> 2022-09-02 04:27:18\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 04:27:18\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 04:27:18\n","loss: 0.4823, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 04:27:19\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 04:27:20\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 04:27:20\n","loss: 0.4390, acc: 0.8197\n","E2E-ABSA >>> 2022-09-02 04:27:20\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 04:27:21\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 04:27:21\n","loss: 0.4768, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 04:27:21\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 04:27:22\n",">>> val_acc: 0.7927, val_precision: 0.7927 val_recall: 0.7927, val_f1: 0.7927\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 04:27:23\n","loss: 0.4457, acc: 0.8224\n","E2E-ABSA >>> 2022-09-02 04:27:23\n",">>> val_acc: 0.7927, val_precision: 0.7927 val_recall: 0.7927, val_f1: 0.7927\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 04:27:23\n",">>> val_acc: 0.7927, val_precision: 0.7927 val_recall: 0.7927, val_f1: 0.7927\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 04:27:24\n","loss: 0.4237, acc: 0.8182\n","E2E-ABSA >>> 2022-09-02 04:27:24\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 04:27:25\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 04:27:25\n",">>> val_acc: 0.7805, val_precision: 0.7805 val_recall: 0.7805, val_f1: 0.7805\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 04:27:25\n","loss: 0.3113, acc: 0.9375\n","E2E-ABSA >>> 2022-09-02 04:27:26\n",">>> val_acc: 0.7805, val_precision: 0.7805 val_recall: 0.7805, val_f1: 0.7805\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 04:27:27\n",">>> val_acc: 0.7927, val_precision: 0.7927 val_recall: 0.7927, val_f1: 0.7927\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 04:27:27\n","loss: 0.4348, acc: 0.8264\n","E2E-ABSA >>> 2022-09-02 04:27:27\n",">>> val_acc: 0.7927, val_precision: 0.7927 val_recall: 0.7927, val_f1: 0.7927\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 04:27:28\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 04:27:28\n","loss: 0.3930, acc: 0.8458\n","E2E-ABSA >>> 2022-09-02 04:27:29\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 04:27:29\n",">>> val_acc: 0.7927, val_precision: 0.7927 val_recall: 0.7927, val_f1: 0.7927\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 04:27:29\n","loss: 0.3992, acc: 0.8244\n","E2E-ABSA >>> 2022-09-02 04:27:30\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 04:27:30\n",">>> val_acc: 0.7927, val_precision: 0.7927 val_recall: 0.7927, val_f1: 0.7927\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 04:27:31\n","loss: 0.3748, acc: 0.8542\n","E2E-ABSA >>> 2022-09-02 04:27:31\n",">>> val_acc: 0.7805, val_precision: 0.7805 val_recall: 0.7805, val_f1: 0.7805\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 04:27:32\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n","E2E-ABSA >>> 2022-09-02 04:27:32\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n","you can download the best model from state_dict/atae_lstm_SemEval2015_know_val_f1_0.8415\n",">>> test_acc: 0.8415, test_precision: 0.8415, test_recall: 0.8415, test_f1: 0.8415\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2015** dataset on model(**IAN**)"],"metadata":{"id":"8gQap8pBQK4S"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name ian --dataset SemEval2015_know --embed_dim 300 --patience 30\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wDhddmi4QK-w","outputId":"ff680fed-9f3f-497a-d19e-03b897b6fddc","executionInfo":{"status":"ok","timestamp":1662092917185,"user_tz":-480,"elapsed":63604,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 750.\n","> testing dataset count: 82.\n","cuda memory allocated: 14801920\n","> n_trainable_params: 2168403, n_nontrainable_params: 1530300\n","> training arguments:\n",">>> model_name: ian\n",">>> dataset: SemEval2015_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f7a8c092c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.ian.IAN'>\n",">>> dataset_file: {'train': './datasets/rest15/output_know_insert/train.tsv', 'test': './datasets/rest15/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:12\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">> saved: state_dict/ian_SemEval2015_know_val_f1_0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:13\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:13\n","loss: 0.7458, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 04:28:13\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:14\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:14\n","loss: 0.6793, acc: 0.7760\n","E2E-ABSA >>> 2022-09-02 04:28:15\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:16\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:16\n","loss: 0.6657, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 04:28:17\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:17\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:18\n","loss: 0.6380, acc: 0.7760\n","E2E-ABSA >>> 2022-09-02 04:28:18\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:19\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:19\n","loss: 0.5959, acc: 0.7937\n","E2E-ABSA >>> 2022-09-02 04:28:20\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:20\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:21\n","loss: 0.6075, acc: 0.7847\n","E2E-ABSA >>> 2022-09-02 04:28:21\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:22\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:23\n","loss: 0.6488, acc: 0.7634\n","E2E-ABSA >>> 2022-09-02 04:28:23\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:24\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:24\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:24\n","loss: 0.6748, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:28:25\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:26\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:26\n","loss: 0.5900, acc: 0.8036\n","E2E-ABSA >>> 2022-09-02 04:28:27\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:27\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:28\n","loss: 0.6705, acc: 0.7404\n","E2E-ABSA >>> 2022-09-02 04:28:28\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:29\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:29\n","loss: 0.5906, acc: 0.7796\n","E2E-ABSA >>> 2022-09-02 04:28:30\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:31\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:31\n","loss: 0.6321, acc: 0.7725\n","E2E-ABSA >>> 2022-09-02 04:28:31\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:32\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:33\n","loss: 0.6196, acc: 0.7722\n","E2E-ABSA >>> 2022-09-02 04:28:33\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:34\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:34\n","loss: 0.6331, acc: 0.7669\n","E2E-ABSA >>> 2022-09-02 04:28:35\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:28:35\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n","E2E-ABSA >>> 2022-09-02 04:28:35\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n","you can download the best model from state_dict/ian_SemEval2015_know_val_f1_0.8293\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n",">>> test_acc: 0.8293, test_precision: 0.8293, test_recall: 0.8293, test_f1: 0.8293\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2015** dataset on model(**MEMNET**)"],"metadata":{"id":"7-nlDvPSQLQv"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name memnet --dataset SemEval2015_know --embed_dim 300 --patience 30\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0FKsYm7IQLWw","outputId":"954e1007-05a7-4bc2-a9e2-4012f49ab5f8","executionInfo":{"status":"ok","timestamp":1662092976502,"user_tz":-480,"elapsed":59327,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 750.\n","> testing dataset count: 82.\n","cuda memory allocated: 7576576\n","> n_trainable_params: 362703, n_nontrainable_params: 1530300\n","> training arguments:\n",">>> model_name: memnet\n",">>> dataset: SemEval2015_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f9c1ffcac20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.memnet.MemNet'>\n",">>> dataset_file: {'train': './datasets/rest15/output_know_insert/train.tsv', 'test': './datasets/rest15/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['context_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:14\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">> saved: state_dict/memnet_SemEval2015_know_val_f1_0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:14\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:15\n","loss: 0.6612, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 04:29:15\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">> saved: state_dict/memnet_SemEval2015_know_val_f1_0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:15\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:15\n","loss: 0.5973, acc: 0.7917\n","E2E-ABSA >>> 2022-09-02 04:29:16\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:16\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:16\n","loss: 0.6050, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 04:29:16\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:17\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:17\n","loss: 0.5674, acc: 0.7917\n","E2E-ABSA >>> 2022-09-02 04:29:17\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:18\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:18\n","loss: 0.5820, acc: 0.7833\n","E2E-ABSA >>> 2022-09-02 04:29:18\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:18\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:19\n","loss: 0.6320, acc: 0.7569\n","E2E-ABSA >>> 2022-09-02 04:29:19\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:19\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:19\n","loss: 0.5803, acc: 0.7827\n","E2E-ABSA >>> 2022-09-02 04:29:19\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:20\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">> saved: state_dict/memnet_SemEval2015_know_val_f1_0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:20\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:20\n","loss: 0.4808, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 04:29:21\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:21\n",">>> val_acc: 0.8049, val_precision: 0.8049 val_recall: 0.8049, val_f1: 0.8049\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:21\n","loss: 0.5767, acc: 0.7768\n","E2E-ABSA >>> 2022-09-02 04:29:21\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:22\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:22\n","loss: 0.5971, acc: 0.7740\n","E2E-ABSA >>> 2022-09-02 04:29:22\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:23\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:23\n","loss: 0.5478, acc: 0.7796\n","E2E-ABSA >>> 2022-09-02 04:29:23\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:23\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">> saved: state_dict/memnet_SemEval2015_know_val_f1_0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:23\n","loss: 0.5294, acc: 0.8025\n","E2E-ABSA >>> 2022-09-02 04:29:24\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:24\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:24\n","loss: 0.5344, acc: 0.7923\n","E2E-ABSA >>> 2022-09-02 04:29:24\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:25\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:25\n","loss: 0.5340, acc: 0.7905\n","E2E-ABSA >>> 2022-09-02 04:29:25\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:26\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:26\n","loss: 0.5435, acc: 0.7820\n","E2E-ABSA >>> 2022-09-02 04:29:26\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:26\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:27\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:27\n","loss: 0.5968, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:29:27\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:28\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:28\n","loss: 0.4986, acc: 0.7891\n","E2E-ABSA >>> 2022-09-02 04:29:28\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:28\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:28\n","loss: 0.5517, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:29:29\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:29\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:29\n","loss: 0.5611, acc: 0.7719\n","E2E-ABSA >>> 2022-09-02 04:29:29\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:30\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:30\n","loss: 0.5141, acc: 0.7861\n","E2E-ABSA >>> 2022-09-02 04:29:30\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:31\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:31\n","loss: 0.4783, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 04:29:31\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:31\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:32\n","loss: 0.5158, acc: 0.7878\n","E2E-ABSA >>> 2022-09-02 04:29:32\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:32\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:32\n","loss: 0.5083, acc: 0.7912\n","E2E-ABSA >>> 2022-09-02 04:29:33\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:33\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:33\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:33\n","loss: 0.3243, acc: 0.9375\n","E2E-ABSA >>> 2022-09-02 04:29:34\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:34\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:34\n","loss: 0.6151, acc: 0.7569\n","E2E-ABSA >>> 2022-09-02 04:29:34\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:29:35\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n","E2E-ABSA >>> 2022-09-02 04:29:35\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n","you can download the best model from state_dict/memnet_SemEval2015_know_val_f1_0.8537\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",">>> test_acc: 0.8537, test_precision: 0.8537, test_recall: 0.8537, test_f1: 0.8537\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2015** dataset on model(**CABASC**)"],"metadata":{"id":"t1iodVnKQLma"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name cabasc --dataset SemEval2015_know --embed_dim 300 --patience 30\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EWVJe1ZwQLsS","outputId":"7f2f298a-1cd1-4c62-c024-783ece3df728","executionInfo":{"status":"ok","timestamp":1662093111117,"user_tz":-480,"elapsed":134628,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 658.\n","> testing dataset count: 79.\n","cuda memory allocated: 11910144\n","> n_trainable_params: 1446005, n_nontrainable_params: 1530300\n","> training arguments:\n",">>> model_name: cabasc\n",">>> dataset: SemEval2015_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f96f1f16c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.cabasc.Cabasc'>\n",">>> dataset_file: {'train': './datasets/rest15/output_know_insert/train.tsv', 'test': './datasets/rest15/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices', 'left_with_aspect_indices', 'right_with_aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:30:17\n",">>> val_acc: 0.8101, val_precision: 0.8101 val_recall: 0.8101, val_f1: 0.8101\n",">> saved: state_dict/cabasc_SemEval2015_know_val_f1_0.8101\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:30:20\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">> saved: state_dict/cabasc_SemEval2015_know_val_f1_0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:30:21\n","loss: 0.6738, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 04:30:23\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:30:26\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:30:28\n","loss: 0.6459, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 04:30:29\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:30:32\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:30:35\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:30:35\n","loss: 0.6891, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 04:30:38\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:30:40\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:30:42\n","loss: 0.6373, acc: 0.7472\n","E2E-ABSA >>> 2022-09-02 04:30:43\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:30:46\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:30:49\n","loss: 0.6466, acc: 0.7566\n","E2E-ABSA >>> 2022-09-02 04:30:49\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:30:52\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:30:55\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:30:56\n","loss: 0.6052, acc: 0.7865\n","E2E-ABSA >>> 2022-09-02 04:30:58\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:31:01\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:31:03\n","loss: 0.5799, acc: 0.7857\n","E2E-ABSA >>> 2022-09-02 04:31:04\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:31:07\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:31:10\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:31:10\n","loss: 0.6357, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:31:13\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:31:16\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:31:17\n","loss: 0.6705, acc: 0.7361\n","E2E-ABSA >>> 2022-09-02 04:31:19\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:31:22\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:31:24\n","loss: 0.6544, acc: 0.7482\n","E2E-ABSA >>> 2022-09-02 04:31:25\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:31:27\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:31:31\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:31:31\n","loss: 0.6727, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:31:34\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:31:36\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:31:39\n","loss: 0.6048, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 04:31:40\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:31:43\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:31:46\n","loss: 0.6207, acc: 0.7594\n","E2E-ABSA >>> 2022-09-02 04:31:46\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 04:31:49\n",">>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n","E2E-ABSA >>> 2022-09-02 04:31:49\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.8354, val_precision: 0.8354 val_recall: 0.8354, val_f1: 0.8354\n","you can download the best model from state_dict/cabasc_SemEval2015_know_val_f1_0.8354\n",">>> test_acc: 0.8354, test_precision: 0.8354, test_recall: 0.8354, test_f1: 0.8354\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2016** dataset on model(**LSTM**)"],"metadata":{"id":"S6gVgYJUV8S_"}},{"cell_type":"markdown","source":["lstm\n","tdlstm  \n","tclstm  \n","ataelstm  \n","ian \n","memnet  \n","cabasc "],"metadata":{"id":"K4teqx1kV8F6"}},{"cell_type":"code","source":["!pwd\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name lstm --dataset SemEval2016_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GuTuSo0bV8ZJ","outputId":"04d428ea-79a8-4266-effc-581a117b3504","executionInfo":{"status":"ok","timestamp":1662093167985,"user_tz":-480,"elapsed":56879,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train_insert.py\n","data_utils.py\t    layers\t\t   README.md\t     train.py\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   state_dict\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1112.\n","> testing dataset count: 118.\n","cuda memory allocated: 10786816\n","> n_trainable_params: 723303, n_nontrainable_params: 1973100\n","> training arguments:\n",">>> model_name: lstm\n",">>> dataset: SemEval2016_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f063fdb9c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.lstm.LSTM'>\n",">>> dataset_file: {'train': './datasets/rest16/output_know_insert/train.tsv', 'test': './datasets/rest16/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:32:28\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">> saved: state_dict/lstm_SemEval2016_know_val_f1_0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:32:28\n","loss: 0.8141, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 04:32:29\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:32:29\n","loss: 0.7377, acc: 0.7177\n","E2E-ABSA >>> 2022-09-02 04:32:29\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:32:30\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:32:30\n","loss: 0.7473, acc: 0.6813\n","E2E-ABSA >>> 2022-09-02 04:32:30\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:32:31\n","loss: 0.6943, acc: 0.7250\n","E2E-ABSA >>> 2022-09-02 04:32:31\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:32:32\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:32:32\n","loss: 0.6995, acc: 0.7312\n","E2E-ABSA >>> 2022-09-02 04:32:32\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:32:33\n","loss: 0.6787, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:32:33\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:32:33\n","loss: 0.6908, acc: 0.7176\n","E2E-ABSA >>> 2022-09-02 04:32:33\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:32:34\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:32:34\n","loss: 0.6945, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 04:32:35\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:32:35\n","loss: 0.6841, acc: 0.7156\n","E2E-ABSA >>> 2022-09-02 04:32:35\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:32:36\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:32:36\n","loss: 0.6565, acc: 0.7219\n","E2E-ABSA >>> 2022-09-02 04:32:36\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:32:37\n","loss: 0.6726, acc: 0.7212\n","E2E-ABSA >>> 2022-09-02 04:32:37\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:32:38\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:32:38\n","loss: 0.6971, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:32:38\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:32:39\n","loss: 0.6678, acc: 0.7172\n","E2E-ABSA >>> 2022-09-02 04:32:39\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:32:40\n","loss: 0.6605, acc: 0.7185\n","E2E-ABSA >>> 2022-09-02 04:32:40\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:32:40\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:32:40\n","loss: 0.6711, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 04:32:41\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:32:41\n","loss: 0.6426, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:32:41\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:32:42\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:32:42\n","loss: 0.6541, acc: 0.7281\n","E2E-ABSA >>> 2022-09-02 04:32:43\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:32:43\n","loss: 0.6225, acc: 0.7375\n","E2E-ABSA >>> 2022-09-02 04:32:43\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:32:44\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:32:44\n","loss: 0.5809, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:32:44\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:32:45\n","loss: 0.6152, acc: 0.7422\n","E2E-ABSA >>> 2022-09-02 04:32:45\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:32:46\n","loss: 0.6173, acc: 0.7311\n","E2E-ABSA >>> 2022-09-02 04:32:46\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:32:46\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n","E2E-ABSA >>> 2022-09-02 04:32:46\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n","you can download the best model from state_dict/lstm_SemEval2016_know_val_f1_0.7288\n",">>> test_acc: 0.7288, test_precision: 0.7288, test_recall: 0.7288, test_f1: 0.7288\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2016** dataset on model(**TDLSTM**)"],"metadata":{"id":"NQdcmH47V8qw"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name td_lstm --dataset SemEval2016_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0sWG6_EbV8wq","outputId":"5b8ada3f-5474-41b8-e656-eeea8a350b95","executionInfo":{"status":"ok","timestamp":1662093281573,"user_tz":-480,"elapsed":113595,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1006.\n","> testing dataset count: 103.\n","cuda memory allocated: 13680128\n","> n_trainable_params: 1446603, n_nontrainable_params: 1973100\n","> training arguments:\n",">>> model_name: td_lstm\n",">>> dataset: SemEval2016_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f50de808c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.td_lstm.TD_LSTM'>\n",">>> dataset_file: {'train': './datasets/rest16/output_know_insert/train.tsv', 'test': './datasets/rest16/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['left_with_aspect_indices', 'right_with_aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:33:26\n",">>> val_acc: 0.6990, val_precision: 0.6990 val_recall: 0.6990, val_f1: 0.6990\n",">> saved: state_dict/td_lstm_SemEval2016_know_val_f1_0.699\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:33:26\n","loss: 0.8863, acc: 0.7061\n","E2E-ABSA >>> 2022-09-02 04:33:26\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">> saved: state_dict/td_lstm_SemEval2016_know_val_f1_0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:33:27\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:33:27\n","loss: 0.7929, acc: 0.6648\n","E2E-ABSA >>> 2022-09-02 04:33:28\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:33:28\n","loss: 0.7032, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:33:29\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:33:29\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:33:30\n","loss: 0.6966, acc: 0.7244\n","E2E-ABSA >>> 2022-09-02 04:33:30\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:33:31\n","loss: 0.6956, acc: 0.7076\n","E2E-ABSA >>> 2022-09-02 04:33:31\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:33:32\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:33:32\n","loss: 0.6873, acc: 0.7178\n","E2E-ABSA >>> 2022-09-02 04:33:32\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:33:33\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:33:34\n","loss: 0.7067, acc: 0.6964\n","E2E-ABSA >>> 2022-09-02 04:33:34\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:33:35\n","loss: 0.6650, acc: 0.7173\n","E2E-ABSA >>> 2022-09-02 04:33:35\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:33:36\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:33:36\n","loss: 0.6925, acc: 0.7049\n","E2E-ABSA >>> 2022-09-02 04:33:37\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:33:37\n","loss: 0.6695, acc: 0.7159\n","E2E-ABSA >>> 2022-09-02 04:33:37\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:33:38\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:33:38\n","loss: 0.6612, acc: 0.7220\n","E2E-ABSA >>> 2022-09-02 04:33:39\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">> saved: state_dict/td_lstm_SemEval2016_know_val_f1_0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:33:39\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">> saved: state_dict/td_lstm_SemEval2016_know_val_f1_0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:33:40\n","loss: 0.6213, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 04:33:40\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:33:41\n","loss: 0.6484, acc: 0.7312\n","E2E-ABSA >>> 2022-09-02 04:33:41\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:33:42\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:33:42\n","loss: 0.6213, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:33:42\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">> saved: state_dict/td_lstm_SemEval2016_know_val_f1_0.767\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:33:43\n","loss: 0.6386, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 04:33:43\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:33:44\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:33:44\n","loss: 0.6166, acc: 0.7450\n","E2E-ABSA >>> 2022-09-02 04:33:45\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:33:45\n","loss: 0.6246, acc: 0.7359\n","E2E-ABSA >>> 2022-09-02 04:33:45\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:33:46\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:33:47\n","loss: 0.6255, acc: 0.7413\n","E2E-ABSA >>> 2022-09-02 04:33:47\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:33:48\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:33:48\n","loss: 0.5812, acc: 0.7750\n","E2E-ABSA >>> 2022-09-02 04:33:48\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 04:33:49\n","loss: 0.6092, acc: 0.7367\n","E2E-ABSA >>> 2022-09-02 04:33:49\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 04:33:50\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 04:33:50\n","loss: 0.5613, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:33:51\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 04:33:51\n","loss: 0.6041, acc: 0.7403\n","E2E-ABSA >>> 2022-09-02 04:33:51\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 04:33:52\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 04:33:52\n","loss: 0.6354, acc: 0.7246\n","E2E-ABSA >>> 2022-09-02 04:33:53\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 04:33:54\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 04:33:54\n","loss: 0.6714, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 04:33:54\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 04:33:55\n","loss: 0.6071, acc: 0.7398\n","E2E-ABSA >>> 2022-09-02 04:33:55\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 04:33:56\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 04:33:56\n","loss: 0.6172, acc: 0.7316\n","E2E-ABSA >>> 2022-09-02 04:33:57\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 04:33:57\n","loss: 0.5782, acc: 0.7546\n","E2E-ABSA >>> 2022-09-02 04:33:57\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 04:33:58\n",">>> val_acc: 0.7767, val_precision: 0.7767 val_recall: 0.7767, val_f1: 0.7767\n",">> saved: state_dict/td_lstm_SemEval2016_know_val_f1_0.7767\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 04:33:58\n","loss: 0.5704, acc: 0.7679\n","E2E-ABSA >>> 2022-09-02 04:33:59\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 04:34:00\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 04:34:00\n","loss: 0.6510, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:34:00\n",">>> val_acc: 0.7864, val_precision: 0.7864 val_recall: 0.7864, val_f1: 0.7864\n",">> saved: state_dict/td_lstm_SemEval2016_know_val_f1_0.7864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 04:34:01\n","loss: 0.5643, acc: 0.7756\n","E2E-ABSA >>> 2022-09-02 04:34:01\n",">>> val_acc: 0.7864, val_precision: 0.7864 val_recall: 0.7864, val_f1: 0.7864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 04:34:02\n",">>> val_acc: 0.7864, val_precision: 0.7864 val_recall: 0.7864, val_f1: 0.7864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 04:34:02\n","loss: 0.5103, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 04:34:03\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 04:34:03\n","loss: 0.5639, acc: 0.7638\n","E2E-ABSA >>> 2022-09-02 04:34:03\n",">>> val_acc: 0.7864, val_precision: 0.7864 val_recall: 0.7864, val_f1: 0.7864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 04:34:04\n",">>> val_acc: 0.7864, val_precision: 0.7864 val_recall: 0.7864, val_f1: 0.7864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 04:34:04\n","loss: 0.5910, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 04:34:05\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 04:34:05\n","loss: 0.5447, acc: 0.7797\n","E2E-ABSA >>> 2022-09-02 04:34:05\n",">>> val_acc: 0.7864, val_precision: 0.7864 val_recall: 0.7864, val_f1: 0.7864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 04:34:06\n",">>> val_acc: 0.7864, val_precision: 0.7864 val_recall: 0.7864, val_f1: 0.7864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 04:34:07\n","loss: 0.5515, acc: 0.7714\n","E2E-ABSA >>> 2022-09-02 04:34:07\n",">>> val_acc: 0.7961, val_precision: 0.7961 val_recall: 0.7961, val_f1: 0.7961\n",">> saved: state_dict/td_lstm_SemEval2016_know_val_f1_0.7961\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 04:34:08\n",">>> val_acc: 0.7864, val_precision: 0.7864 val_recall: 0.7864, val_f1: 0.7864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 04:34:08\n","loss: 0.5889, acc: 0.7569\n","E2E-ABSA >>> 2022-09-02 04:34:08\n",">>> val_acc: 0.7767, val_precision: 0.7767 val_recall: 0.7767, val_f1: 0.7767\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 04:34:09\n","loss: 0.5203, acc: 0.7853\n","E2E-ABSA >>> 2022-09-02 04:34:09\n",">>> val_acc: 0.7864, val_precision: 0.7864 val_recall: 0.7864, val_f1: 0.7864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 04:34:10\n",">>> val_acc: 0.7864, val_precision: 0.7864 val_recall: 0.7864, val_f1: 0.7864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 04:34:10\n","loss: 0.5066, acc: 0.8063\n","E2E-ABSA >>> 2022-09-02 04:34:11\n",">>> val_acc: 0.7767, val_precision: 0.7767 val_recall: 0.7767, val_f1: 0.7767\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 04:34:11\n","loss: 0.5335, acc: 0.7763\n","E2E-ABSA >>> 2022-09-02 04:34:11\n",">>> val_acc: 0.7961, val_precision: 0.7961 val_recall: 0.7961, val_f1: 0.7961\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 04:34:12\n",">>> val_acc: 0.7864, val_precision: 0.7864 val_recall: 0.7864, val_f1: 0.7864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 04:34:13\n","loss: 0.5574, acc: 0.7681\n","E2E-ABSA >>> 2022-09-02 04:34:13\n",">>> val_acc: 0.7767, val_precision: 0.7767 val_recall: 0.7767, val_f1: 0.7767\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 04:34:14\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">> saved: state_dict/td_lstm_SemEval2016_know_val_f1_0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 04:34:14\n","loss: 0.6564, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:34:14\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 04:34:15\n","loss: 0.5150, acc: 0.7991\n","E2E-ABSA >>> 2022-09-02 04:34:15\n",">>> val_acc: 0.7961, val_precision: 0.7961 val_recall: 0.7961, val_f1: 0.7961\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 04:34:16\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","E2E-ABSA >>> 2022-09-02 04:34:16\n","loss: 0.5650, acc: 0.7773\n","E2E-ABSA >>> 2022-09-02 04:34:17\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","E2E-ABSA >>> 2022-09-02 04:34:17\n","loss: 0.5050, acc: 0.8007\n","E2E-ABSA >>> 2022-09-02 04:34:17\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","E2E-ABSA >>> 2022-09-02 04:34:18\n",">>> val_acc: 0.7961, val_precision: 0.7961 val_recall: 0.7961, val_f1: 0.7961\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","E2E-ABSA >>> 2022-09-02 04:34:18\n","loss: 0.5192, acc: 0.7593\n","E2E-ABSA >>> 2022-09-02 04:34:19\n",">>> val_acc: 0.7961, val_precision: 0.7961 val_recall: 0.7961, val_f1: 0.7961\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","E2E-ABSA >>> 2022-09-02 04:34:20\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","E2E-ABSA >>> 2022-09-02 04:34:20\n","loss: 0.5555, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 04:34:20\n",">>> val_acc: 0.7961, val_precision: 0.7961 val_recall: 0.7961, val_f1: 0.7961\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","E2E-ABSA >>> 2022-09-02 04:34:21\n","loss: 0.5093, acc: 0.8109\n","E2E-ABSA >>> 2022-09-02 04:34:21\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","E2E-ABSA >>> 2022-09-02 04:34:22\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","E2E-ABSA >>> 2022-09-02 04:34:22\n","loss: 0.4622, acc: 0.8490\n","E2E-ABSA >>> 2022-09-02 04:34:23\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","E2E-ABSA >>> 2022-09-02 04:34:23\n","loss: 0.4986, acc: 0.8074\n","E2E-ABSA >>> 2022-09-02 04:34:23\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","E2E-ABSA >>> 2022-09-02 04:34:24\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","E2E-ABSA >>> 2022-09-02 04:34:24\n","loss: 0.4752, acc: 0.8288\n","E2E-ABSA >>> 2022-09-02 04:34:25\n",">>> val_acc: 0.7864, val_precision: 0.7864 val_recall: 0.7864, val_f1: 0.7864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","E2E-ABSA >>> 2022-09-02 04:34:25\n","loss: 0.4925, acc: 0.8083\n","E2E-ABSA >>> 2022-09-02 04:34:25\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","E2E-ABSA >>> 2022-09-02 04:34:26\n",">>> val_acc: 0.8155, val_precision: 0.8155 val_recall: 0.8155, val_f1: 0.8155\n",">> saved: state_dict/td_lstm_SemEval2016_know_val_f1_0.8155\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","E2E-ABSA >>> 2022-09-02 04:34:27\n","loss: 0.4516, acc: 0.8290\n","E2E-ABSA >>> 2022-09-02 04:34:27\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","E2E-ABSA >>> 2022-09-02 04:34:28\n",">>> val_acc: 0.8155, val_precision: 0.8155 val_recall: 0.8155, val_f1: 0.8155\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","E2E-ABSA >>> 2022-09-02 04:34:28\n","loss: 0.4314, acc: 0.8359\n","E2E-ABSA >>> 2022-09-02 04:34:28\n",">>> val_acc: 0.7961, val_precision: 0.7961 val_recall: 0.7961, val_f1: 0.7961\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","E2E-ABSA >>> 2022-09-02 04:34:29\n","loss: 0.4618, acc: 0.8153\n","E2E-ABSA >>> 2022-09-02 04:34:29\n",">>> val_acc: 0.8155, val_precision: 0.8155 val_recall: 0.8155, val_f1: 0.8155\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","E2E-ABSA >>> 2022-09-02 04:34:30\n",">>> val_acc: 0.8155, val_precision: 0.8155 val_recall: 0.8155, val_f1: 0.8155\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","E2E-ABSA >>> 2022-09-02 04:34:30\n","loss: 0.4874, acc: 0.8388\n","E2E-ABSA >>> 2022-09-02 04:34:31\n",">>> val_acc: 0.8155, val_precision: 0.8155 val_recall: 0.8155, val_f1: 0.8155\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","E2E-ABSA >>> 2022-09-02 04:34:31\n","loss: 0.4702, acc: 0.8214\n","E2E-ABSA >>> 2022-09-02 04:34:31\n",">>> val_acc: 0.8155, val_precision: 0.8155 val_recall: 0.8155, val_f1: 0.8155\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","E2E-ABSA >>> 2022-09-02 04:34:32\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 90.\n","E2E-ABSA >>> 2022-09-02 04:34:33\n","loss: 0.4772, acc: 0.8271\n","E2E-ABSA >>> 2022-09-02 04:34:33\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 91.\n","E2E-ABSA >>> 2022-09-02 04:34:34\n",">>> val_acc: 0.7961, val_precision: 0.7961 val_recall: 0.7961, val_f1: 0.7961\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 92.\n","E2E-ABSA >>> 2022-09-02 04:34:34\n","loss: 0.4738, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 04:34:34\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 93.\n","E2E-ABSA >>> 2022-09-02 04:34:35\n","loss: 0.4701, acc: 0.8171\n","E2E-ABSA >>> 2022-09-02 04:34:35\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 94.\n","E2E-ABSA >>> 2022-09-02 04:34:36\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 95.\n","E2E-ABSA >>> 2022-09-02 04:34:36\n","loss: 0.4519, acc: 0.8417\n","E2E-ABSA >>> 2022-09-02 04:34:37\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 96.\n","E2E-ABSA >>> 2022-09-02 04:34:37\n","loss: 0.4585, acc: 0.8377\n","E2E-ABSA >>> 2022-09-02 04:34:37\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 97.\n","E2E-ABSA >>> 2022-09-02 04:34:38\n",">>> val_acc: 0.8155, val_precision: 0.8155 val_recall: 0.8155, val_f1: 0.8155\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 98.\n","E2E-ABSA >>> 2022-09-02 04:34:38\n","loss: 0.4276, acc: 0.8510\n","E2E-ABSA >>> 2022-09-02 04:34:39\n",">>> val_acc: 0.8155, val_precision: 0.8155 val_recall: 0.8155, val_f1: 0.8155\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 99.\n","E2E-ABSA >>> 2022-09-02 04:34:40\n","loss: 0.4568, acc: 0.8350\n","E2E-ABSA >>> 2022-09-02 04:34:40\n",">>> val_acc: 0.8058, val_precision: 0.8058 val_recall: 0.8058, val_f1: 0.8058\n","you can download the best model from state_dict/td_lstm_SemEval2016_know_val_f1_0.8155\n",">>> test_acc: 0.8155, test_precision: 0.8155, test_recall: 0.8155, test_f1: 0.8155\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2016** dataset on model(**TCLSTM**)"],"metadata":{"id":"6w1G6R_tV8_w"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name tc_lstm --dataset SemEval2016_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sr-PScc_V9FS","outputId":"33a0ecc8-c86f-4308-ed03-24bb12ac4cc5","executionInfo":{"status":"ok","timestamp":1662093353738,"user_tz":-480,"elapsed":72177,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1006.\n","> testing dataset count: 103.\n","cuda memory allocated: 16659456\n","> n_trainable_params: 2166603, n_nontrainable_params: 1973100\n","> training arguments:\n",">>> model_name: tc_lstm\n",">>> dataset: SemEval2016_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f67a8bfcc20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.tc_lstm.TC_LSTM'>\n",">>> dataset_file: {'train': './datasets/rest16/output_know_insert/train.tsv', 'test': './datasets/rest16/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['left_with_aspect_indices', 'right_with_aspect_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:35:19\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">> saved: state_dict/tc_lstm_SemEval2016_know_val_f1_0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:35:19\n","loss: 0.7757, acc: 0.6976\n","E2E-ABSA >>> 2022-09-02 04:35:20\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:35:21\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:35:21\n","loss: 0.6948, acc: 0.7273\n","E2E-ABSA >>> 2022-09-02 04:35:21\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:35:22\n","loss: 0.7041, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 04:35:22\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:35:23\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">> saved: state_dict/tc_lstm_SemEval2016_know_val_f1_0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:35:23\n","loss: 0.6888, acc: 0.7131\n","E2E-ABSA >>> 2022-09-02 04:35:24\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:35:25\n","loss: 0.6653, acc: 0.7288\n","E2E-ABSA >>> 2022-09-02 04:35:25\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:35:26\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:35:26\n","loss: 0.6402, acc: 0.7178\n","E2E-ABSA >>> 2022-09-02 04:35:26\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:35:27\n",">>> val_acc: 0.7767, val_precision: 0.7767 val_recall: 0.7767, val_f1: 0.7767\n",">> saved: state_dict/tc_lstm_SemEval2016_know_val_f1_0.7767\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:35:27\n","loss: 0.6272, acc: 0.7679\n","E2E-ABSA >>> 2022-09-02 04:35:28\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:35:29\n","loss: 0.6299, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 04:35:29\n",">>> val_acc: 0.7767, val_precision: 0.7767 val_recall: 0.7767, val_f1: 0.7767\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:35:30\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:35:30\n","loss: 0.6846, acc: 0.7014\n","E2E-ABSA >>> 2022-09-02 04:35:31\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:35:32\n","loss: 0.6326, acc: 0.7250\n","E2E-ABSA >>> 2022-09-02 04:35:32\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:35:32\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:35:33\n","loss: 0.6472, acc: 0.7177\n","E2E-ABSA >>> 2022-09-02 04:35:33\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:35:34\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:35:34\n","loss: 0.6223, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 04:35:35\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:35:35\n","loss: 0.5964, acc: 0.7484\n","E2E-ABSA >>> 2022-09-02 04:35:36\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:35:37\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:35:37\n","loss: 0.6324, acc: 0.7366\n","E2E-ABSA >>> 2022-09-02 04:35:37\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:35:38\n","loss: 0.5666, acc: 0.7512\n","E2E-ABSA >>> 2022-09-02 04:35:38\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:35:39\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:35:39\n","loss: 0.6180, acc: 0.7375\n","E2E-ABSA >>> 2022-09-02 04:35:40\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:35:41\n","loss: 0.5779, acc: 0.7530\n","E2E-ABSA >>> 2022-09-02 04:35:41\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:35:41\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:35:42\n","loss: 0.5737, acc: 0.7587\n","E2E-ABSA >>> 2022-09-02 04:35:42\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:35:43\n",">>> val_acc: 0.7670, val_precision: 0.7670 val_recall: 0.7670, val_f1: 0.7670\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:35:43\n","loss: 0.6029, acc: 0.7375\n","E2E-ABSA >>> 2022-09-02 04:35:44\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 04:35:44\n","loss: 0.5426, acc: 0.7713\n","E2E-ABSA >>> 2022-09-02 04:35:45\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 04:35:45\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 04:35:46\n","loss: 0.5292, acc: 0.8095\n","E2E-ABSA >>> 2022-09-02 04:35:46\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 04:35:47\n","loss: 0.5440, acc: 0.7694\n","E2E-ABSA >>> 2022-09-02 04:35:47\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 04:35:48\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 04:35:48\n","loss: 0.5202, acc: 0.7734\n","E2E-ABSA >>> 2022-09-02 04:35:49\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 04:35:49\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 04:35:49\n","loss: 0.5925, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:35:50\n",">>> val_acc: 0.7476, val_precision: 0.7476 val_recall: 0.7476, val_f1: 0.7476\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 04:35:51\n","loss: 0.5012, acc: 0.7965\n","E2E-ABSA >>> 2022-09-02 04:35:51\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 04:35:52\n",">>> val_acc: 0.7573, val_precision: 0.7573 val_recall: 0.7573, val_f1: 0.7573\n","E2E-ABSA >>> 2022-09-02 04:35:52\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7767, val_precision: 0.7767 val_recall: 0.7767, val_f1: 0.7767\n","you can download the best model from state_dict/tc_lstm_SemEval2016_know_val_f1_0.7767\n",">>> test_acc: 0.7767, test_precision: 0.7767, test_recall: 0.7767, test_f1: 0.7767\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2016** dataset on model(**ATAELSTM**)"],"metadata":{"id":"eaVEvAO5V9Us"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name atae_lstm --dataset SemEval2016_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hxg73V-AV9Zo","outputId":"f5378ce4-aea3-4f30-aeed-36b0559c6327","executionInfo":{"status":"ok","timestamp":1662093453440,"user_tz":-480,"elapsed":99714,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1112.\n","> testing dataset count: 118.\n","cuda memory allocated: 17998336\n","> n_trainable_params: 2525703, n_nontrainable_params: 1973100\n","> training arguments:\n",">>> model_name: atae_lstm\n",">>> dataset: SemEval2016_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f3bff427c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.atae_lstm.ATAE_LSTM'>\n",">>> dataset_file: {'train': './datasets/rest16/output_know_insert/train.tsv', 'test': './datasets/rest16/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:36:31\n",">>> val_acc: 0.6949, val_precision: 0.6949 val_recall: 0.6949, val_f1: 0.6949\n",">> saved: state_dict/atae_lstm_SemEval2016_know_val_f1_0.6949\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:36:31\n","loss: 0.7657, acc: 0.7146\n","E2E-ABSA >>> 2022-09-02 04:36:32\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">> saved: state_dict/atae_lstm_SemEval2016_know_val_f1_0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:36:33\n","loss: 0.7468, acc: 0.7052\n","E2E-ABSA >>> 2022-09-02 04:36:33\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:36:34\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:36:34\n","loss: 0.6779, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:36:35\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:36:35\n","loss: 0.7105, acc: 0.7212\n","E2E-ABSA >>> 2022-09-02 04:36:36\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:36:37\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:36:37\n","loss: 0.6329, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:36:37\n",">>> val_acc: 0.7373, val_precision: 0.7373 val_recall: 0.7373, val_f1: 0.7373\n",">> saved: state_dict/atae_lstm_SemEval2016_know_val_f1_0.7373\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:36:38\n","loss: 0.6520, acc: 0.7359\n","E2E-ABSA >>> 2022-09-02 04:36:38\n",">>> val_acc: 0.7373, val_precision: 0.7373 val_recall: 0.7373, val_f1: 0.7373\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:36:39\n","loss: 0.6719, acc: 0.7284\n","E2E-ABSA >>> 2022-09-02 04:36:39\n",">>> val_acc: 0.7373, val_precision: 0.7373 val_recall: 0.7373, val_f1: 0.7373\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:36:40\n",">>> val_acc: 0.7373, val_precision: 0.7373 val_recall: 0.7373, val_f1: 0.7373\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:36:41\n","loss: 0.6716, acc: 0.7229\n","E2E-ABSA >>> 2022-09-02 04:36:41\n",">>> val_acc: 0.7373, val_precision: 0.7373 val_recall: 0.7373, val_f1: 0.7373\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:36:42\n","loss: 0.6490, acc: 0.7365\n","E2E-ABSA >>> 2022-09-02 04:36:42\n",">>> val_acc: 0.7373, val_precision: 0.7373 val_recall: 0.7373, val_f1: 0.7373\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:36:43\n",">>> val_acc: 0.7373, val_precision: 0.7373 val_recall: 0.7373, val_f1: 0.7373\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:36:43\n","loss: 0.6585, acc: 0.7250\n","E2E-ABSA >>> 2022-09-02 04:36:44\n",">>> val_acc: 0.7373, val_precision: 0.7373 val_recall: 0.7373, val_f1: 0.7373\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:36:45\n","loss: 0.6436, acc: 0.7350\n","E2E-ABSA >>> 2022-09-02 04:36:45\n",">>> val_acc: 0.7373, val_precision: 0.7373 val_recall: 0.7373, val_f1: 0.7373\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:36:46\n",">>> val_acc: 0.7373, val_precision: 0.7373 val_recall: 0.7373, val_f1: 0.7373\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:36:46\n","loss: 0.6333, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 04:36:47\n",">>> val_acc: 0.7373, val_precision: 0.7373 val_recall: 0.7373, val_f1: 0.7373\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:36:48\n","loss: 0.6005, acc: 0.7562\n","E2E-ABSA >>> 2022-09-02 04:36:48\n",">>> val_acc: 0.7458, val_precision: 0.7458 val_recall: 0.7458, val_f1: 0.7458\n",">> saved: state_dict/atae_lstm_SemEval2016_know_val_f1_0.7458\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:36:49\n","loss: 0.6245, acc: 0.7392\n","E2E-ABSA >>> 2022-09-02 04:36:49\n",">>> val_acc: 0.7542, val_precision: 0.7542 val_recall: 0.7542, val_f1: 0.7542\n",">> saved: state_dict/atae_lstm_SemEval2016_know_val_f1_0.7542\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:36:50\n",">>> val_acc: 0.7458, val_precision: 0.7458 val_recall: 0.7458, val_f1: 0.7458\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:36:50\n","loss: 0.5676, acc: 0.7688\n","E2E-ABSA >>> 2022-09-02 04:36:51\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">> saved: state_dict/atae_lstm_SemEval2016_know_val_f1_0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:36:52\n","loss: 0.5994, acc: 0.7531\n","E2E-ABSA >>> 2022-09-02 04:36:52\n",">>> val_acc: 0.7542, val_precision: 0.7542 val_recall: 0.7542, val_f1: 0.7542\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:36:53\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">> saved: state_dict/atae_lstm_SemEval2016_know_val_f1_0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:36:53\n","loss: 0.5996, acc: 0.7750\n","E2E-ABSA >>> 2022-09-02 04:36:54\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:36:54\n","loss: 0.6014, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 04:36:55\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:36:56\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:36:56\n","loss: 0.5695, acc: 0.7562\n","E2E-ABSA >>> 2022-09-02 04:36:57\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:36:57\n","loss: 0.5493, acc: 0.7688\n","E2E-ABSA >>> 2022-09-02 04:36:58\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:36:59\n","loss: 0.5311, acc: 0.7752\n","E2E-ABSA >>> 2022-09-02 04:36:59\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:37:00\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 04:37:00\n","loss: 0.4999, acc: 0.7875\n","E2E-ABSA >>> 2022-09-02 04:37:01\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 04:37:01\n","loss: 0.4966, acc: 0.7865\n","E2E-ABSA >>> 2022-09-02 04:37:01\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 04:37:02\n",">>> val_acc: 0.8136, val_precision: 0.8136 val_recall: 0.8136, val_f1: 0.8136\n",">> saved: state_dict/atae_lstm_SemEval2016_know_val_f1_0.8136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 04:37:03\n","loss: 0.4720, acc: 0.8156\n","E2E-ABSA >>> 2022-09-02 04:37:03\n",">>> val_acc: 0.7966, val_precision: 0.7966 val_recall: 0.7966, val_f1: 0.7966\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 04:37:04\n","loss: 0.4897, acc: 0.8113\n","E2E-ABSA >>> 2022-09-02 04:37:04\n",">>> val_acc: 0.7966, val_precision: 0.7966 val_recall: 0.7966, val_f1: 0.7966\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 04:37:05\n",">>> val_acc: 0.7881, val_precision: 0.7881 val_recall: 0.7881, val_f1: 0.7881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 04:37:05\n","loss: 0.4162, acc: 0.8187\n","E2E-ABSA >>> 2022-09-02 04:37:06\n",">>> val_acc: 0.8136, val_precision: 0.8136 val_recall: 0.8136, val_f1: 0.8136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 04:37:07\n","loss: 0.4646, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 04:37:07\n",">>> val_acc: 0.8136, val_precision: 0.8136 val_recall: 0.8136, val_f1: 0.8136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 04:37:08\n","loss: 0.4558, acc: 0.8121\n","E2E-ABSA >>> 2022-09-02 04:37:08\n",">>> val_acc: 0.7542, val_precision: 0.7542 val_recall: 0.7542, val_f1: 0.7542\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 04:37:09\n",">>> val_acc: 0.8051, val_precision: 0.8051 val_recall: 0.8051, val_f1: 0.8051\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 04:37:10\n","loss: 0.4632, acc: 0.8063\n","E2E-ABSA >>> 2022-09-02 04:37:10\n",">>> val_acc: 0.7881, val_precision: 0.7881 val_recall: 0.7881, val_f1: 0.7881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 04:37:11\n","loss: 0.4605, acc: 0.8073\n","E2E-ABSA >>> 2022-09-02 04:37:11\n",">>> val_acc: 0.7881, val_precision: 0.7881 val_recall: 0.7881, val_f1: 0.7881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 04:37:12\n",">>> val_acc: 0.7797, val_precision: 0.7797 val_recall: 0.7797, val_f1: 0.7797\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 04:37:12\n","loss: 0.4816, acc: 0.8156\n","E2E-ABSA >>> 2022-09-02 04:37:13\n",">>> val_acc: 0.8051, val_precision: 0.8051 val_recall: 0.8051, val_f1: 0.8051\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 04:37:14\n","loss: 0.4562, acc: 0.8200\n","E2E-ABSA >>> 2022-09-02 04:37:14\n",">>> val_acc: 0.7881, val_precision: 0.7881 val_recall: 0.7881, val_f1: 0.7881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 04:37:15\n",">>> val_acc: 0.8051, val_precision: 0.8051 val_recall: 0.8051, val_f1: 0.8051\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 04:37:15\n","loss: 0.4695, acc: 0.7937\n","E2E-ABSA >>> 2022-09-02 04:37:16\n",">>> val_acc: 0.7542, val_precision: 0.7542 val_recall: 0.7542, val_f1: 0.7542\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 04:37:16\n","loss: 0.4215, acc: 0.8375\n","E2E-ABSA >>> 2022-09-02 04:37:17\n",">>> val_acc: 0.7966, val_precision: 0.7966 val_recall: 0.7966, val_f1: 0.7966\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 04:37:18\n","loss: 0.4133, acc: 0.8327\n","E2E-ABSA >>> 2022-09-02 04:37:18\n",">>> val_acc: 0.7881, val_precision: 0.7881 val_recall: 0.7881, val_f1: 0.7881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 04:37:19\n",">>> val_acc: 0.7542, val_precision: 0.7542 val_recall: 0.7542, val_f1: 0.7542\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 04:37:19\n","loss: 0.4180, acc: 0.8354\n","E2E-ABSA >>> 2022-09-02 04:37:20\n",">>> val_acc: 0.7797, val_precision: 0.7797 val_recall: 0.7797, val_f1: 0.7797\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 04:37:20\n","loss: 0.3987, acc: 0.8313\n","E2E-ABSA >>> 2022-09-02 04:37:21\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 04:37:22\n",">>> val_acc: 0.7881, val_precision: 0.7881 val_recall: 0.7881, val_f1: 0.7881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 04:37:22\n","loss: 0.3700, acc: 0.8625\n","E2E-ABSA >>> 2022-09-02 04:37:22\n",">>> val_acc: 0.8051, val_precision: 0.8051 val_recall: 0.8051, val_f1: 0.8051\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 04:37:23\n","loss: 0.3841, acc: 0.8538\n","E2E-ABSA >>> 2022-09-02 04:37:23\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 04:37:24\n",">>> val_acc: 0.7966, val_precision: 0.7966 val_recall: 0.7966, val_f1: 0.7966\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 04:37:25\n","loss: 0.3658, acc: 0.8625\n","E2E-ABSA >>> 2022-09-02 04:37:26\n",">>> val_acc: 0.7797, val_precision: 0.7797 val_recall: 0.7797, val_f1: 0.7797\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 04:37:26\n","loss: 0.3491, acc: 0.8562\n","E2E-ABSA >>> 2022-09-02 04:37:27\n",">>> val_acc: 0.8136, val_precision: 0.8136 val_recall: 0.8136, val_f1: 0.8136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 04:37:28\n","loss: 0.3891, acc: 0.8372\n","E2E-ABSA >>> 2022-09-02 04:37:28\n",">>> val_acc: 0.7966, val_precision: 0.7966 val_recall: 0.7966, val_f1: 0.7966\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 04:37:29\n",">>> val_acc: 0.8136, val_precision: 0.8136 val_recall: 0.8136, val_f1: 0.8136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 04:37:29\n","loss: 0.3558, acc: 0.8542\n","E2E-ABSA >>> 2022-09-02 04:37:30\n",">>> val_acc: 0.8136, val_precision: 0.8136 val_recall: 0.8136, val_f1: 0.8136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 04:37:30\n","loss: 0.3699, acc: 0.8490\n","E2E-ABSA >>> 2022-09-02 04:37:31\n",">>> val_acc: 0.7881, val_precision: 0.7881 val_recall: 0.7881, val_f1: 0.7881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 04:37:32\n",">>> val_acc: 0.7966, val_precision: 0.7966 val_recall: 0.7966, val_f1: 0.7966\n","E2E-ABSA >>> 2022-09-02 04:37:32\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.8136, val_precision: 0.8136 val_recall: 0.8136, val_f1: 0.8136\n","you can download the best model from state_dict/atae_lstm_SemEval2016_know_val_f1_0.8136\n",">>> test_acc: 0.8136, test_precision: 0.8136, test_recall: 0.8136, test_f1: 0.8136\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2016** dataset on model(**IAN**)"],"metadata":{"id":"WH09g2AEV9oq"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name ian --dataset SemEval2016_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XWl0zrVXV9t1","outputId":"1f75558c-4134-485f-9d75-9588b33aef49","executionInfo":{"status":"ok","timestamp":1662093527478,"user_tz":-480,"elapsed":74050,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1112.\n","> testing dataset count: 118.\n","cuda memory allocated: 16572928\n","> n_trainable_params: 2168403, n_nontrainable_params: 1973100\n","> training arguments:\n",">>> model_name: ian\n",">>> dataset: SemEval2016_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f30b96afc20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.ian.IAN'>\n",">>> dataset_file: {'train': './datasets/rest16/output_know_insert/train.tsv', 'test': './datasets/rest16/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:11\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">> saved: state_dict/ian_SemEval2016_know_val_f1_0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:12\n","loss: 0.7823, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:38:13\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:13\n","loss: 0.7333, acc: 0.7167\n","E2E-ABSA >>> 2022-09-02 04:38:14\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:15\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:15\n","loss: 0.6991, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:38:16\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:17\n","loss: 0.7070, acc: 0.7175\n","E2E-ABSA >>> 2022-09-02 04:38:17\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:18\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:18\n","loss: 0.6782, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:38:19\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:20\n","loss: 0.6681, acc: 0.7266\n","E2E-ABSA >>> 2022-09-02 04:38:21\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:22\n","loss: 0.7091, acc: 0.7176\n","E2E-ABSA >>> 2022-09-02 04:38:22\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:23\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:23\n","loss: 0.7199, acc: 0.7042\n","E2E-ABSA >>> 2022-09-02 04:38:24\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:25\n","loss: 0.7094, acc: 0.7177\n","E2E-ABSA >>> 2022-09-02 04:38:25\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:26\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:27\n","loss: 0.6834, acc: 0.7281\n","E2E-ABSA >>> 2022-09-02 04:38:27\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:28\n","loss: 0.7026, acc: 0.7113\n","E2E-ABSA >>> 2022-09-02 04:38:28\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:30\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:30\n","loss: 0.6501, acc: 0.7875\n","E2E-ABSA >>> 2022-09-02 04:38:31\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:31\n","loss: 0.6925, acc: 0.7203\n","E2E-ABSA >>> 2022-09-02 04:38:32\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:33\n","loss: 0.6954, acc: 0.7176\n","E2E-ABSA >>> 2022-09-02 04:38:33\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:34\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:35\n","loss: 0.7147, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 04:38:35\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:36\n","loss: 0.7063, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 04:38:36\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:37\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:38\n","loss: 0.6668, acc: 0.7312\n","E2E-ABSA >>> 2022-09-02 04:38:39\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:39\n","loss: 0.6901, acc: 0.7150\n","E2E-ABSA >>> 2022-09-02 04:38:40\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:41\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:41\n","loss: 0.6381, acc: 0.7625\n","E2E-ABSA >>> 2022-09-02 04:38:42\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:43\n","loss: 0.6969, acc: 0.7156\n","E2E-ABSA >>> 2022-09-02 04:38:43\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:44\n","loss: 0.6834, acc: 0.7176\n","E2E-ABSA >>> 2022-09-02 04:38:44\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 04:38:45\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n","E2E-ABSA >>> 2022-09-02 04:38:45\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n","you can download the best model from state_dict/ian_SemEval2016_know_val_f1_0.7288\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n",">>> test_acc: 0.7288, test_precision: 0.7288, test_recall: 0.7288, test_f1: 0.7288\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2016** dataset on model(**MEMNET**)"],"metadata":{"id":"kkiz9HNjV98D"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name memnet --dataset SemEval2016_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vNy_J5q3V-Cs","outputId":"1e741a44-eb8a-4bcd-f683-d30e5dee2cb2","executionInfo":{"status":"ok","timestamp":1662093587383,"user_tz":-480,"elapsed":59917,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1112.\n","> testing dataset count: 118.\n","cuda memory allocated: 9347584\n","> n_trainable_params: 362703, n_nontrainable_params: 1973100\n","> training arguments:\n",">>> model_name: memnet\n",">>> dataset: SemEval2016_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f676702ac20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.memnet.MemNet'>\n",">>> dataset_file: {'train': './datasets/rest16/output_know_insert/train.tsv', 'test': './datasets/rest16/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['context_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:25\n",">>> val_acc: 0.7203, val_precision: 0.7203 val_recall: 0.7203, val_f1: 0.7203\n",">> saved: state_dict/memnet_SemEval2016_know_val_f1_0.7203\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:25\n","loss: 0.7996, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:39:26\n",">>> val_acc: 0.7458, val_precision: 0.7458 val_recall: 0.7458, val_f1: 0.7458\n",">> saved: state_dict/memnet_SemEval2016_know_val_f1_0.7458\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:26\n","loss: 0.7314, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 04:39:26\n",">>> val_acc: 0.7458, val_precision: 0.7458 val_recall: 0.7458, val_f1: 0.7458\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:27\n",">>> val_acc: 0.7542, val_precision: 0.7542 val_recall: 0.7542, val_f1: 0.7542\n",">> saved: state_dict/memnet_SemEval2016_know_val_f1_0.7542\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:27\n","loss: 0.7278, acc: 0.6969\n","E2E-ABSA >>> 2022-09-02 04:39:27\n",">>> val_acc: 0.7458, val_precision: 0.7458 val_recall: 0.7458, val_f1: 0.7458\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:28\n","loss: 0.6907, acc: 0.7412\n","E2E-ABSA >>> 2022-09-02 04:39:28\n",">>> val_acc: 0.7542, val_precision: 0.7542 val_recall: 0.7542, val_f1: 0.7542\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:29\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">> saved: state_dict/memnet_SemEval2016_know_val_f1_0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:29\n","loss: 0.7219, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 04:39:29\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:29\n","loss: 0.6450, acc: 0.7453\n","E2E-ABSA >>> 2022-09-02 04:39:30\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:30\n","loss: 0.6605, acc: 0.7419\n","E2E-ABSA >>> 2022-09-02 04:39:30\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:31\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:31\n","loss: 0.6462, acc: 0.7458\n","E2E-ABSA >>> 2022-09-02 04:39:31\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:32\n","loss: 0.6554, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 04:39:32\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:33\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:33\n","loss: 0.6069, acc: 0.7625\n","E2E-ABSA >>> 2022-09-02 04:39:33\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:33\n","loss: 0.6264, acc: 0.7412\n","E2E-ABSA >>> 2022-09-02 04:39:34\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:34\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:34\n","loss: 0.6522, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:39:35\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:35\n","loss: 0.6153, acc: 0.7406\n","E2E-ABSA >>> 2022-09-02 04:39:35\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:36\n","loss: 0.6175, acc: 0.7464\n","E2E-ABSA >>> 2022-09-02 04:39:36\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:36\n",">>> val_acc: 0.7542, val_precision: 0.7542 val_recall: 0.7542, val_f1: 0.7542\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:37\n","loss: 0.6251, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 04:39:37\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:37\n","loss: 0.6140, acc: 0.7438\n","E2E-ABSA >>> 2022-09-02 04:39:38\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:38\n",">>> val_acc: 0.7542, val_precision: 0.7542 val_recall: 0.7542, val_f1: 0.7542\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:38\n","loss: 0.5773, acc: 0.7625\n","E2E-ABSA >>> 2022-09-02 04:39:39\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:39\n","loss: 0.6110, acc: 0.7400\n","E2E-ABSA >>> 2022-09-02 04:39:39\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:40\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:40\n","loss: 0.5636, acc: 0.7750\n","E2E-ABSA >>> 2022-09-02 04:39:40\n",">>> val_acc: 0.7542, val_precision: 0.7542 val_recall: 0.7542, val_f1: 0.7542\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:41\n","loss: 0.5958, acc: 0.7547\n","E2E-ABSA >>> 2022-09-02 04:39:41\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:42\n","loss: 0.5807, acc: 0.7536\n","E2E-ABSA >>> 2022-09-02 04:39:42\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:42\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:42\n","loss: 0.5974, acc: 0.7333\n","E2E-ABSA >>> 2022-09-02 04:39:43\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:43\n","loss: 0.5743, acc: 0.7573\n","E2E-ABSA >>> 2022-09-02 04:39:43\n",">>> val_acc: 0.7542, val_precision: 0.7542 val_recall: 0.7542, val_f1: 0.7542\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:44\n",">>> val_acc: 0.7542, val_precision: 0.7542 val_recall: 0.7542, val_f1: 0.7542\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:44\n","loss: 0.5557, acc: 0.7625\n","E2E-ABSA >>> 2022-09-02 04:39:44\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:45\n","loss: 0.5416, acc: 0.7775\n","E2E-ABSA >>> 2022-09-02 04:39:45\n",">>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 04:39:45\n",">>> val_acc: 0.7627, val_precision: 0.7627 val_recall: 0.7627, val_f1: 0.7627\n","E2E-ABSA >>> 2022-09-02 04:39:45\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7712, val_precision: 0.7712 val_recall: 0.7712, val_f1: 0.7712\n","you can download the best model from state_dict/memnet_SemEval2016_know_val_f1_0.7712\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",">>> test_acc: 0.7712, test_precision: 0.7712, test_recall: 0.7712, test_f1: 0.7712\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **SemEval2016** dataset on model(**CABASC**)"],"metadata":{"id":"TdycHmnoV-Pi"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name cabasc --dataset SemEval2016_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UpkEJu1_V-Uk","outputId":"d77e9509-b768-46c1-c636-c547e3fcd17e","executionInfo":{"status":"ok","timestamp":1662093764514,"user_tz":-480,"elapsed":177144,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 1006.\n","> testing dataset count: 103.\n","cuda memory allocated: 13681152\n","> n_trainable_params: 1446005, n_nontrainable_params: 1973100\n","> training arguments:\n",">>> model_name: cabasc\n",">>> dataset: SemEval2016_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f080a3c0c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.cabasc.Cabasc'>\n",">>> dataset_file: {'train': './datasets/rest16/output_know_insert/train.tsv', 'test': './datasets/rest16/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices', 'left_with_aspect_indices', 'right_with_aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:40:28\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">> saved: state_dict/cabasc_SemEval2016_know_val_f1_0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:40:31\n","loss: 0.7370, acc: 0.7297\n","E2E-ABSA >>> 2022-09-02 04:40:33\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:40:37\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:40:38\n","loss: 0.6627, acc: 0.7670\n","E2E-ABSA >>> 2022-09-02 04:40:42\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:40:45\n","loss: 0.6945, acc: 0.7122\n","E2E-ABSA >>> 2022-09-02 04:40:46\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:40:51\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:40:52\n","loss: 0.6530, acc: 0.7216\n","E2E-ABSA >>> 2022-09-02 04:40:55\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:40:59\n","loss: 0.6935, acc: 0.7108\n","E2E-ABSA >>> 2022-09-02 04:41:00\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:41:04\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:41:06\n","loss: 0.6918, acc: 0.7273\n","E2E-ABSA >>> 2022-09-02 04:41:08\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:41:13\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:41:13\n","loss: 0.6494, acc: 0.7679\n","E2E-ABSA >>> 2022-09-02 04:41:17\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:41:20\n","loss: 0.6813, acc: 0.7273\n","E2E-ABSA >>> 2022-09-02 04:41:22\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:41:26\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:41:28\n","loss: 0.6827, acc: 0.7014\n","E2E-ABSA >>> 2022-09-02 04:41:31\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:41:34\n","loss: 0.6772, acc: 0.7136\n","E2E-ABSA >>> 2022-09-02 04:41:35\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:41:40\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:41:42\n","loss: 0.6377, acc: 0.7220\n","E2E-ABSA >>> 2022-09-02 04:41:44\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:41:49\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:41:49\n","loss: 0.7342, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 04:41:53\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:41:56\n","loss: 0.6862, acc: 0.7078\n","E2E-ABSA >>> 2022-09-02 04:41:58\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:42:02\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:42:03\n","loss: 0.6843, acc: 0.7455\n","E2E-ABSA >>> 2022-09-02 04:42:06\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:42:10\n","loss: 0.6576, acc: 0.7230\n","E2E-ABSA >>> 2022-09-02 04:42:11\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:42:15\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:42:17\n","loss: 0.6911, acc: 0.6900\n","E2E-ABSA >>> 2022-09-02 04:42:20\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:42:24\n","loss: 0.6567, acc: 0.7167\n","E2E-ABSA >>> 2022-09-02 04:42:24\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:42:29\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:42:31\n","loss: 0.6609, acc: 0.7205\n","E2E-ABSA >>> 2022-09-02 04:42:33\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:42:38\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:42:38\n","loss: 0.6506, acc: 0.7312\n","E2E-ABSA >>> 2022-09-02 04:42:42\n",">>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n","E2E-ABSA >>> 2022-09-02 04:42:42\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7379, val_precision: 0.7379 val_recall: 0.7379, val_f1: 0.7379\n","you can download the best model from state_dict/cabasc_SemEval2016_know_val_f1_0.7379\n",">>> test_acc: 0.7379, test_precision: 0.7379, test_recall: 0.7379, test_f1: 0.7379\n"]}]},{"cell_type":"markdown","source":["lstm\n","tdlstm  \n","tclstm  \n","ataelstm  \n","ian \n","memnet  \n","cabasc "],"metadata":{"id":"88nfASKEV-ZD"}},{"cell_type":"markdown","source":["# 增加字典知识后：Training **acl14shortdata** dataset on model(**LSTM**)\n"],"metadata":{"id":"keat3WAkV-iU"}},{"cell_type":"code","source":["!pwd\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name lstm --dataset acl14shortdata_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"leo3yMMJV-nP","outputId":"a0ff9a31-722a-4434-e434-305f39a3978c","executionInfo":{"status":"ok","timestamp":1662094087160,"user_tz":-480,"elapsed":322657,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train_insert.py\n","data_utils.py\t    layers\t\t   README.md\t     train.py\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   state_dict\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 5623.\n","> testing dataset count: 625.\n","cuda memory allocated: 19671552\n","> n_trainable_params: 723303, n_nontrainable_params: 4136100\n","> training arguments:\n",">>> model_name: lstm\n",">>> dataset: acl14shortdata_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f2302b12c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.lstm.LSTM'>\n",">>> dataset_file: {'train': './datasets/acl14shortdata/output_know_insert/train.tsv', 'test': './datasets/acl14shortdata/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:43:23\n","loss: 1.0973, acc: 0.3638\n","E2E-ABSA >>> 2022-09-02 04:43:24\n","loss: 1.0699, acc: 0.4272\n","E2E-ABSA >>> 2022-09-02 04:43:25\n","loss: 1.0548, acc: 0.4575\n","E2E-ABSA >>> 2022-09-02 04:43:26\n",">>> val_acc: 0.4560, val_precision: 0.4560 val_recall: 0.4560, val_f1: 0.4560\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.456\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:43:26\n","loss: 1.0068, acc: 0.5234\n","E2E-ABSA >>> 2022-09-02 04:43:27\n","loss: 1.0183, acc: 0.5127\n","E2E-ABSA >>> 2022-09-02 04:43:28\n","loss: 1.0262, acc: 0.5003\n","E2E-ABSA >>> 2022-09-02 04:43:29\n","loss: 1.0249, acc: 0.5032\n","E2E-ABSA >>> 2022-09-02 04:43:29\n",">>> val_acc: 0.4640, val_precision: 0.4640 val_recall: 0.4640, val_f1: 0.4640\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.464\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:43:30\n","loss: 1.0307, acc: 0.4889\n","E2E-ABSA >>> 2022-09-02 04:43:30\n","loss: 1.0201, acc: 0.5000\n","E2E-ABSA >>> 2022-09-02 04:43:31\n","loss: 1.0168, acc: 0.5032\n","E2E-ABSA >>> 2022-09-02 04:43:32\n",">>> val_acc: 0.4672, val_precision: 0.4672 val_recall: 0.4672, val_f1: 0.4672\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.4672\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:43:32\n","loss: 1.0118, acc: 0.5071\n","E2E-ABSA >>> 2022-09-02 04:43:33\n","loss: 1.0108, acc: 0.5091\n","E2E-ABSA >>> 2022-09-02 04:43:34\n","loss: 1.0083, acc: 0.5090\n","E2E-ABSA >>> 2022-09-02 04:43:34\n","loss: 1.0040, acc: 0.5105\n","E2E-ABSA >>> 2022-09-02 04:43:34\n",">>> val_acc: 0.4736, val_precision: 0.4736 val_recall: 0.4736, val_f1: 0.4736\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.4736\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:43:35\n","loss: 0.9958, acc: 0.5163\n","E2E-ABSA >>> 2022-09-02 04:43:36\n","loss: 1.0028, acc: 0.5117\n","E2E-ABSA >>> 2022-09-02 04:43:37\n","loss: 0.9967, acc: 0.5176\n","E2E-ABSA >>> 2022-09-02 04:43:37\n",">>> val_acc: 0.4768, val_precision: 0.4768 val_recall: 0.4768, val_f1: 0.4768\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.4768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:43:38\n","loss: 1.0248, acc: 0.4703\n","E2E-ABSA >>> 2022-09-02 04:43:38\n","loss: 0.9922, acc: 0.5165\n","E2E-ABSA >>> 2022-09-02 04:43:39\n","loss: 0.9916, acc: 0.5169\n","E2E-ABSA >>> 2022-09-02 04:43:40\n","loss: 0.9864, acc: 0.5261\n","E2E-ABSA >>> 2022-09-02 04:43:40\n",">>> val_acc: 0.4848, val_precision: 0.4848 val_recall: 0.4848, val_f1: 0.4848\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.4848\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:43:41\n","loss: 0.9799, acc: 0.5220\n","E2E-ABSA >>> 2022-09-02 04:43:42\n","loss: 0.9830, acc: 0.5236\n","E2E-ABSA >>> 2022-09-02 04:43:42\n","loss: 0.9776, acc: 0.5271\n","E2E-ABSA >>> 2022-09-02 04:43:43\n",">>> val_acc: 0.5120, val_precision: 0.5120 val_recall: 0.5120, val_f1: 0.5120\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:43:43\n","loss: 0.9647, acc: 0.5503\n","E2E-ABSA >>> 2022-09-02 04:43:44\n","loss: 0.9687, acc: 0.5354\n","E2E-ABSA >>> 2022-09-02 04:43:45\n","loss: 0.9624, acc: 0.5403\n","E2E-ABSA >>> 2022-09-02 04:43:45\n","loss: 0.9607, acc: 0.5439\n","E2E-ABSA >>> 2022-09-02 04:43:46\n",">>> val_acc: 0.5248, val_precision: 0.5248 val_recall: 0.5248, val_f1: 0.5248\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.5248\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:43:46\n","loss: 0.9219, acc: 0.5818\n","E2E-ABSA >>> 2022-09-02 04:43:47\n","loss: 0.9302, acc: 0.5635\n","E2E-ABSA >>> 2022-09-02 04:43:48\n","loss: 0.9376, acc: 0.5561\n","E2E-ABSA >>> 2022-09-02 04:43:49\n",">>> val_acc: 0.5488, val_precision: 0.5488 val_recall: 0.5488, val_f1: 0.5488\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.5488\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:43:49\n","loss: 0.9005, acc: 0.5703\n","E2E-ABSA >>> 2022-09-02 04:43:50\n","loss: 0.8938, acc: 0.5833\n","E2E-ABSA >>> 2022-09-02 04:43:50\n","loss: 0.8994, acc: 0.5744\n","E2E-ABSA >>> 2022-09-02 04:43:51\n","loss: 0.9052, acc: 0.5706\n","E2E-ABSA >>> 2022-09-02 04:43:51\n",">>> val_acc: 0.5552, val_precision: 0.5552 val_recall: 0.5552, val_f1: 0.5552\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.5552\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:43:52\n","loss: 0.8746, acc: 0.6117\n","E2E-ABSA >>> 2022-09-02 04:43:53\n","loss: 0.8965, acc: 0.5809\n","E2E-ABSA >>> 2022-09-02 04:43:53\n","loss: 0.8911, acc: 0.5824\n","E2E-ABSA >>> 2022-09-02 04:43:54\n",">>> val_acc: 0.5568, val_precision: 0.5568 val_recall: 0.5568, val_f1: 0.5568\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.5568\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:43:54\n","loss: 0.8735, acc: 0.5692\n","E2E-ABSA >>> 2022-09-02 04:43:55\n","loss: 0.8652, acc: 0.5884\n","E2E-ABSA >>> 2022-09-02 04:43:56\n","loss: 0.8748, acc: 0.5836\n","E2E-ABSA >>> 2022-09-02 04:43:57\n","loss: 0.8717, acc: 0.5892\n","E2E-ABSA >>> 2022-09-02 04:43:57\n",">>> val_acc: 0.5744, val_precision: 0.5744 val_recall: 0.5744, val_f1: 0.5744\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.5744\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:43:58\n","loss: 0.8585, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 04:43:58\n","loss: 0.8489, acc: 0.6200\n","E2E-ABSA >>> 2022-09-02 04:43:59\n","loss: 0.8467, acc: 0.6116\n","E2E-ABSA >>> 2022-09-02 04:44:00\n",">>> val_acc: 0.5904, val_precision: 0.5904 val_recall: 0.5904, val_f1: 0.5904\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.5904\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:44:00\n","loss: 0.8579, acc: 0.6120\n","E2E-ABSA >>> 2022-09-02 04:44:01\n","loss: 0.8345, acc: 0.6190\n","E2E-ABSA >>> 2022-09-02 04:44:02\n","loss: 0.8359, acc: 0.6161\n","E2E-ABSA >>> 2022-09-02 04:44:02\n","loss: 0.8380, acc: 0.6155\n","E2E-ABSA >>> 2022-09-02 04:44:03\n",">>> val_acc: 0.5840, val_precision: 0.5840 val_recall: 0.5840, val_f1: 0.5840\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:44:03\n","loss: 0.8242, acc: 0.6398\n","E2E-ABSA >>> 2022-09-02 04:44:04\n","loss: 0.8253, acc: 0.6315\n","E2E-ABSA >>> 2022-09-02 04:44:05\n","loss: 0.8260, acc: 0.6268\n","E2E-ABSA >>> 2022-09-02 04:44:05\n",">>> val_acc: 0.5776, val_precision: 0.5776 val_recall: 0.5776, val_f1: 0.5776\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:44:06\n","loss: 0.8173, acc: 0.6656\n","E2E-ABSA >>> 2022-09-02 04:44:06\n","loss: 0.8102, acc: 0.6432\n","E2E-ABSA >>> 2022-09-02 04:44:07\n","loss: 0.8009, acc: 0.6494\n","E2E-ABSA >>> 2022-09-02 04:44:08\n","loss: 0.8082, acc: 0.6373\n","E2E-ABSA >>> 2022-09-02 04:44:08\n",">>> val_acc: 0.6048, val_precision: 0.6048 val_recall: 0.6048, val_f1: 0.6048\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:44:09\n","loss: 0.8100, acc: 0.6415\n","E2E-ABSA >>> 2022-09-02 04:44:09\n","loss: 0.7945, acc: 0.6376\n","E2E-ABSA >>> 2022-09-02 04:44:10\n","loss: 0.7914, acc: 0.6444\n","E2E-ABSA >>> 2022-09-02 04:44:11\n",">>> val_acc: 0.5984, val_precision: 0.5984 val_recall: 0.5984, val_f1: 0.5984\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:44:11\n","loss: 0.7887, acc: 0.6211\n","E2E-ABSA >>> 2022-09-02 04:44:12\n","loss: 0.7693, acc: 0.6498\n","E2E-ABSA >>> 2022-09-02 04:44:13\n","loss: 0.7763, acc: 0.6458\n","E2E-ABSA >>> 2022-09-02 04:44:13\n","loss: 0.7814, acc: 0.6491\n","E2E-ABSA >>> 2022-09-02 04:44:14\n",">>> val_acc: 0.5872, val_precision: 0.5872 val_recall: 0.5872, val_f1: 0.5872\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:44:14\n","loss: 0.8050, acc: 0.6318\n","E2E-ABSA >>> 2022-09-02 04:44:15\n","loss: 0.7747, acc: 0.6582\n","E2E-ABSA >>> 2022-09-02 04:44:16\n","loss: 0.7747, acc: 0.6560\n","E2E-ABSA >>> 2022-09-02 04:44:17\n",">>> val_acc: 0.6352, val_precision: 0.6352 val_recall: 0.6352, val_f1: 0.6352\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6352\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:44:17\n","loss: 0.7904, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 04:44:17\n","loss: 0.7711, acc: 0.6490\n","E2E-ABSA >>> 2022-09-02 04:44:18\n","loss: 0.7594, acc: 0.6619\n","E2E-ABSA >>> 2022-09-02 04:44:19\n","loss: 0.7623, acc: 0.6609\n","E2E-ABSA >>> 2022-09-02 04:44:19\n",">>> val_acc: 0.6384, val_precision: 0.6384 val_recall: 0.6384, val_f1: 0.6384\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6384\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:44:20\n","loss: 0.7615, acc: 0.6542\n","E2E-ABSA >>> 2022-09-02 04:44:21\n","loss: 0.7656, acc: 0.6555\n","E2E-ABSA >>> 2022-09-02 04:44:21\n","loss: 0.7597, acc: 0.6623\n","E2E-ABSA >>> 2022-09-02 04:44:22\n",">>> val_acc: 0.6448, val_precision: 0.6448 val_recall: 0.6448, val_f1: 0.6448\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6448\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:44:22\n","loss: 0.7354, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 04:44:23\n","loss: 0.7484, acc: 0.6846\n","E2E-ABSA >>> 2022-09-02 04:44:24\n","loss: 0.7509, acc: 0.6749\n","E2E-ABSA >>> 2022-09-02 04:44:25\n","loss: 0.7556, acc: 0.6680\n","E2E-ABSA >>> 2022-09-02 04:44:25\n",">>> val_acc: 0.6480, val_precision: 0.6480 val_recall: 0.6480, val_f1: 0.6480\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.648\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:44:25\n","loss: 0.7322, acc: 0.6964\n","E2E-ABSA >>> 2022-09-02 04:44:26\n","loss: 0.7454, acc: 0.6779\n","E2E-ABSA >>> 2022-09-02 04:44:27\n","loss: 0.7484, acc: 0.6748\n","E2E-ABSA >>> 2022-09-02 04:44:28\n",">>> val_acc: 0.6608, val_precision: 0.6608 val_recall: 0.6608, val_f1: 0.6608\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6608\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:44:28\n","loss: 0.6887, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 04:44:29\n","loss: 0.7574, acc: 0.6544\n","E2E-ABSA >>> 2022-09-02 04:44:29\n","loss: 0.7420, acc: 0.6740\n","E2E-ABSA >>> 2022-09-02 04:44:30\n","loss: 0.7411, acc: 0.6704\n","E2E-ABSA >>> 2022-09-02 04:44:31\n",">>> val_acc: 0.6512, val_precision: 0.6512 val_recall: 0.6512, val_f1: 0.6512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:44:31\n","loss: 0.7436, acc: 0.6671\n","E2E-ABSA >>> 2022-09-02 04:44:32\n","loss: 0.7515, acc: 0.6649\n","E2E-ABSA >>> 2022-09-02 04:44:33\n","loss: 0.7527, acc: 0.6679\n","E2E-ABSA >>> 2022-09-02 04:44:33\n","loss: 0.7444, acc: 0.6742\n","E2E-ABSA >>> 2022-09-02 04:44:33\n",">>> val_acc: 0.6496, val_precision: 0.6496 val_recall: 0.6496, val_f1: 0.6496\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:44:34\n","loss: 0.7425, acc: 0.6581\n","E2E-ABSA >>> 2022-09-02 04:44:35\n","loss: 0.7257, acc: 0.6722\n","E2E-ABSA >>> 2022-09-02 04:44:36\n","loss: 0.7324, acc: 0.6744\n","E2E-ABSA >>> 2022-09-02 04:44:36\n",">>> val_acc: 0.6512, val_precision: 0.6512 val_recall: 0.6512, val_f1: 0.6512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:44:37\n","loss: 0.7425, acc: 0.6758\n","E2E-ABSA >>> 2022-09-02 04:44:37\n","loss: 0.7376, acc: 0.6753\n","E2E-ABSA >>> 2022-09-02 04:44:38\n","loss: 0.7325, acc: 0.6799\n","E2E-ABSA >>> 2022-09-02 04:44:39\n","loss: 0.7364, acc: 0.6773\n","E2E-ABSA >>> 2022-09-02 04:44:39\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:44:40\n","loss: 0.7331, acc: 0.6810\n","E2E-ABSA >>> 2022-09-02 04:44:40\n","loss: 0.7371, acc: 0.6738\n","E2E-ABSA >>> 2022-09-02 04:44:41\n","loss: 0.7369, acc: 0.6742\n","E2E-ABSA >>> 2022-09-02 04:44:42\n",">>> val_acc: 0.6272, val_precision: 0.6272 val_recall: 0.6272, val_f1: 0.6272\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:44:42\n","loss: 0.7108, acc: 0.7088\n","E2E-ABSA >>> 2022-09-02 04:44:43\n","loss: 0.7279, acc: 0.6949\n","E2E-ABSA >>> 2022-09-02 04:44:44\n","loss: 0.7296, acc: 0.6890\n","E2E-ABSA >>> 2022-09-02 04:44:44\n","loss: 0.7294, acc: 0.6864\n","E2E-ABSA >>> 2022-09-02 04:44:45\n",">>> val_acc: 0.6576, val_precision: 0.6576 val_recall: 0.6576, val_f1: 0.6576\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:44:45\n","loss: 0.7287, acc: 0.6821\n","E2E-ABSA >>> 2022-09-02 04:44:46\n","loss: 0.7270, acc: 0.6722\n","E2E-ABSA >>> 2022-09-02 04:44:47\n","loss: 0.7261, acc: 0.6762\n","E2E-ABSA >>> 2022-09-02 04:44:47\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:44:48\n","loss: 0.7484, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:44:49\n","loss: 0.7504, acc: 0.6786\n","E2E-ABSA >>> 2022-09-02 04:44:49\n","loss: 0.7379, acc: 0.6781\n","E2E-ABSA >>> 2022-09-02 04:44:50\n","loss: 0.7252, acc: 0.6873\n","E2E-ABSA >>> 2022-09-02 04:44:50\n",">>> val_acc: 0.6736, val_precision: 0.6736 val_recall: 0.6736, val_f1: 0.6736\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6736\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 04:44:51\n","loss: 0.7280, acc: 0.6825\n","E2E-ABSA >>> 2022-09-02 04:44:52\n","loss: 0.7281, acc: 0.6902\n","E2E-ABSA >>> 2022-09-02 04:44:52\n","loss: 0.7275, acc: 0.6895\n","E2E-ABSA >>> 2022-09-02 04:44:53\n",">>> val_acc: 0.6768, val_precision: 0.6768 val_recall: 0.6768, val_f1: 0.6768\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 04:44:53\n","loss: 0.7578, acc: 0.6597\n","E2E-ABSA >>> 2022-09-02 04:44:54\n","loss: 0.7413, acc: 0.6806\n","E2E-ABSA >>> 2022-09-02 04:44:55\n","loss: 0.7301, acc: 0.6849\n","E2E-ABSA >>> 2022-09-02 04:44:56\n","loss: 0.7201, acc: 0.6908\n","E2E-ABSA >>> 2022-09-02 04:44:56\n",">>> val_acc: 0.6832, val_precision: 0.6832 val_recall: 0.6832, val_f1: 0.6832\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6832\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 04:44:57\n","loss: 0.7036, acc: 0.6897\n","E2E-ABSA >>> 2022-09-02 04:44:57\n","loss: 0.7254, acc: 0.6844\n","E2E-ABSA >>> 2022-09-02 04:44:58\n","loss: 0.7140, acc: 0.6932\n","E2E-ABSA >>> 2022-09-02 04:44:59\n",">>> val_acc: 0.6528, val_precision: 0.6528 val_recall: 0.6528, val_f1: 0.6528\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 04:44:59\n","loss: 0.7262, acc: 0.6914\n","E2E-ABSA >>> 2022-09-02 04:45:00\n","loss: 0.7180, acc: 0.6960\n","E2E-ABSA >>> 2022-09-02 04:45:01\n","loss: 0.7127, acc: 0.6967\n","E2E-ABSA >>> 2022-09-02 04:45:01\n","loss: 0.7137, acc: 0.6931\n","E2E-ABSA >>> 2022-09-02 04:45:02\n",">>> val_acc: 0.6512, val_precision: 0.6512 val_recall: 0.6512, val_f1: 0.6512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 04:45:02\n","loss: 0.7501, acc: 0.6781\n","E2E-ABSA >>> 2022-09-02 04:45:03\n","loss: 0.7271, acc: 0.6944\n","E2E-ABSA >>> 2022-09-02 04:45:04\n","loss: 0.7197, acc: 0.6929\n","E2E-ABSA >>> 2022-09-02 04:45:04\n",">>> val_acc: 0.6736, val_precision: 0.6736 val_recall: 0.6736, val_f1: 0.6736\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 04:45:05\n","loss: 0.6902, acc: 0.6853\n","E2E-ABSA >>> 2022-09-02 04:45:05\n","loss: 0.7134, acc: 0.6851\n","E2E-ABSA >>> 2022-09-02 04:45:06\n","loss: 0.7200, acc: 0.6872\n","E2E-ABSA >>> 2022-09-02 04:45:07\n","loss: 0.7132, acc: 0.6926\n","E2E-ABSA >>> 2022-09-02 04:45:07\n",">>> val_acc: 0.6640, val_precision: 0.6640 val_recall: 0.6640, val_f1: 0.6640\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 04:45:08\n","loss: 0.7104, acc: 0.6834\n","E2E-ABSA >>> 2022-09-02 04:45:09\n","loss: 0.7085, acc: 0.6925\n","E2E-ABSA >>> 2022-09-02 04:45:09\n","loss: 0.7045, acc: 0.6968\n","E2E-ABSA >>> 2022-09-02 04:45:10\n",">>> val_acc: 0.6672, val_precision: 0.6672 val_recall: 0.6672, val_f1: 0.6672\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 04:45:10\n","loss: 0.7340, acc: 0.7161\n","E2E-ABSA >>> 2022-09-02 04:45:11\n","loss: 0.7030, acc: 0.7011\n","E2E-ABSA >>> 2022-09-02 04:45:12\n","loss: 0.7130, acc: 0.6881\n","E2E-ABSA >>> 2022-09-02 04:45:12\n","loss: 0.7123, acc: 0.6858\n","E2E-ABSA >>> 2022-09-02 04:45:13\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 04:45:13\n","loss: 0.6992, acc: 0.6944\n","E2E-ABSA >>> 2022-09-02 04:45:14\n","loss: 0.7034, acc: 0.6966\n","E2E-ABSA >>> 2022-09-02 04:45:15\n","loss: 0.7035, acc: 0.6960\n","E2E-ABSA >>> 2022-09-02 04:45:16\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 04:45:16\n","loss: 0.6957, acc: 0.7000\n","E2E-ABSA >>> 2022-09-02 04:45:16\n","loss: 0.7049, acc: 0.6984\n","E2E-ABSA >>> 2022-09-02 04:45:17\n","loss: 0.6988, acc: 0.6949\n","E2E-ABSA >>> 2022-09-02 04:45:18\n","loss: 0.6982, acc: 0.6975\n","E2E-ABSA >>> 2022-09-02 04:45:18\n",">>> val_acc: 0.6704, val_precision: 0.6704 val_recall: 0.6704, val_f1: 0.6704\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 04:45:19\n","loss: 0.7305, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:45:20\n","loss: 0.6998, acc: 0.7057\n","E2E-ABSA >>> 2022-09-02 04:45:20\n","loss: 0.7050, acc: 0.6992\n","E2E-ABSA >>> 2022-09-02 04:45:21\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 04:45:21\n","loss: 0.6780, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 04:45:22\n","loss: 0.6837, acc: 0.7020\n","E2E-ABSA >>> 2022-09-02 04:45:23\n","loss: 0.6938, acc: 0.7011\n","E2E-ABSA >>> 2022-09-02 04:45:23\n","loss: 0.6971, acc: 0.6976\n","E2E-ABSA >>> 2022-09-02 04:45:24\n",">>> val_acc: 0.6608, val_precision: 0.6608 val_recall: 0.6608, val_f1: 0.6608\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 04:45:24\n","loss: 0.7122, acc: 0.6963\n","E2E-ABSA >>> 2022-09-02 04:45:25\n","loss: 0.7036, acc: 0.6951\n","E2E-ABSA >>> 2022-09-02 04:45:26\n","loss: 0.7023, acc: 0.6967\n","E2E-ABSA >>> 2022-09-02 04:45:27\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 04:45:27\n","loss: 0.6673, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 04:45:28\n","loss: 0.6802, acc: 0.7115\n","E2E-ABSA >>> 2022-09-02 04:45:29\n","loss: 0.7031, acc: 0.6969\n","E2E-ABSA >>> 2022-09-02 04:45:30\n","loss: 0.7024, acc: 0.6981\n","E2E-ABSA >>> 2022-09-02 04:45:30\n",">>> val_acc: 0.6640, val_precision: 0.6640 val_recall: 0.6640, val_f1: 0.6640\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 04:45:30\n","loss: 0.6881, acc: 0.7010\n","E2E-ABSA >>> 2022-09-02 04:45:31\n","loss: 0.6893, acc: 0.7012\n","E2E-ABSA >>> 2022-09-02 04:45:32\n","loss: 0.6991, acc: 0.6981\n","E2E-ABSA >>> 2022-09-02 04:45:33\n",">>> val_acc: 0.6704, val_precision: 0.6704 val_recall: 0.6704, val_f1: 0.6704\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 04:45:33\n","loss: 0.7728, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:45:34\n","loss: 0.7010, acc: 0.7089\n","E2E-ABSA >>> 2022-09-02 04:45:34\n","loss: 0.7027, acc: 0.7022\n","E2E-ABSA >>> 2022-09-02 04:45:35\n","loss: 0.6973, acc: 0.7027\n","E2E-ABSA >>> 2022-09-02 04:45:36\n",">>> val_acc: 0.6736, val_precision: 0.6736 val_recall: 0.6736, val_f1: 0.6736\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 04:45:36\n","loss: 0.6567, acc: 0.7176\n","E2E-ABSA >>> 2022-09-02 04:45:37\n","loss: 0.6775, acc: 0.7131\n","E2E-ABSA >>> 2022-09-02 04:45:38\n","loss: 0.6847, acc: 0.7100\n","E2E-ABSA >>> 2022-09-02 04:45:38\n",">>> val_acc: 0.6736, val_precision: 0.6736 val_recall: 0.6736, val_f1: 0.6736\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 04:45:38\n","loss: 0.6269, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 04:45:39\n","loss: 0.6965, acc: 0.7157\n","E2E-ABSA >>> 2022-09-02 04:45:40\n","loss: 0.6979, acc: 0.7047\n","E2E-ABSA >>> 2022-09-02 04:45:41\n","loss: 0.6854, acc: 0.7081\n","E2E-ABSA >>> 2022-09-02 04:45:41\n",">>> val_acc: 0.6640, val_precision: 0.6640 val_recall: 0.6640, val_f1: 0.6640\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 04:45:42\n","loss: 0.6778, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:45:42\n","loss: 0.6735, acc: 0.7118\n","E2E-ABSA >>> 2022-09-02 04:45:43\n","loss: 0.6829, acc: 0.7051\n","E2E-ABSA >>> 2022-09-02 04:45:44\n","loss: 0.6866, acc: 0.7028\n","E2E-ABSA >>> 2022-09-02 04:45:44\n",">>> val_acc: 0.6704, val_precision: 0.6704 val_recall: 0.6704, val_f1: 0.6704\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 04:45:45\n","loss: 0.6812, acc: 0.7113\n","E2E-ABSA >>> 2022-09-02 04:45:45\n","loss: 0.6911, acc: 0.7000\n","E2E-ABSA >>> 2022-09-02 04:45:46\n","loss: 0.6867, acc: 0.7027\n","E2E-ABSA >>> 2022-09-02 04:45:47\n",">>> val_acc: 0.6672, val_precision: 0.6672 val_recall: 0.6672, val_f1: 0.6672\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 04:45:47\n","loss: 0.6841, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 04:45:48\n","loss: 0.6795, acc: 0.7023\n","E2E-ABSA >>> 2022-09-02 04:45:49\n","loss: 0.6867, acc: 0.6991\n","E2E-ABSA >>> 2022-09-02 04:45:49\n","loss: 0.6844, acc: 0.7022\n","E2E-ABSA >>> 2022-09-02 04:45:50\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 04:45:50\n","loss: 0.6668, acc: 0.7103\n","E2E-ABSA >>> 2022-09-02 04:45:51\n","loss: 0.6814, acc: 0.7111\n","E2E-ABSA >>> 2022-09-02 04:45:52\n","loss: 0.6855, acc: 0.7078\n","E2E-ABSA >>> 2022-09-02 04:45:52\n",">>> val_acc: 0.6736, val_precision: 0.6736 val_recall: 0.6736, val_f1: 0.6736\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 04:45:53\n","loss: 0.7042, acc: 0.7045\n","E2E-ABSA >>> 2022-09-02 04:45:53\n","loss: 0.6720, acc: 0.7201\n","E2E-ABSA >>> 2022-09-02 04:45:54\n","loss: 0.6769, acc: 0.7162\n","E2E-ABSA >>> 2022-09-02 04:45:55\n","loss: 0.6825, acc: 0.7115\n","E2E-ABSA >>> 2022-09-02 04:45:55\n",">>> val_acc: 0.6512, val_precision: 0.6512 val_recall: 0.6512, val_f1: 0.6512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 04:45:56\n","loss: 0.6715, acc: 0.7255\n","E2E-ABSA >>> 2022-09-02 04:45:57\n","loss: 0.6729, acc: 0.7178\n","E2E-ABSA >>> 2022-09-02 04:45:57\n","loss: 0.6813, acc: 0.7151\n","E2E-ABSA >>> 2022-09-02 04:45:58\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 04:45:58\n","loss: 0.6492, acc: 0.7281\n","E2E-ABSA >>> 2022-09-02 04:45:59\n","loss: 0.6780, acc: 0.7094\n","E2E-ABSA >>> 2022-09-02 04:46:00\n","loss: 0.6802, acc: 0.7055\n","E2E-ABSA >>> 2022-09-02 04:46:00\n","loss: 0.6826, acc: 0.7037\n","E2E-ABSA >>> 2022-09-02 04:46:01\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 04:46:01\n","loss: 0.6829, acc: 0.6939\n","E2E-ABSA >>> 2022-09-02 04:46:02\n","loss: 0.6863, acc: 0.6991\n","E2E-ABSA >>> 2022-09-02 04:46:03\n","loss: 0.6843, acc: 0.7020\n","E2E-ABSA >>> 2022-09-02 04:46:04\n",">>> val_acc: 0.6560, val_precision: 0.6560 val_recall: 0.6560, val_f1: 0.6560\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 04:46:04\n","loss: 0.6777, acc: 0.7066\n","E2E-ABSA >>> 2022-09-02 04:46:05\n","loss: 0.6998, acc: 0.6898\n","E2E-ABSA >>> 2022-09-02 04:46:05\n","loss: 0.6955, acc: 0.6962\n","E2E-ABSA >>> 2022-09-02 04:46:06\n","loss: 0.6810, acc: 0.7089\n","E2E-ABSA >>> 2022-09-02 04:46:06\n",">>> val_acc: 0.6640, val_precision: 0.6640 val_recall: 0.6640, val_f1: 0.6640\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 04:46:07\n","loss: 0.6672, acc: 0.7269\n","E2E-ABSA >>> 2022-09-02 04:46:08\n","loss: 0.6680, acc: 0.7174\n","E2E-ABSA >>> 2022-09-02 04:46:08\n","loss: 0.6762, acc: 0.7159\n","E2E-ABSA >>> 2022-09-02 04:46:09\n",">>> val_acc: 0.6608, val_precision: 0.6608 val_recall: 0.6608, val_f1: 0.6608\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 04:46:09\n","loss: 0.7217, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 04:46:10\n","loss: 0.6702, acc: 0.7126\n","E2E-ABSA >>> 2022-09-02 04:46:11\n","loss: 0.6732, acc: 0.7058\n","E2E-ABSA >>> 2022-09-02 04:46:12\n","loss: 0.6792, acc: 0.7073\n","E2E-ABSA >>> 2022-09-02 04:46:12\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 04:46:13\n","loss: 0.6676, acc: 0.7117\n","E2E-ABSA >>> 2022-09-02 04:46:13\n","loss: 0.6697, acc: 0.7142\n","E2E-ABSA >>> 2022-09-02 04:46:14\n","loss: 0.6686, acc: 0.7136\n","E2E-ABSA >>> 2022-09-02 04:46:15\n",">>> val_acc: 0.6800, val_precision: 0.6800 val_recall: 0.6800, val_f1: 0.6800\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 04:46:15\n","loss: 0.6127, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 04:46:16\n","loss: 0.6673, acc: 0.7236\n","E2E-ABSA >>> 2022-09-02 04:46:16\n","loss: 0.6661, acc: 0.7179\n","E2E-ABSA >>> 2022-09-02 04:46:17\n","loss: 0.6721, acc: 0.7123\n","E2E-ABSA >>> 2022-09-02 04:46:17\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 04:46:18\n","loss: 0.6697, acc: 0.7048\n","E2E-ABSA >>> 2022-09-02 04:46:19\n","loss: 0.6670, acc: 0.7127\n","E2E-ABSA >>> 2022-09-02 04:46:20\n","loss: 0.6668, acc: 0.7203\n","E2E-ABSA >>> 2022-09-02 04:46:20\n",">>> val_acc: 0.6848, val_precision: 0.6848 val_recall: 0.6848, val_f1: 0.6848\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6848\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 04:46:21\n","loss: 0.7402, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 04:46:21\n","loss: 0.6733, acc: 0.7112\n","E2E-ABSA >>> 2022-09-02 04:46:22\n","loss: 0.6770, acc: 0.7132\n","E2E-ABSA >>> 2022-09-02 04:46:23\n","loss: 0.6776, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 04:46:23\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 04:46:24\n","loss: 0.7043, acc: 0.6988\n","E2E-ABSA >>> 2022-09-02 04:46:24\n","loss: 0.6809, acc: 0.7115\n","E2E-ABSA >>> 2022-09-02 04:46:25\n","loss: 0.6729, acc: 0.7137\n","E2E-ABSA >>> 2022-09-02 04:46:26\n",">>> val_acc: 0.6816, val_precision: 0.6816 val_recall: 0.6816, val_f1: 0.6816\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 04:46:26\n","loss: 0.6887, acc: 0.7156\n","E2E-ABSA >>> 2022-09-02 04:46:27\n","loss: 0.6738, acc: 0.7161\n","E2E-ABSA >>> 2022-09-02 04:46:28\n","loss: 0.6740, acc: 0.7145\n","E2E-ABSA >>> 2022-09-02 04:46:28\n","loss: 0.6716, acc: 0.7141\n","E2E-ABSA >>> 2022-09-02 04:46:29\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 04:46:29\n","loss: 0.6238, acc: 0.7390\n","E2E-ABSA >>> 2022-09-02 04:46:30\n","loss: 0.6559, acc: 0.7169\n","E2E-ABSA >>> 2022-09-02 04:46:31\n","loss: 0.6578, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:46:32\n",">>> val_acc: 0.6864, val_precision: 0.6864 val_recall: 0.6864, val_f1: 0.6864\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 04:46:32\n","loss: 0.6813, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 04:46:32\n","loss: 0.6825, acc: 0.6994\n","E2E-ABSA >>> 2022-09-02 04:46:33\n","loss: 0.6634, acc: 0.7112\n","E2E-ABSA >>> 2022-09-02 04:46:34\n","loss: 0.6660, acc: 0.7150\n","E2E-ABSA >>> 2022-09-02 04:46:34\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","E2E-ABSA >>> 2022-09-02 04:46:35\n","loss: 0.6546, acc: 0.7266\n","E2E-ABSA >>> 2022-09-02 04:46:36\n","loss: 0.6758, acc: 0.7138\n","E2E-ABSA >>> 2022-09-02 04:46:36\n","loss: 0.6764, acc: 0.7119\n","E2E-ABSA >>> 2022-09-02 04:46:37\n",">>> val_acc: 0.6880, val_precision: 0.6880 val_recall: 0.6880, val_f1: 0.6880\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","E2E-ABSA >>> 2022-09-02 04:46:37\n","loss: 0.7159, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:46:38\n","loss: 0.6582, acc: 0.7154\n","E2E-ABSA >>> 2022-09-02 04:46:39\n","loss: 0.6702, acc: 0.7111\n","E2E-ABSA >>> 2022-09-02 04:46:40\n","loss: 0.6697, acc: 0.7165\n","E2E-ABSA >>> 2022-09-02 04:46:40\n",">>> val_acc: 0.6896, val_precision: 0.6896 val_recall: 0.6896, val_f1: 0.6896\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6896\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","E2E-ABSA >>> 2022-09-02 04:46:40\n","loss: 0.6498, acc: 0.7198\n","E2E-ABSA >>> 2022-09-02 04:46:41\n","loss: 0.6656, acc: 0.7117\n","E2E-ABSA >>> 2022-09-02 04:46:42\n","loss: 0.6565, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:46:43\n",">>> val_acc: 0.6832, val_precision: 0.6832 val_recall: 0.6832, val_f1: 0.6832\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","E2E-ABSA >>> 2022-09-02 04:46:43\n","loss: 0.6807, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 04:46:44\n","loss: 0.6872, acc: 0.7043\n","E2E-ABSA >>> 2022-09-02 04:46:44\n","loss: 0.6854, acc: 0.7076\n","E2E-ABSA >>> 2022-09-02 04:46:45\n","loss: 0.6778, acc: 0.7092\n","E2E-ABSA >>> 2022-09-02 04:46:46\n",">>> val_acc: 0.6800, val_precision: 0.6800 val_recall: 0.6800, val_f1: 0.6800\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","E2E-ABSA >>> 2022-09-02 04:46:46\n","loss: 0.6961, acc: 0.7076\n","E2E-ABSA >>> 2022-09-02 04:46:47\n","loss: 0.6701, acc: 0.7183\n","E2E-ABSA >>> 2022-09-02 04:46:48\n","loss: 0.6627, acc: 0.7168\n","E2E-ABSA >>> 2022-09-02 04:46:48\n",">>> val_acc: 0.6816, val_precision: 0.6816 val_recall: 0.6816, val_f1: 0.6816\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","E2E-ABSA >>> 2022-09-02 04:46:49\n","loss: 0.6492, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:46:49\n","loss: 0.6243, acc: 0.7356\n","E2E-ABSA >>> 2022-09-02 04:46:50\n","loss: 0.6618, acc: 0.7151\n","E2E-ABSA >>> 2022-09-02 04:46:51\n","loss: 0.6616, acc: 0.7190\n","E2E-ABSA >>> 2022-09-02 04:46:51\n",">>> val_acc: 0.6640, val_precision: 0.6640 val_recall: 0.6640, val_f1: 0.6640\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","E2E-ABSA >>> 2022-09-02 04:46:52\n","loss: 0.6937, acc: 0.7103\n","E2E-ABSA >>> 2022-09-02 04:46:52\n","loss: 0.6711, acc: 0.7171\n","E2E-ABSA >>> 2022-09-02 04:46:53\n","loss: 0.6683, acc: 0.7173\n","E2E-ABSA >>> 2022-09-02 04:46:54\n","loss: 0.6654, acc: 0.7172\n","E2E-ABSA >>> 2022-09-02 04:46:54\n",">>> val_acc: 0.6848, val_precision: 0.6848 val_recall: 0.6848, val_f1: 0.6848\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","E2E-ABSA >>> 2022-09-02 04:46:55\n","loss: 0.6520, acc: 0.7256\n","E2E-ABSA >>> 2022-09-02 04:46:56\n","loss: 0.6631, acc: 0.7197\n","E2E-ABSA >>> 2022-09-02 04:46:56\n","loss: 0.6611, acc: 0.7225\n","E2E-ABSA >>> 2022-09-02 04:46:57\n",">>> val_acc: 0.6864, val_precision: 0.6864 val_recall: 0.6864, val_f1: 0.6864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","E2E-ABSA >>> 2022-09-02 04:46:57\n","loss: 0.6995, acc: 0.7018\n","E2E-ABSA >>> 2022-09-02 04:46:58\n","loss: 0.6730, acc: 0.7213\n","E2E-ABSA >>> 2022-09-02 04:46:59\n","loss: 0.6757, acc: 0.7167\n","E2E-ABSA >>> 2022-09-02 04:46:59\n","loss: 0.6658, acc: 0.7200\n","E2E-ABSA >>> 2022-09-02 04:47:00\n",">>> val_acc: 0.6816, val_precision: 0.6816 val_recall: 0.6816, val_f1: 0.6816\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","E2E-ABSA >>> 2022-09-02 04:47:00\n","loss: 0.6712, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 04:47:01\n","loss: 0.6706, acc: 0.7162\n","E2E-ABSA >>> 2022-09-02 04:47:02\n","loss: 0.6726, acc: 0.7147\n","E2E-ABSA >>> 2022-09-02 04:47:02\n",">>> val_acc: 0.6944, val_precision: 0.6944 val_recall: 0.6944, val_f1: 0.6944\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6944\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","E2E-ABSA >>> 2022-09-02 04:47:03\n","loss: 0.6696, acc: 0.7273\n","E2E-ABSA >>> 2022-09-02 04:47:04\n","loss: 0.6563, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 04:47:04\n","loss: 0.6652, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:47:05\n","loss: 0.6647, acc: 0.7171\n","E2E-ABSA >>> 2022-09-02 04:47:05\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","E2E-ABSA >>> 2022-09-02 04:47:06\n","loss: 0.6557, acc: 0.7201\n","E2E-ABSA >>> 2022-09-02 04:47:07\n","loss: 0.6582, acc: 0.7132\n","E2E-ABSA >>> 2022-09-02 04:47:08\n","loss: 0.6580, acc: 0.7149\n","E2E-ABSA >>> 2022-09-02 04:47:08\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","E2E-ABSA >>> 2022-09-02 04:47:08\n","loss: 0.6989, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 04:47:09\n","loss: 0.6690, acc: 0.7232\n","E2E-ABSA >>> 2022-09-02 04:47:10\n","loss: 0.6709, acc: 0.7214\n","E2E-ABSA >>> 2022-09-02 04:47:11\n","loss: 0.6608, acc: 0.7211\n","E2E-ABSA >>> 2022-09-02 04:47:11\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","E2E-ABSA >>> 2022-09-02 04:47:12\n","loss: 0.6397, acc: 0.7429\n","E2E-ABSA >>> 2022-09-02 04:47:12\n","loss: 0.6477, acc: 0.7324\n","E2E-ABSA >>> 2022-09-02 04:47:13\n","loss: 0.6583, acc: 0.7229\n","E2E-ABSA >>> 2022-09-02 04:47:14\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","E2E-ABSA >>> 2022-09-02 04:47:14\n","loss: 0.6989, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 04:47:15\n","loss: 0.6896, acc: 0.7114\n","E2E-ABSA >>> 2022-09-02 04:47:16\n","loss: 0.6732, acc: 0.7161\n","E2E-ABSA >>> 2022-09-02 04:47:16\n","loss: 0.6591, acc: 0.7208\n","E2E-ABSA >>> 2022-09-02 04:47:17\n",">>> val_acc: 0.6880, val_precision: 0.6880 val_recall: 0.6880, val_f1: 0.6880\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","E2E-ABSA >>> 2022-09-02 04:47:17\n","loss: 0.6500, acc: 0.7254\n","E2E-ABSA >>> 2022-09-02 04:47:18\n","loss: 0.6598, acc: 0.7184\n","E2E-ABSA >>> 2022-09-02 04:47:19\n","loss: 0.6628, acc: 0.7176\n","E2E-ABSA >>> 2022-09-02 04:47:19\n",">>> val_acc: 0.6768, val_precision: 0.6768 val_recall: 0.6768, val_f1: 0.6768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","E2E-ABSA >>> 2022-09-02 04:47:20\n","loss: 0.6880, acc: 0.7148\n","E2E-ABSA >>> 2022-09-02 04:47:20\n","loss: 0.6460, acc: 0.7363\n","E2E-ABSA >>> 2022-09-02 04:47:21\n","loss: 0.6499, acc: 0.7271\n","E2E-ABSA >>> 2022-09-02 04:47:22\n","loss: 0.6558, acc: 0.7248\n","E2E-ABSA >>> 2022-09-02 04:47:22\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","E2E-ABSA >>> 2022-09-02 04:47:23\n","loss: 0.6575, acc: 0.7312\n","E2E-ABSA >>> 2022-09-02 04:47:24\n","loss: 0.6517, acc: 0.7257\n","E2E-ABSA >>> 2022-09-02 04:47:24\n","loss: 0.6608, acc: 0.7181\n","E2E-ABSA >>> 2022-09-02 04:47:25\n",">>> val_acc: 0.6800, val_precision: 0.6800 val_recall: 0.6800, val_f1: 0.6800\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","E2E-ABSA >>> 2022-09-02 04:47:25\n","loss: 0.6625, acc: 0.7121\n","E2E-ABSA >>> 2022-09-02 04:47:26\n","loss: 0.6644, acc: 0.7227\n","E2E-ABSA >>> 2022-09-02 04:47:27\n","loss: 0.6606, acc: 0.7229\n","E2E-ABSA >>> 2022-09-02 04:47:27\n","loss: 0.6572, acc: 0.7243\n","E2E-ABSA >>> 2022-09-02 04:47:28\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","E2E-ABSA >>> 2022-09-02 04:47:29\n","loss: 0.6757, acc: 0.7039\n","E2E-ABSA >>> 2022-09-02 04:47:30\n","loss: 0.6601, acc: 0.7166\n","E2E-ABSA >>> 2022-09-02 04:47:30\n","loss: 0.6620, acc: 0.7147\n","E2E-ABSA >>> 2022-09-02 04:47:31\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","E2E-ABSA >>> 2022-09-02 04:47:31\n","loss: 0.6384, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 04:47:32\n","loss: 0.6685, acc: 0.7092\n","E2E-ABSA >>> 2022-09-02 04:47:33\n","loss: 0.6618, acc: 0.7126\n","E2E-ABSA >>> 2022-09-02 04:47:34\n","loss: 0.6644, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 04:47:34\n",">>> val_acc: 0.6944, val_precision: 0.6944 val_recall: 0.6944, val_f1: 0.6944\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","E2E-ABSA >>> 2022-09-02 04:47:35\n","loss: 0.6577, acc: 0.7049\n","E2E-ABSA >>> 2022-09-02 04:47:35\n","loss: 0.6368, acc: 0.7307\n","E2E-ABSA >>> 2022-09-02 04:47:36\n","loss: 0.6523, acc: 0.7181\n","E2E-ABSA >>> 2022-09-02 04:47:37\n",">>> val_acc: 0.6944, val_precision: 0.6944 val_recall: 0.6944, val_f1: 0.6944\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 90.\n","E2E-ABSA >>> 2022-09-02 04:47:37\n","loss: 0.6354, acc: 0.7375\n","E2E-ABSA >>> 2022-09-02 04:47:38\n","loss: 0.6447, acc: 0.7323\n","E2E-ABSA >>> 2022-09-02 04:47:38\n","loss: 0.6499, acc: 0.7244\n","E2E-ABSA >>> 2022-09-02 04:47:39\n","loss: 0.6579, acc: 0.7236\n","E2E-ABSA >>> 2022-09-02 04:47:40\n",">>> val_acc: 0.6800, val_precision: 0.6800 val_recall: 0.6800, val_f1: 0.6800\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 91.\n","E2E-ABSA >>> 2022-09-02 04:47:40\n","loss: 0.6596, acc: 0.7132\n","E2E-ABSA >>> 2022-09-02 04:47:41\n","loss: 0.6460, acc: 0.7288\n","E2E-ABSA >>> 2022-09-02 04:47:42\n","loss: 0.6458, acc: 0.7262\n","E2E-ABSA >>> 2022-09-02 04:47:42\n",">>> val_acc: 0.6976, val_precision: 0.6976 val_recall: 0.6976, val_f1: 0.6976\n",">> saved: state_dict/lstm_acl14shortdata_know_val_f1_0.6976\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 92.\n","E2E-ABSA >>> 2022-09-02 04:47:43\n","loss: 0.6804, acc: 0.7227\n","E2E-ABSA >>> 2022-09-02 04:47:43\n","loss: 0.6625, acc: 0.7134\n","E2E-ABSA >>> 2022-09-02 04:47:44\n","loss: 0.6617, acc: 0.7199\n","E2E-ABSA >>> 2022-09-02 04:47:45\n","loss: 0.6568, acc: 0.7257\n","E2E-ABSA >>> 2022-09-02 04:47:45\n",">>> val_acc: 0.6848, val_precision: 0.6848 val_recall: 0.6848, val_f1: 0.6848\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 93.\n","E2E-ABSA >>> 2022-09-02 04:47:46\n","loss: 0.6809, acc: 0.7236\n","E2E-ABSA >>> 2022-09-02 04:47:46\n","loss: 0.6735, acc: 0.7157\n","E2E-ABSA >>> 2022-09-02 04:47:47\n","loss: 0.6552, acc: 0.7218\n","E2E-ABSA >>> 2022-09-02 04:47:48\n",">>> val_acc: 0.6880, val_precision: 0.6880 val_recall: 0.6880, val_f1: 0.6880\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 94.\n","E2E-ABSA >>> 2022-09-02 04:47:48\n","loss: 0.5831, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 04:47:49\n","loss: 0.6544, acc: 0.7137\n","E2E-ABSA >>> 2022-09-02 04:47:50\n","loss: 0.6666, acc: 0.7131\n","E2E-ABSA >>> 2022-09-02 04:47:50\n","loss: 0.6570, acc: 0.7238\n","E2E-ABSA >>> 2022-09-02 04:47:51\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 95.\n","E2E-ABSA >>> 2022-09-02 04:47:51\n","loss: 0.6733, acc: 0.7156\n","E2E-ABSA >>> 2022-09-02 04:47:52\n","loss: 0.6662, acc: 0.7160\n","E2E-ABSA >>> 2022-09-02 04:47:53\n","loss: 0.6540, acc: 0.7207\n","E2E-ABSA >>> 2022-09-02 04:47:54\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 96.\n","E2E-ABSA >>> 2022-09-02 04:47:54\n","loss: 0.5681, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 04:47:54\n","loss: 0.6497, acc: 0.7245\n","E2E-ABSA >>> 2022-09-02 04:47:55\n","loss: 0.6479, acc: 0.7272\n","E2E-ABSA >>> 2022-09-02 04:47:56\n","loss: 0.6533, acc: 0.7212\n","E2E-ABSA >>> 2022-09-02 04:47:56\n",">>> val_acc: 0.6816, val_precision: 0.6816 val_recall: 0.6816, val_f1: 0.6816\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 97.\n","E2E-ABSA >>> 2022-09-02 04:47:57\n","loss: 0.6877, acc: 0.7132\n","E2E-ABSA >>> 2022-09-02 04:47:58\n","loss: 0.6629, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 04:47:58\n","loss: 0.6623, acc: 0.7244\n","E2E-ABSA >>> 2022-09-02 04:47:59\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 98.\n","E2E-ABSA >>> 2022-09-02 04:47:59\n","loss: 0.6755, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 04:48:00\n","loss: 0.6448, acc: 0.7380\n","E2E-ABSA >>> 2022-09-02 04:48:01\n","loss: 0.6440, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 04:48:02\n","loss: 0.6455, acc: 0.7274\n","E2E-ABSA >>> 2022-09-02 04:48:02\n",">>> val_acc: 0.6880, val_precision: 0.6880 val_recall: 0.6880, val_f1: 0.6880\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 99.\n","E2E-ABSA >>> 2022-09-02 04:48:02\n","loss: 0.6672, acc: 0.7296\n","E2E-ABSA >>> 2022-09-02 04:48:03\n","loss: 0.6590, acc: 0.7323\n","E2E-ABSA >>> 2022-09-02 04:48:04\n","loss: 0.6491, acc: 0.7331\n","E2E-ABSA >>> 2022-09-02 04:48:05\n","loss: 0.6510, acc: 0.7291\n","E2E-ABSA >>> 2022-09-02 04:48:05\n",">>> val_acc: 0.6832, val_precision: 0.6832 val_recall: 0.6832, val_f1: 0.6832\n","you can download the best model from state_dict/lstm_acl14shortdata_know_val_f1_0.6976\n",">>> test_acc: 0.6976, test_precision: 0.6976, test_recall: 0.6976, test_f1: 0.6976\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **acl14shortdata** dataset on model(**TDLSTM**)\n","\n"],"metadata":{"id":"MPeI8ZAIV-1i"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name td_lstm --dataset acl14shortdata_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ZvxqSTqV-57","outputId":"48e98507-88bc-403c-f352-481dee9097c3","executionInfo":{"status":"ok","timestamp":1662094474576,"user_tz":-480,"elapsed":387431,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 4917.\n","> testing dataset count: 539.\n","cuda memory allocated: 22564864\n","> n_trainable_params: 1446603, n_nontrainable_params: 4136100\n","> training arguments:\n",">>> model_name: td_lstm\n",">>> dataset: acl14shortdata_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f6ada9e3c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.td_lstm.TD_LSTM'>\n",">>> dataset_file: {'train': './datasets/acl14shortdata/output_know_insert/train.tsv', 'test': './datasets/acl14shortdata/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['left_with_aspect_indices', 'right_with_aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:48:47\n","loss: 1.0439, acc: 0.4819\n","E2E-ABSA >>> 2022-09-02 04:48:48\n","loss: 1.0263, acc: 0.4947\n","E2E-ABSA >>> 2022-09-02 04:48:49\n","loss: 1.0167, acc: 0.5006\n","E2E-ABSA >>> 2022-09-02 04:48:49\n",">>> val_acc: 0.4750, val_precision: 0.4750 val_recall: 0.4750, val_f1: 0.4750\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.475\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:48:50\n","loss: 0.9809, acc: 0.5312\n","E2E-ABSA >>> 2022-09-02 04:48:51\n","loss: 0.9817, acc: 0.5296\n","E2E-ABSA >>> 2022-09-02 04:48:52\n","loss: 0.9750, acc: 0.5312\n","E2E-ABSA >>> 2022-09-02 04:48:53\n",">>> val_acc: 0.5139, val_precision: 0.5139 val_recall: 0.5139, val_f1: 0.5139\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.5139\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:48:54\n","loss: 0.9530, acc: 0.5536\n","E2E-ABSA >>> 2022-09-02 04:48:55\n","loss: 0.9553, acc: 0.5448\n","E2E-ABSA >>> 2022-09-02 04:48:56\n","loss: 0.9546, acc: 0.5453\n","E2E-ABSA >>> 2022-09-02 04:48:56\n",">>> val_acc: 0.5195, val_precision: 0.5195 val_recall: 0.5195, val_f1: 0.5195\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.5195\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:48:57\n","loss: 0.9575, acc: 0.5329\n","E2E-ABSA >>> 2022-09-02 04:48:58\n","loss: 0.9426, acc: 0.5536\n","E2E-ABSA >>> 2022-09-02 04:48:59\n","loss: 0.9391, acc: 0.5543\n","E2E-ABSA >>> 2022-09-02 04:49:00\n",">>> val_acc: 0.5306, val_precision: 0.5306 val_recall: 0.5306, val_f1: 0.5306\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.5306\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:49:00\n","loss: 0.9312, acc: 0.5653\n","E2E-ABSA >>> 2022-09-02 04:49:01\n","loss: 0.9313, acc: 0.5658\n","E2E-ABSA >>> 2022-09-02 04:49:03\n","loss: 0.9272, acc: 0.5634\n","E2E-ABSA >>> 2022-09-02 04:49:03\n",">>> val_acc: 0.5306, val_precision: 0.5306 val_recall: 0.5306, val_f1: 0.5306\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:49:04\n","loss: 0.9357, acc: 0.5604\n","E2E-ABSA >>> 2022-09-02 04:49:05\n","loss: 0.9191, acc: 0.5695\n","E2E-ABSA >>> 2022-09-02 04:49:06\n","loss: 0.9132, acc: 0.5767\n","E2E-ABSA >>> 2022-09-02 04:49:07\n",">>> val_acc: 0.5455, val_precision: 0.5455 val_recall: 0.5455, val_f1: 0.5455\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.5455\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:49:07\n","loss: 0.9066, acc: 0.5817\n","E2E-ABSA >>> 2022-09-02 04:49:08\n","loss: 0.9011, acc: 0.5880\n","E2E-ABSA >>> 2022-09-02 04:49:09\n","loss: 0.9015, acc: 0.5866\n","E2E-ABSA >>> 2022-09-02 04:49:10\n",">>> val_acc: 0.5603, val_precision: 0.5603 val_recall: 0.5603, val_f1: 0.5603\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.5603\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:49:11\n","loss: 0.8989, acc: 0.5980\n","E2E-ABSA >>> 2022-09-02 04:49:12\n","loss: 0.8928, acc: 0.6003\n","E2E-ABSA >>> 2022-09-02 04:49:13\n","loss: 0.8901, acc: 0.5976\n","E2E-ABSA >>> 2022-09-02 04:49:14\n",">>> val_acc: 0.5603, val_precision: 0.5603 val_recall: 0.5603, val_f1: 0.5603\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:49:14\n","loss: 0.8836, acc: 0.5990\n","E2E-ABSA >>> 2022-09-02 04:49:15\n","loss: 0.8828, acc: 0.6016\n","E2E-ABSA >>> 2022-09-02 04:49:16\n","loss: 0.8770, acc: 0.6065\n","E2E-ABSA >>> 2022-09-02 04:49:17\n",">>> val_acc: 0.5807, val_precision: 0.5807 val_recall: 0.5807, val_f1: 0.5807\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.5807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:49:17\n","loss: 0.8336, acc: 0.6406\n","E2E-ABSA >>> 2022-09-02 04:49:18\n","loss: 0.8569, acc: 0.6240\n","E2E-ABSA >>> 2022-09-02 04:49:20\n","loss: 0.8558, acc: 0.6176\n","E2E-ABSA >>> 2022-09-02 04:49:21\n",">>> val_acc: 0.6030, val_precision: 0.6030 val_recall: 0.6030, val_f1: 0.6030\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.603\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:49:21\n","loss: 0.8511, acc: 0.6344\n","E2E-ABSA >>> 2022-09-02 04:49:22\n","loss: 0.8381, acc: 0.6370\n","E2E-ABSA >>> 2022-09-02 04:49:23\n","loss: 0.8405, acc: 0.6290\n","E2E-ABSA >>> 2022-09-02 04:49:24\n",">>> val_acc: 0.6030, val_precision: 0.6030 val_recall: 0.6030, val_f1: 0.6030\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:49:24\n","loss: 0.8138, acc: 0.6406\n","E2E-ABSA >>> 2022-09-02 04:49:25\n","loss: 0.8425, acc: 0.6228\n","E2E-ABSA >>> 2022-09-02 04:49:26\n","loss: 0.8332, acc: 0.6309\n","E2E-ABSA >>> 2022-09-02 04:49:28\n",">>> val_acc: 0.6011, val_precision: 0.6011 val_recall: 0.6011, val_f1: 0.6011\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:49:28\n","loss: 0.8116, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 04:49:29\n","loss: 0.8165, acc: 0.6478\n","E2E-ABSA >>> 2022-09-02 04:49:30\n","loss: 0.8176, acc: 0.6449\n","E2E-ABSA >>> 2022-09-02 04:49:31\n","loss: 0.8208, acc: 0.6392\n","E2E-ABSA >>> 2022-09-02 04:49:32\n",">>> val_acc: 0.6011, val_precision: 0.6011 val_recall: 0.6011, val_f1: 0.6011\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:49:33\n","loss: 0.8161, acc: 0.6458\n","E2E-ABSA >>> 2022-09-02 04:49:34\n","loss: 0.8096, acc: 0.6480\n","E2E-ABSA >>> 2022-09-02 04:49:35\n","loss: 0.8140, acc: 0.6417\n","E2E-ABSA >>> 2022-09-02 04:49:35\n",">>> val_acc: 0.6011, val_precision: 0.6011 val_recall: 0.6011, val_f1: 0.6011\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:49:36\n","loss: 0.8121, acc: 0.6527\n","E2E-ABSA >>> 2022-09-02 04:49:37\n","loss: 0.8115, acc: 0.6516\n","E2E-ABSA >>> 2022-09-02 04:49:38\n","loss: 0.8084, acc: 0.6502\n","E2E-ABSA >>> 2022-09-02 04:49:38\n",">>> val_acc: 0.6067, val_precision: 0.6067 val_recall: 0.6067, val_f1: 0.6067\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.6067\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:49:39\n","loss: 0.8026, acc: 0.6500\n","E2E-ABSA >>> 2022-09-02 04:49:40\n","loss: 0.7944, acc: 0.6531\n","E2E-ABSA >>> 2022-09-02 04:49:42\n","loss: 0.7984, acc: 0.6536\n","E2E-ABSA >>> 2022-09-02 04:49:42\n",">>> val_acc: 0.5993, val_precision: 0.5993 val_recall: 0.5993, val_f1: 0.5993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:49:43\n","loss: 0.8003, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 04:49:44\n","loss: 0.7977, acc: 0.6515\n","E2E-ABSA >>> 2022-09-02 04:49:45\n","loss: 0.7991, acc: 0.6542\n","E2E-ABSA >>> 2022-09-02 04:49:45\n",">>> val_acc: 0.6030, val_precision: 0.6030 val_recall: 0.6030, val_f1: 0.6030\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:49:46\n","loss: 0.8127, acc: 0.6426\n","E2E-ABSA >>> 2022-09-02 04:49:47\n","loss: 0.7958, acc: 0.6517\n","E2E-ABSA >>> 2022-09-02 04:49:48\n","loss: 0.7969, acc: 0.6525\n","E2E-ABSA >>> 2022-09-02 04:49:49\n",">>> val_acc: 0.6085, val_precision: 0.6085 val_recall: 0.6085, val_f1: 0.6085\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.6085\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:49:50\n","loss: 0.7975, acc: 0.6629\n","E2E-ABSA >>> 2022-09-02 04:49:51\n","loss: 0.7958, acc: 0.6542\n","E2E-ABSA >>> 2022-09-02 04:49:52\n","loss: 0.7962, acc: 0.6506\n","E2E-ABSA >>> 2022-09-02 04:49:52\n",">>> val_acc: 0.6104, val_precision: 0.6104 val_recall: 0.6104, val_f1: 0.6104\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.6104\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:49:53\n","loss: 0.8073, acc: 0.6341\n","E2E-ABSA >>> 2022-09-02 04:49:54\n","loss: 0.7971, acc: 0.6474\n","E2E-ABSA >>> 2022-09-02 04:49:55\n","loss: 0.7880, acc: 0.6565\n","E2E-ABSA >>> 2022-09-02 04:49:56\n",">>> val_acc: 0.6197, val_precision: 0.6197 val_recall: 0.6197, val_f1: 0.6197\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.6197\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:49:56\n","loss: 0.7821, acc: 0.6687\n","E2E-ABSA >>> 2022-09-02 04:49:57\n","loss: 0.7791, acc: 0.6607\n","E2E-ABSA >>> 2022-09-02 04:49:58\n","loss: 0.7919, acc: 0.6505\n","E2E-ABSA >>> 2022-09-02 04:49:59\n",">>> val_acc: 0.6197, val_precision: 0.6197 val_recall: 0.6197, val_f1: 0.6197\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:50:00\n","loss: 0.8560, acc: 0.6230\n","E2E-ABSA >>> 2022-09-02 04:50:01\n","loss: 0.8093, acc: 0.6439\n","E2E-ABSA >>> 2022-09-02 04:50:02\n","loss: 0.7934, acc: 0.6522\n","E2E-ABSA >>> 2022-09-02 04:50:03\n",">>> val_acc: 0.6085, val_precision: 0.6085 val_recall: 0.6085, val_f1: 0.6085\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:50:03\n","loss: 0.7355, acc: 0.6901\n","E2E-ABSA >>> 2022-09-02 04:50:04\n","loss: 0.7798, acc: 0.6663\n","E2E-ABSA >>> 2022-09-02 04:50:05\n","loss: 0.7779, acc: 0.6602\n","E2E-ABSA >>> 2022-09-02 04:50:06\n",">>> val_acc: 0.6104, val_precision: 0.6104 val_recall: 0.6104, val_f1: 0.6104\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:50:06\n","loss: 0.7063, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 04:50:07\n","loss: 0.7667, acc: 0.6665\n","E2E-ABSA >>> 2022-09-02 04:50:09\n","loss: 0.7792, acc: 0.6557\n","E2E-ABSA >>> 2022-09-02 04:50:10\n",">>> val_acc: 0.6197, val_precision: 0.6197 val_recall: 0.6197, val_f1: 0.6197\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:50:10\n","loss: 0.8401, acc: 0.5859\n","E2E-ABSA >>> 2022-09-02 04:50:11\n","loss: 0.7773, acc: 0.6574\n","E2E-ABSA >>> 2022-09-02 04:50:12\n","loss: 0.7862, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 04:50:13\n","loss: 0.7820, acc: 0.6585\n","E2E-ABSA >>> 2022-09-02 04:50:13\n",">>> val_acc: 0.6067, val_precision: 0.6067 val_recall: 0.6067, val_f1: 0.6067\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:50:14\n","loss: 0.7887, acc: 0.6625\n","E2E-ABSA >>> 2022-09-02 04:50:15\n","loss: 0.7913, acc: 0.6538\n","E2E-ABSA >>> 2022-09-02 04:50:16\n","loss: 0.7823, acc: 0.6613\n","E2E-ABSA >>> 2022-09-02 04:50:17\n",">>> val_acc: 0.6122, val_precision: 0.6122 val_recall: 0.6122, val_f1: 0.6122\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:50:18\n","loss: 0.7612, acc: 0.6678\n","E2E-ABSA >>> 2022-09-02 04:50:19\n","loss: 0.7765, acc: 0.6628\n","E2E-ABSA >>> 2022-09-02 04:50:20\n","loss: 0.7772, acc: 0.6622\n","E2E-ABSA >>> 2022-09-02 04:50:20\n",">>> val_acc: 0.6308, val_precision: 0.6308 val_recall: 0.6308, val_f1: 0.6308\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.6308\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:50:21\n","loss: 0.7598, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 04:50:22\n","loss: 0.7769, acc: 0.6627\n","E2E-ABSA >>> 2022-09-02 04:50:23\n","loss: 0.7772, acc: 0.6629\n","E2E-ABSA >>> 2022-09-02 04:50:24\n",">>> val_acc: 0.6178, val_precision: 0.6178 val_recall: 0.6178, val_f1: 0.6178\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:50:24\n","loss: 0.7620, acc: 0.6776\n","E2E-ABSA >>> 2022-09-02 04:50:25\n","loss: 0.7725, acc: 0.6733\n","E2E-ABSA >>> 2022-09-02 04:50:26\n","loss: 0.7804, acc: 0.6646\n","E2E-ABSA >>> 2022-09-02 04:50:27\n",">>> val_acc: 0.6252, val_precision: 0.6252 val_recall: 0.6252, val_f1: 0.6252\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:50:28\n","loss: 0.7917, acc: 0.6544\n","E2E-ABSA >>> 2022-09-02 04:50:29\n","loss: 0.7809, acc: 0.6566\n","E2E-ABSA >>> 2022-09-02 04:50:30\n","loss: 0.7768, acc: 0.6618\n","E2E-ABSA >>> 2022-09-02 04:50:30\n",">>> val_acc: 0.6382, val_precision: 0.6382 val_recall: 0.6382, val_f1: 0.6382\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.6382\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:50:31\n","loss: 0.7309, acc: 0.6896\n","E2E-ABSA >>> 2022-09-02 04:50:32\n","loss: 0.7692, acc: 0.6641\n","E2E-ABSA >>> 2022-09-02 04:50:33\n","loss: 0.7699, acc: 0.6615\n","E2E-ABSA >>> 2022-09-02 04:50:34\n",">>> val_acc: 0.6271, val_precision: 0.6271 val_recall: 0.6271, val_f1: 0.6271\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 04:50:34\n","loss: 0.7581, acc: 0.6755\n","E2E-ABSA >>> 2022-09-02 04:50:35\n","loss: 0.7732, acc: 0.6600\n","E2E-ABSA >>> 2022-09-02 04:50:37\n","loss: 0.7677, acc: 0.6652\n","E2E-ABSA >>> 2022-09-02 04:50:37\n",">>> val_acc: 0.6160, val_precision: 0.6160 val_recall: 0.6160, val_f1: 0.6160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 04:50:38\n","loss: 0.7634, acc: 0.6776\n","E2E-ABSA >>> 2022-09-02 04:50:39\n","loss: 0.7686, acc: 0.6736\n","E2E-ABSA >>> 2022-09-02 04:50:40\n","loss: 0.7691, acc: 0.6665\n","E2E-ABSA >>> 2022-09-02 04:50:41\n",">>> val_acc: 0.6234, val_precision: 0.6234 val_recall: 0.6234, val_f1: 0.6234\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 04:50:41\n","loss: 0.7712, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 04:50:42\n","loss: 0.7697, acc: 0.6733\n","E2E-ABSA >>> 2022-09-02 04:50:43\n","loss: 0.7786, acc: 0.6631\n","E2E-ABSA >>> 2022-09-02 04:50:44\n",">>> val_acc: 0.6271, val_precision: 0.6271 val_recall: 0.6271, val_f1: 0.6271\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 04:50:44\n","loss: 0.8358, acc: 0.6228\n","E2E-ABSA >>> 2022-09-02 04:50:46\n","loss: 0.7930, acc: 0.6543\n","E2E-ABSA >>> 2022-09-02 04:50:47\n","loss: 0.7715, acc: 0.6631\n","E2E-ABSA >>> 2022-09-02 04:50:48\n",">>> val_acc: 0.6197, val_precision: 0.6197 val_recall: 0.6197, val_f1: 0.6197\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 04:50:48\n","loss: 0.7631, acc: 0.6531\n","E2E-ABSA >>> 2022-09-02 04:50:49\n","loss: 0.7803, acc: 0.6557\n","E2E-ABSA >>> 2022-09-02 04:50:50\n","loss: 0.7705, acc: 0.6599\n","E2E-ABSA >>> 2022-09-02 04:50:51\n",">>> val_acc: 0.6345, val_precision: 0.6345 val_recall: 0.6345, val_f1: 0.6345\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 04:50:51\n","loss: 0.7649, acc: 0.6406\n","E2E-ABSA >>> 2022-09-02 04:50:52\n","loss: 0.7623, acc: 0.6708\n","E2E-ABSA >>> 2022-09-02 04:50:53\n","loss: 0.7683, acc: 0.6683\n","E2E-ABSA >>> 2022-09-02 04:50:54\n",">>> val_acc: 0.6382, val_precision: 0.6382 val_recall: 0.6382, val_f1: 0.6382\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 04:50:54\n","loss: 0.7830, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 04:50:56\n","loss: 0.7674, acc: 0.6617\n","E2E-ABSA >>> 2022-09-02 04:50:57\n","loss: 0.7615, acc: 0.6688\n","E2E-ABSA >>> 2022-09-02 04:50:58\n","loss: 0.7644, acc: 0.6692\n","E2E-ABSA >>> 2022-09-02 04:50:58\n",">>> val_acc: 0.6271, val_precision: 0.6271 val_recall: 0.6271, val_f1: 0.6271\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 04:50:59\n","loss: 0.7523, acc: 0.6803\n","E2E-ABSA >>> 2022-09-02 04:51:00\n","loss: 0.7717, acc: 0.6668\n","E2E-ABSA >>> 2022-09-02 04:51:01\n","loss: 0.7660, acc: 0.6712\n","E2E-ABSA >>> 2022-09-02 04:51:01\n",">>> val_acc: 0.6289, val_precision: 0.6289 val_recall: 0.6289, val_f1: 0.6289\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 04:51:02\n","loss: 0.7716, acc: 0.6548\n","E2E-ABSA >>> 2022-09-02 04:51:03\n","loss: 0.7688, acc: 0.6629\n","E2E-ABSA >>> 2022-09-02 04:51:04\n","loss: 0.7643, acc: 0.6675\n","E2E-ABSA >>> 2022-09-02 04:51:05\n",">>> val_acc: 0.6327, val_precision: 0.6327 val_recall: 0.6327, val_f1: 0.6327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 04:51:06\n","loss: 0.7528, acc: 0.6766\n","E2E-ABSA >>> 2022-09-02 04:51:07\n","loss: 0.7697, acc: 0.6677\n","E2E-ABSA >>> 2022-09-02 04:51:08\n","loss: 0.7613, acc: 0.6663\n","E2E-ABSA >>> 2022-09-02 04:51:08\n",">>> val_acc: 0.6289, val_precision: 0.6289 val_recall: 0.6289, val_f1: 0.6289\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 04:51:09\n","loss: 0.7902, acc: 0.6667\n","E2E-ABSA >>> 2022-09-02 04:51:10\n","loss: 0.7687, acc: 0.6711\n","E2E-ABSA >>> 2022-09-02 04:51:11\n","loss: 0.7592, acc: 0.6781\n","E2E-ABSA >>> 2022-09-02 04:51:12\n",">>> val_acc: 0.6271, val_precision: 0.6271 val_recall: 0.6271, val_f1: 0.6271\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 04:51:12\n","loss: 0.7495, acc: 0.6895\n","E2E-ABSA >>> 2022-09-02 04:51:13\n","loss: 0.7680, acc: 0.6738\n","E2E-ABSA >>> 2022-09-02 04:51:14\n","loss: 0.7617, acc: 0.6752\n","E2E-ABSA >>> 2022-09-02 04:51:15\n",">>> val_acc: 0.6271, val_precision: 0.6271 val_recall: 0.6271, val_f1: 0.6271\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 04:51:16\n","loss: 0.7538, acc: 0.6730\n","E2E-ABSA >>> 2022-09-02 04:51:17\n","loss: 0.7690, acc: 0.6695\n","E2E-ABSA >>> 2022-09-02 04:51:18\n","loss: 0.7586, acc: 0.6736\n","E2E-ABSA >>> 2022-09-02 04:51:18\n",">>> val_acc: 0.6308, val_precision: 0.6308 val_recall: 0.6308, val_f1: 0.6308\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 04:51:19\n","loss: 0.7788, acc: 0.6589\n","E2E-ABSA >>> 2022-09-02 04:51:20\n","loss: 0.7732, acc: 0.6655\n","E2E-ABSA >>> 2022-09-02 04:51:21\n","loss: 0.7613, acc: 0.6721\n","E2E-ABSA >>> 2022-09-02 04:51:22\n",">>> val_acc: 0.6271, val_precision: 0.6271 val_recall: 0.6271, val_f1: 0.6271\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 04:51:22\n","loss: 0.7693, acc: 0.6547\n","E2E-ABSA >>> 2022-09-02 04:51:23\n","loss: 0.7522, acc: 0.6759\n","E2E-ABSA >>> 2022-09-02 04:51:24\n","loss: 0.7555, acc: 0.6760\n","E2E-ABSA >>> 2022-09-02 04:51:25\n",">>> val_acc: 0.6289, val_precision: 0.6289 val_recall: 0.6289, val_f1: 0.6289\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 04:51:26\n","loss: 0.7501, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:51:27\n","loss: 0.7668, acc: 0.6705\n","E2E-ABSA >>> 2022-09-02 04:51:28\n","loss: 0.7633, acc: 0.6684\n","E2E-ABSA >>> 2022-09-02 04:51:29\n",">>> val_acc: 0.6271, val_precision: 0.6271 val_recall: 0.6271, val_f1: 0.6271\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 04:51:29\n","loss: 0.7290, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 04:51:31\n","loss: 0.7486, acc: 0.6764\n","E2E-ABSA >>> 2022-09-02 04:51:32\n","loss: 0.7506, acc: 0.6730\n","E2E-ABSA >>> 2022-09-02 04:51:33\n",">>> val_acc: 0.6327, val_precision: 0.6327 val_recall: 0.6327, val_f1: 0.6327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 04:51:33\n","loss: 0.8209, acc: 0.6211\n","E2E-ABSA >>> 2022-09-02 04:51:34\n","loss: 0.7588, acc: 0.6751\n","E2E-ABSA >>> 2022-09-02 04:51:35\n","loss: 0.7615, acc: 0.6713\n","E2E-ABSA >>> 2022-09-02 04:51:36\n",">>> val_acc: 0.6327, val_precision: 0.6327 val_recall: 0.6327, val_f1: 0.6327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 04:51:36\n","loss: 0.7938, acc: 0.6406\n","E2E-ABSA >>> 2022-09-02 04:51:37\n","loss: 0.7597, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 04:51:38\n","loss: 0.7539, acc: 0.6752\n","E2E-ABSA >>> 2022-09-02 04:51:40\n","loss: 0.7564, acc: 0.6720\n","E2E-ABSA >>> 2022-09-02 04:51:40\n",">>> val_acc: 0.6252, val_precision: 0.6252 val_recall: 0.6252, val_f1: 0.6252\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 04:51:41\n","loss: 0.7725, acc: 0.6687\n","E2E-ABSA >>> 2022-09-02 04:51:42\n","loss: 0.7640, acc: 0.6734\n","E2E-ABSA >>> 2022-09-02 04:51:43\n","loss: 0.7552, acc: 0.6779\n","E2E-ABSA >>> 2022-09-02 04:51:43\n",">>> val_acc: 0.6327, val_precision: 0.6327 val_recall: 0.6327, val_f1: 0.6327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 04:51:44\n","loss: 0.7562, acc: 0.6793\n","E2E-ABSA >>> 2022-09-02 04:51:45\n","loss: 0.7477, acc: 0.6803\n","E2E-ABSA >>> 2022-09-02 04:51:46\n","loss: 0.7534, acc: 0.6734\n","E2E-ABSA >>> 2022-09-02 04:51:47\n",">>> val_acc: 0.6345, val_precision: 0.6345 val_recall: 0.6345, val_f1: 0.6345\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 04:51:47\n","loss: 0.7516, acc: 0.6793\n","E2E-ABSA >>> 2022-09-02 04:51:49\n","loss: 0.7599, acc: 0.6739\n","E2E-ABSA >>> 2022-09-02 04:51:50\n","loss: 0.7594, acc: 0.6736\n","E2E-ABSA >>> 2022-09-02 04:51:50\n",">>> val_acc: 0.6327, val_precision: 0.6327 val_recall: 0.6327, val_f1: 0.6327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 04:51:51\n","loss: 0.7632, acc: 0.6743\n","E2E-ABSA >>> 2022-09-02 04:51:52\n","loss: 0.7625, acc: 0.6761\n","E2E-ABSA >>> 2022-09-02 04:51:53\n","loss: 0.7576, acc: 0.6728\n","E2E-ABSA >>> 2022-09-02 04:51:53\n",">>> val_acc: 0.6345, val_precision: 0.6345 val_recall: 0.6345, val_f1: 0.6345\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 04:51:54\n","loss: 0.7517, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 04:51:55\n","loss: 0.7563, acc: 0.6749\n","E2E-ABSA >>> 2022-09-02 04:51:56\n","loss: 0.7497, acc: 0.6803\n","E2E-ABSA >>> 2022-09-02 04:51:57\n",">>> val_acc: 0.6438, val_precision: 0.6438 val_recall: 0.6438, val_f1: 0.6438\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.6438\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 04:51:57\n","loss: 0.7370, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:51:59\n","loss: 0.7449, acc: 0.6809\n","E2E-ABSA >>> 2022-09-02 04:52:00\n","loss: 0.7533, acc: 0.6764\n","E2E-ABSA >>> 2022-09-02 04:52:00\n",">>> val_acc: 0.6327, val_precision: 0.6327 val_recall: 0.6327, val_f1: 0.6327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 04:52:01\n","loss: 0.7566, acc: 0.6683\n","E2E-ABSA >>> 2022-09-02 04:52:02\n","loss: 0.7525, acc: 0.6785\n","E2E-ABSA >>> 2022-09-02 04:52:03\n","loss: 0.7496, acc: 0.6776\n","E2E-ABSA >>> 2022-09-02 04:52:04\n",">>> val_acc: 0.6419, val_precision: 0.6419 val_recall: 0.6419, val_f1: 0.6419\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 04:52:04\n","loss: 0.7373, acc: 0.6861\n","E2E-ABSA >>> 2022-09-02 04:52:05\n","loss: 0.7639, acc: 0.6710\n","E2E-ABSA >>> 2022-09-02 04:52:06\n","loss: 0.7549, acc: 0.6775\n","E2E-ABSA >>> 2022-09-02 04:52:07\n",">>> val_acc: 0.6327, val_precision: 0.6327 val_recall: 0.6327, val_f1: 0.6327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 04:52:08\n","loss: 0.7671, acc: 0.6632\n","E2E-ABSA >>> 2022-09-02 04:52:09\n","loss: 0.7613, acc: 0.6737\n","E2E-ABSA >>> 2022-09-02 04:52:10\n","loss: 0.7580, acc: 0.6713\n","E2E-ABSA >>> 2022-09-02 04:52:11\n",">>> val_acc: 0.6308, val_precision: 0.6308 val_recall: 0.6308, val_f1: 0.6308\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 04:52:11\n","loss: 0.7870, acc: 0.6585\n","E2E-ABSA >>> 2022-09-02 04:52:12\n","loss: 0.7615, acc: 0.6685\n","E2E-ABSA >>> 2022-09-02 04:52:13\n","loss: 0.7538, acc: 0.6812\n","E2E-ABSA >>> 2022-09-02 04:52:14\n",">>> val_acc: 0.6401, val_precision: 0.6401 val_recall: 0.6401, val_f1: 0.6401\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 04:52:14\n","loss: 0.6927, acc: 0.7156\n","E2E-ABSA >>> 2022-09-02 04:52:15\n","loss: 0.7257, acc: 0.6901\n","E2E-ABSA >>> 2022-09-02 04:52:16\n","loss: 0.7475, acc: 0.6793\n","E2E-ABSA >>> 2022-09-02 04:52:17\n",">>> val_acc: 0.6308, val_precision: 0.6308 val_recall: 0.6308, val_f1: 0.6308\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 04:52:18\n","loss: 0.7681, acc: 0.6510\n","E2E-ABSA >>> 2022-09-02 04:52:19\n","loss: 0.7569, acc: 0.6713\n","E2E-ABSA >>> 2022-09-02 04:52:20\n","loss: 0.7554, acc: 0.6728\n","E2E-ABSA >>> 2022-09-02 04:52:21\n",">>> val_acc: 0.6345, val_precision: 0.6345 val_recall: 0.6345, val_f1: 0.6345\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 04:52:21\n","loss: 0.6486, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 04:52:22\n","loss: 0.7519, acc: 0.6809\n","E2E-ABSA >>> 2022-09-02 04:52:23\n","loss: 0.7572, acc: 0.6725\n","E2E-ABSA >>> 2022-09-02 04:52:24\n","loss: 0.7514, acc: 0.6793\n","E2E-ABSA >>> 2022-09-02 04:52:24\n",">>> val_acc: 0.6382, val_precision: 0.6382 val_recall: 0.6382, val_f1: 0.6382\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 04:52:25\n","loss: 0.7637, acc: 0.6790\n","E2E-ABSA >>> 2022-09-02 04:52:26\n","loss: 0.7596, acc: 0.6783\n","E2E-ABSA >>> 2022-09-02 04:52:27\n","loss: 0.7480, acc: 0.6807\n","E2E-ABSA >>> 2022-09-02 04:52:28\n",">>> val_acc: 0.6364, val_precision: 0.6364 val_recall: 0.6364, val_f1: 0.6364\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 04:52:29\n","loss: 0.7705, acc: 0.6612\n","E2E-ABSA >>> 2022-09-02 04:52:30\n","loss: 0.7570, acc: 0.6779\n","E2E-ABSA >>> 2022-09-02 04:52:31\n","loss: 0.7481, acc: 0.6801\n","E2E-ABSA >>> 2022-09-02 04:52:31\n",">>> val_acc: 0.6364, val_precision: 0.6364 val_recall: 0.6364, val_f1: 0.6364\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 04:52:32\n","loss: 0.7530, acc: 0.6852\n","E2E-ABSA >>> 2022-09-02 04:52:33\n","loss: 0.7535, acc: 0.6750\n","E2E-ABSA >>> 2022-09-02 04:52:34\n","loss: 0.7520, acc: 0.6723\n","E2E-ABSA >>> 2022-09-02 04:52:35\n",">>> val_acc: 0.6382, val_precision: 0.6382 val_recall: 0.6382, val_f1: 0.6382\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 04:52:35\n","loss: 0.7529, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 04:52:36\n","loss: 0.7487, acc: 0.6788\n","E2E-ABSA >>> 2022-09-02 04:52:38\n","loss: 0.7492, acc: 0.6751\n","E2E-ABSA >>> 2022-09-02 04:52:38\n",">>> val_acc: 0.6271, val_precision: 0.6271 val_recall: 0.6271, val_f1: 0.6271\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 04:52:39\n","loss: 0.7550, acc: 0.6836\n","E2E-ABSA >>> 2022-09-02 04:52:40\n","loss: 0.7587, acc: 0.6764\n","E2E-ABSA >>> 2022-09-02 04:52:41\n","loss: 0.7505, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 04:52:42\n",">>> val_acc: 0.6327, val_precision: 0.6327 val_recall: 0.6327, val_f1: 0.6327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","E2E-ABSA >>> 2022-09-02 04:52:42\n","loss: 0.7548, acc: 0.6786\n","E2E-ABSA >>> 2022-09-02 04:52:43\n","loss: 0.7484, acc: 0.6779\n","E2E-ABSA >>> 2022-09-02 04:52:44\n","loss: 0.7449, acc: 0.6814\n","E2E-ABSA >>> 2022-09-02 04:52:45\n",">>> val_acc: 0.6419, val_precision: 0.6419 val_recall: 0.6419, val_f1: 0.6419\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","E2E-ABSA >>> 2022-09-02 04:52:45\n","loss: 0.6928, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 04:52:47\n","loss: 0.7370, acc: 0.6913\n","E2E-ABSA >>> 2022-09-02 04:52:48\n","loss: 0.7516, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 04:52:48\n",">>> val_acc: 0.6438, val_precision: 0.6438 val_recall: 0.6438, val_f1: 0.6438\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","E2E-ABSA >>> 2022-09-02 04:52:49\n","loss: 0.7474, acc: 0.7000\n","E2E-ABSA >>> 2022-09-02 04:52:50\n","loss: 0.7343, acc: 0.6960\n","E2E-ABSA >>> 2022-09-02 04:52:51\n","loss: 0.7445, acc: 0.6833\n","E2E-ABSA >>> 2022-09-02 04:52:52\n",">>> val_acc: 0.6438, val_precision: 0.6438 val_recall: 0.6438, val_f1: 0.6438\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","E2E-ABSA >>> 2022-09-02 04:52:52\n","loss: 0.7529, acc: 0.6738\n","E2E-ABSA >>> 2022-09-02 04:52:53\n","loss: 0.7399, acc: 0.6866\n","E2E-ABSA >>> 2022-09-02 04:52:54\n","loss: 0.7483, acc: 0.6829\n","E2E-ABSA >>> 2022-09-02 04:52:55\n",">>> val_acc: 0.6419, val_precision: 0.6419 val_recall: 0.6419, val_f1: 0.6419\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","E2E-ABSA >>> 2022-09-02 04:52:56\n","loss: 0.7110, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 04:52:57\n","loss: 0.7559, acc: 0.6734\n","E2E-ABSA >>> 2022-09-02 04:52:58\n","loss: 0.7492, acc: 0.6830\n","E2E-ABSA >>> 2022-09-02 04:52:59\n",">>> val_acc: 0.6364, val_precision: 0.6364 val_recall: 0.6364, val_f1: 0.6364\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","E2E-ABSA >>> 2022-09-02 04:52:59\n","loss: 0.7454, acc: 0.6992\n","E2E-ABSA >>> 2022-09-02 04:53:00\n","loss: 0.7354, acc: 0.6864\n","E2E-ABSA >>> 2022-09-02 04:53:01\n","loss: 0.7414, acc: 0.6811\n","E2E-ABSA >>> 2022-09-02 04:53:02\n",">>> val_acc: 0.6382, val_precision: 0.6382 val_recall: 0.6382, val_f1: 0.6382\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","E2E-ABSA >>> 2022-09-02 04:53:02\n","loss: 0.8843, acc: 0.5859\n","E2E-ABSA >>> 2022-09-02 04:53:03\n","loss: 0.7654, acc: 0.6661\n","E2E-ABSA >>> 2022-09-02 04:53:04\n","loss: 0.7507, acc: 0.6764\n","E2E-ABSA >>> 2022-09-02 04:53:05\n","loss: 0.7457, acc: 0.6799\n","E2E-ABSA >>> 2022-09-02 04:53:06\n",">>> val_acc: 0.6456, val_precision: 0.6456 val_recall: 0.6456, val_f1: 0.6456\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.6456\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","E2E-ABSA >>> 2022-09-02 04:53:07\n","loss: 0.7510, acc: 0.6813\n","E2E-ABSA >>> 2022-09-02 04:53:08\n","loss: 0.7426, acc: 0.6869\n","E2E-ABSA >>> 2022-09-02 04:53:09\n","loss: 0.7485, acc: 0.6837\n","E2E-ABSA >>> 2022-09-02 04:53:09\n",">>> val_acc: 0.6512, val_precision: 0.6512 val_recall: 0.6512, val_f1: 0.6512\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.6512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","E2E-ABSA >>> 2022-09-02 04:53:10\n","loss: 0.7373, acc: 0.6780\n","E2E-ABSA >>> 2022-09-02 04:53:11\n","loss: 0.7471, acc: 0.6745\n","E2E-ABSA >>> 2022-09-02 04:53:12\n","loss: 0.7445, acc: 0.6817\n","E2E-ABSA >>> 2022-09-02 04:53:13\n",">>> val_acc: 0.6494, val_precision: 0.6494 val_recall: 0.6494, val_f1: 0.6494\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","E2E-ABSA >>> 2022-09-02 04:53:13\n","loss: 0.7372, acc: 0.6868\n","E2E-ABSA >>> 2022-09-02 04:53:14\n","loss: 0.7482, acc: 0.6827\n","E2E-ABSA >>> 2022-09-02 04:53:16\n","loss: 0.7448, acc: 0.6798\n","E2E-ABSA >>> 2022-09-02 04:53:16\n",">>> val_acc: 0.6382, val_precision: 0.6382 val_recall: 0.6382, val_f1: 0.6382\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","E2E-ABSA >>> 2022-09-02 04:53:17\n","loss: 0.7425, acc: 0.7015\n","E2E-ABSA >>> 2022-09-02 04:53:18\n","loss: 0.7329, acc: 0.6939\n","E2E-ABSA >>> 2022-09-02 04:53:19\n","loss: 0.7449, acc: 0.6850\n","E2E-ABSA >>> 2022-09-02 04:53:19\n",">>> val_acc: 0.6456, val_precision: 0.6456 val_recall: 0.6456, val_f1: 0.6456\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","E2E-ABSA >>> 2022-09-02 04:53:20\n","loss: 0.7483, acc: 0.6746\n","E2E-ABSA >>> 2022-09-02 04:53:21\n","loss: 0.7409, acc: 0.6823\n","E2E-ABSA >>> 2022-09-02 04:53:22\n","loss: 0.7399, acc: 0.6849\n","E2E-ABSA >>> 2022-09-02 04:53:23\n",">>> val_acc: 0.6364, val_precision: 0.6364 val_recall: 0.6364, val_f1: 0.6364\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","E2E-ABSA >>> 2022-09-02 04:53:23\n","loss: 0.7454, acc: 0.6792\n","E2E-ABSA >>> 2022-09-02 04:53:25\n","loss: 0.7286, acc: 0.6895\n","E2E-ABSA >>> 2022-09-02 04:53:26\n","loss: 0.7372, acc: 0.6865\n","E2E-ABSA >>> 2022-09-02 04:53:26\n",">>> val_acc: 0.6438, val_precision: 0.6438 val_recall: 0.6438, val_f1: 0.6438\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","E2E-ABSA >>> 2022-09-02 04:53:27\n","loss: 0.7344, acc: 0.6923\n","E2E-ABSA >>> 2022-09-02 04:53:28\n","loss: 0.7379, acc: 0.6830\n","E2E-ABSA >>> 2022-09-02 04:53:29\n","loss: 0.7398, acc: 0.6828\n","E2E-ABSA >>> 2022-09-02 04:53:30\n",">>> val_acc: 0.6456, val_precision: 0.6456 val_recall: 0.6456, val_f1: 0.6456\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","E2E-ABSA >>> 2022-09-02 04:53:30\n","loss: 0.7705, acc: 0.6676\n","E2E-ABSA >>> 2022-09-02 04:53:31\n","loss: 0.7442, acc: 0.6775\n","E2E-ABSA >>> 2022-09-02 04:53:32\n","loss: 0.7420, acc: 0.6837\n","E2E-ABSA >>> 2022-09-02 04:53:33\n",">>> val_acc: 0.6494, val_precision: 0.6494 val_recall: 0.6494, val_f1: 0.6494\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","E2E-ABSA >>> 2022-09-02 04:53:34\n","loss: 0.7169, acc: 0.6944\n","E2E-ABSA >>> 2022-09-02 04:53:35\n","loss: 0.7489, acc: 0.6765\n","E2E-ABSA >>> 2022-09-02 04:53:36\n","loss: 0.7418, acc: 0.6835\n","E2E-ABSA >>> 2022-09-02 04:53:37\n",">>> val_acc: 0.6456, val_precision: 0.6456 val_recall: 0.6456, val_f1: 0.6456\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","E2E-ABSA >>> 2022-09-02 04:53:37\n","loss: 0.7358, acc: 0.6830\n","E2E-ABSA >>> 2022-09-02 04:53:39\n","loss: 0.7451, acc: 0.6812\n","E2E-ABSA >>> 2022-09-02 04:53:40\n","loss: 0.7445, acc: 0.6782\n","E2E-ABSA >>> 2022-09-02 04:53:41\n",">>> val_acc: 0.6456, val_precision: 0.6456 val_recall: 0.6456, val_f1: 0.6456\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","E2E-ABSA >>> 2022-09-02 04:53:41\n","loss: 0.7580, acc: 0.6594\n","E2E-ABSA >>> 2022-09-02 04:53:42\n","loss: 0.7477, acc: 0.6703\n","E2E-ABSA >>> 2022-09-02 04:53:43\n","loss: 0.7528, acc: 0.6744\n","E2E-ABSA >>> 2022-09-02 04:53:44\n",">>> val_acc: 0.6438, val_precision: 0.6438 val_recall: 0.6438, val_f1: 0.6438\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","E2E-ABSA >>> 2022-09-02 04:53:44\n","loss: 0.6742, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 04:53:45\n","loss: 0.7287, acc: 0.6992\n","E2E-ABSA >>> 2022-09-02 04:53:46\n","loss: 0.7316, acc: 0.6831\n","E2E-ABSA >>> 2022-09-02 04:53:47\n",">>> val_acc: 0.6419, val_precision: 0.6419 val_recall: 0.6419, val_f1: 0.6419\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","E2E-ABSA >>> 2022-09-02 04:53:48\n","loss: 0.8479, acc: 0.6406\n","E2E-ABSA >>> 2022-09-02 04:53:49\n","loss: 0.7370, acc: 0.6863\n","E2E-ABSA >>> 2022-09-02 04:53:50\n","loss: 0.7463, acc: 0.6805\n","E2E-ABSA >>> 2022-09-02 04:53:51\n","loss: 0.7389, acc: 0.6848\n","E2E-ABSA >>> 2022-09-02 04:53:51\n",">>> val_acc: 0.6364, val_precision: 0.6364 val_recall: 0.6364, val_f1: 0.6364\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","E2E-ABSA >>> 2022-09-02 04:53:52\n","loss: 0.7399, acc: 0.6842\n","E2E-ABSA >>> 2022-09-02 04:53:53\n","loss: 0.7455, acc: 0.6747\n","E2E-ABSA >>> 2022-09-02 04:53:54\n","loss: 0.7401, acc: 0.6826\n","E2E-ABSA >>> 2022-09-02 04:53:54\n",">>> val_acc: 0.6438, val_precision: 0.6438 val_recall: 0.6438, val_f1: 0.6438\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","E2E-ABSA >>> 2022-09-02 04:53:55\n","loss: 0.7385, acc: 0.6825\n","E2E-ABSA >>> 2022-09-02 04:53:56\n","loss: 0.7281, acc: 0.6848\n","E2E-ABSA >>> 2022-09-02 04:53:58\n","loss: 0.7413, acc: 0.6825\n","E2E-ABSA >>> 2022-09-02 04:53:58\n",">>> val_acc: 0.6512, val_precision: 0.6512 val_recall: 0.6512, val_f1: 0.6512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 90.\n","E2E-ABSA >>> 2022-09-02 04:53:59\n","loss: 0.7422, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:54:00\n","loss: 0.7234, acc: 0.6962\n","E2E-ABSA >>> 2022-09-02 04:54:01\n","loss: 0.7335, acc: 0.6897\n","E2E-ABSA >>> 2022-09-02 04:54:01\n",">>> val_acc: 0.6438, val_precision: 0.6438 val_recall: 0.6438, val_f1: 0.6438\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 91.\n","E2E-ABSA >>> 2022-09-02 04:54:02\n","loss: 0.7456, acc: 0.6823\n","E2E-ABSA >>> 2022-09-02 04:54:03\n","loss: 0.7442, acc: 0.6882\n","E2E-ABSA >>> 2022-09-02 04:54:04\n","loss: 0.7393, acc: 0.6877\n","E2E-ABSA >>> 2022-09-02 04:54:05\n",">>> val_acc: 0.6438, val_precision: 0.6438 val_recall: 0.6438, val_f1: 0.6438\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 92.\n","E2E-ABSA >>> 2022-09-02 04:54:05\n","loss: 0.7441, acc: 0.6895\n","E2E-ABSA >>> 2022-09-02 04:54:06\n","loss: 0.7367, acc: 0.6883\n","E2E-ABSA >>> 2022-09-02 04:54:08\n","loss: 0.7445, acc: 0.6823\n","E2E-ABSA >>> 2022-09-02 04:54:08\n",">>> val_acc: 0.6419, val_precision: 0.6419 val_recall: 0.6419, val_f1: 0.6419\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 93.\n","E2E-ABSA >>> 2022-09-02 04:54:09\n","loss: 0.7194, acc: 0.6975\n","E2E-ABSA >>> 2022-09-02 04:54:10\n","loss: 0.7492, acc: 0.6763\n","E2E-ABSA >>> 2022-09-02 04:54:11\n","loss: 0.7416, acc: 0.6846\n","E2E-ABSA >>> 2022-09-02 04:54:12\n",">>> val_acc: 0.6475, val_precision: 0.6475 val_recall: 0.6475, val_f1: 0.6475\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 94.\n","E2E-ABSA >>> 2022-09-02 04:54:12\n","loss: 0.7606, acc: 0.6758\n","E2E-ABSA >>> 2022-09-02 04:54:13\n","loss: 0.7391, acc: 0.6900\n","E2E-ABSA >>> 2022-09-02 04:54:14\n","loss: 0.7393, acc: 0.6890\n","E2E-ABSA >>> 2022-09-02 04:54:15\n",">>> val_acc: 0.6512, val_precision: 0.6512 val_recall: 0.6512, val_f1: 0.6512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 95.\n","E2E-ABSA >>> 2022-09-02 04:54:16\n","loss: 0.7740, acc: 0.6641\n","E2E-ABSA >>> 2022-09-02 04:54:17\n","loss: 0.7438, acc: 0.6866\n","E2E-ABSA >>> 2022-09-02 04:54:18\n","loss: 0.7412, acc: 0.6870\n","E2E-ABSA >>> 2022-09-02 04:54:19\n",">>> val_acc: 0.6531, val_precision: 0.6531 val_recall: 0.6531, val_f1: 0.6531\n",">> saved: state_dict/td_lstm_acl14shortdata_know_val_f1_0.6531\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 96.\n","E2E-ABSA >>> 2022-09-02 04:54:19\n","loss: 0.7650, acc: 0.6582\n","E2E-ABSA >>> 2022-09-02 04:54:20\n","loss: 0.7404, acc: 0.6790\n","E2E-ABSA >>> 2022-09-02 04:54:21\n","loss: 0.7411, acc: 0.6862\n","E2E-ABSA >>> 2022-09-02 04:54:22\n",">>> val_acc: 0.6419, val_precision: 0.6419 val_recall: 0.6419, val_f1: 0.6419\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 97.\n","E2E-ABSA >>> 2022-09-02 04:54:22\n","loss: 0.7001, acc: 0.7057\n","E2E-ABSA >>> 2022-09-02 04:54:23\n","loss: 0.7393, acc: 0.6835\n","E2E-ABSA >>> 2022-09-02 04:54:24\n","loss: 0.7384, acc: 0.6858\n","E2E-ABSA >>> 2022-09-02 04:54:25\n",">>> val_acc: 0.6475, val_precision: 0.6475 val_recall: 0.6475, val_f1: 0.6475\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 98.\n","E2E-ABSA >>> 2022-09-02 04:54:26\n","loss: 0.7534, acc: 0.6914\n","E2E-ABSA >>> 2022-09-02 04:54:27\n","loss: 0.7528, acc: 0.6681\n","E2E-ABSA >>> 2022-09-02 04:54:28\n","loss: 0.7368, acc: 0.6837\n","E2E-ABSA >>> 2022-09-02 04:54:29\n",">>> val_acc: 0.6531, val_precision: 0.6531 val_recall: 0.6531, val_f1: 0.6531\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 99.\n","E2E-ABSA >>> 2022-09-02 04:54:29\n","loss: 0.7237, acc: 0.6641\n","E2E-ABSA >>> 2022-09-02 04:54:30\n","loss: 0.7431, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 04:54:31\n","loss: 0.7369, acc: 0.6869\n","E2E-ABSA >>> 2022-09-02 04:54:32\n","loss: 0.7363, acc: 0.6864\n","E2E-ABSA >>> 2022-09-02 04:54:32\n",">>> val_acc: 0.6494, val_precision: 0.6494 val_recall: 0.6494, val_f1: 0.6494\n","you can download the best model from state_dict/td_lstm_acl14shortdata_know_val_f1_0.6531\n",">>> test_acc: 0.6531, test_precision: 0.6531, test_recall: 0.6531, test_f1: 0.6531\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **acl14shortdata** dataset on model(**TCLSTM**)\n"],"metadata":{"id":"ifC0IDucV_GV"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name tc_lstm --dataset acl14shortdata_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ElgpXGOV_KZ","outputId":"0dd7b021-f5ce-4ee1-b6ed-d650cd9c76ca","executionInfo":{"status":"ok","timestamp":1662094889767,"user_tz":-480,"elapsed":415206,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 4917.\n","> testing dataset count: 539.\n","cuda memory allocated: 25445376\n","> n_trainable_params: 2166603, n_nontrainable_params: 4136100\n","> training arguments:\n",">>> model_name: tc_lstm\n",">>> dataset: acl14shortdata_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f379e250c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.tc_lstm.TC_LSTM'>\n",">>> dataset_file: {'train': './datasets/acl14shortdata/output_know_insert/train.tsv', 'test': './datasets/acl14shortdata/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['left_with_aspect_indices', 'right_with_aspect_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 04:55:13\n","loss: 1.0553, acc: 0.4344\n","E2E-ABSA >>> 2022-09-02 04:55:15\n","loss: 1.0233, acc: 0.4831\n","E2E-ABSA >>> 2022-09-02 04:55:16\n","loss: 1.0069, acc: 0.5004\n","E2E-ABSA >>> 2022-09-02 04:55:16\n",">>> val_acc: 0.5213, val_precision: 0.5213 val_recall: 0.5213, val_f1: 0.5213\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.5213\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 04:55:17\n","loss: 0.9617, acc: 0.5442\n","E2E-ABSA >>> 2022-09-02 04:55:18\n","loss: 0.9513, acc: 0.5521\n","E2E-ABSA >>> 2022-09-02 04:55:19\n","loss: 0.9459, acc: 0.5571\n","E2E-ABSA >>> 2022-09-02 04:55:20\n",">>> val_acc: 0.5436, val_precision: 0.5436 val_recall: 0.5436, val_f1: 0.5436\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.5436\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 04:55:21\n","loss: 0.9085, acc: 0.5789\n","E2E-ABSA >>> 2022-09-02 04:55:22\n","loss: 0.9243, acc: 0.5717\n","E2E-ABSA >>> 2022-09-02 04:55:23\n","loss: 0.9263, acc: 0.5744\n","E2E-ABSA >>> 2022-09-02 04:55:24\n",">>> val_acc: 0.5417, val_precision: 0.5417 val_recall: 0.5417, val_f1: 0.5417\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 04:55:24\n","loss: 0.9024, acc: 0.6020\n","E2E-ABSA >>> 2022-09-02 04:55:26\n","loss: 0.9149, acc: 0.5856\n","E2E-ABSA >>> 2022-09-02 04:55:27\n","loss: 0.9123, acc: 0.5836\n","E2E-ABSA >>> 2022-09-02 04:55:27\n",">>> val_acc: 0.5529, val_precision: 0.5529 val_recall: 0.5529, val_f1: 0.5529\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.5529\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 04:55:28\n","loss: 0.9006, acc: 0.5938\n","E2E-ABSA >>> 2022-09-02 04:55:29\n","loss: 0.9008, acc: 0.5926\n","E2E-ABSA >>> 2022-09-02 04:55:30\n","loss: 0.9009, acc: 0.5884\n","E2E-ABSA >>> 2022-09-02 04:55:31\n",">>> val_acc: 0.5622, val_precision: 0.5622 val_recall: 0.5622, val_f1: 0.5622\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.5622\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 04:55:32\n","loss: 0.8833, acc: 0.6062\n","E2E-ABSA >>> 2022-09-02 04:55:33\n","loss: 0.8898, acc: 0.6039\n","E2E-ABSA >>> 2022-09-02 04:55:35\n","loss: 0.8819, acc: 0.6029\n","E2E-ABSA >>> 2022-09-02 04:55:35\n",">>> val_acc: 0.5714, val_precision: 0.5714 val_recall: 0.5714, val_f1: 0.5714\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.5714\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 04:55:36\n","loss: 0.8911, acc: 0.5962\n","E2E-ABSA >>> 2022-09-02 04:55:37\n","loss: 0.8819, acc: 0.6012\n","E2E-ABSA >>> 2022-09-02 04:55:38\n","loss: 0.8781, acc: 0.6029\n","E2E-ABSA >>> 2022-09-02 04:55:39\n",">>> val_acc: 0.5751, val_precision: 0.5751 val_recall: 0.5751, val_f1: 0.5751\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.5751\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 04:55:40\n","loss: 0.8402, acc: 0.6264\n","E2E-ABSA >>> 2022-09-02 04:55:41\n","loss: 0.8609, acc: 0.6076\n","E2E-ABSA >>> 2022-09-02 04:55:42\n","loss: 0.8586, acc: 0.6158\n","E2E-ABSA >>> 2022-09-02 04:55:43\n",">>> val_acc: 0.5937, val_precision: 0.5937 val_recall: 0.5937, val_f1: 0.5937\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.5937\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 04:55:43\n","loss: 0.8694, acc: 0.6285\n","E2E-ABSA >>> 2022-09-02 04:55:44\n","loss: 0.8480, acc: 0.6245\n","E2E-ABSA >>> 2022-09-02 04:55:46\n","loss: 0.8453, acc: 0.6247\n","E2E-ABSA >>> 2022-09-02 04:55:47\n",">>> val_acc: 0.5863, val_precision: 0.5863 val_recall: 0.5863, val_f1: 0.5863\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 04:55:47\n","loss: 0.8314, acc: 0.6317\n","E2E-ABSA >>> 2022-09-02 04:55:48\n","loss: 0.8413, acc: 0.6294\n","E2E-ABSA >>> 2022-09-02 04:55:49\n","loss: 0.8340, acc: 0.6362\n","E2E-ABSA >>> 2022-09-02 04:55:50\n",">>> val_acc: 0.5881, val_precision: 0.5881 val_recall: 0.5881, val_f1: 0.5881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 04:55:51\n","loss: 0.7863, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 04:55:52\n","loss: 0.8295, acc: 0.6323\n","E2E-ABSA >>> 2022-09-02 04:55:53\n","loss: 0.8258, acc: 0.6378\n","E2E-ABSA >>> 2022-09-02 04:55:54\n",">>> val_acc: 0.5955, val_precision: 0.5955 val_recall: 0.5955, val_f1: 0.5955\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.5955\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 04:55:54\n","loss: 0.8787, acc: 0.5781\n","E2E-ABSA >>> 2022-09-02 04:55:55\n","loss: 0.8142, acc: 0.6512\n","E2E-ABSA >>> 2022-09-02 04:55:57\n","loss: 0.8113, acc: 0.6480\n","E2E-ABSA >>> 2022-09-02 04:55:58\n",">>> val_acc: 0.6048, val_precision: 0.6048 val_recall: 0.6048, val_f1: 0.6048\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 04:55:58\n","loss: 0.8387, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 04:55:59\n","loss: 0.7950, acc: 0.6569\n","E2E-ABSA >>> 2022-09-02 04:56:00\n","loss: 0.7912, acc: 0.6590\n","E2E-ABSA >>> 2022-09-02 04:56:01\n","loss: 0.8036, acc: 0.6491\n","E2E-ABSA >>> 2022-09-02 04:56:02\n",">>> val_acc: 0.6085, val_precision: 0.6085 val_recall: 0.6085, val_f1: 0.6085\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6085\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 04:56:03\n","loss: 0.8042, acc: 0.6478\n","E2E-ABSA >>> 2022-09-02 04:56:04\n","loss: 0.7982, acc: 0.6499\n","E2E-ABSA >>> 2022-09-02 04:56:05\n","loss: 0.7931, acc: 0.6554\n","E2E-ABSA >>> 2022-09-02 04:56:05\n",">>> val_acc: 0.6048, val_precision: 0.6048 val_recall: 0.6048, val_f1: 0.6048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 04:56:06\n","loss: 0.7703, acc: 0.6676\n","E2E-ABSA >>> 2022-09-02 04:56:07\n","loss: 0.7870, acc: 0.6569\n","E2E-ABSA >>> 2022-09-02 04:56:09\n","loss: 0.7879, acc: 0.6569\n","E2E-ABSA >>> 2022-09-02 04:56:09\n",">>> val_acc: 0.6141, val_precision: 0.6141 val_recall: 0.6141, val_f1: 0.6141\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6141\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 04:56:10\n","loss: 0.7863, acc: 0.6438\n","E2E-ABSA >>> 2022-09-02 04:56:11\n","loss: 0.7867, acc: 0.6517\n","E2E-ABSA >>> 2022-09-02 04:56:12\n","loss: 0.7806, acc: 0.6583\n","E2E-ABSA >>> 2022-09-02 04:56:13\n",">>> val_acc: 0.6141, val_precision: 0.6141 val_recall: 0.6141, val_f1: 0.6141\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 04:56:14\n","loss: 0.7458, acc: 0.6832\n","E2E-ABSA >>> 2022-09-02 04:56:15\n","loss: 0.7730, acc: 0.6646\n","E2E-ABSA >>> 2022-09-02 04:56:16\n","loss: 0.7741, acc: 0.6625\n","E2E-ABSA >>> 2022-09-02 04:56:17\n",">>> val_acc: 0.6085, val_precision: 0.6085 val_recall: 0.6085, val_f1: 0.6085\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 04:56:17\n","loss: 0.7674, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 04:56:18\n","loss: 0.7741, acc: 0.6555\n","E2E-ABSA >>> 2022-09-02 04:56:20\n","loss: 0.7756, acc: 0.6600\n","E2E-ABSA >>> 2022-09-02 04:56:20\n",">>> val_acc: 0.6141, val_precision: 0.6141 val_recall: 0.6141, val_f1: 0.6141\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 04:56:21\n","loss: 0.7570, acc: 0.6741\n","E2E-ABSA >>> 2022-09-02 04:56:22\n","loss: 0.7785, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 04:56:23\n","loss: 0.7714, acc: 0.6606\n","E2E-ABSA >>> 2022-09-02 04:56:24\n",">>> val_acc: 0.6178, val_precision: 0.6178 val_recall: 0.6178, val_f1: 0.6178\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6178\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 04:56:25\n","loss: 0.7826, acc: 0.6458\n","E2E-ABSA >>> 2022-09-02 04:56:26\n","loss: 0.7749, acc: 0.6546\n","E2E-ABSA >>> 2022-09-02 04:56:27\n","loss: 0.7706, acc: 0.6603\n","E2E-ABSA >>> 2022-09-02 04:56:28\n",">>> val_acc: 0.6160, val_precision: 0.6160 val_recall: 0.6160, val_f1: 0.6160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 04:56:28\n","loss: 0.7713, acc: 0.6438\n","E2E-ABSA >>> 2022-09-02 04:56:29\n","loss: 0.7759, acc: 0.6558\n","E2E-ABSA >>> 2022-09-02 04:56:31\n","loss: 0.7703, acc: 0.6604\n","E2E-ABSA >>> 2022-09-02 04:56:31\n",">>> val_acc: 0.6160, val_precision: 0.6160 val_recall: 0.6160, val_f1: 0.6160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 04:56:32\n","loss: 0.7316, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 04:56:33\n","loss: 0.7365, acc: 0.6861\n","E2E-ABSA >>> 2022-09-02 04:56:34\n","loss: 0.7535, acc: 0.6711\n","E2E-ABSA >>> 2022-09-02 04:56:35\n",">>> val_acc: 0.6141, val_precision: 0.6141 val_recall: 0.6141, val_f1: 0.6141\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 04:56:35\n","loss: 0.7492, acc: 0.6745\n","E2E-ABSA >>> 2022-09-02 04:56:37\n","loss: 0.7611, acc: 0.6683\n","E2E-ABSA >>> 2022-09-02 04:56:38\n","loss: 0.7532, acc: 0.6738\n","E2E-ABSA >>> 2022-09-02 04:56:39\n",">>> val_acc: 0.6234, val_precision: 0.6234 val_recall: 0.6234, val_f1: 0.6234\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6234\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 04:56:39\n","loss: 0.7727, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:56:40\n","loss: 0.7368, acc: 0.6800\n","E2E-ABSA >>> 2022-09-02 04:56:41\n","loss: 0.7545, acc: 0.6696\n","E2E-ABSA >>> 2022-09-02 04:56:43\n",">>> val_acc: 0.6289, val_precision: 0.6289 val_recall: 0.6289, val_f1: 0.6289\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6289\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 04:56:43\n","loss: 0.7272, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 04:56:44\n","loss: 0.7605, acc: 0.6748\n","E2E-ABSA >>> 2022-09-02 04:56:45\n","loss: 0.7584, acc: 0.6755\n","E2E-ABSA >>> 2022-09-02 04:56:46\n","loss: 0.7556, acc: 0.6752\n","E2E-ABSA >>> 2022-09-02 04:56:46\n",">>> val_acc: 0.6197, val_precision: 0.6197 val_recall: 0.6197, val_f1: 0.6197\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 04:56:48\n","loss: 0.7388, acc: 0.6744\n","E2E-ABSA >>> 2022-09-02 04:56:49\n","loss: 0.7452, acc: 0.6778\n","E2E-ABSA >>> 2022-09-02 04:56:50\n","loss: 0.7526, acc: 0.6773\n","E2E-ABSA >>> 2022-09-02 04:56:50\n",">>> val_acc: 0.6271, val_precision: 0.6271 val_recall: 0.6271, val_f1: 0.6271\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 04:56:51\n","loss: 0.7395, acc: 0.6821\n","E2E-ABSA >>> 2022-09-02 04:56:52\n","loss: 0.7483, acc: 0.6774\n","E2E-ABSA >>> 2022-09-02 04:56:54\n","loss: 0.7500, acc: 0.6766\n","E2E-ABSA >>> 2022-09-02 04:56:54\n",">>> val_acc: 0.6215, val_precision: 0.6215 val_recall: 0.6215, val_f1: 0.6215\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 04:56:55\n","loss: 0.7364, acc: 0.6882\n","E2E-ABSA >>> 2022-09-02 04:56:56\n","loss: 0.7368, acc: 0.6814\n","E2E-ABSA >>> 2022-09-02 04:56:57\n","loss: 0.7482, acc: 0.6776\n","E2E-ABSA >>> 2022-09-02 04:56:58\n",">>> val_acc: 0.6308, val_precision: 0.6308 val_recall: 0.6308, val_f1: 0.6308\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6308\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 04:56:59\n","loss: 0.7432, acc: 0.6850\n","E2E-ABSA >>> 2022-09-02 04:57:00\n","loss: 0.7481, acc: 0.6804\n","E2E-ABSA >>> 2022-09-02 04:57:01\n","loss: 0.7490, acc: 0.6739\n","E2E-ABSA >>> 2022-09-02 04:57:01\n",">>> val_acc: 0.6308, val_precision: 0.6308 val_recall: 0.6308, val_f1: 0.6308\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 04:57:02\n","loss: 0.7306, acc: 0.6783\n","E2E-ABSA >>> 2022-09-02 04:57:03\n","loss: 0.7369, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 04:57:04\n","loss: 0.7452, acc: 0.6784\n","E2E-ABSA >>> 2022-09-02 04:57:05\n",">>> val_acc: 0.6308, val_precision: 0.6308 val_recall: 0.6308, val_f1: 0.6308\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 04:57:06\n","loss: 0.7359, acc: 0.6740\n","E2E-ABSA >>> 2022-09-02 04:57:07\n","loss: 0.7322, acc: 0.6879\n","E2E-ABSA >>> 2022-09-02 04:57:08\n","loss: 0.7409, acc: 0.6796\n","E2E-ABSA >>> 2022-09-02 04:57:09\n",">>> val_acc: 0.6289, val_precision: 0.6289 val_recall: 0.6289, val_f1: 0.6289\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 04:57:09\n","loss: 0.7248, acc: 0.6959\n","E2E-ABSA >>> 2022-09-02 04:57:11\n","loss: 0.7368, acc: 0.6887\n","E2E-ABSA >>> 2022-09-02 04:57:12\n","loss: 0.7336, acc: 0.6907\n","E2E-ABSA >>> 2022-09-02 04:57:13\n",">>> val_acc: 0.6345, val_precision: 0.6345 val_recall: 0.6345, val_f1: 0.6345\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6345\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 04:57:13\n","loss: 0.7696, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 04:57:14\n","loss: 0.7496, acc: 0.6858\n","E2E-ABSA >>> 2022-09-02 04:57:15\n","loss: 0.7408, acc: 0.6844\n","E2E-ABSA >>> 2022-09-02 04:57:16\n",">>> val_acc: 0.6345, val_precision: 0.6345 val_recall: 0.6345, val_f1: 0.6345\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 04:57:17\n","loss: 0.7444, acc: 0.6771\n","E2E-ABSA >>> 2022-09-02 04:57:18\n","loss: 0.7517, acc: 0.6691\n","E2E-ABSA >>> 2022-09-02 04:57:19\n","loss: 0.7458, acc: 0.6777\n","E2E-ABSA >>> 2022-09-02 04:57:20\n",">>> val_acc: 0.6289, val_precision: 0.6289 val_recall: 0.6289, val_f1: 0.6289\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 04:57:20\n","loss: 0.7675, acc: 0.6763\n","E2E-ABSA >>> 2022-09-02 04:57:21\n","loss: 0.7419, acc: 0.6826\n","E2E-ABSA >>> 2022-09-02 04:57:23\n","loss: 0.7367, acc: 0.6809\n","E2E-ABSA >>> 2022-09-02 04:57:24\n",">>> val_acc: 0.6345, val_precision: 0.6345 val_recall: 0.6345, val_f1: 0.6345\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 04:57:24\n","loss: 0.7045, acc: 0.6906\n","E2E-ABSA >>> 2022-09-02 04:57:25\n","loss: 0.7366, acc: 0.6760\n","E2E-ABSA >>> 2022-09-02 04:57:26\n","loss: 0.7431, acc: 0.6778\n","E2E-ABSA >>> 2022-09-02 04:57:27\n",">>> val_acc: 0.6401, val_precision: 0.6401 val_recall: 0.6401, val_f1: 0.6401\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6401\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 04:57:28\n","loss: 0.6280, acc: 0.7760\n","E2E-ABSA >>> 2022-09-02 04:57:29\n","loss: 0.7222, acc: 0.6942\n","E2E-ABSA >>> 2022-09-02 04:57:30\n","loss: 0.7305, acc: 0.6899\n","E2E-ABSA >>> 2022-09-02 04:57:31\n",">>> val_acc: 0.6289, val_precision: 0.6289 val_recall: 0.6289, val_f1: 0.6289\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 04:57:31\n","loss: 0.7341, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 04:57:32\n","loss: 0.7347, acc: 0.6815\n","E2E-ABSA >>> 2022-09-02 04:57:34\n","loss: 0.7234, acc: 0.6936\n","E2E-ABSA >>> 2022-09-02 04:57:35\n","loss: 0.7353, acc: 0.6889\n","E2E-ABSA >>> 2022-09-02 04:57:35\n",">>> val_acc: 0.6382, val_precision: 0.6382 val_recall: 0.6382, val_f1: 0.6382\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 04:57:37\n","loss: 0.7323, acc: 0.6823\n","E2E-ABSA >>> 2022-09-02 04:57:38\n","loss: 0.7370, acc: 0.6783\n","E2E-ABSA >>> 2022-09-02 04:57:39\n","loss: 0.7335, acc: 0.6805\n","E2E-ABSA >>> 2022-09-02 04:57:39\n",">>> val_acc: 0.6345, val_precision: 0.6345 val_recall: 0.6345, val_f1: 0.6345\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 04:57:40\n","loss: 0.7231, acc: 0.6989\n","E2E-ABSA >>> 2022-09-02 04:57:41\n","loss: 0.7379, acc: 0.6812\n","E2E-ABSA >>> 2022-09-02 04:57:42\n","loss: 0.7359, acc: 0.6801\n","E2E-ABSA >>> 2022-09-02 04:57:43\n",">>> val_acc: 0.6382, val_precision: 0.6382 val_recall: 0.6382, val_f1: 0.6382\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 04:57:44\n","loss: 0.7253, acc: 0.7000\n","E2E-ABSA >>> 2022-09-02 04:57:45\n","loss: 0.7270, acc: 0.6892\n","E2E-ABSA >>> 2022-09-02 04:57:46\n","loss: 0.7316, acc: 0.6866\n","E2E-ABSA >>> 2022-09-02 04:57:47\n",">>> val_acc: 0.6401, val_precision: 0.6401 val_recall: 0.6401, val_f1: 0.6401\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 04:57:47\n","loss: 0.6904, acc: 0.7153\n","E2E-ABSA >>> 2022-09-02 04:57:49\n","loss: 0.7169, acc: 0.6893\n","E2E-ABSA >>> 2022-09-02 04:57:50\n","loss: 0.7240, acc: 0.6909\n","E2E-ABSA >>> 2022-09-02 04:57:50\n",">>> val_acc: 0.6364, val_precision: 0.6364 val_recall: 0.6364, val_f1: 0.6364\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 04:57:51\n","loss: 0.7538, acc: 0.6689\n","E2E-ABSA >>> 2022-09-02 04:57:52\n","loss: 0.7392, acc: 0.6818\n","E2E-ABSA >>> 2022-09-02 04:57:53\n","loss: 0.7263, acc: 0.6903\n","E2E-ABSA >>> 2022-09-02 04:57:54\n",">>> val_acc: 0.6364, val_precision: 0.6364 val_recall: 0.6364, val_f1: 0.6364\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 04:57:55\n","loss: 0.7335, acc: 0.6763\n","E2E-ABSA >>> 2022-09-02 04:57:56\n","loss: 0.7439, acc: 0.6775\n","E2E-ABSA >>> 2022-09-02 04:57:57\n","loss: 0.7299, acc: 0.6846\n","E2E-ABSA >>> 2022-09-02 04:57:58\n",">>> val_acc: 0.6327, val_precision: 0.6327 val_recall: 0.6327, val_f1: 0.6327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 04:57:58\n","loss: 0.7510, acc: 0.6732\n","E2E-ABSA >>> 2022-09-02 04:58:00\n","loss: 0.7244, acc: 0.6896\n","E2E-ABSA >>> 2022-09-02 04:58:01\n","loss: 0.7208, acc: 0.6943\n","E2E-ABSA >>> 2022-09-02 04:58:02\n",">>> val_acc: 0.6401, val_precision: 0.6401 val_recall: 0.6401, val_f1: 0.6401\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 04:58:02\n","loss: 0.7536, acc: 0.6469\n","E2E-ABSA >>> 2022-09-02 04:58:03\n","loss: 0.7372, acc: 0.6817\n","E2E-ABSA >>> 2022-09-02 04:58:04\n","loss: 0.7325, acc: 0.6859\n","E2E-ABSA >>> 2022-09-02 04:58:05\n",">>> val_acc: 0.6382, val_precision: 0.6382 val_recall: 0.6382, val_f1: 0.6382\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 04:58:06\n","loss: 0.7015, acc: 0.7148\n","E2E-ABSA >>> 2022-09-02 04:58:07\n","loss: 0.7073, acc: 0.6932\n","E2E-ABSA >>> 2022-09-02 04:58:08\n","loss: 0.7225, acc: 0.6899\n","E2E-ABSA >>> 2022-09-02 04:58:09\n",">>> val_acc: 0.6438, val_precision: 0.6438 val_recall: 0.6438, val_f1: 0.6438\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6438\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 04:58:09\n","loss: 0.7040, acc: 0.6901\n","E2E-ABSA >>> 2022-09-02 04:58:10\n","loss: 0.7044, acc: 0.7061\n","E2E-ABSA >>> 2022-09-02 04:58:12\n","loss: 0.7144, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 04:58:13\n",">>> val_acc: 0.6531, val_precision: 0.6531 val_recall: 0.6531, val_f1: 0.6531\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6531\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 04:58:13\n","loss: 0.6910, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 04:58:14\n","loss: 0.7142, acc: 0.6918\n","E2E-ABSA >>> 2022-09-02 04:58:15\n","loss: 0.7175, acc: 0.6918\n","E2E-ABSA >>> 2022-09-02 04:58:17\n",">>> val_acc: 0.6475, val_precision: 0.6475 val_recall: 0.6475, val_f1: 0.6475\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 04:58:17\n","loss: 0.6620, acc: 0.7266\n","E2E-ABSA >>> 2022-09-02 04:58:18\n","loss: 0.7301, acc: 0.6788\n","E2E-ABSA >>> 2022-09-02 04:58:19\n","loss: 0.7234, acc: 0.6854\n","E2E-ABSA >>> 2022-09-02 04:58:20\n","loss: 0.7232, acc: 0.6882\n","E2E-ABSA >>> 2022-09-02 04:58:20\n",">>> val_acc: 0.6438, val_precision: 0.6438 val_recall: 0.6438, val_f1: 0.6438\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 04:58:21\n","loss: 0.7345, acc: 0.6787\n","E2E-ABSA >>> 2022-09-02 04:58:23\n","loss: 0.7148, acc: 0.6937\n","E2E-ABSA >>> 2022-09-02 04:58:24\n","loss: 0.7233, acc: 0.6915\n","E2E-ABSA >>> 2022-09-02 04:58:24\n",">>> val_acc: 0.6364, val_precision: 0.6364 val_recall: 0.6364, val_f1: 0.6364\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 04:58:25\n","loss: 0.7055, acc: 0.6916\n","E2E-ABSA >>> 2022-09-02 04:58:26\n","loss: 0.7171, acc: 0.6940\n","E2E-ABSA >>> 2022-09-02 04:58:27\n","loss: 0.7163, acc: 0.6937\n","E2E-ABSA >>> 2022-09-02 04:58:28\n",">>> val_acc: 0.6494, val_precision: 0.6494 val_recall: 0.6494, val_f1: 0.6494\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 04:58:29\n","loss: 0.7288, acc: 0.6897\n","E2E-ABSA >>> 2022-09-02 04:58:30\n","loss: 0.7201, acc: 0.6912\n","E2E-ABSA >>> 2022-09-02 04:58:31\n","loss: 0.7172, acc: 0.6912\n","E2E-ABSA >>> 2022-09-02 04:58:31\n",">>> val_acc: 0.6419, val_precision: 0.6419 val_recall: 0.6419, val_f1: 0.6419\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 04:58:32\n","loss: 0.6740, acc: 0.7253\n","E2E-ABSA >>> 2022-09-02 04:58:33\n","loss: 0.6943, acc: 0.7127\n","E2E-ABSA >>> 2022-09-02 04:58:35\n","loss: 0.7130, acc: 0.6986\n","E2E-ABSA >>> 2022-09-02 04:58:35\n",">>> val_acc: 0.6549, val_precision: 0.6549 val_recall: 0.6549, val_f1: 0.6549\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6549\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 04:58:36\n","loss: 0.7121, acc: 0.6994\n","E2E-ABSA >>> 2022-09-02 04:58:37\n","loss: 0.7082, acc: 0.7046\n","E2E-ABSA >>> 2022-09-02 04:58:38\n","loss: 0.7170, acc: 0.6978\n","E2E-ABSA >>> 2022-09-02 04:58:39\n",">>> val_acc: 0.6401, val_precision: 0.6401 val_recall: 0.6401, val_f1: 0.6401\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 04:58:40\n","loss: 0.7128, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 04:58:41\n","loss: 0.7233, acc: 0.6844\n","E2E-ABSA >>> 2022-09-02 04:58:42\n","loss: 0.7167, acc: 0.6923\n","E2E-ABSA >>> 2022-09-02 04:58:43\n",">>> val_acc: 0.6475, val_precision: 0.6475 val_recall: 0.6475, val_f1: 0.6475\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 04:58:43\n","loss: 0.6982, acc: 0.6911\n","E2E-ABSA >>> 2022-09-02 04:58:44\n","loss: 0.7054, acc: 0.6945\n","E2E-ABSA >>> 2022-09-02 04:58:46\n","loss: 0.7140, acc: 0.6897\n","E2E-ABSA >>> 2022-09-02 04:58:46\n",">>> val_acc: 0.6456, val_precision: 0.6456 val_recall: 0.6456, val_f1: 0.6456\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 04:58:47\n","loss: 0.7394, acc: 0.6832\n","E2E-ABSA >>> 2022-09-02 04:58:48\n","loss: 0.7021, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 04:58:49\n","loss: 0.7170, acc: 0.6929\n","E2E-ABSA >>> 2022-09-02 04:58:50\n",">>> val_acc: 0.6456, val_precision: 0.6456 val_recall: 0.6456, val_f1: 0.6456\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 04:58:50\n","loss: 0.7182, acc: 0.6997\n","E2E-ABSA >>> 2022-09-02 04:58:52\n","loss: 0.7176, acc: 0.6898\n","E2E-ABSA >>> 2022-09-02 04:58:53\n","loss: 0.7099, acc: 0.6962\n","E2E-ABSA >>> 2022-09-02 04:58:54\n",">>> val_acc: 0.6531, val_precision: 0.6531 val_recall: 0.6531, val_f1: 0.6531\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 04:58:54\n","loss: 0.6950, acc: 0.7076\n","E2E-ABSA >>> 2022-09-02 04:58:55\n","loss: 0.7089, acc: 0.6924\n","E2E-ABSA >>> 2022-09-02 04:58:56\n","loss: 0.7088, acc: 0.6965\n","E2E-ABSA >>> 2022-09-02 04:58:58\n",">>> val_acc: 0.6512, val_precision: 0.6512 val_recall: 0.6512, val_f1: 0.6512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 04:58:58\n","loss: 0.7060, acc: 0.6937\n","E2E-ABSA >>> 2022-09-02 04:58:59\n","loss: 0.7052, acc: 0.7005\n","E2E-ABSA >>> 2022-09-02 04:59:00\n","loss: 0.7038, acc: 0.7000\n","E2E-ABSA >>> 2022-09-02 04:59:01\n",">>> val_acc: 0.6401, val_precision: 0.6401 val_recall: 0.6401, val_f1: 0.6401\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 04:59:01\n","loss: 0.6131, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 04:59:03\n","loss: 0.6991, acc: 0.7048\n","E2E-ABSA >>> 2022-09-02 04:59:04\n","loss: 0.7099, acc: 0.7002\n","E2E-ABSA >>> 2022-09-02 04:59:05\n",">>> val_acc: 0.6494, val_precision: 0.6494 val_recall: 0.6494, val_f1: 0.6494\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 04:59:05\n","loss: 0.7997, acc: 0.6406\n","E2E-ABSA >>> 2022-09-02 04:59:06\n","loss: 0.7196, acc: 0.7085\n","E2E-ABSA >>> 2022-09-02 04:59:07\n","loss: 0.7147, acc: 0.7093\n","E2E-ABSA >>> 2022-09-02 04:59:09\n","loss: 0.7122, acc: 0.7021\n","E2E-ABSA >>> 2022-09-02 04:59:09\n",">>> val_acc: 0.6419, val_precision: 0.6419 val_recall: 0.6419, val_f1: 0.6419\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 04:59:10\n","loss: 0.7026, acc: 0.7070\n","E2E-ABSA >>> 2022-09-02 04:59:11\n","loss: 0.7033, acc: 0.7066\n","E2E-ABSA >>> 2022-09-02 04:59:12\n","loss: 0.7108, acc: 0.7012\n","E2E-ABSA >>> 2022-09-02 04:59:13\n",">>> val_acc: 0.6512, val_precision: 0.6512 val_recall: 0.6512, val_f1: 0.6512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 04:59:14\n","loss: 0.7085, acc: 0.7116\n","E2E-ABSA >>> 2022-09-02 04:59:15\n","loss: 0.7162, acc: 0.6981\n","E2E-ABSA >>> 2022-09-02 04:59:16\n","loss: 0.7098, acc: 0.6990\n","E2E-ABSA >>> 2022-09-02 04:59:16\n",">>> val_acc: 0.6549, val_precision: 0.6549 val_recall: 0.6549, val_f1: 0.6549\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 04:59:17\n","loss: 0.7319, acc: 0.6852\n","E2E-ABSA >>> 2022-09-02 04:59:18\n","loss: 0.7185, acc: 0.6962\n","E2E-ABSA >>> 2022-09-02 04:59:19\n","loss: 0.7069, acc: 0.7011\n","E2E-ABSA >>> 2022-09-02 04:59:20\n",">>> val_acc: 0.6549, val_precision: 0.6549 val_recall: 0.6549, val_f1: 0.6549\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 04:59:21\n","loss: 0.7189, acc: 0.6962\n","E2E-ABSA >>> 2022-09-02 04:59:22\n","loss: 0.7045, acc: 0.7097\n","E2E-ABSA >>> 2022-09-02 04:59:23\n","loss: 0.7040, acc: 0.7027\n","E2E-ABSA >>> 2022-09-02 04:59:24\n",">>> val_acc: 0.6586, val_precision: 0.6586 val_recall: 0.6586, val_f1: 0.6586\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6586\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 04:59:25\n","loss: 0.6806, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 04:59:26\n","loss: 0.7038, acc: 0.7005\n","E2E-ABSA >>> 2022-09-02 04:59:27\n","loss: 0.7125, acc: 0.6977\n","E2E-ABSA >>> 2022-09-02 04:59:28\n",">>> val_acc: 0.6549, val_precision: 0.6549 val_recall: 0.6549, val_f1: 0.6549\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","E2E-ABSA >>> 2022-09-02 04:59:28\n","loss: 0.7038, acc: 0.7087\n","E2E-ABSA >>> 2022-09-02 04:59:29\n","loss: 0.6990, acc: 0.7047\n","E2E-ABSA >>> 2022-09-02 04:59:30\n","loss: 0.7113, acc: 0.6951\n","E2E-ABSA >>> 2022-09-02 04:59:31\n",">>> val_acc: 0.6568, val_precision: 0.6568 val_recall: 0.6568, val_f1: 0.6568\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","E2E-ABSA >>> 2022-09-02 04:59:32\n","loss: 0.6743, acc: 0.7096\n","E2E-ABSA >>> 2022-09-02 04:59:33\n","loss: 0.6905, acc: 0.7095\n","E2E-ABSA >>> 2022-09-02 04:59:35\n","loss: 0.7018, acc: 0.7009\n","E2E-ABSA >>> 2022-09-02 04:59:36\n",">>> val_acc: 0.6494, val_precision: 0.6494 val_recall: 0.6494, val_f1: 0.6494\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","E2E-ABSA >>> 2022-09-02 04:59:36\n","loss: 0.7248, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 04:59:37\n","loss: 0.7153, acc: 0.6960\n","E2E-ABSA >>> 2022-09-02 04:59:38\n","loss: 0.7028, acc: 0.7016\n","E2E-ABSA >>> 2022-09-02 04:59:39\n",">>> val_acc: 0.6531, val_precision: 0.6531 val_recall: 0.6531, val_f1: 0.6531\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","E2E-ABSA >>> 2022-09-02 04:59:40\n","loss: 0.7024, acc: 0.6934\n","E2E-ABSA >>> 2022-09-02 04:59:41\n","loss: 0.7053, acc: 0.7003\n","E2E-ABSA >>> 2022-09-02 04:59:42\n","loss: 0.7066, acc: 0.6996\n","E2E-ABSA >>> 2022-09-02 04:59:43\n",">>> val_acc: 0.6549, val_precision: 0.6549 val_recall: 0.6549, val_f1: 0.6549\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","E2E-ABSA >>> 2022-09-02 04:59:43\n","loss: 0.7017, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 04:59:44\n","loss: 0.7013, acc: 0.7026\n","E2E-ABSA >>> 2022-09-02 04:59:46\n","loss: 0.6957, acc: 0.7015\n","E2E-ABSA >>> 2022-09-02 04:59:47\n",">>> val_acc: 0.6512, val_precision: 0.6512 val_recall: 0.6512, val_f1: 0.6512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","E2E-ABSA >>> 2022-09-02 04:59:47\n","loss: 0.7288, acc: 0.6523\n","E2E-ABSA >>> 2022-09-02 04:59:48\n","loss: 0.6997, acc: 0.6918\n","E2E-ABSA >>> 2022-09-02 04:59:49\n","loss: 0.6953, acc: 0.7011\n","E2E-ABSA >>> 2022-09-02 04:59:50\n",">>> val_acc: 0.6531, val_precision: 0.6531 val_recall: 0.6531, val_f1: 0.6531\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","E2E-ABSA >>> 2022-09-02 04:59:51\n","loss: 0.7943, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 04:59:52\n","loss: 0.6936, acc: 0.7066\n","E2E-ABSA >>> 2022-09-02 04:59:53\n","loss: 0.7040, acc: 0.6995\n","E2E-ABSA >>> 2022-09-02 04:59:54\n","loss: 0.7003, acc: 0.7016\n","E2E-ABSA >>> 2022-09-02 04:59:54\n",">>> val_acc: 0.6549, val_precision: 0.6549 val_recall: 0.6549, val_f1: 0.6549\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","E2E-ABSA >>> 2022-09-02 04:59:55\n","loss: 0.6831, acc: 0.7087\n","E2E-ABSA >>> 2022-09-02 04:59:56\n","loss: 0.6955, acc: 0.7041\n","E2E-ABSA >>> 2022-09-02 04:59:58\n","loss: 0.6993, acc: 0.7037\n","E2E-ABSA >>> 2022-09-02 04:59:58\n",">>> val_acc: 0.6419, val_precision: 0.6419 val_recall: 0.6419, val_f1: 0.6419\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","E2E-ABSA >>> 2022-09-02 04:59:59\n","loss: 0.6754, acc: 0.7133\n","E2E-ABSA >>> 2022-09-02 05:00:00\n","loss: 0.6948, acc: 0.6995\n","E2E-ABSA >>> 2022-09-02 05:00:01\n","loss: 0.6953, acc: 0.6993\n","E2E-ABSA >>> 2022-09-02 05:00:02\n",">>> val_acc: 0.6512, val_precision: 0.6512 val_recall: 0.6512, val_f1: 0.6512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","E2E-ABSA >>> 2022-09-02 05:00:03\n","loss: 0.6815, acc: 0.7165\n","E2E-ABSA >>> 2022-09-02 05:00:04\n","loss: 0.6810, acc: 0.7137\n","E2E-ABSA >>> 2022-09-02 05:00:05\n","loss: 0.6920, acc: 0.7049\n","E2E-ABSA >>> 2022-09-02 05:00:05\n",">>> val_acc: 0.6512, val_precision: 0.6512 val_recall: 0.6512, val_f1: 0.6512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","E2E-ABSA >>> 2022-09-02 05:00:06\n","loss: 0.6969, acc: 0.7105\n","E2E-ABSA >>> 2022-09-02 05:00:07\n","loss: 0.7038, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 05:00:09\n","loss: 0.6919, acc: 0.7074\n","E2E-ABSA >>> 2022-09-02 05:00:09\n",">>> val_acc: 0.6494, val_precision: 0.6494 val_recall: 0.6494, val_f1: 0.6494\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","E2E-ABSA >>> 2022-09-02 05:00:10\n","loss: 0.6701, acc: 0.7178\n","E2E-ABSA >>> 2022-09-02 05:00:11\n","loss: 0.6844, acc: 0.7132\n","E2E-ABSA >>> 2022-09-02 05:00:12\n","loss: 0.6902, acc: 0.7059\n","E2E-ABSA >>> 2022-09-02 05:00:13\n",">>> val_acc: 0.6475, val_precision: 0.6475 val_recall: 0.6475, val_f1: 0.6475\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","E2E-ABSA >>> 2022-09-02 05:00:14\n","loss: 0.7085, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 05:00:15\n","loss: 0.7050, acc: 0.6965\n","E2E-ABSA >>> 2022-09-02 05:00:16\n","loss: 0.7000, acc: 0.6998\n","E2E-ABSA >>> 2022-09-02 05:00:17\n",">>> val_acc: 0.6456, val_precision: 0.6456 val_recall: 0.6456, val_f1: 0.6456\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","E2E-ABSA >>> 2022-09-02 05:00:17\n","loss: 0.6938, acc: 0.7055\n","E2E-ABSA >>> 2022-09-02 05:00:18\n","loss: 0.6851, acc: 0.7159\n","E2E-ABSA >>> 2022-09-02 05:00:19\n","loss: 0.6978, acc: 0.7019\n","E2E-ABSA >>> 2022-09-02 05:00:20\n",">>> val_acc: 0.6531, val_precision: 0.6531 val_recall: 0.6531, val_f1: 0.6531\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","E2E-ABSA >>> 2022-09-02 05:00:21\n","loss: 0.7000, acc: 0.7003\n","E2E-ABSA >>> 2022-09-02 05:00:22\n","loss: 0.7041, acc: 0.6918\n","E2E-ABSA >>> 2022-09-02 05:00:23\n","loss: 0.6945, acc: 0.6988\n","E2E-ABSA >>> 2022-09-02 05:00:24\n",">>> val_acc: 0.6568, val_precision: 0.6568 val_recall: 0.6568, val_f1: 0.6568\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","E2E-ABSA >>> 2022-09-02 05:00:24\n","loss: 0.7112, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 05:00:26\n","loss: 0.7021, acc: 0.7059\n","E2E-ABSA >>> 2022-09-02 05:00:27\n","loss: 0.6938, acc: 0.7066\n","E2E-ABSA >>> 2022-09-02 05:00:28\n",">>> val_acc: 0.6605, val_precision: 0.6605 val_recall: 0.6605, val_f1: 0.6605\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.6605\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","E2E-ABSA >>> 2022-09-02 05:00:28\n","loss: 0.6873, acc: 0.6942\n","E2E-ABSA >>> 2022-09-02 05:00:29\n","loss: 0.6777, acc: 0.7065\n","E2E-ABSA >>> 2022-09-02 05:00:30\n","loss: 0.6778, acc: 0.7072\n","E2E-ABSA >>> 2022-09-02 05:00:32\n",">>> val_acc: 0.6605, val_precision: 0.6605 val_recall: 0.6605, val_f1: 0.6605\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","E2E-ABSA >>> 2022-09-02 05:00:32\n","loss: 0.7221, acc: 0.6969\n","E2E-ABSA >>> 2022-09-02 05:00:33\n","loss: 0.6842, acc: 0.7021\n","E2E-ABSA >>> 2022-09-02 05:00:34\n","loss: 0.6896, acc: 0.7060\n","E2E-ABSA >>> 2022-09-02 05:00:35\n",">>> val_acc: 0.6494, val_precision: 0.6494 val_recall: 0.6494, val_f1: 0.6494\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","E2E-ABSA >>> 2022-09-02 05:00:35\n","loss: 0.7341, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 05:00:37\n","loss: 0.6799, acc: 0.7210\n","E2E-ABSA >>> 2022-09-02 05:00:38\n","loss: 0.6813, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 05:00:39\n",">>> val_acc: 0.6456, val_precision: 0.6456 val_recall: 0.6456, val_f1: 0.6456\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","E2E-ABSA >>> 2022-09-02 05:00:39\n","loss: 0.6639, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 05:00:40\n","loss: 0.6905, acc: 0.7091\n","E2E-ABSA >>> 2022-09-02 05:00:41\n","loss: 0.6853, acc: 0.7129\n","E2E-ABSA >>> 2022-09-02 05:00:43\n","loss: 0.6910, acc: 0.7120\n","E2E-ABSA >>> 2022-09-02 05:00:43\n",">>> val_acc: 0.6475, val_precision: 0.6475 val_recall: 0.6475, val_f1: 0.6475\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","E2E-ABSA >>> 2022-09-02 05:00:44\n","loss: 0.7109, acc: 0.6914\n","E2E-ABSA >>> 2022-09-02 05:00:45\n","loss: 0.6900, acc: 0.7070\n","E2E-ABSA >>> 2022-09-02 05:00:46\n","loss: 0.6894, acc: 0.7057\n","E2E-ABSA >>> 2022-09-02 05:00:47\n",">>> val_acc: 0.6475, val_precision: 0.6475 val_recall: 0.6475, val_f1: 0.6475\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","E2E-ABSA >>> 2022-09-02 05:00:48\n","loss: 0.6945, acc: 0.7045\n","E2E-ABSA >>> 2022-09-02 05:00:49\n","loss: 0.6882, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 05:00:50\n","loss: 0.6875, acc: 0.7101\n","E2E-ABSA >>> 2022-09-02 05:00:50\n",">>> val_acc: 0.6549, val_precision: 0.6549 val_recall: 0.6549, val_f1: 0.6549\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 90.\n","E2E-ABSA >>> 2022-09-02 05:00:51\n","loss: 0.6837, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 05:00:52\n","loss: 0.6784, acc: 0.7156\n","E2E-ABSA >>> 2022-09-02 05:00:54\n","loss: 0.6878, acc: 0.7107\n","E2E-ABSA >>> 2022-09-02 05:00:54\n",">>> val_acc: 0.6512, val_precision: 0.6512 val_recall: 0.6512, val_f1: 0.6512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 91.\n","E2E-ABSA >>> 2022-09-02 05:00:55\n","loss: 0.6922, acc: 0.7066\n","E2E-ABSA >>> 2022-09-02 05:00:56\n","loss: 0.7000, acc: 0.7013\n","E2E-ABSA >>> 2022-09-02 05:00:57\n","loss: 0.6892, acc: 0.7073\n","E2E-ABSA >>> 2022-09-02 05:00:58\n",">>> val_acc: 0.6494, val_precision: 0.6494 val_recall: 0.6494, val_f1: 0.6494\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 92.\n","E2E-ABSA >>> 2022-09-02 05:00:59\n","loss: 0.6539, acc: 0.7178\n","E2E-ABSA >>> 2022-09-02 05:01:00\n","loss: 0.6677, acc: 0.7207\n","E2E-ABSA >>> 2022-09-02 05:01:01\n","loss: 0.6770, acc: 0.7126\n","E2E-ABSA >>> 2022-09-02 05:01:02\n",">>> val_acc: 0.6660, val_precision: 0.6660 val_recall: 0.6660, val_f1: 0.6660\n",">> saved: state_dict/tc_lstm_acl14shortdata_know_val_f1_0.666\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 93.\n","E2E-ABSA >>> 2022-09-02 05:01:02\n","loss: 0.6682, acc: 0.7210\n","E2E-ABSA >>> 2022-09-02 05:01:03\n","loss: 0.6848, acc: 0.7019\n","E2E-ABSA >>> 2022-09-02 05:01:05\n","loss: 0.6871, acc: 0.7036\n","E2E-ABSA >>> 2022-09-02 05:01:05\n",">>> val_acc: 0.6568, val_precision: 0.6568 val_recall: 0.6568, val_f1: 0.6568\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 94.\n","E2E-ABSA >>> 2022-09-02 05:01:06\n","loss: 0.6677, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 05:01:07\n","loss: 0.6745, acc: 0.7124\n","E2E-ABSA >>> 2022-09-02 05:01:08\n","loss: 0.6884, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 05:01:09\n",">>> val_acc: 0.6623, val_precision: 0.6623 val_recall: 0.6623, val_f1: 0.6623\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 95.\n","E2E-ABSA >>> 2022-09-02 05:01:10\n","loss: 0.6730, acc: 0.7219\n","E2E-ABSA >>> 2022-09-02 05:01:11\n","loss: 0.6588, acc: 0.7259\n","E2E-ABSA >>> 2022-09-02 05:01:12\n","loss: 0.6808, acc: 0.7099\n","E2E-ABSA >>> 2022-09-02 05:01:13\n",">>> val_acc: 0.6475, val_precision: 0.6475 val_recall: 0.6475, val_f1: 0.6475\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 96.\n","E2E-ABSA >>> 2022-09-02 05:01:13\n","loss: 0.6935, acc: 0.6973\n","E2E-ABSA >>> 2022-09-02 05:01:14\n","loss: 0.6880, acc: 0.7088\n","E2E-ABSA >>> 2022-09-02 05:01:15\n","loss: 0.6841, acc: 0.7107\n","E2E-ABSA >>> 2022-09-02 05:01:17\n",">>> val_acc: 0.6456, val_precision: 0.6456 val_recall: 0.6456, val_f1: 0.6456\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 97.\n","E2E-ABSA >>> 2022-09-02 05:01:17\n","loss: 0.7501, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 05:01:18\n","loss: 0.6843, acc: 0.6981\n","E2E-ABSA >>> 2022-09-02 05:01:19\n","loss: 0.6742, acc: 0.7121\n","E2E-ABSA >>> 2022-09-02 05:01:20\n",">>> val_acc: 0.6475, val_precision: 0.6475 val_recall: 0.6475, val_f1: 0.6475\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 98.\n","E2E-ABSA >>> 2022-09-02 05:01:20\n","loss: 0.5823, acc: 0.7930\n","E2E-ABSA >>> 2022-09-02 05:01:22\n","loss: 0.6784, acc: 0.7123\n","E2E-ABSA >>> 2022-09-02 05:01:23\n","loss: 0.6791, acc: 0.7118\n","E2E-ABSA >>> 2022-09-02 05:01:24\n",">>> val_acc: 0.6568, val_precision: 0.6568 val_recall: 0.6568, val_f1: 0.6568\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 99.\n","E2E-ABSA >>> 2022-09-02 05:01:24\n","loss: 0.6231, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 05:01:25\n","loss: 0.6718, acc: 0.7193\n","E2E-ABSA >>> 2022-09-02 05:01:26\n","loss: 0.6773, acc: 0.7136\n","E2E-ABSA >>> 2022-09-02 05:01:28\n","loss: 0.6787, acc: 0.7149\n","E2E-ABSA >>> 2022-09-02 05:01:28\n",">>> val_acc: 0.6456, val_precision: 0.6456 val_recall: 0.6456, val_f1: 0.6456\n","you can download the best model from state_dict/tc_lstm_acl14shortdata_know_val_f1_0.666\n",">>> test_acc: 0.6660, test_precision: 0.6660, test_recall: 0.6660, test_f1: 0.6660\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **acl14shortdata** dataset on model(**ATAELSTM**)\n","\n"],"metadata":{"id":"xODWdvSfXio0"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name atae_lstm --dataset acl14shortdata_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KXbe6avvXiwl","outputId":"c091595e-0f38-435a-c211-3aee8898c153","executionInfo":{"status":"ok","timestamp":1662095367631,"user_tz":-480,"elapsed":477872,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 5623.\n","> testing dataset count: 625.\n","cuda memory allocated: 26883072\n","> n_trainable_params: 2525703, n_nontrainable_params: 4136100\n","> training arguments:\n",">>> model_name: atae_lstm\n",">>> dataset: acl14shortdata_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7ff68945cc20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.atae_lstm.ATAE_LSTM'>\n",">>> dataset_file: {'train': './datasets/acl14shortdata/output_know_insert/train.tsv', 'test': './datasets/acl14shortdata/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 05:02:10\n","loss: 1.0929, acc: 0.3594\n","E2E-ABSA >>> 2022-09-02 05:02:11\n","loss: 1.0531, acc: 0.4369\n","E2E-ABSA >>> 2022-09-02 05:02:13\n","loss: 1.0334, acc: 0.4612\n","E2E-ABSA >>> 2022-09-02 05:02:13\n",">>> val_acc: 0.4976, val_precision: 0.4976 val_recall: 0.4976, val_f1: 0.4976\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.4976\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 05:02:14\n","loss: 0.9673, acc: 0.5352\n","E2E-ABSA >>> 2022-09-02 05:02:15\n","loss: 0.9608, acc: 0.5473\n","E2E-ABSA >>> 2022-09-02 05:02:17\n","loss: 0.9683, acc: 0.5381\n","E2E-ABSA >>> 2022-09-02 05:02:18\n","loss: 0.9658, acc: 0.5424\n","E2E-ABSA >>> 2022-09-02 05:02:18\n",">>> val_acc: 0.5328, val_precision: 0.5328 val_recall: 0.5328, val_f1: 0.5328\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.5328\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 05:02:19\n","loss: 0.9516, acc: 0.5553\n","E2E-ABSA >>> 2022-09-02 05:02:20\n","loss: 0.9445, acc: 0.5561\n","E2E-ABSA >>> 2022-09-02 05:02:22\n","loss: 0.9488, acc: 0.5494\n","E2E-ABSA >>> 2022-09-02 05:02:22\n",">>> val_acc: 0.5312, val_precision: 0.5312 val_recall: 0.5312, val_f1: 0.5312\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 05:02:23\n","loss: 0.9337, acc: 0.5511\n","E2E-ABSA >>> 2022-09-02 05:02:24\n","loss: 0.9278, acc: 0.5586\n","E2E-ABSA >>> 2022-09-02 05:02:25\n","loss: 0.9314, acc: 0.5592\n","E2E-ABSA >>> 2022-09-02 05:02:27\n","loss: 0.9279, acc: 0.5640\n","E2E-ABSA >>> 2022-09-02 05:02:27\n",">>> val_acc: 0.5328, val_precision: 0.5328 val_recall: 0.5328, val_f1: 0.5328\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 05:02:28\n","loss: 0.9248, acc: 0.5829\n","E2E-ABSA >>> 2022-09-02 05:02:29\n","loss: 0.9223, acc: 0.5785\n","E2E-ABSA >>> 2022-09-02 05:02:30\n","loss: 0.9226, acc: 0.5732\n","E2E-ABSA >>> 2022-09-02 05:02:31\n",">>> val_acc: 0.5440, val_precision: 0.5440 val_recall: 0.5440, val_f1: 0.5440\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.544\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 05:02:32\n","loss: 0.9357, acc: 0.5625\n","E2E-ABSA >>> 2022-09-02 05:02:33\n","loss: 0.9164, acc: 0.5915\n","E2E-ABSA >>> 2022-09-02 05:02:34\n","loss: 0.9081, acc: 0.5914\n","E2E-ABSA >>> 2022-09-02 05:02:35\n","loss: 0.9107, acc: 0.5888\n","E2E-ABSA >>> 2022-09-02 05:02:36\n",">>> val_acc: 0.5472, val_precision: 0.5472 val_recall: 0.5472, val_f1: 0.5472\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.5472\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 05:02:37\n","loss: 0.8930, acc: 0.6030\n","E2E-ABSA >>> 2022-09-02 05:02:38\n","loss: 0.8928, acc: 0.6034\n","E2E-ABSA >>> 2022-09-02 05:02:39\n","loss: 0.8970, acc: 0.5974\n","E2E-ABSA >>> 2022-09-02 05:02:40\n",">>> val_acc: 0.5520, val_precision: 0.5520 val_recall: 0.5520, val_f1: 0.5520\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.552\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 05:02:41\n","loss: 0.8980, acc: 0.5816\n","E2E-ABSA >>> 2022-09-02 05:02:42\n","loss: 0.8748, acc: 0.6011\n","E2E-ABSA >>> 2022-09-02 05:02:43\n","loss: 0.8918, acc: 0.5924\n","E2E-ABSA >>> 2022-09-02 05:02:44\n","loss: 0.8953, acc: 0.5915\n","E2E-ABSA >>> 2022-09-02 05:02:45\n",">>> val_acc: 0.5520, val_precision: 0.5520 val_recall: 0.5520, val_f1: 0.5520\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 05:02:46\n","loss: 0.8755, acc: 0.6138\n","E2E-ABSA >>> 2022-09-02 05:02:47\n","loss: 0.8915, acc: 0.5951\n","E2E-ABSA >>> 2022-09-02 05:02:48\n","loss: 0.8837, acc: 0.6004\n","E2E-ABSA >>> 2022-09-02 05:02:49\n",">>> val_acc: 0.5568, val_precision: 0.5568 val_recall: 0.5568, val_f1: 0.5568\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.5568\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 05:02:50\n","loss: 0.9284, acc: 0.5488\n","E2E-ABSA >>> 2022-09-02 05:02:51\n","loss: 0.8766, acc: 0.6061\n","E2E-ABSA >>> 2022-09-02 05:02:52\n","loss: 0.8773, acc: 0.6037\n","E2E-ABSA >>> 2022-09-02 05:02:53\n","loss: 0.8822, acc: 0.6022\n","E2E-ABSA >>> 2022-09-02 05:02:54\n",">>> val_acc: 0.5600, val_precision: 0.5600 val_recall: 0.5600, val_f1: 0.5600\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.56\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 05:02:55\n","loss: 0.8558, acc: 0.6156\n","E2E-ABSA >>> 2022-09-02 05:02:56\n","loss: 0.8716, acc: 0.6052\n","E2E-ABSA >>> 2022-09-02 05:02:57\n","loss: 0.8669, acc: 0.6069\n","E2E-ABSA >>> 2022-09-02 05:02:58\n",">>> val_acc: 0.5776, val_precision: 0.5776 val_recall: 0.5776, val_f1: 0.5776\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.5776\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 05:02:59\n","loss: 0.8546, acc: 0.6027\n","E2E-ABSA >>> 2022-09-02 05:03:00\n","loss: 0.8449, acc: 0.6182\n","E2E-ABSA >>> 2022-09-02 05:03:01\n","loss: 0.8450, acc: 0.6231\n","E2E-ABSA >>> 2022-09-02 05:03:02\n","loss: 0.8398, acc: 0.6273\n","E2E-ABSA >>> 2022-09-02 05:03:03\n",">>> val_acc: 0.5952, val_precision: 0.5952 val_recall: 0.5952, val_f1: 0.5952\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.5952\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 05:03:04\n","loss: 0.8185, acc: 0.6357\n","E2E-ABSA >>> 2022-09-02 05:03:05\n","loss: 0.8184, acc: 0.6346\n","E2E-ABSA >>> 2022-09-02 05:03:06\n","loss: 0.8147, acc: 0.6393\n","E2E-ABSA >>> 2022-09-02 05:03:07\n",">>> val_acc: 0.5952, val_precision: 0.5952 val_recall: 0.5952, val_f1: 0.5952\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 05:03:08\n","loss: 0.7835, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 05:03:09\n","loss: 0.7805, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 05:03:10\n","loss: 0.7874, acc: 0.6568\n","E2E-ABSA >>> 2022-09-02 05:03:11\n","loss: 0.7783, acc: 0.6593\n","E2E-ABSA >>> 2022-09-02 05:03:12\n",">>> val_acc: 0.6128, val_precision: 0.6128 val_recall: 0.6128, val_f1: 0.6128\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.6128\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 05:03:13\n","loss: 0.7373, acc: 0.6901\n","E2E-ABSA >>> 2022-09-02 05:03:14\n","loss: 0.7532, acc: 0.6722\n","E2E-ABSA >>> 2022-09-02 05:03:15\n","loss: 0.7521, acc: 0.6735\n","E2E-ABSA >>> 2022-09-02 05:03:16\n",">>> val_acc: 0.6320, val_precision: 0.6320 val_recall: 0.6320, val_f1: 0.6320\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.632\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 05:03:17\n","loss: 0.7441, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 05:03:18\n","loss: 0.7338, acc: 0.6917\n","E2E-ABSA >>> 2022-09-02 05:03:19\n","loss: 0.7407, acc: 0.6793\n","E2E-ABSA >>> 2022-09-02 05:03:20\n","loss: 0.7400, acc: 0.6818\n","E2E-ABSA >>> 2022-09-02 05:03:21\n",">>> val_acc: 0.6416, val_precision: 0.6416 val_recall: 0.6416, val_f1: 0.6416\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.6416\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 05:03:22\n","loss: 0.7152, acc: 0.6949\n","E2E-ABSA >>> 2022-09-02 05:03:23\n","loss: 0.7235, acc: 0.6923\n","E2E-ABSA >>> 2022-09-02 05:03:24\n","loss: 0.7195, acc: 0.6908\n","E2E-ABSA >>> 2022-09-02 05:03:25\n",">>> val_acc: 0.6496, val_precision: 0.6496 val_recall: 0.6496, val_f1: 0.6496\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.6496\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 05:03:26\n","loss: 0.6847, acc: 0.7070\n","E2E-ABSA >>> 2022-09-02 05:03:27\n","loss: 0.7024, acc: 0.7042\n","E2E-ABSA >>> 2022-09-02 05:03:28\n","loss: 0.7028, acc: 0.7095\n","E2E-ABSA >>> 2022-09-02 05:03:29\n","loss: 0.7100, acc: 0.7049\n","E2E-ABSA >>> 2022-09-02 05:03:30\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 05:03:31\n","loss: 0.7185, acc: 0.7119\n","E2E-ABSA >>> 2022-09-02 05:03:32\n","loss: 0.7132, acc: 0.7043\n","E2E-ABSA >>> 2022-09-02 05:03:33\n","loss: 0.7072, acc: 0.7050\n","E2E-ABSA >>> 2022-09-02 05:03:34\n",">>> val_acc: 0.6496, val_precision: 0.6496 val_recall: 0.6496, val_f1: 0.6496\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 05:03:34\n","loss: 0.7243, acc: 0.6927\n","E2E-ABSA >>> 2022-09-02 05:03:36\n","loss: 0.7015, acc: 0.7115\n","E2E-ABSA >>> 2022-09-02 05:03:37\n","loss: 0.6848, acc: 0.7167\n","E2E-ABSA >>> 2022-09-02 05:03:39\n","loss: 0.6911, acc: 0.7117\n","E2E-ABSA >>> 2022-09-02 05:03:39\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 05:03:40\n","loss: 0.6983, acc: 0.6937\n","E2E-ABSA >>> 2022-09-02 05:03:41\n","loss: 0.7005, acc: 0.7078\n","E2E-ABSA >>> 2022-09-02 05:03:42\n","loss: 0.6993, acc: 0.7063\n","E2E-ABSA >>> 2022-09-02 05:03:44\n",">>> val_acc: 0.6800, val_precision: 0.6800 val_recall: 0.6800, val_f1: 0.6800\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.68\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 05:03:44\n","loss: 0.6369, acc: 0.7422\n","E2E-ABSA >>> 2022-09-02 05:03:45\n","loss: 0.6806, acc: 0.7211\n","E2E-ABSA >>> 2022-09-02 05:03:46\n","loss: 0.6906, acc: 0.7142\n","E2E-ABSA >>> 2022-09-02 05:03:47\n","loss: 0.6816, acc: 0.7167\n","E2E-ABSA >>> 2022-09-02 05:03:48\n",">>> val_acc: 0.6672, val_precision: 0.6672 val_recall: 0.6672, val_f1: 0.6672\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 05:03:49\n","loss: 0.6849, acc: 0.7098\n","E2E-ABSA >>> 2022-09-02 05:03:50\n","loss: 0.6760, acc: 0.7179\n","E2E-ABSA >>> 2022-09-02 05:03:51\n","loss: 0.6811, acc: 0.7117\n","E2E-ABSA >>> 2022-09-02 05:03:53\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 05:03:53\n","loss: 0.6568, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 05:03:54\n","loss: 0.6703, acc: 0.7266\n","E2E-ABSA >>> 2022-09-02 05:03:55\n","loss: 0.6687, acc: 0.7203\n","E2E-ABSA >>> 2022-09-02 05:03:56\n","loss: 0.6748, acc: 0.7190\n","E2E-ABSA >>> 2022-09-02 05:03:57\n",">>> val_acc: 0.6768, val_precision: 0.6768 val_recall: 0.6768, val_f1: 0.6768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 05:03:58\n","loss: 0.6754, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 05:03:59\n","loss: 0.6812, acc: 0.7138\n","E2E-ABSA >>> 2022-09-02 05:04:00\n","loss: 0.6724, acc: 0.7195\n","E2E-ABSA >>> 2022-09-02 05:04:01\n","loss: 0.6751, acc: 0.7174\n","E2E-ABSA >>> 2022-09-02 05:04:01\n",">>> val_acc: 0.6672, val_precision: 0.6672 val_recall: 0.6672, val_f1: 0.6672\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 05:04:03\n","loss: 0.6492, acc: 0.7350\n","E2E-ABSA >>> 2022-09-02 05:04:04\n","loss: 0.6599, acc: 0.7241\n","E2E-ABSA >>> 2022-09-02 05:04:05\n","loss: 0.6653, acc: 0.7252\n","E2E-ABSA >>> 2022-09-02 05:04:06\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 05:04:06\n","loss: 0.6721, acc: 0.7253\n","E2E-ABSA >>> 2022-09-02 05:04:08\n","loss: 0.6685, acc: 0.7247\n","E2E-ABSA >>> 2022-09-02 05:04:09\n","loss: 0.6664, acc: 0.7220\n","E2E-ABSA >>> 2022-09-02 05:04:10\n","loss: 0.6682, acc: 0.7207\n","E2E-ABSA >>> 2022-09-02 05:04:10\n",">>> val_acc: 0.6768, val_precision: 0.6768 val_recall: 0.6768, val_f1: 0.6768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 05:04:11\n","loss: 0.6701, acc: 0.7207\n","E2E-ABSA >>> 2022-09-02 05:04:13\n","loss: 0.6677, acc: 0.7165\n","E2E-ABSA >>> 2022-09-02 05:04:14\n","loss: 0.6645, acc: 0.7217\n","E2E-ABSA >>> 2022-09-02 05:04:15\n",">>> val_acc: 0.6768, val_precision: 0.6768 val_recall: 0.6768, val_f1: 0.6768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 05:04:15\n","loss: 0.6781, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 05:04:16\n","loss: 0.6508, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 05:04:18\n","loss: 0.6598, acc: 0.7298\n","E2E-ABSA >>> 2022-09-02 05:04:19\n","loss: 0.6620, acc: 0.7249\n","E2E-ABSA >>> 2022-09-02 05:04:19\n",">>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.696\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 05:04:20\n","loss: 0.6589, acc: 0.7269\n","E2E-ABSA >>> 2022-09-02 05:04:21\n","loss: 0.6609, acc: 0.7282\n","E2E-ABSA >>> 2022-09-02 05:04:23\n","loss: 0.6617, acc: 0.7265\n","E2E-ABSA >>> 2022-09-02 05:04:24\n",">>> val_acc: 0.6704, val_precision: 0.6704 val_recall: 0.6704, val_f1: 0.6704\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 05:04:24\n","loss: 0.6250, acc: 0.7469\n","E2E-ABSA >>> 2022-09-02 05:04:25\n","loss: 0.6477, acc: 0.7304\n","E2E-ABSA >>> 2022-09-02 05:04:26\n","loss: 0.6505, acc: 0.7273\n","E2E-ABSA >>> 2022-09-02 05:04:28\n","loss: 0.6554, acc: 0.7254\n","E2E-ABSA >>> 2022-09-02 05:04:28\n",">>> val_acc: 0.6768, val_precision: 0.6768 val_recall: 0.6768, val_f1: 0.6768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 05:04:29\n","loss: 0.6443, acc: 0.7393\n","E2E-ABSA >>> 2022-09-02 05:04:30\n","loss: 0.6419, acc: 0.7360\n","E2E-ABSA >>> 2022-09-02 05:04:31\n","loss: 0.6544, acc: 0.7268\n","E2E-ABSA >>> 2022-09-02 05:04:32\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 05:04:33\n","loss: 0.6256, acc: 0.7326\n","E2E-ABSA >>> 2022-09-02 05:04:34\n","loss: 0.6327, acc: 0.7330\n","E2E-ABSA >>> 2022-09-02 05:04:35\n","loss: 0.6401, acc: 0.7336\n","E2E-ABSA >>> 2022-09-02 05:04:36\n","loss: 0.6483, acc: 0.7308\n","E2E-ABSA >>> 2022-09-02 05:04:37\n",">>> val_acc: 0.6704, val_precision: 0.6704 val_recall: 0.6704, val_f1: 0.6704\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 05:04:38\n","loss: 0.6500, acc: 0.7448\n","E2E-ABSA >>> 2022-09-02 05:04:39\n","loss: 0.6347, acc: 0.7463\n","E2E-ABSA >>> 2022-09-02 05:04:40\n","loss: 0.6430, acc: 0.7368\n","E2E-ABSA >>> 2022-09-02 05:04:41\n",">>> val_acc: 0.6672, val_precision: 0.6672 val_recall: 0.6672, val_f1: 0.6672\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 05:04:42\n","loss: 0.6746, acc: 0.7480\n","E2E-ABSA >>> 2022-09-02 05:04:43\n","loss: 0.6287, acc: 0.7509\n","E2E-ABSA >>> 2022-09-02 05:04:44\n","loss: 0.6436, acc: 0.7363\n","E2E-ABSA >>> 2022-09-02 05:04:45\n","loss: 0.6445, acc: 0.7340\n","E2E-ABSA >>> 2022-09-02 05:04:46\n",">>> val_acc: 0.6800, val_precision: 0.6800 val_recall: 0.6800, val_f1: 0.6800\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 05:04:47\n","loss: 0.6132, acc: 0.7516\n","E2E-ABSA >>> 2022-09-02 05:04:48\n","loss: 0.6315, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 05:04:49\n","loss: 0.6346, acc: 0.7406\n","E2E-ABSA >>> 2022-09-02 05:04:50\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 05:04:50\n","loss: 0.6075, acc: 0.7612\n","E2E-ABSA >>> 2022-09-02 05:04:52\n","loss: 0.6362, acc: 0.7407\n","E2E-ABSA >>> 2022-09-02 05:04:53\n","loss: 0.6353, acc: 0.7379\n","E2E-ABSA >>> 2022-09-02 05:04:54\n","loss: 0.6406, acc: 0.7357\n","E2E-ABSA >>> 2022-09-02 05:04:55\n",">>> val_acc: 0.6944, val_precision: 0.6944 val_recall: 0.6944, val_f1: 0.6944\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 05:04:56\n","loss: 0.6224, acc: 0.7467\n","E2E-ABSA >>> 2022-09-02 05:04:57\n","loss: 0.6091, acc: 0.7504\n","E2E-ABSA >>> 2022-09-02 05:04:58\n","loss: 0.6263, acc: 0.7391\n","E2E-ABSA >>> 2022-09-02 05:04:59\n",">>> val_acc: 0.7008, val_precision: 0.7008 val_recall: 0.7008, val_f1: 0.7008\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.7008\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 05:04:59\n","loss: 0.6571, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 05:05:01\n","loss: 0.6392, acc: 0.7394\n","E2E-ABSA >>> 2022-09-02 05:05:02\n","loss: 0.6285, acc: 0.7436\n","E2E-ABSA >>> 2022-09-02 05:05:03\n","loss: 0.6357, acc: 0.7377\n","E2E-ABSA >>> 2022-09-02 05:05:04\n",">>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 05:05:04\n","loss: 0.6801, acc: 0.7092\n","E2E-ABSA >>> 2022-09-02 05:05:06\n","loss: 0.6574, acc: 0.7271\n","E2E-ABSA >>> 2022-09-02 05:05:07\n","loss: 0.6353, acc: 0.7397\n","E2E-ABSA >>> 2022-09-02 05:05:08\n",">>> val_acc: 0.6896, val_precision: 0.6896 val_recall: 0.6896, val_f1: 0.6896\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 05:05:08\n","loss: 0.6527, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 05:05:09\n","loss: 0.6330, acc: 0.7365\n","E2E-ABSA >>> 2022-09-02 05:05:11\n","loss: 0.6321, acc: 0.7352\n","E2E-ABSA >>> 2022-09-02 05:05:12\n","loss: 0.6318, acc: 0.7369\n","E2E-ABSA >>> 2022-09-02 05:05:12\n",">>> val_acc: 0.7072, val_precision: 0.7072 val_recall: 0.7072, val_f1: 0.7072\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.7072\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 05:05:13\n","loss: 0.6373, acc: 0.7243\n","E2E-ABSA >>> 2022-09-02 05:05:14\n","loss: 0.6186, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 05:05:16\n","loss: 0.6246, acc: 0.7369\n","E2E-ABSA >>> 2022-09-02 05:05:17\n",">>> val_acc: 0.7200, val_precision: 0.7200 val_recall: 0.7200, val_f1: 0.7200\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.72\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 05:05:17\n","loss: 0.5489, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 05:05:18\n","loss: 0.6066, acc: 0.7468\n","E2E-ABSA >>> 2022-09-02 05:05:20\n","loss: 0.6192, acc: 0.7399\n","E2E-ABSA >>> 2022-09-02 05:05:21\n","loss: 0.6250, acc: 0.7401\n","E2E-ABSA >>> 2022-09-02 05:05:21\n",">>> val_acc: 0.6848, val_precision: 0.6848 val_recall: 0.6848, val_f1: 0.6848\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 05:05:22\n","loss: 0.6169, acc: 0.7520\n","E2E-ABSA >>> 2022-09-02 05:05:23\n","loss: 0.6209, acc: 0.7447\n","E2E-ABSA >>> 2022-09-02 05:05:24\n","loss: 0.6195, acc: 0.7415\n","E2E-ABSA >>> 2022-09-02 05:05:26\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 05:05:26\n","loss: 0.5655, acc: 0.8021\n","E2E-ABSA >>> 2022-09-02 05:05:27\n","loss: 0.6206, acc: 0.7416\n","E2E-ABSA >>> 2022-09-02 05:05:28\n","loss: 0.6266, acc: 0.7403\n","E2E-ABSA >>> 2022-09-02 05:05:30\n","loss: 0.6228, acc: 0.7434\n","E2E-ABSA >>> 2022-09-02 05:05:30\n",">>> val_acc: 0.7072, val_precision: 0.7072 val_recall: 0.7072, val_f1: 0.7072\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 05:05:31\n","loss: 0.6181, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 05:05:32\n","loss: 0.6129, acc: 0.7480\n","E2E-ABSA >>> 2022-09-02 05:05:33\n","loss: 0.6141, acc: 0.7447\n","E2E-ABSA >>> 2022-09-02 05:05:35\n",">>> val_acc: 0.6912, val_precision: 0.6912 val_recall: 0.6912, val_f1: 0.6912\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 05:05:35\n","loss: 0.5443, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 05:05:36\n","loss: 0.6150, acc: 0.7454\n","E2E-ABSA >>> 2022-09-02 05:05:38\n","loss: 0.6093, acc: 0.7485\n","E2E-ABSA >>> 2022-09-02 05:05:39\n","loss: 0.6156, acc: 0.7423\n","E2E-ABSA >>> 2022-09-02 05:05:39\n",">>> val_acc: 0.6992, val_precision: 0.6992 val_recall: 0.6992, val_f1: 0.6992\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 05:05:40\n","loss: 0.6111, acc: 0.7567\n","E2E-ABSA >>> 2022-09-02 05:05:41\n","loss: 0.6026, acc: 0.7592\n","E2E-ABSA >>> 2022-09-02 05:05:43\n","loss: 0.6189, acc: 0.7483\n","E2E-ABSA >>> 2022-09-02 05:05:44\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 05:05:44\n","loss: 0.6596, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 05:05:45\n","loss: 0.6099, acc: 0.7470\n","E2E-ABSA >>> 2022-09-02 05:05:46\n","loss: 0.6244, acc: 0.7390\n","E2E-ABSA >>> 2022-09-02 05:05:47\n","loss: 0.6236, acc: 0.7370\n","E2E-ABSA >>> 2022-09-02 05:05:48\n",">>> val_acc: 0.7104, val_precision: 0.7104 val_recall: 0.7104, val_f1: 0.7104\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 05:05:49\n","loss: 0.5872, acc: 0.7680\n","E2E-ABSA >>> 2022-09-02 05:05:50\n","loss: 0.6128, acc: 0.7508\n","E2E-ABSA >>> 2022-09-02 05:05:51\n","loss: 0.6157, acc: 0.7475\n","E2E-ABSA >>> 2022-09-02 05:05:52\n","loss: 0.6124, acc: 0.7496\n","E2E-ABSA >>> 2022-09-02 05:05:53\n",">>> val_acc: 0.6944, val_precision: 0.6944 val_recall: 0.6944, val_f1: 0.6944\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 05:05:54\n","loss: 0.5864, acc: 0.7588\n","E2E-ABSA >>> 2022-09-02 05:05:55\n","loss: 0.5970, acc: 0.7562\n","E2E-ABSA >>> 2022-09-02 05:05:56\n","loss: 0.6121, acc: 0.7465\n","E2E-ABSA >>> 2022-09-02 05:05:57\n",">>> val_acc: 0.7072, val_precision: 0.7072 val_recall: 0.7072, val_f1: 0.7072\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 05:05:58\n","loss: 0.6269, acc: 0.7318\n","E2E-ABSA >>> 2022-09-02 05:05:59\n","loss: 0.6284, acc: 0.7399\n","E2E-ABSA >>> 2022-09-02 05:06:00\n","loss: 0.6182, acc: 0.7427\n","E2E-ABSA >>> 2022-09-02 05:06:01\n","loss: 0.6100, acc: 0.7473\n","E2E-ABSA >>> 2022-09-02 05:06:02\n",">>> val_acc: 0.7040, val_precision: 0.7040 val_recall: 0.7040, val_f1: 0.7040\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 05:06:03\n","loss: 0.5672, acc: 0.7643\n","E2E-ABSA >>> 2022-09-02 05:06:04\n","loss: 0.5935, acc: 0.7612\n","E2E-ABSA >>> 2022-09-02 05:06:05\n","loss: 0.6022, acc: 0.7549\n","E2E-ABSA >>> 2022-09-02 05:06:06\n",">>> val_acc: 0.6880, val_precision: 0.6880 val_recall: 0.6880, val_f1: 0.6880\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 05:06:06\n","loss: 0.6264, acc: 0.7415\n","E2E-ABSA >>> 2022-09-02 05:06:08\n","loss: 0.6212, acc: 0.7352\n","E2E-ABSA >>> 2022-09-02 05:06:09\n","loss: 0.6216, acc: 0.7382\n","E2E-ABSA >>> 2022-09-02 05:06:10\n","loss: 0.6088, acc: 0.7455\n","E2E-ABSA >>> 2022-09-02 05:06:10\n",">>> val_acc: 0.7072, val_precision: 0.7072 val_recall: 0.7072, val_f1: 0.7072\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 05:06:11\n","loss: 0.5899, acc: 0.7622\n","E2E-ABSA >>> 2022-09-02 05:06:13\n","loss: 0.5924, acc: 0.7617\n","E2E-ABSA >>> 2022-09-02 05:06:14\n","loss: 0.5956, acc: 0.7573\n","E2E-ABSA >>> 2022-09-02 05:06:15\n",">>> val_acc: 0.7040, val_precision: 0.7040 val_recall: 0.7040, val_f1: 0.7040\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 05:06:15\n","loss: 0.5535, acc: 0.7766\n","E2E-ABSA >>> 2022-09-02 05:06:16\n","loss: 0.6003, acc: 0.7509\n","E2E-ABSA >>> 2022-09-02 05:06:18\n","loss: 0.5938, acc: 0.7523\n","E2E-ABSA >>> 2022-09-02 05:06:19\n","loss: 0.6000, acc: 0.7491\n","E2E-ABSA >>> 2022-09-02 05:06:19\n",">>> val_acc: 0.6944, val_precision: 0.6944 val_recall: 0.6944, val_f1: 0.6944\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 05:06:20\n","loss: 0.6019, acc: 0.7514\n","E2E-ABSA >>> 2022-09-02 05:06:21\n","loss: 0.6067, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 05:06:23\n","loss: 0.6036, acc: 0.7522\n","E2E-ABSA >>> 2022-09-02 05:06:24\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 05:06:24\n","loss: 0.5833, acc: 0.7413\n","E2E-ABSA >>> 2022-09-02 05:06:25\n","loss: 0.6050, acc: 0.7514\n","E2E-ABSA >>> 2022-09-02 05:06:26\n","loss: 0.6032, acc: 0.7516\n","E2E-ABSA >>> 2022-09-02 05:06:28\n","loss: 0.6007, acc: 0.7502\n","E2E-ABSA >>> 2022-09-02 05:06:28\n",">>> val_acc: 0.7024, val_precision: 0.7024 val_recall: 0.7024, val_f1: 0.7024\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 05:06:29\n","loss: 0.5776, acc: 0.7671\n","E2E-ABSA >>> 2022-09-02 05:06:30\n","loss: 0.5944, acc: 0.7592\n","E2E-ABSA >>> 2022-09-02 05:06:31\n","loss: 0.5998, acc: 0.7546\n","E2E-ABSA >>> 2022-09-02 05:06:32\n",">>> val_acc: 0.7056, val_precision: 0.7056 val_recall: 0.7056, val_f1: 0.7056\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 05:06:33\n","loss: 0.5864, acc: 0.7422\n","E2E-ABSA >>> 2022-09-02 05:06:34\n","loss: 0.5920, acc: 0.7443\n","E2E-ABSA >>> 2022-09-02 05:06:35\n","loss: 0.6014, acc: 0.7487\n","E2E-ABSA >>> 2022-09-02 05:06:36\n","loss: 0.5994, acc: 0.7508\n","E2E-ABSA >>> 2022-09-02 05:06:37\n",">>> val_acc: 0.6992, val_precision: 0.6992 val_recall: 0.6992, val_f1: 0.6992\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 05:06:38\n","loss: 0.6028, acc: 0.7508\n","E2E-ABSA >>> 2022-09-02 05:06:39\n","loss: 0.5996, acc: 0.7559\n","E2E-ABSA >>> 2022-09-02 05:06:40\n","loss: 0.5982, acc: 0.7562\n","E2E-ABSA >>> 2022-09-02 05:06:41\n",">>> val_acc: 0.7120, val_precision: 0.7120 val_recall: 0.7120, val_f1: 0.7120\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 05:06:42\n","loss: 0.5966, acc: 0.7522\n","E2E-ABSA >>> 2022-09-02 05:06:43\n","loss: 0.5942, acc: 0.7534\n","E2E-ABSA >>> 2022-09-02 05:06:44\n","loss: 0.5894, acc: 0.7577\n","E2E-ABSA >>> 2022-09-02 05:06:45\n","loss: 0.5886, acc: 0.7584\n","E2E-ABSA >>> 2022-09-02 05:06:46\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 05:06:47\n","loss: 0.5867, acc: 0.7541\n","E2E-ABSA >>> 2022-09-02 05:06:48\n","loss: 0.5886, acc: 0.7511\n","E2E-ABSA >>> 2022-09-02 05:06:49\n","loss: 0.5921, acc: 0.7532\n","E2E-ABSA >>> 2022-09-02 05:06:50\n",">>> val_acc: 0.7168, val_precision: 0.7168 val_recall: 0.7168, val_f1: 0.7168\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 05:06:50\n","loss: 0.5760, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 05:06:52\n","loss: 0.5957, acc: 0.7545\n","E2E-ABSA >>> 2022-09-02 05:06:53\n","loss: 0.5903, acc: 0.7528\n","E2E-ABSA >>> 2022-09-02 05:06:54\n","loss: 0.5921, acc: 0.7564\n","E2E-ABSA >>> 2022-09-02 05:06:55\n",">>> val_acc: 0.6992, val_precision: 0.6992 val_recall: 0.6992, val_f1: 0.6992\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 05:06:55\n","loss: 0.5580, acc: 0.7726\n","E2E-ABSA >>> 2022-09-02 05:06:57\n","loss: 0.5760, acc: 0.7624\n","E2E-ABSA >>> 2022-09-02 05:06:58\n","loss: 0.5845, acc: 0.7560\n","E2E-ABSA >>> 2022-09-02 05:06:59\n",">>> val_acc: 0.7120, val_precision: 0.7120 val_recall: 0.7120, val_f1: 0.7120\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 05:06:59\n","loss: 0.5980, acc: 0.7875\n","E2E-ABSA >>> 2022-09-02 05:07:00\n","loss: 0.5744, acc: 0.7693\n","E2E-ABSA >>> 2022-09-02 05:07:02\n","loss: 0.5895, acc: 0.7585\n","E2E-ABSA >>> 2022-09-02 05:07:03\n","loss: 0.5842, acc: 0.7607\n","E2E-ABSA >>> 2022-09-02 05:07:03\n",">>> val_acc: 0.7056, val_precision: 0.7056 val_recall: 0.7056, val_f1: 0.7056\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 05:07:04\n","loss: 0.5757, acc: 0.7702\n","E2E-ABSA >>> 2022-09-02 05:07:05\n","loss: 0.5901, acc: 0.7574\n","E2E-ABSA >>> 2022-09-02 05:07:07\n","loss: 0.5892, acc: 0.7591\n","E2E-ABSA >>> 2022-09-02 05:07:08\n",">>> val_acc: 0.7008, val_precision: 0.7008 val_recall: 0.7008, val_f1: 0.7008\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 05:07:08\n","loss: 0.5665, acc: 0.7383\n","E2E-ABSA >>> 2022-09-02 05:07:09\n","loss: 0.5694, acc: 0.7597\n","E2E-ABSA >>> 2022-09-02 05:07:10\n","loss: 0.5862, acc: 0.7535\n","E2E-ABSA >>> 2022-09-02 05:07:12\n","loss: 0.5850, acc: 0.7549\n","E2E-ABSA >>> 2022-09-02 05:07:12\n",">>> val_acc: 0.7248, val_precision: 0.7248 val_recall: 0.7248, val_f1: 0.7248\n",">> saved: state_dict/atae_lstm_acl14shortdata_know_val_f1_0.7248\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","E2E-ABSA >>> 2022-09-02 05:07:13\n","loss: 0.5944, acc: 0.7578\n","E2E-ABSA >>> 2022-09-02 05:07:14\n","loss: 0.5750, acc: 0.7622\n","E2E-ABSA >>> 2022-09-02 05:07:16\n","loss: 0.5798, acc: 0.7602\n","E2E-ABSA >>> 2022-09-02 05:07:17\n",">>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","E2E-ABSA >>> 2022-09-02 05:07:17\n","loss: 0.5912, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 05:07:18\n","loss: 0.5609, acc: 0.7684\n","E2E-ABSA >>> 2022-09-02 05:07:19\n","loss: 0.5798, acc: 0.7580\n","E2E-ABSA >>> 2022-09-02 05:07:21\n","loss: 0.5791, acc: 0.7600\n","E2E-ABSA >>> 2022-09-02 05:07:21\n",">>> val_acc: 0.7072, val_precision: 0.7072 val_recall: 0.7072, val_f1: 0.7072\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","E2E-ABSA >>> 2022-09-02 05:07:22\n","loss: 0.5618, acc: 0.7604\n","E2E-ABSA >>> 2022-09-02 05:07:23\n","loss: 0.5723, acc: 0.7680\n","E2E-ABSA >>> 2022-09-02 05:07:24\n","loss: 0.5713, acc: 0.7680\n","E2E-ABSA >>> 2022-09-02 05:07:26\n",">>> val_acc: 0.7104, val_precision: 0.7104 val_recall: 0.7104, val_f1: 0.7104\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","E2E-ABSA >>> 2022-09-02 05:07:26\n","loss: 0.5240, acc: 0.7734\n","E2E-ABSA >>> 2022-09-02 05:07:27\n","loss: 0.5544, acc: 0.7766\n","E2E-ABSA >>> 2022-09-02 05:07:28\n","loss: 0.5754, acc: 0.7632\n","E2E-ABSA >>> 2022-09-02 05:07:29\n","loss: 0.5788, acc: 0.7622\n","E2E-ABSA >>> 2022-09-02 05:07:30\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","E2E-ABSA >>> 2022-09-02 05:07:31\n","loss: 0.5315, acc: 0.7768\n","E2E-ABSA >>> 2022-09-02 05:07:32\n","loss: 0.5712, acc: 0.7648\n","E2E-ABSA >>> 2022-09-02 05:07:33\n","loss: 0.5812, acc: 0.7598\n","E2E-ABSA >>> 2022-09-02 05:07:35\n",">>> val_acc: 0.7072, val_precision: 0.7072 val_recall: 0.7072, val_f1: 0.7072\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","E2E-ABSA >>> 2022-09-02 05:07:35\n","loss: 0.4295, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 05:07:36\n","loss: 0.5577, acc: 0.7692\n","E2E-ABSA >>> 2022-09-02 05:07:37\n","loss: 0.5628, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 05:07:39\n","loss: 0.5692, acc: 0.7673\n","E2E-ABSA >>> 2022-09-02 05:07:39\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","E2E-ABSA >>> 2022-09-02 05:07:40\n","loss: 0.5368, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 05:07:41\n","loss: 0.5566, acc: 0.7738\n","E2E-ABSA >>> 2022-09-02 05:07:43\n","loss: 0.5689, acc: 0.7703\n","E2E-ABSA >>> 2022-09-02 05:07:44\n","loss: 0.5702, acc: 0.7690\n","E2E-ABSA >>> 2022-09-02 05:07:44\n",">>> val_acc: 0.7008, val_precision: 0.7008 val_recall: 0.7008, val_f1: 0.7008\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","E2E-ABSA >>> 2022-09-02 05:07:45\n","loss: 0.5973, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 05:07:46\n","loss: 0.5730, acc: 0.7631\n","E2E-ABSA >>> 2022-09-02 05:07:48\n","loss: 0.5732, acc: 0.7608\n","E2E-ABSA >>> 2022-09-02 05:07:48\n",">>> val_acc: 0.7152, val_precision: 0.7152 val_recall: 0.7152, val_f1: 0.7152\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","E2E-ABSA >>> 2022-09-02 05:07:49\n","loss: 0.5725, acc: 0.7539\n","E2E-ABSA >>> 2022-09-02 05:07:50\n","loss: 0.5628, acc: 0.7682\n","E2E-ABSA >>> 2022-09-02 05:07:51\n","loss: 0.5624, acc: 0.7697\n","E2E-ABSA >>> 2022-09-02 05:07:53\n","loss: 0.5712, acc: 0.7651\n","E2E-ABSA >>> 2022-09-02 05:07:53\n",">>> val_acc: 0.7152, val_precision: 0.7152 val_recall: 0.7152, val_f1: 0.7152\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","E2E-ABSA >>> 2022-09-02 05:07:54\n","loss: 0.5687, acc: 0.7689\n","E2E-ABSA >>> 2022-09-02 05:07:55\n","loss: 0.5721, acc: 0.7653\n","E2E-ABSA >>> 2022-09-02 05:07:56\n","loss: 0.5710, acc: 0.7682\n","E2E-ABSA >>> 2022-09-02 05:07:57\n",">>> val_acc: 0.7152, val_precision: 0.7152 val_recall: 0.7152, val_f1: 0.7152\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","E2E-ABSA >>> 2022-09-02 05:07:58\n","loss: 0.5587, acc: 0.7756\n","E2E-ABSA >>> 2022-09-02 05:07:59\n","loss: 0.5670, acc: 0.7648\n","E2E-ABSA >>> 2022-09-02 05:08:00\n","loss: 0.5737, acc: 0.7638\n","E2E-ABSA >>> 2022-09-02 05:08:01\n","loss: 0.5663, acc: 0.7649\n","E2E-ABSA >>> 2022-09-02 05:08:02\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","E2E-ABSA >>> 2022-09-02 05:08:03\n","loss: 0.5606, acc: 0.7724\n","E2E-ABSA >>> 2022-09-02 05:08:04\n","loss: 0.5676, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 05:08:05\n","loss: 0.5638, acc: 0.7701\n","E2E-ABSA >>> 2022-09-02 05:08:06\n",">>> val_acc: 0.7056, val_precision: 0.7056 val_recall: 0.7056, val_f1: 0.7056\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","E2E-ABSA >>> 2022-09-02 05:08:07\n","loss: 0.5786, acc: 0.7672\n","E2E-ABSA >>> 2022-09-02 05:08:08\n","loss: 0.5474, acc: 0.7728\n","E2E-ABSA >>> 2022-09-02 05:08:09\n","loss: 0.5572, acc: 0.7682\n","E2E-ABSA >>> 2022-09-02 05:08:10\n","loss: 0.5593, acc: 0.7671\n","E2E-ABSA >>> 2022-09-02 05:08:11\n",">>> val_acc: 0.7056, val_precision: 0.7056 val_recall: 0.7056, val_f1: 0.7056\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","E2E-ABSA >>> 2022-09-02 05:08:12\n","loss: 0.5551, acc: 0.7756\n","E2E-ABSA >>> 2022-09-02 05:08:13\n","loss: 0.5580, acc: 0.7650\n","E2E-ABSA >>> 2022-09-02 05:08:14\n","loss: 0.5599, acc: 0.7669\n","E2E-ABSA >>> 2022-09-02 05:08:15\n",">>> val_acc: 0.7024, val_precision: 0.7024 val_recall: 0.7024, val_f1: 0.7024\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","E2E-ABSA >>> 2022-09-02 05:08:15\n","loss: 0.5618, acc: 0.7795\n","E2E-ABSA >>> 2022-09-02 05:08:17\n","loss: 0.5563, acc: 0.7845\n","E2E-ABSA >>> 2022-09-02 05:08:18\n","loss: 0.5611, acc: 0.7757\n","E2E-ABSA >>> 2022-09-02 05:08:19\n","loss: 0.5590, acc: 0.7740\n","E2E-ABSA >>> 2022-09-02 05:08:19\n",">>> val_acc: 0.7168, val_precision: 0.7168 val_recall: 0.7168, val_f1: 0.7168\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","E2E-ABSA >>> 2022-09-02 05:08:20\n","loss: 0.5517, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 05:08:22\n","loss: 0.5498, acc: 0.7717\n","E2E-ABSA >>> 2022-09-02 05:08:23\n","loss: 0.5522, acc: 0.7680\n","E2E-ABSA >>> 2022-09-02 05:08:24\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","E2E-ABSA >>> 2022-09-02 05:08:24\n","loss: 0.5011, acc: 0.7910\n","E2E-ABSA >>> 2022-09-02 05:08:25\n","loss: 0.5310, acc: 0.7822\n","E2E-ABSA >>> 2022-09-02 05:08:27\n","loss: 0.5414, acc: 0.7751\n","E2E-ABSA >>> 2022-09-02 05:08:28\n","loss: 0.5493, acc: 0.7700\n","E2E-ABSA >>> 2022-09-02 05:08:28\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","E2E-ABSA >>> 2022-09-02 05:08:29\n","loss: 0.5518, acc: 0.7797\n","E2E-ABSA >>> 2022-09-02 05:08:30\n","loss: 0.5504, acc: 0.7736\n","E2E-ABSA >>> 2022-09-02 05:08:32\n","loss: 0.5509, acc: 0.7723\n","E2E-ABSA >>> 2022-09-02 05:08:33\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","E2E-ABSA >>> 2022-09-02 05:08:33\n","loss: 0.5504, acc: 0.7768\n","E2E-ABSA >>> 2022-09-02 05:08:34\n","loss: 0.5447, acc: 0.7744\n","E2E-ABSA >>> 2022-09-02 05:08:35\n","loss: 0.5443, acc: 0.7695\n","E2E-ABSA >>> 2022-09-02 05:08:37\n","loss: 0.5461, acc: 0.7729\n","E2E-ABSA >>> 2022-09-02 05:08:37\n",">>> val_acc: 0.7152, val_precision: 0.7152 val_recall: 0.7152, val_f1: 0.7152\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","E2E-ABSA >>> 2022-09-02 05:08:38\n","loss: 0.5566, acc: 0.7697\n","E2E-ABSA >>> 2022-09-02 05:08:39\n","loss: 0.5455, acc: 0.7727\n","E2E-ABSA >>> 2022-09-02 05:08:40\n","loss: 0.5411, acc: 0.7799\n","E2E-ABSA >>> 2022-09-02 05:08:41\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","E2E-ABSA >>> 2022-09-02 05:08:42\n","loss: 0.5227, acc: 0.7839\n","E2E-ABSA >>> 2022-09-02 05:08:43\n","loss: 0.5248, acc: 0.7928\n","E2E-ABSA >>> 2022-09-02 05:08:44\n","loss: 0.5263, acc: 0.7905\n","E2E-ABSA >>> 2022-09-02 05:08:45\n","loss: 0.5411, acc: 0.7801\n","E2E-ABSA >>> 2022-09-02 05:08:46\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","E2E-ABSA >>> 2022-09-02 05:08:47\n","loss: 0.5627, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 05:08:48\n","loss: 0.5497, acc: 0.7736\n","E2E-ABSA >>> 2022-09-02 05:08:49\n","loss: 0.5419, acc: 0.7769\n","E2E-ABSA >>> 2022-09-02 05:08:50\n",">>> val_acc: 0.7120, val_precision: 0.7120 val_recall: 0.7120, val_f1: 0.7120\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 90.\n","E2E-ABSA >>> 2022-09-02 05:08:51\n","loss: 0.5192, acc: 0.7719\n","E2E-ABSA >>> 2022-09-02 05:08:52\n","loss: 0.5481, acc: 0.7729\n","E2E-ABSA >>> 2022-09-02 05:08:53\n","loss: 0.5406, acc: 0.7778\n","E2E-ABSA >>> 2022-09-02 05:08:54\n","loss: 0.5391, acc: 0.7785\n","E2E-ABSA >>> 2022-09-02 05:08:55\n",">>> val_acc: 0.7136, val_precision: 0.7136 val_recall: 0.7136, val_f1: 0.7136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 91.\n","E2E-ABSA >>> 2022-09-02 05:08:56\n","loss: 0.5369, acc: 0.7757\n","E2E-ABSA >>> 2022-09-02 05:08:57\n","loss: 0.5255, acc: 0.7887\n","E2E-ABSA >>> 2022-09-02 05:08:58\n","loss: 0.5404, acc: 0.7801\n","E2E-ABSA >>> 2022-09-02 05:08:59\n",">>> val_acc: 0.7168, val_precision: 0.7168 val_recall: 0.7168, val_f1: 0.7168\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 92.\n","E2E-ABSA >>> 2022-09-02 05:08:59\n","loss: 0.5235, acc: 0.7734\n","E2E-ABSA >>> 2022-09-02 05:09:01\n","loss: 0.5173, acc: 0.7936\n","E2E-ABSA >>> 2022-09-02 05:09:02\n","loss: 0.5392, acc: 0.7763\n","E2E-ABSA >>> 2022-09-02 05:09:03\n","loss: 0.5381, acc: 0.7765\n","E2E-ABSA >>> 2022-09-02 05:09:04\n",">>> val_acc: 0.7056, val_precision: 0.7056 val_recall: 0.7056, val_f1: 0.7056\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 93.\n","E2E-ABSA >>> 2022-09-02 05:09:04\n","loss: 0.5339, acc: 0.7930\n","E2E-ABSA >>> 2022-09-02 05:09:06\n","loss: 0.5223, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 05:09:07\n","loss: 0.5318, acc: 0.7857\n","E2E-ABSA >>> 2022-09-02 05:09:08\n",">>> val_acc: 0.7152, val_precision: 0.7152 val_recall: 0.7152, val_f1: 0.7152\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 94.\n","E2E-ABSA >>> 2022-09-02 05:09:08\n","loss: 0.5675, acc: 0.7760\n","E2E-ABSA >>> 2022-09-02 05:09:09\n","loss: 0.5225, acc: 0.7902\n","E2E-ABSA >>> 2022-09-02 05:09:11\n","loss: 0.5348, acc: 0.7789\n","E2E-ABSA >>> 2022-09-02 05:09:12\n","loss: 0.5291, acc: 0.7833\n","E2E-ABSA >>> 2022-09-02 05:09:12\n",">>> val_acc: 0.7072, val_precision: 0.7072 val_recall: 0.7072, val_f1: 0.7072\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 95.\n","E2E-ABSA >>> 2022-09-02 05:09:13\n","loss: 0.4953, acc: 0.8094\n","E2E-ABSA >>> 2022-09-02 05:09:14\n","loss: 0.5204, acc: 0.7918\n","E2E-ABSA >>> 2022-09-02 05:09:16\n","loss: 0.5282, acc: 0.7849\n","E2E-ABSA >>> 2022-09-02 05:09:17\n",">>> val_acc: 0.7168, val_precision: 0.7168 val_recall: 0.7168, val_f1: 0.7168\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 96.\n","E2E-ABSA >>> 2022-09-02 05:09:17\n","loss: 0.4931, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 05:09:18\n","loss: 0.5199, acc: 0.7870\n","E2E-ABSA >>> 2022-09-02 05:09:19\n","loss: 0.5235, acc: 0.7855\n","E2E-ABSA >>> 2022-09-02 05:09:21\n","loss: 0.5262, acc: 0.7837\n","E2E-ABSA >>> 2022-09-02 05:09:21\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 97.\n","E2E-ABSA >>> 2022-09-02 05:09:22\n","loss: 0.4977, acc: 0.8036\n","E2E-ABSA >>> 2022-09-02 05:09:23\n","loss: 0.5108, acc: 0.7917\n","E2E-ABSA >>> 2022-09-02 05:09:24\n","loss: 0.5153, acc: 0.7944\n","E2E-ABSA >>> 2022-09-02 05:09:26\n",">>> val_acc: 0.7056, val_precision: 0.7056 val_recall: 0.7056, val_f1: 0.7056\n","E2E-ABSA >>> 2022-09-02 05:09:26\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7248, val_precision: 0.7248 val_recall: 0.7248, val_f1: 0.7248\n","you can download the best model from state_dict/atae_lstm_acl14shortdata_know_val_f1_0.7248\n",">>> test_acc: 0.7248, test_precision: 0.7248, test_recall: 0.7248, test_f1: 0.7248\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **acl14shortdata** dataset on model(**IAN**)\n"],"metadata":{"id":"SeyAFJHIXjEI"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name ian --dataset acl14shortdata_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_xMbYMy8XjK-","outputId":"9c0bec64-8dbd-4913-d192-b1b39619b9e5","executionInfo":{"status":"ok","timestamp":1662095741318,"user_tz":-480,"elapsed":373080,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 5623.\n","> testing dataset count: 625.\n","cuda memory allocated: 25457664\n","> n_trainable_params: 2168403, n_nontrainable_params: 4136100\n","> training arguments:\n",">>> model_name: ian\n",">>> dataset: acl14shortdata_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7fdf1548ac20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.ian.IAN'>\n",">>> dataset_file: {'train': './datasets/acl14shortdata/output_know_insert/train.tsv', 'test': './datasets/acl14shortdata/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:10:09\n","loss: 1.0670, acc: 0.4319\n","E2E-ABSA >>> 2022-09-02 05:10:10\n","loss: 1.0495, acc: 0.4669\n","E2E-ABSA >>> 2022-09-02 05:10:12\n","loss: 1.0348, acc: 0.4829\n","E2E-ABSA >>> 2022-09-02 05:10:13\n",">>> val_acc: 0.4640, val_precision: 0.4640 val_recall: 0.4640, val_f1: 0.4640\n",">> saved: state_dict/ian_acl14shortdata_know_val_f1_0.464\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:10:14\n","loss: 1.0033, acc: 0.5130\n","E2E-ABSA >>> 2022-09-02 05:10:15\n","loss: 0.9975, acc: 0.5177\n","E2E-ABSA >>> 2022-09-02 05:10:17\n","loss: 0.9995, acc: 0.5131\n","E2E-ABSA >>> 2022-09-02 05:10:18\n","loss: 0.9956, acc: 0.5167\n","E2E-ABSA >>> 2022-09-02 05:10:18\n",">>> val_acc: 0.4832, val_precision: 0.4832 val_recall: 0.4832, val_f1: 0.4832\n",">> saved: state_dict/ian_acl14shortdata_know_val_f1_0.4832\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:10:20\n","loss: 0.9947, acc: 0.5150\n","E2E-ABSA >>> 2022-09-02 05:10:21\n","loss: 0.9865, acc: 0.5236\n","E2E-ABSA >>> 2022-09-02 05:10:23\n","loss: 0.9799, acc: 0.5258\n","E2E-ABSA >>> 2022-09-02 05:10:24\n",">>> val_acc: 0.4992, val_precision: 0.4992 val_recall: 0.4992, val_f1: 0.4992\n",">> saved: state_dict/ian_acl14shortdata_know_val_f1_0.4992\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:10:24\n","loss: 0.9631, acc: 0.5412\n","E2E-ABSA >>> 2022-09-02 05:10:26\n","loss: 0.9645, acc: 0.5378\n","E2E-ABSA >>> 2022-09-02 05:10:27\n","loss: 0.9592, acc: 0.5423\n","E2E-ABSA >>> 2022-09-02 05:10:29\n","loss: 0.9648, acc: 0.5378\n","E2E-ABSA >>> 2022-09-02 05:10:29\n",">>> val_acc: 0.5216, val_precision: 0.5216 val_recall: 0.5216, val_f1: 0.5216\n",">> saved: state_dict/ian_acl14shortdata_know_val_f1_0.5216\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:10:30\n","loss: 0.9726, acc: 0.5462\n","E2E-ABSA >>> 2022-09-02 05:10:32\n","loss: 0.9601, acc: 0.5508\n","E2E-ABSA >>> 2022-09-02 05:10:33\n","loss: 0.9599, acc: 0.5467\n","E2E-ABSA >>> 2022-09-02 05:10:34\n",">>> val_acc: 0.5248, val_precision: 0.5248 val_recall: 0.5248, val_f1: 0.5248\n",">> saved: state_dict/ian_acl14shortdata_know_val_f1_0.5248\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:10:35\n","loss: 0.9643, acc: 0.5469\n","E2E-ABSA >>> 2022-09-02 05:10:36\n","loss: 0.9540, acc: 0.5536\n","E2E-ABSA >>> 2022-09-02 05:10:38\n","loss: 0.9558, acc: 0.5568\n","E2E-ABSA >>> 2022-09-02 05:10:39\n","loss: 0.9525, acc: 0.5550\n","E2E-ABSA >>> 2022-09-02 05:10:40\n",">>> val_acc: 0.5200, val_precision: 0.5200 val_recall: 0.5200, val_f1: 0.5200\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:10:41\n","loss: 0.9309, acc: 0.5810\n","E2E-ABSA >>> 2022-09-02 05:10:42\n","loss: 0.9436, acc: 0.5698\n","E2E-ABSA >>> 2022-09-02 05:10:44\n","loss: 0.9420, acc: 0.5647\n","E2E-ABSA >>> 2022-09-02 05:10:45\n",">>> val_acc: 0.5184, val_precision: 0.5184 val_recall: 0.5184, val_f1: 0.5184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:10:46\n","loss: 0.9366, acc: 0.5694\n","E2E-ABSA >>> 2022-09-02 05:10:47\n","loss: 0.9516, acc: 0.5671\n","E2E-ABSA >>> 2022-09-02 05:10:48\n","loss: 0.9499, acc: 0.5622\n","E2E-ABSA >>> 2022-09-02 05:10:50\n","loss: 0.9463, acc: 0.5647\n","E2E-ABSA >>> 2022-09-02 05:10:50\n",">>> val_acc: 0.5216, val_precision: 0.5216 val_recall: 0.5216, val_f1: 0.5216\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:10:51\n","loss: 0.9299, acc: 0.5699\n","E2E-ABSA >>> 2022-09-02 05:10:53\n","loss: 0.9332, acc: 0.5747\n","E2E-ABSA >>> 2022-09-02 05:10:54\n","loss: 0.9348, acc: 0.5715\n","E2E-ABSA >>> 2022-09-02 05:10:56\n",">>> val_acc: 0.5248, val_precision: 0.5248 val_recall: 0.5248, val_f1: 0.5248\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:10:56\n","loss: 0.8776, acc: 0.6348\n","E2E-ABSA >>> 2022-09-02 05:10:57\n","loss: 0.9251, acc: 0.5795\n","E2E-ABSA >>> 2022-09-02 05:10:59\n","loss: 0.9310, acc: 0.5749\n","E2E-ABSA >>> 2022-09-02 05:11:00\n","loss: 0.9374, acc: 0.5745\n","E2E-ABSA >>> 2022-09-02 05:11:01\n",">>> val_acc: 0.5280, val_precision: 0.5280 val_recall: 0.5280, val_f1: 0.5280\n",">> saved: state_dict/ian_acl14shortdata_know_val_f1_0.528\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:11:02\n","loss: 0.9385, acc: 0.5633\n","E2E-ABSA >>> 2022-09-02 05:11:04\n","loss: 0.9394, acc: 0.5705\n","E2E-ABSA >>> 2022-09-02 05:11:05\n","loss: 0.9352, acc: 0.5759\n","E2E-ABSA >>> 2022-09-02 05:11:06\n",">>> val_acc: 0.5280, val_precision: 0.5280 val_recall: 0.5280, val_f1: 0.5280\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:11:07\n","loss: 0.9373, acc: 0.5670\n","E2E-ABSA >>> 2022-09-02 05:11:08\n","loss: 0.9446, acc: 0.5659\n","E2E-ABSA >>> 2022-09-02 05:11:10\n","loss: 0.9360, acc: 0.5737\n","E2E-ABSA >>> 2022-09-02 05:11:11\n","loss: 0.9379, acc: 0.5705\n","E2E-ABSA >>> 2022-09-02 05:11:12\n",">>> val_acc: 0.5328, val_precision: 0.5328 val_recall: 0.5328, val_f1: 0.5328\n",">> saved: state_dict/ian_acl14shortdata_know_val_f1_0.5328\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:11:13\n","loss: 0.9116, acc: 0.5789\n","E2E-ABSA >>> 2022-09-02 05:11:14\n","loss: 0.9195, acc: 0.5842\n","E2E-ABSA >>> 2022-09-02 05:11:16\n","loss: 0.9291, acc: 0.5790\n","E2E-ABSA >>> 2022-09-02 05:11:17\n",">>> val_acc: 0.5376, val_precision: 0.5376 val_recall: 0.5376, val_f1: 0.5376\n",">> saved: state_dict/ian_acl14shortdata_know_val_f1_0.5376\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:11:17\n","loss: 0.9113, acc: 0.5990\n","E2E-ABSA >>> 2022-09-02 05:11:19\n","loss: 0.9448, acc: 0.5665\n","E2E-ABSA >>> 2022-09-02 05:11:20\n","loss: 0.9349, acc: 0.5711\n","E2E-ABSA >>> 2022-09-02 05:11:22\n","loss: 0.9367, acc: 0.5702\n","E2E-ABSA >>> 2022-09-02 05:11:22\n",">>> val_acc: 0.5328, val_precision: 0.5328 val_recall: 0.5328, val_f1: 0.5328\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:11:23\n","loss: 0.9201, acc: 0.5955\n","E2E-ABSA >>> 2022-09-02 05:11:25\n","loss: 0.9270, acc: 0.5850\n","E2E-ABSA >>> 2022-09-02 05:11:26\n","loss: 0.9324, acc: 0.5774\n","E2E-ABSA >>> 2022-09-02 05:11:27\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:11:28\n","loss: 0.9403, acc: 0.5875\n","E2E-ABSA >>> 2022-09-02 05:11:29\n","loss: 0.9274, acc: 0.5786\n","E2E-ABSA >>> 2022-09-02 05:11:31\n","loss: 0.9273, acc: 0.5747\n","E2E-ABSA >>> 2022-09-02 05:11:32\n","loss: 0.9290, acc: 0.5773\n","E2E-ABSA >>> 2022-09-02 05:11:33\n",">>> val_acc: 0.5296, val_precision: 0.5296 val_recall: 0.5296, val_f1: 0.5296\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:11:34\n","loss: 0.9337, acc: 0.5763\n","E2E-ABSA >>> 2022-09-02 05:11:35\n","loss: 0.9294, acc: 0.5800\n","E2E-ABSA >>> 2022-09-02 05:11:37\n","loss: 0.9296, acc: 0.5802\n","E2E-ABSA >>> 2022-09-02 05:11:38\n",">>> val_acc: 0.5376, val_precision: 0.5376 val_recall: 0.5376, val_f1: 0.5376\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:11:39\n","loss: 0.8964, acc: 0.5898\n","E2E-ABSA >>> 2022-09-02 05:11:40\n","loss: 0.9273, acc: 0.5727\n","E2E-ABSA >>> 2022-09-02 05:11:42\n","loss: 0.9329, acc: 0.5700\n","E2E-ABSA >>> 2022-09-02 05:11:43\n","loss: 0.9311, acc: 0.5746\n","E2E-ABSA >>> 2022-09-02 05:11:44\n",">>> val_acc: 0.5376, val_precision: 0.5376 val_recall: 0.5376, val_f1: 0.5376\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:11:45\n","loss: 0.9533, acc: 0.5615\n","E2E-ABSA >>> 2022-09-02 05:11:46\n","loss: 0.9376, acc: 0.5720\n","E2E-ABSA >>> 2022-09-02 05:11:48\n","loss: 0.9320, acc: 0.5729\n","E2E-ABSA >>> 2022-09-02 05:11:49\n",">>> val_acc: 0.5328, val_precision: 0.5328 val_recall: 0.5328, val_f1: 0.5328\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:11:50\n","loss: 0.9137, acc: 0.5938\n","E2E-ABSA >>> 2022-09-02 05:11:51\n","loss: 0.9384, acc: 0.5664\n","E2E-ABSA >>> 2022-09-02 05:11:52\n","loss: 0.9377, acc: 0.5696\n","E2E-ABSA >>> 2022-09-02 05:11:54\n","loss: 0.9293, acc: 0.5755\n","E2E-ABSA >>> 2022-09-02 05:11:55\n",">>> val_acc: 0.5328, val_precision: 0.5328 val_recall: 0.5328, val_f1: 0.5328\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:11:56\n","loss: 0.9474, acc: 0.5490\n","E2E-ABSA >>> 2022-09-02 05:11:57\n","loss: 0.9278, acc: 0.5719\n","E2E-ABSA >>> 2022-09-02 05:11:58\n","loss: 0.9296, acc: 0.5712\n","E2E-ABSA >>> 2022-09-02 05:12:00\n",">>> val_acc: 0.5328, val_precision: 0.5328 val_recall: 0.5328, val_f1: 0.5328\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:12:00\n","loss: 0.9010, acc: 0.6172\n","E2E-ABSA >>> 2022-09-02 05:12:02\n","loss: 0.9285, acc: 0.5747\n","E2E-ABSA >>> 2022-09-02 05:12:03\n","loss: 0.9275, acc: 0.5763\n","E2E-ABSA >>> 2022-09-02 05:12:04\n","loss: 0.9288, acc: 0.5755\n","E2E-ABSA >>> 2022-09-02 05:12:05\n",">>> val_acc: 0.5376, val_precision: 0.5376 val_recall: 0.5376, val_f1: 0.5376\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:12:06\n","loss: 0.9357, acc: 0.5670\n","E2E-ABSA >>> 2022-09-02 05:12:08\n","loss: 0.9473, acc: 0.5585\n","E2E-ABSA >>> 2022-09-02 05:12:09\n","loss: 0.9384, acc: 0.5681\n","E2E-ABSA >>> 2022-09-02 05:12:11\n",">>> val_acc: 0.5376, val_precision: 0.5376 val_recall: 0.5376, val_f1: 0.5376\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:12:11\n","loss: 0.9305, acc: 0.5625\n","E2E-ABSA >>> 2022-09-02 05:12:12\n","loss: 0.9324, acc: 0.5739\n","E2E-ABSA >>> 2022-09-02 05:12:14\n","loss: 0.9254, acc: 0.5806\n","E2E-ABSA >>> 2022-09-02 05:12:15\n","loss: 0.9239, acc: 0.5798\n","E2E-ABSA >>> 2022-09-02 05:12:16\n",">>> val_acc: 0.5376, val_precision: 0.5376 val_recall: 0.5376, val_f1: 0.5376\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:12:17\n","loss: 0.9142, acc: 0.5817\n","E2E-ABSA >>> 2022-09-02 05:12:18\n","loss: 0.9209, acc: 0.5789\n","E2E-ABSA >>> 2022-09-02 05:12:20\n","loss: 0.9186, acc: 0.5826\n","E2E-ABSA >>> 2022-09-02 05:12:21\n","loss: 0.9268, acc: 0.5758\n","E2E-ABSA >>> 2022-09-02 05:12:21\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:12:23\n","loss: 0.9193, acc: 0.5844\n","E2E-ABSA >>> 2022-09-02 05:12:24\n","loss: 0.9230, acc: 0.5763\n","E2E-ABSA >>> 2022-09-02 05:12:26\n","loss: 0.9258, acc: 0.5735\n","E2E-ABSA >>> 2022-09-02 05:12:27\n",">>> val_acc: 0.5392, val_precision: 0.5392 val_recall: 0.5392, val_f1: 0.5392\n",">> saved: state_dict/ian_acl14shortdata_know_val_f1_0.5392\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:12:27\n","loss: 0.9420, acc: 0.5755\n","E2E-ABSA >>> 2022-09-02 05:12:29\n","loss: 0.9401, acc: 0.5633\n","E2E-ABSA >>> 2022-09-02 05:12:30\n","loss: 0.9306, acc: 0.5711\n","E2E-ABSA >>> 2022-09-02 05:12:32\n","loss: 0.9262, acc: 0.5749\n","E2E-ABSA >>> 2022-09-02 05:12:32\n",">>> val_acc: 0.5344, val_precision: 0.5344 val_recall: 0.5344, val_f1: 0.5344\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:12:33\n","loss: 0.9201, acc: 0.5736\n","E2E-ABSA >>> 2022-09-02 05:12:35\n","loss: 0.9212, acc: 0.5788\n","E2E-ABSA >>> 2022-09-02 05:12:36\n","loss: 0.9279, acc: 0.5777\n","E2E-ABSA >>> 2022-09-02 05:12:37\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:12:38\n","loss: 0.9524, acc: 0.5611\n","E2E-ABSA >>> 2022-09-02 05:12:39\n","loss: 0.9382, acc: 0.5673\n","E2E-ABSA >>> 2022-09-02 05:12:41\n","loss: 0.9321, acc: 0.5717\n","E2E-ABSA >>> 2022-09-02 05:12:42\n","loss: 0.9245, acc: 0.5767\n","E2E-ABSA >>> 2022-09-02 05:12:43\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:12:44\n","loss: 0.9277, acc: 0.5761\n","E2E-ABSA >>> 2022-09-02 05:12:45\n","loss: 0.9318, acc: 0.5710\n","E2E-ABSA >>> 2022-09-02 05:12:47\n","loss: 0.9293, acc: 0.5715\n","E2E-ABSA >>> 2022-09-02 05:12:48\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:12:49\n","loss: 0.9603, acc: 0.5484\n","E2E-ABSA >>> 2022-09-02 05:12:50\n","loss: 0.9321, acc: 0.5723\n","E2E-ABSA >>> 2022-09-02 05:12:51\n","loss: 0.9285, acc: 0.5734\n","E2E-ABSA >>> 2022-09-02 05:12:53\n","loss: 0.9254, acc: 0.5754\n","E2E-ABSA >>> 2022-09-02 05:12:53\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:12:55\n","loss: 0.9248, acc: 0.5760\n","E2E-ABSA >>> 2022-09-02 05:12:56\n","loss: 0.9236, acc: 0.5795\n","E2E-ABSA >>> 2022-09-02 05:12:57\n","loss: 0.9265, acc: 0.5775\n","E2E-ABSA >>> 2022-09-02 05:12:59\n",">>> val_acc: 0.5408, val_precision: 0.5408 val_recall: 0.5408, val_f1: 0.5408\n",">> saved: state_dict/ian_acl14shortdata_know_val_f1_0.5408\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:12:59\n","loss: 0.9304, acc: 0.5920\n","E2E-ABSA >>> 2022-09-02 05:13:01\n","loss: 0.9238, acc: 0.5786\n","E2E-ABSA >>> 2022-09-02 05:13:02\n","loss: 0.9274, acc: 0.5747\n","E2E-ABSA >>> 2022-09-02 05:13:04\n","loss: 0.9236, acc: 0.5774\n","E2E-ABSA >>> 2022-09-02 05:13:04\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:13:05\n","loss: 0.9213, acc: 0.5811\n","E2E-ABSA >>> 2022-09-02 05:13:07\n","loss: 0.9252, acc: 0.5751\n","E2E-ABSA >>> 2022-09-02 05:13:08\n","loss: 0.9280, acc: 0.5709\n","E2E-ABSA >>> 2022-09-02 05:13:09\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:13:10\n","loss: 0.9066, acc: 0.5879\n","E2E-ABSA >>> 2022-09-02 05:13:11\n","loss: 0.9265, acc: 0.5724\n","E2E-ABSA >>> 2022-09-02 05:13:13\n","loss: 0.9280, acc: 0.5730\n","E2E-ABSA >>> 2022-09-02 05:13:14\n","loss: 0.9245, acc: 0.5766\n","E2E-ABSA >>> 2022-09-02 05:13:15\n",">>> val_acc: 0.5408, val_precision: 0.5408 val_recall: 0.5408, val_f1: 0.5408\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:13:16\n","loss: 0.9141, acc: 0.5844\n","E2E-ABSA >>> 2022-09-02 05:13:17\n","loss: 0.9316, acc: 0.5687\n","E2E-ABSA >>> 2022-09-02 05:13:19\n","loss: 0.9271, acc: 0.5748\n","E2E-ABSA >>> 2022-09-02 05:13:20\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:13:20\n","loss: 0.9537, acc: 0.5513\n","E2E-ABSA >>> 2022-09-02 05:13:22\n","loss: 0.9254, acc: 0.5703\n","E2E-ABSA >>> 2022-09-02 05:13:23\n","loss: 0.9190, acc: 0.5787\n","E2E-ABSA >>> 2022-09-02 05:13:25\n","loss: 0.9239, acc: 0.5766\n","E2E-ABSA >>> 2022-09-02 05:13:25\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:13:26\n","loss: 0.9154, acc: 0.5929\n","E2E-ABSA >>> 2022-09-02 05:13:28\n","loss: 0.9206, acc: 0.5870\n","E2E-ABSA >>> 2022-09-02 05:13:29\n","loss: 0.9267, acc: 0.5777\n","E2E-ABSA >>> 2022-09-02 05:13:31\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:13:31\n","loss: 0.9312, acc: 0.5781\n","E2E-ABSA >>> 2022-09-02 05:13:32\n","loss: 0.9138, acc: 0.5847\n","E2E-ABSA >>> 2022-09-02 05:13:34\n","loss: 0.9212, acc: 0.5809\n","E2E-ABSA >>> 2022-09-02 05:13:35\n","loss: 0.9244, acc: 0.5762\n","E2E-ABSA >>> 2022-09-02 05:13:36\n",">>> val_acc: 0.5408, val_precision: 0.5408 val_recall: 0.5408, val_f1: 0.5408\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:13:37\n","loss: 0.9307, acc: 0.5686\n","E2E-ABSA >>> 2022-09-02 05:13:38\n","loss: 0.9220, acc: 0.5778\n","E2E-ABSA >>> 2022-09-02 05:13:40\n","loss: 0.9256, acc: 0.5749\n","E2E-ABSA >>> 2022-09-02 05:13:42\n",">>> val_acc: 0.5344, val_precision: 0.5344 val_recall: 0.5344, val_f1: 0.5344\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:13:42\n","loss: 0.9517, acc: 0.5531\n","E2E-ABSA >>> 2022-09-02 05:13:44\n","loss: 0.9177, acc: 0.5760\n","E2E-ABSA >>> 2022-09-02 05:13:45\n","loss: 0.9238, acc: 0.5747\n","E2E-ABSA >>> 2022-09-02 05:13:47\n","loss: 0.9225, acc: 0.5777\n","E2E-ABSA >>> 2022-09-02 05:13:47\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:13:48\n","loss: 0.9326, acc: 0.5790\n","E2E-ABSA >>> 2022-09-02 05:13:50\n","loss: 0.9242, acc: 0.5789\n","E2E-ABSA >>> 2022-09-02 05:13:51\n","loss: 0.9246, acc: 0.5770\n","E2E-ABSA >>> 2022-09-02 05:13:52\n",">>> val_acc: 0.5344, val_precision: 0.5344 val_recall: 0.5344, val_f1: 0.5344\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:13:53\n","loss: 0.9255, acc: 0.5664\n","E2E-ABSA >>> 2022-09-02 05:13:54\n","loss: 0.9120, acc: 0.5927\n","E2E-ABSA >>> 2022-09-02 05:13:56\n","loss: 0.9168, acc: 0.5874\n","E2E-ABSA >>> 2022-09-02 05:13:57\n","loss: 0.9228, acc: 0.5777\n","E2E-ABSA >>> 2022-09-02 05:13:58\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:13:59\n","loss: 0.9057, acc: 0.5781\n","E2E-ABSA >>> 2022-09-02 05:14:00\n","loss: 0.9150, acc: 0.5770\n","E2E-ABSA >>> 2022-09-02 05:14:02\n","loss: 0.9213, acc: 0.5779\n","E2E-ABSA >>> 2022-09-02 05:14:03\n",">>> val_acc: 0.5408, val_precision: 0.5408 val_recall: 0.5408, val_f1: 0.5408\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:14:03\n","loss: 0.9864, acc: 0.5365\n","E2E-ABSA >>> 2022-09-02 05:14:05\n","loss: 0.9142, acc: 0.5859\n","E2E-ABSA >>> 2022-09-02 05:14:06\n","loss: 0.9184, acc: 0.5814\n","E2E-ABSA >>> 2022-09-02 05:14:08\n","loss: 0.9198, acc: 0.5789\n","E2E-ABSA >>> 2022-09-02 05:14:08\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:14:09\n","loss: 0.9336, acc: 0.5719\n","E2E-ABSA >>> 2022-09-02 05:14:11\n","loss: 0.9238, acc: 0.5734\n","E2E-ABSA >>> 2022-09-02 05:14:12\n","loss: 0.9240, acc: 0.5769\n","E2E-ABSA >>> 2022-09-02 05:14:14\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:14:14\n","loss: 0.9188, acc: 0.5859\n","E2E-ABSA >>> 2022-09-02 05:14:15\n","loss: 0.9115, acc: 0.5891\n","E2E-ABSA >>> 2022-09-02 05:14:17\n","loss: 0.9157, acc: 0.5838\n","E2E-ABSA >>> 2022-09-02 05:14:18\n","loss: 0.9162, acc: 0.5826\n","E2E-ABSA >>> 2022-09-02 05:14:19\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:14:20\n","loss: 0.9352, acc: 0.5725\n","E2E-ABSA >>> 2022-09-02 05:14:21\n","loss: 0.9216, acc: 0.5733\n","E2E-ABSA >>> 2022-09-02 05:14:23\n","loss: 0.9201, acc: 0.5823\n","E2E-ABSA >>> 2022-09-02 05:14:24\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:14:25\n","loss: 1.0252, acc: 0.5000\n","E2E-ABSA >>> 2022-09-02 05:14:26\n","loss: 0.9163, acc: 0.5883\n","E2E-ABSA >>> 2022-09-02 05:14:27\n","loss: 0.9168, acc: 0.5846\n","E2E-ABSA >>> 2022-09-02 05:14:29\n","loss: 0.9226, acc: 0.5806\n","E2E-ABSA >>> 2022-09-02 05:14:30\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:14:31\n","loss: 0.9175, acc: 0.5913\n","E2E-ABSA >>> 2022-09-02 05:14:32\n","loss: 0.9337, acc: 0.5687\n","E2E-ABSA >>> 2022-09-02 05:14:34\n","loss: 0.9242, acc: 0.5756\n","E2E-ABSA >>> 2022-09-02 05:14:35\n","loss: 0.9229, acc: 0.5773\n","E2E-ABSA >>> 2022-09-02 05:14:35\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:14:37\n","loss: 0.9226, acc: 0.5813\n","E2E-ABSA >>> 2022-09-02 05:14:38\n","loss: 0.9250, acc: 0.5722\n","E2E-ABSA >>> 2022-09-02 05:14:40\n","loss: 0.9213, acc: 0.5765\n","E2E-ABSA >>> 2022-09-02 05:14:41\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:14:41\n","loss: 0.9399, acc: 0.5625\n","E2E-ABSA >>> 2022-09-02 05:14:43\n","loss: 0.9416, acc: 0.5642\n","E2E-ABSA >>> 2022-09-02 05:14:44\n","loss: 0.9274, acc: 0.5733\n","E2E-ABSA >>> 2022-09-02 05:14:46\n","loss: 0.9228, acc: 0.5774\n","E2E-ABSA >>> 2022-09-02 05:14:46\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:14:47\n","loss: 0.9059, acc: 0.6029\n","E2E-ABSA >>> 2022-09-02 05:14:49\n","loss: 0.9162, acc: 0.5851\n","E2E-ABSA >>> 2022-09-02 05:14:50\n","loss: 0.9214, acc: 0.5771\n","E2E-ABSA >>> 2022-09-02 05:14:51\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:14:52\n","loss: 0.9361, acc: 0.5767\n","E2E-ABSA >>> 2022-09-02 05:14:53\n","loss: 0.9235, acc: 0.5794\n","E2E-ABSA >>> 2022-09-02 05:14:55\n","loss: 0.9179, acc: 0.5815\n","E2E-ABSA >>> 2022-09-02 05:14:56\n","loss: 0.9205, acc: 0.5787\n","E2E-ABSA >>> 2022-09-02 05:14:57\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:14:58\n","loss: 0.9354, acc: 0.5659\n","E2E-ABSA >>> 2022-09-02 05:14:59\n","loss: 0.9322, acc: 0.5693\n","E2E-ABSA >>> 2022-09-02 05:15:01\n","loss: 0.9224, acc: 0.5775\n","E2E-ABSA >>> 2022-09-02 05:15:02\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:15:02\n","loss: 0.8936, acc: 0.6031\n","E2E-ABSA >>> 2022-09-02 05:15:04\n","loss: 0.9192, acc: 0.5853\n","E2E-ABSA >>> 2022-09-02 05:15:05\n","loss: 0.9184, acc: 0.5794\n","E2E-ABSA >>> 2022-09-02 05:15:07\n","loss: 0.9211, acc: 0.5772\n","E2E-ABSA >>> 2022-09-02 05:15:07\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:15:08\n","loss: 0.9227, acc: 0.5788\n","E2E-ABSA >>> 2022-09-02 05:15:10\n","loss: 0.9198, acc: 0.5788\n","E2E-ABSA >>> 2022-09-02 05:15:11\n","loss: 0.9221, acc: 0.5777\n","E2E-ABSA >>> 2022-09-02 05:15:12\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:15:13\n","loss: 0.9364, acc: 0.5729\n","E2E-ABSA >>> 2022-09-02 05:15:14\n","loss: 0.9331, acc: 0.5680\n","E2E-ABSA >>> 2022-09-02 05:15:16\n","loss: 0.9207, acc: 0.5810\n","E2E-ABSA >>> 2022-09-02 05:15:17\n","loss: 0.9217, acc: 0.5783\n","E2E-ABSA >>> 2022-09-02 05:15:18\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:15:19\n","loss: 0.8893, acc: 0.6057\n","E2E-ABSA >>> 2022-09-02 05:15:20\n","loss: 0.9047, acc: 0.5904\n","E2E-ABSA >>> 2022-09-02 05:15:22\n","loss: 0.9170, acc: 0.5775\n","E2E-ABSA >>> 2022-09-02 05:15:23\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:15:24\n","loss: 0.9369, acc: 0.5625\n","E2E-ABSA >>> 2022-09-02 05:15:25\n","loss: 0.9207, acc: 0.5810\n","E2E-ABSA >>> 2022-09-02 05:15:26\n","loss: 0.9214, acc: 0.5779\n","E2E-ABSA >>> 2022-09-02 05:15:28\n","loss: 0.9238, acc: 0.5761\n","E2E-ABSA >>> 2022-09-02 05:15:28\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:15:30\n","loss: 0.9162, acc: 0.5758\n","E2E-ABSA >>> 2022-09-02 05:15:31\n","loss: 0.9145, acc: 0.5813\n","E2E-ABSA >>> 2022-09-02 05:15:32\n","loss: 0.9196, acc: 0.5783\n","E2E-ABSA >>> 2022-09-02 05:15:34\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","E2E-ABSA >>> 2022-09-02 05:15:34\n","loss: 0.9596, acc: 0.5335\n","E2E-ABSA >>> 2022-09-02 05:15:36\n","loss: 0.9292, acc: 0.5674\n","E2E-ABSA >>> 2022-09-02 05:15:37\n","loss: 0.9292, acc: 0.5721\n","E2E-ABSA >>> 2022-09-02 05:15:38\n","loss: 0.9247, acc: 0.5774\n","E2E-ABSA >>> 2022-09-02 05:15:39\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n","E2E-ABSA >>> 2022-09-02 05:15:39\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.5408, val_precision: 0.5408 val_recall: 0.5408, val_f1: 0.5408\n","you can download the best model from state_dict/ian_acl14shortdata_know_val_f1_0.5408\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/DictionaryFused-E2E-ABSA/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n",">>> test_acc: 0.5408, test_precision: 0.5408, test_recall: 0.5408, test_f1: 0.5408\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **acl14shortdata** dataset on model(**MEMNET**)\n"],"metadata":{"id":"5CRPy6TUXjdB"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name memnet --dataset acl14shortdata_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TB9jVmjXXjhr","outputId":"d3177ad0-753e-4237-a565-f49a0ac1d79a","executionInfo":{"status":"ok","timestamp":1662096068265,"user_tz":-480,"elapsed":326957,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 5623.\n","> testing dataset count: 625.\n","cuda memory allocated: 18232320\n","> n_trainable_params: 362703, n_nontrainable_params: 4136100\n","> training arguments:\n",">>> model_name: memnet\n",">>> dataset: acl14shortdata_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f5938919c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.memnet.MemNet'>\n",">>> dataset_file: {'train': './datasets/acl14shortdata/output_know_insert/train.tsv', 'test': './datasets/acl14shortdata/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['context_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:21\n","loss: 1.0357, acc: 0.4994\n","E2E-ABSA >>> 2022-09-02 05:16:22\n","loss: 1.0187, acc: 0.5072\n","E2E-ABSA >>> 2022-09-02 05:16:22\n","loss: 1.0022, acc: 0.5181\n","E2E-ABSA >>> 2022-09-02 05:16:23\n",">>> val_acc: 0.5216, val_precision: 0.5216 val_recall: 0.5216, val_f1: 0.5216\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.5216\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:23\n","loss: 0.9068, acc: 0.5885\n","E2E-ABSA >>> 2022-09-02 05:16:24\n","loss: 0.9410, acc: 0.5680\n","E2E-ABSA >>> 2022-09-02 05:16:25\n","loss: 0.9411, acc: 0.5635\n","E2E-ABSA >>> 2022-09-02 05:16:26\n","loss: 0.9418, acc: 0.5647\n","E2E-ABSA >>> 2022-09-02 05:16:26\n",">>> val_acc: 0.5264, val_precision: 0.5264 val_recall: 0.5264, val_f1: 0.5264\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.5264\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:27\n","loss: 0.8969, acc: 0.5957\n","E2E-ABSA >>> 2022-09-02 05:16:27\n","loss: 0.9087, acc: 0.5835\n","E2E-ABSA >>> 2022-09-02 05:16:28\n","loss: 0.9168, acc: 0.5733\n","E2E-ABSA >>> 2022-09-02 05:16:29\n",">>> val_acc: 0.5360, val_precision: 0.5360 val_recall: 0.5360, val_f1: 0.5360\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.536\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:29\n","loss: 0.8888, acc: 0.5881\n","E2E-ABSA >>> 2022-09-02 05:16:30\n","loss: 0.9102, acc: 0.5760\n","E2E-ABSA >>> 2022-09-02 05:16:31\n","loss: 0.9029, acc: 0.5804\n","E2E-ABSA >>> 2022-09-02 05:16:31\n","loss: 0.8935, acc: 0.5908\n","E2E-ABSA >>> 2022-09-02 05:16:32\n",">>> val_acc: 0.5376, val_precision: 0.5376 val_recall: 0.5376, val_f1: 0.5376\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.5376\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:32\n","loss: 0.8803, acc: 0.5931\n","E2E-ABSA >>> 2022-09-02 05:16:33\n","loss: 0.8782, acc: 0.5954\n","E2E-ABSA >>> 2022-09-02 05:16:34\n","loss: 0.8676, acc: 0.6102\n","E2E-ABSA >>> 2022-09-02 05:16:34\n",">>> val_acc: 0.5776, val_precision: 0.5776 val_recall: 0.5776, val_f1: 0.5776\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.5776\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:35\n","loss: 0.8312, acc: 0.6219\n","E2E-ABSA >>> 2022-09-02 05:16:35\n","loss: 0.8461, acc: 0.6129\n","E2E-ABSA >>> 2022-09-02 05:16:36\n","loss: 0.8401, acc: 0.6208\n","E2E-ABSA >>> 2022-09-02 05:16:37\n","loss: 0.8369, acc: 0.6208\n","E2E-ABSA >>> 2022-09-02 05:16:37\n",">>> val_acc: 0.6000, val_precision: 0.6000 val_recall: 0.6000, val_f1: 0.6000\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.6\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:38\n","loss: 0.8176, acc: 0.6357\n","E2E-ABSA >>> 2022-09-02 05:16:39\n","loss: 0.8101, acc: 0.6426\n","E2E-ABSA >>> 2022-09-02 05:16:39\n","loss: 0.8138, acc: 0.6361\n","E2E-ABSA >>> 2022-09-02 05:16:40\n",">>> val_acc: 0.6256, val_precision: 0.6256 val_recall: 0.6256, val_f1: 0.6256\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.6256\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:40\n","loss: 0.7627, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 05:16:41\n","loss: 0.7762, acc: 0.6650\n","E2E-ABSA >>> 2022-09-02 05:16:42\n","loss: 0.7789, acc: 0.6602\n","E2E-ABSA >>> 2022-09-02 05:16:43\n","loss: 0.7819, acc: 0.6577\n","E2E-ABSA >>> 2022-09-02 05:16:43\n",">>> val_acc: 0.6224, val_precision: 0.6224 val_recall: 0.6224, val_f1: 0.6224\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:44\n","loss: 0.7497, acc: 0.6704\n","E2E-ABSA >>> 2022-09-02 05:16:44\n","loss: 0.7676, acc: 0.6668\n","E2E-ABSA >>> 2022-09-02 05:16:45\n","loss: 0.7658, acc: 0.6655\n","E2E-ABSA >>> 2022-09-02 05:16:46\n",">>> val_acc: 0.6400, val_precision: 0.6400 val_recall: 0.6400, val_f1: 0.6400\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.64\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:46\n","loss: 0.7203, acc: 0.6973\n","E2E-ABSA >>> 2022-09-02 05:16:47\n","loss: 0.7487, acc: 0.6766\n","E2E-ABSA >>> 2022-09-02 05:16:48\n","loss: 0.7490, acc: 0.6770\n","E2E-ABSA >>> 2022-09-02 05:16:48\n","loss: 0.7464, acc: 0.6766\n","E2E-ABSA >>> 2022-09-02 05:16:49\n",">>> val_acc: 0.6544, val_precision: 0.6544 val_recall: 0.6544, val_f1: 0.6544\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.6544\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:49\n","loss: 0.7539, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 05:16:50\n","loss: 0.7493, acc: 0.6774\n","E2E-ABSA >>> 2022-09-02 05:16:51\n","loss: 0.7431, acc: 0.6828\n","E2E-ABSA >>> 2022-09-02 05:16:52\n",">>> val_acc: 0.6592, val_precision: 0.6592 val_recall: 0.6592, val_f1: 0.6592\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.6592\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:52\n","loss: 0.6975, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 05:16:53\n","loss: 0.7389, acc: 0.6851\n","E2E-ABSA >>> 2022-09-02 05:16:53\n","loss: 0.7342, acc: 0.6834\n","E2E-ABSA >>> 2022-09-02 05:16:54\n","loss: 0.7248, acc: 0.6860\n","E2E-ABSA >>> 2022-09-02 05:16:54\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:55\n","loss: 0.7385, acc: 0.6702\n","E2E-ABSA >>> 2022-09-02 05:16:56\n","loss: 0.7178, acc: 0.6928\n","E2E-ABSA >>> 2022-09-02 05:16:57\n","loss: 0.7161, acc: 0.6932\n","E2E-ABSA >>> 2022-09-02 05:16:57\n",">>> val_acc: 0.6560, val_precision: 0.6560 val_recall: 0.6560, val_f1: 0.6560\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:16:57\n","loss: 0.7204, acc: 0.7057\n","E2E-ABSA >>> 2022-09-02 05:16:58\n","loss: 0.7176, acc: 0.6895\n","E2E-ABSA >>> 2022-09-02 05:16:59\n","loss: 0.7122, acc: 0.6914\n","E2E-ABSA >>> 2022-09-02 05:17:00\n","loss: 0.7131, acc: 0.6929\n","E2E-ABSA >>> 2022-09-02 05:17:00\n",">>> val_acc: 0.6544, val_precision: 0.6544 val_recall: 0.6544, val_f1: 0.6544\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:01\n","loss: 0.7144, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 05:17:01\n","loss: 0.7219, acc: 0.6879\n","E2E-ABSA >>> 2022-09-02 05:17:02\n","loss: 0.7145, acc: 0.6962\n","E2E-ABSA >>> 2022-09-02 05:17:03\n",">>> val_acc: 0.6688, val_precision: 0.6688 val_recall: 0.6688, val_f1: 0.6688\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.6688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:03\n","loss: 0.7236, acc: 0.6750\n","E2E-ABSA >>> 2022-09-02 05:17:04\n","loss: 0.6914, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 05:17:05\n","loss: 0.6994, acc: 0.6960\n","E2E-ABSA >>> 2022-09-02 05:17:05\n","loss: 0.7042, acc: 0.6943\n","E2E-ABSA >>> 2022-09-02 05:17:06\n",">>> val_acc: 0.6768, val_precision: 0.6768 val_recall: 0.6768, val_f1: 0.6768\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.6768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:06\n","loss: 0.7163, acc: 0.7004\n","E2E-ABSA >>> 2022-09-02 05:17:07\n","loss: 0.6985, acc: 0.7065\n","E2E-ABSA >>> 2022-09-02 05:17:08\n","loss: 0.6945, acc: 0.7059\n","E2E-ABSA >>> 2022-09-02 05:17:09\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:09\n","loss: 0.6355, acc: 0.7227\n","E2E-ABSA >>> 2022-09-02 05:17:10\n","loss: 0.6851, acc: 0.7117\n","E2E-ABSA >>> 2022-09-02 05:17:10\n","loss: 0.6930, acc: 0.7057\n","E2E-ABSA >>> 2022-09-02 05:17:11\n","loss: 0.6945, acc: 0.7011\n","E2E-ABSA >>> 2022-09-02 05:17:12\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:12\n","loss: 0.7044, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 05:17:13\n","loss: 0.7037, acc: 0.7035\n","E2E-ABSA >>> 2022-09-02 05:17:13\n","loss: 0.6993, acc: 0.7017\n","E2E-ABSA >>> 2022-09-02 05:17:14\n",">>> val_acc: 0.6624, val_precision: 0.6624 val_recall: 0.6624, val_f1: 0.6624\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:14\n","loss: 0.7340, acc: 0.6510\n","E2E-ABSA >>> 2022-09-02 05:17:15\n","loss: 0.7064, acc: 0.6964\n","E2E-ABSA >>> 2022-09-02 05:17:16\n","loss: 0.6958, acc: 0.6993\n","E2E-ABSA >>> 2022-09-02 05:17:17\n","loss: 0.6908, acc: 0.7047\n","E2E-ABSA >>> 2022-09-02 05:17:17\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:18\n","loss: 0.6904, acc: 0.7146\n","E2E-ABSA >>> 2022-09-02 05:17:18\n","loss: 0.6676, acc: 0.7164\n","E2E-ABSA >>> 2022-09-02 05:17:19\n","loss: 0.6824, acc: 0.7075\n","E2E-ABSA >>> 2022-09-02 05:17:20\n",">>> val_acc: 0.6656, val_precision: 0.6656 val_recall: 0.6656, val_f1: 0.6656\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:20\n","loss: 0.5842, acc: 0.7422\n","E2E-ABSA >>> 2022-09-02 05:17:21\n","loss: 0.6656, acc: 0.7141\n","E2E-ABSA >>> 2022-09-02 05:17:22\n","loss: 0.6844, acc: 0.7025\n","E2E-ABSA >>> 2022-09-02 05:17:22\n","loss: 0.6875, acc: 0.7003\n","E2E-ABSA >>> 2022-09-02 05:17:23\n",">>> val_acc: 0.6720, val_precision: 0.6720 val_recall: 0.6720, val_f1: 0.6720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:23\n","loss: 0.7002, acc: 0.7076\n","E2E-ABSA >>> 2022-09-02 05:17:24\n","loss: 0.6955, acc: 0.7055\n","E2E-ABSA >>> 2022-09-02 05:17:25\n","loss: 0.6862, acc: 0.7070\n","E2E-ABSA >>> 2022-09-02 05:17:26\n",">>> val_acc: 0.6768, val_precision: 0.6768 val_recall: 0.6768, val_f1: 0.6768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:26\n","loss: 0.6086, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 05:17:26\n","loss: 0.6476, acc: 0.7248\n","E2E-ABSA >>> 2022-09-02 05:17:27\n","loss: 0.6666, acc: 0.7203\n","E2E-ABSA >>> 2022-09-02 05:17:28\n","loss: 0.6715, acc: 0.7163\n","E2E-ABSA >>> 2022-09-02 05:17:28\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:29\n","loss: 0.6654, acc: 0.7115\n","E2E-ABSA >>> 2022-09-02 05:17:30\n","loss: 0.6823, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 05:17:30\n","loss: 0.6840, acc: 0.7056\n","E2E-ABSA >>> 2022-09-02 05:17:31\n","loss: 0.6804, acc: 0.7057\n","E2E-ABSA >>> 2022-09-02 05:17:31\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:32\n","loss: 0.6632, acc: 0.7288\n","E2E-ABSA >>> 2022-09-02 05:17:33\n","loss: 0.6889, acc: 0.7122\n","E2E-ABSA >>> 2022-09-02 05:17:34\n","loss: 0.6815, acc: 0.7100\n","E2E-ABSA >>> 2022-09-02 05:17:34\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:35\n","loss: 0.6714, acc: 0.7214\n","E2E-ABSA >>> 2022-09-02 05:17:35\n","loss: 0.6616, acc: 0.7318\n","E2E-ABSA >>> 2022-09-02 05:17:36\n","loss: 0.6776, acc: 0.7155\n","E2E-ABSA >>> 2022-09-02 05:17:37\n","loss: 0.6783, acc: 0.7107\n","E2E-ABSA >>> 2022-09-02 05:17:37\n",">>> val_acc: 0.6832, val_precision: 0.6832 val_recall: 0.6832, val_f1: 0.6832\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.6832\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:38\n","loss: 0.6673, acc: 0.7227\n","E2E-ABSA >>> 2022-09-02 05:17:39\n","loss: 0.6665, acc: 0.7149\n","E2E-ABSA >>> 2022-09-02 05:17:39\n","loss: 0.6707, acc: 0.7145\n","E2E-ABSA >>> 2022-09-02 05:17:40\n",">>> val_acc: 0.6768, val_precision: 0.6768 val_recall: 0.6768, val_f1: 0.6768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:40\n","loss: 0.6306, acc: 0.7315\n","E2E-ABSA >>> 2022-09-02 05:17:41\n","loss: 0.6487, acc: 0.7205\n","E2E-ABSA >>> 2022-09-02 05:17:42\n","loss: 0.6713, acc: 0.7098\n","E2E-ABSA >>> 2022-09-02 05:17:43\n","loss: 0.6740, acc: 0.7122\n","E2E-ABSA >>> 2022-09-02 05:17:43\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:44\n","loss: 0.6444, acc: 0.7357\n","E2E-ABSA >>> 2022-09-02 05:17:44\n","loss: 0.6825, acc: 0.7116\n","E2E-ABSA >>> 2022-09-02 05:17:45\n","loss: 0.6751, acc: 0.7175\n","E2E-ABSA >>> 2022-09-02 05:17:46\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:47\n","loss: 0.7186, acc: 0.6953\n","E2E-ABSA >>> 2022-09-02 05:17:47\n","loss: 0.6813, acc: 0.7152\n","E2E-ABSA >>> 2022-09-02 05:17:48\n","loss: 0.6696, acc: 0.7169\n","E2E-ABSA >>> 2022-09-02 05:17:49\n","loss: 0.6730, acc: 0.7167\n","E2E-ABSA >>> 2022-09-02 05:17:49\n",">>> val_acc: 0.6768, val_precision: 0.6768 val_recall: 0.6768, val_f1: 0.6768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:50\n","loss: 0.6856, acc: 0.6946\n","E2E-ABSA >>> 2022-09-02 05:17:51\n","loss: 0.6608, acc: 0.7184\n","E2E-ABSA >>> 2022-09-02 05:17:51\n","loss: 0.6689, acc: 0.7129\n","E2E-ABSA >>> 2022-09-02 05:17:52\n",">>> val_acc: 0.6816, val_precision: 0.6816 val_recall: 0.6816, val_f1: 0.6816\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:52\n","loss: 0.6186, acc: 0.7309\n","E2E-ABSA >>> 2022-09-02 05:17:53\n","loss: 0.6769, acc: 0.7091\n","E2E-ABSA >>> 2022-09-02 05:17:54\n","loss: 0.6723, acc: 0.7140\n","E2E-ABSA >>> 2022-09-02 05:17:54\n","loss: 0.6685, acc: 0.7169\n","E2E-ABSA >>> 2022-09-02 05:17:55\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:55\n","loss: 0.6834, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 05:17:56\n","loss: 0.6747, acc: 0.7096\n","E2E-ABSA >>> 2022-09-02 05:17:57\n","loss: 0.6748, acc: 0.7099\n","E2E-ABSA >>> 2022-09-02 05:17:58\n",">>> val_acc: 0.6864, val_precision: 0.6864 val_recall: 0.6864, val_f1: 0.6864\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.6864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:17:58\n","loss: 0.6595, acc: 0.7207\n","E2E-ABSA >>> 2022-09-02 05:17:59\n","loss: 0.6497, acc: 0.7325\n","E2E-ABSA >>> 2022-09-02 05:17:59\n","loss: 0.6627, acc: 0.7185\n","E2E-ABSA >>> 2022-09-02 05:18:00\n","loss: 0.6671, acc: 0.7169\n","E2E-ABSA >>> 2022-09-02 05:18:00\n",">>> val_acc: 0.6768, val_precision: 0.6768 val_recall: 0.6768, val_f1: 0.6768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:01\n","loss: 0.6378, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 05:18:02\n","loss: 0.6602, acc: 0.7233\n","E2E-ABSA >>> 2022-09-02 05:18:03\n","loss: 0.6639, acc: 0.7194\n","E2E-ABSA >>> 2022-09-02 05:18:03\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:03\n","loss: 0.6272, acc: 0.7522\n","E2E-ABSA >>> 2022-09-02 05:18:04\n","loss: 0.6609, acc: 0.7227\n","E2E-ABSA >>> 2022-09-02 05:18:05\n","loss: 0.6624, acc: 0.7157\n","E2E-ABSA >>> 2022-09-02 05:18:06\n","loss: 0.6664, acc: 0.7138\n","E2E-ABSA >>> 2022-09-02 05:18:06\n",">>> val_acc: 0.6768, val_precision: 0.6768 val_recall: 0.6768, val_f1: 0.6768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:07\n","loss: 0.6575, acc: 0.7237\n","E2E-ABSA >>> 2022-09-02 05:18:07\n","loss: 0.6771, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 05:18:08\n","loss: 0.6686, acc: 0.7108\n","E2E-ABSA >>> 2022-09-02 05:18:09\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:09\n","loss: 0.6932, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 05:18:10\n","loss: 0.6502, acc: 0.7268\n","E2E-ABSA >>> 2022-09-02 05:18:11\n","loss: 0.6651, acc: 0.7246\n","E2E-ABSA >>> 2022-09-02 05:18:11\n","loss: 0.6655, acc: 0.7222\n","E2E-ABSA >>> 2022-09-02 05:18:12\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:12\n","loss: 0.6534, acc: 0.7335\n","E2E-ABSA >>> 2022-09-02 05:18:13\n","loss: 0.6576, acc: 0.7177\n","E2E-ABSA >>> 2022-09-02 05:18:14\n","loss: 0.6611, acc: 0.7176\n","E2E-ABSA >>> 2022-09-02 05:18:15\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:15\n","loss: 0.7126, acc: 0.6844\n","E2E-ABSA >>> 2022-09-02 05:18:16\n","loss: 0.6606, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 05:18:16\n","loss: 0.6621, acc: 0.7193\n","E2E-ABSA >>> 2022-09-02 05:18:17\n","loss: 0.6700, acc: 0.7152\n","E2E-ABSA >>> 2022-09-02 05:18:18\n",">>> val_acc: 0.6848, val_precision: 0.6848 val_recall: 0.6848, val_f1: 0.6848\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:18\n","loss: 0.6333, acc: 0.7362\n","E2E-ABSA >>> 2022-09-02 05:18:19\n","loss: 0.6532, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 05:18:20\n","loss: 0.6498, acc: 0.7257\n","E2E-ABSA >>> 2022-09-02 05:18:20\n",">>> val_acc: 0.6800, val_precision: 0.6800 val_recall: 0.6800, val_f1: 0.6800\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:21\n","loss: 0.6571, acc: 0.7383\n","E2E-ABSA >>> 2022-09-02 05:18:21\n","loss: 0.6620, acc: 0.7209\n","E2E-ABSA >>> 2022-09-02 05:18:22\n","loss: 0.6679, acc: 0.7176\n","E2E-ABSA >>> 2022-09-02 05:18:23\n","loss: 0.6612, acc: 0.7217\n","E2E-ABSA >>> 2022-09-02 05:18:23\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:24\n","loss: 0.6162, acc: 0.7383\n","E2E-ABSA >>> 2022-09-02 05:18:25\n","loss: 0.6512, acc: 0.7195\n","E2E-ABSA >>> 2022-09-02 05:18:25\n","loss: 0.6640, acc: 0.7178\n","E2E-ABSA >>> 2022-09-02 05:18:26\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:26\n","loss: 0.6536, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 05:18:27\n","loss: 0.6492, acc: 0.7327\n","E2E-ABSA >>> 2022-09-02 05:18:28\n","loss: 0.6595, acc: 0.7199\n","E2E-ABSA >>> 2022-09-02 05:18:28\n","loss: 0.6571, acc: 0.7254\n","E2E-ABSA >>> 2022-09-02 05:18:29\n",">>> val_acc: 0.6800, val_precision: 0.6800 val_recall: 0.6800, val_f1: 0.6800\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:29\n","loss: 0.6406, acc: 0.7417\n","E2E-ABSA >>> 2022-09-02 05:18:30\n","loss: 0.6564, acc: 0.7324\n","E2E-ABSA >>> 2022-09-02 05:18:31\n","loss: 0.6507, acc: 0.7351\n","E2E-ABSA >>> 2022-09-02 05:18:32\n",">>> val_acc: 0.6768, val_precision: 0.6768 val_recall: 0.6768, val_f1: 0.6768\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:32\n","loss: 0.6626, acc: 0.6875\n","E2E-ABSA >>> 2022-09-02 05:18:33\n","loss: 0.6600, acc: 0.7234\n","E2E-ABSA >>> 2022-09-02 05:18:33\n","loss: 0.6526, acc: 0.7260\n","E2E-ABSA >>> 2022-09-02 05:18:34\n","loss: 0.6582, acc: 0.7208\n","E2E-ABSA >>> 2022-09-02 05:18:35\n",">>> val_acc: 0.6848, val_precision: 0.6848 val_recall: 0.6848, val_f1: 0.6848\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:35\n","loss: 0.6844, acc: 0.7087\n","E2E-ABSA >>> 2022-09-02 05:18:36\n","loss: 0.6583, acc: 0.7228\n","E2E-ABSA >>> 2022-09-02 05:18:37\n","loss: 0.6583, acc: 0.7224\n","E2E-ABSA >>> 2022-09-02 05:18:37\n",">>> val_acc: 0.6800, val_precision: 0.6800 val_recall: 0.6800, val_f1: 0.6800\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:37\n","loss: 0.7521, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 05:18:38\n","loss: 0.6520, acc: 0.7308\n","E2E-ABSA >>> 2022-09-02 05:18:39\n","loss: 0.6423, acc: 0.7341\n","E2E-ABSA >>> 2022-09-02 05:18:40\n","loss: 0.6560, acc: 0.7286\n","E2E-ABSA >>> 2022-09-02 05:18:40\n",">>> val_acc: 0.6880, val_precision: 0.6880 val_recall: 0.6880, val_f1: 0.6880\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.688\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:41\n","loss: 0.6927, acc: 0.6995\n","E2E-ABSA >>> 2022-09-02 05:18:41\n","loss: 0.6776, acc: 0.6998\n","E2E-ABSA >>> 2022-09-02 05:18:42\n","loss: 0.6663, acc: 0.7143\n","E2E-ABSA >>> 2022-09-02 05:18:43\n","loss: 0.6545, acc: 0.7215\n","E2E-ABSA >>> 2022-09-02 05:18:43\n",">>> val_acc: 0.6832, val_precision: 0.6832 val_recall: 0.6832, val_f1: 0.6832\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:44\n","loss: 0.6471, acc: 0.7269\n","E2E-ABSA >>> 2022-09-02 05:18:45\n","loss: 0.6495, acc: 0.7222\n","E2E-ABSA >>> 2022-09-02 05:18:45\n","loss: 0.6447, acc: 0.7283\n","E2E-ABSA >>> 2022-09-02 05:18:46\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:46\n","loss: 0.6701, acc: 0.7214\n","E2E-ABSA >>> 2022-09-02 05:18:47\n","loss: 0.6431, acc: 0.7306\n","E2E-ABSA >>> 2022-09-02 05:18:48\n","loss: 0.6496, acc: 0.7261\n","E2E-ABSA >>> 2022-09-02 05:18:49\n","loss: 0.6506, acc: 0.7270\n","E2E-ABSA >>> 2022-09-02 05:18:49\n",">>> val_acc: 0.6880, val_precision: 0.6880 val_recall: 0.6880, val_f1: 0.6880\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:50\n","loss: 0.6215, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 05:18:50\n","loss: 0.6455, acc: 0.7258\n","E2E-ABSA >>> 2022-09-02 05:18:51\n","loss: 0.6524, acc: 0.7194\n","E2E-ABSA >>> 2022-09-02 05:18:52\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:52\n","loss: 0.6573, acc: 0.7216\n","E2E-ABSA >>> 2022-09-02 05:18:53\n","loss: 0.6544, acc: 0.7161\n","E2E-ABSA >>> 2022-09-02 05:18:54\n","loss: 0.6473, acc: 0.7221\n","E2E-ABSA >>> 2022-09-02 05:18:54\n","loss: 0.6522, acc: 0.7240\n","E2E-ABSA >>> 2022-09-02 05:18:54\n",">>> val_acc: 0.6816, val_precision: 0.6816 val_recall: 0.6816, val_f1: 0.6816\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:55\n","loss: 0.6598, acc: 0.7242\n","E2E-ABSA >>> 2022-09-02 05:18:56\n","loss: 0.6563, acc: 0.7236\n","E2E-ABSA >>> 2022-09-02 05:18:57\n","loss: 0.6531, acc: 0.7232\n","E2E-ABSA >>> 2022-09-02 05:18:57\n",">>> val_acc: 0.6880, val_precision: 0.6880 val_recall: 0.6880, val_f1: 0.6880\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:18:58\n","loss: 0.6808, acc: 0.6969\n","E2E-ABSA >>> 2022-09-02 05:18:58\n","loss: 0.6663, acc: 0.7196\n","E2E-ABSA >>> 2022-09-02 05:18:59\n","loss: 0.6613, acc: 0.7211\n","E2E-ABSA >>> 2022-09-02 05:19:00\n","loss: 0.6535, acc: 0.7259\n","E2E-ABSA >>> 2022-09-02 05:19:00\n",">>> val_acc: 0.6944, val_precision: 0.6944 val_recall: 0.6944, val_f1: 0.6944\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.6944\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:01\n","loss: 0.6422, acc: 0.7372\n","E2E-ABSA >>> 2022-09-02 05:19:02\n","loss: 0.6476, acc: 0.7267\n","E2E-ABSA >>> 2022-09-02 05:19:02\n","loss: 0.6503, acc: 0.7274\n","E2E-ABSA >>> 2022-09-02 05:19:03\n",">>> val_acc: 0.6816, val_precision: 0.6816 val_recall: 0.6816, val_f1: 0.6816\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:03\n","loss: 0.6646, acc: 0.7153\n","E2E-ABSA >>> 2022-09-02 05:19:04\n","loss: 0.6572, acc: 0.7224\n","E2E-ABSA >>> 2022-09-02 05:19:05\n","loss: 0.6610, acc: 0.7211\n","E2E-ABSA >>> 2022-09-02 05:19:06\n","loss: 0.6515, acc: 0.7262\n","E2E-ABSA >>> 2022-09-02 05:19:06\n",">>> val_acc: 0.6832, val_precision: 0.6832 val_recall: 0.6832, val_f1: 0.6832\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:07\n","loss: 0.6668, acc: 0.7277\n","E2E-ABSA >>> 2022-09-02 05:19:07\n","loss: 0.6480, acc: 0.7327\n","E2E-ABSA >>> 2022-09-02 05:19:08\n","loss: 0.6428, acc: 0.7313\n","E2E-ABSA >>> 2022-09-02 05:19:09\n",">>> val_acc: 0.6816, val_precision: 0.6816 val_recall: 0.6816, val_f1: 0.6816\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:09\n","loss: 0.6179, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 05:19:10\n","loss: 0.6505, acc: 0.7287\n","E2E-ABSA >>> 2022-09-02 05:19:11\n","loss: 0.6516, acc: 0.7260\n","E2E-ABSA >>> 2022-09-02 05:19:11\n","loss: 0.6489, acc: 0.7276\n","E2E-ABSA >>> 2022-09-02 05:19:12\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:12\n","loss: 0.6412, acc: 0.7297\n","E2E-ABSA >>> 2022-09-02 05:19:13\n","loss: 0.6553, acc: 0.7233\n","E2E-ABSA >>> 2022-09-02 05:19:14\n","loss: 0.6563, acc: 0.7232\n","E2E-ABSA >>> 2022-09-02 05:19:14\n",">>> val_acc: 0.6880, val_precision: 0.6880 val_recall: 0.6880, val_f1: 0.6880\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:15\n","loss: 0.6615, acc: 0.7321\n","E2E-ABSA >>> 2022-09-02 05:19:15\n","loss: 0.6647, acc: 0.7173\n","E2E-ABSA >>> 2022-09-02 05:19:16\n","loss: 0.6492, acc: 0.7267\n","E2E-ABSA >>> 2022-09-02 05:19:17\n","loss: 0.6443, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 05:19:17\n",">>> val_acc: 0.6816, val_precision: 0.6816 val_recall: 0.6816, val_f1: 0.6816\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:18\n","loss: 0.6542, acc: 0.7311\n","E2E-ABSA >>> 2022-09-02 05:19:19\n","loss: 0.6450, acc: 0.7315\n","E2E-ABSA >>> 2022-09-02 05:19:19\n","loss: 0.6413, acc: 0.7310\n","E2E-ABSA >>> 2022-09-02 05:19:20\n",">>> val_acc: 0.6880, val_precision: 0.6880 val_recall: 0.6880, val_f1: 0.6880\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:20\n","loss: 0.6330, acc: 0.7578\n","E2E-ABSA >>> 2022-09-02 05:19:21\n","loss: 0.6435, acc: 0.7354\n","E2E-ABSA >>> 2022-09-02 05:19:22\n","loss: 0.6407, acc: 0.7335\n","E2E-ABSA >>> 2022-09-02 05:19:23\n","loss: 0.6421, acc: 0.7321\n","E2E-ABSA >>> 2022-09-02 05:19:23\n",">>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.696\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:23\n","loss: 0.6380, acc: 0.7266\n","E2E-ABSA >>> 2022-09-02 05:19:24\n","loss: 0.6257, acc: 0.7406\n","E2E-ABSA >>> 2022-09-02 05:19:25\n","loss: 0.6411, acc: 0.7289\n","E2E-ABSA >>> 2022-09-02 05:19:26\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:26\n","loss: 0.6938, acc: 0.6937\n","E2E-ABSA >>> 2022-09-02 05:19:27\n","loss: 0.6576, acc: 0.7203\n","E2E-ABSA >>> 2022-09-02 05:19:28\n","loss: 0.6508, acc: 0.7244\n","E2E-ABSA >>> 2022-09-02 05:19:28\n","loss: 0.6435, acc: 0.7299\n","E2E-ABSA >>> 2022-09-02 05:19:29\n",">>> val_acc: 0.6880, val_precision: 0.6880 val_recall: 0.6880, val_f1: 0.6880\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:29\n","loss: 0.6316, acc: 0.7261\n","E2E-ABSA >>> 2022-09-02 05:19:30\n","loss: 0.6310, acc: 0.7284\n","E2E-ABSA >>> 2022-09-02 05:19:31\n","loss: 0.6299, acc: 0.7316\n","E2E-ABSA >>> 2022-09-02 05:19:31\n",">>> val_acc: 0.6864, val_precision: 0.6864 val_recall: 0.6864, val_f1: 0.6864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:32\n","loss: 0.6074, acc: 0.7227\n","E2E-ABSA >>> 2022-09-02 05:19:32\n","loss: 0.6400, acc: 0.7247\n","E2E-ABSA >>> 2022-09-02 05:19:33\n","loss: 0.6421, acc: 0.7274\n","E2E-ABSA >>> 2022-09-02 05:19:34\n","loss: 0.6426, acc: 0.7277\n","E2E-ABSA >>> 2022-09-02 05:19:34\n",">>> val_acc: 0.6944, val_precision: 0.6944 val_recall: 0.6944, val_f1: 0.6944\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:35\n","loss: 0.6248, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 05:19:36\n","loss: 0.6427, acc: 0.7302\n","E2E-ABSA >>> 2022-09-02 05:19:36\n","loss: 0.6457, acc: 0.7287\n","E2E-ABSA >>> 2022-09-02 05:19:37\n",">>> val_acc: 0.6848, val_precision: 0.6848 val_recall: 0.6848, val_f1: 0.6848\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:37\n","loss: 0.6760, acc: 0.6979\n","E2E-ABSA >>> 2022-09-02 05:19:38\n","loss: 0.6633, acc: 0.7148\n","E2E-ABSA >>> 2022-09-02 05:19:39\n","loss: 0.6336, acc: 0.7314\n","E2E-ABSA >>> 2022-09-02 05:19:40\n","loss: 0.6367, acc: 0.7306\n","E2E-ABSA >>> 2022-09-02 05:19:40\n",">>> val_acc: 0.6912, val_precision: 0.6912 val_recall: 0.6912, val_f1: 0.6912\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:40\n","loss: 0.6396, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 05:19:41\n","loss: 0.6378, acc: 0.7301\n","E2E-ABSA >>> 2022-09-02 05:19:42\n","loss: 0.6425, acc: 0.7284\n","E2E-ABSA >>> 2022-09-02 05:19:43\n",">>> val_acc: 0.6896, val_precision: 0.6896 val_recall: 0.6896, val_f1: 0.6896\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:43\n","loss: 0.6467, acc: 0.7734\n","E2E-ABSA >>> 2022-09-02 05:19:44\n","loss: 0.6327, acc: 0.7402\n","E2E-ABSA >>> 2022-09-02 05:19:44\n","loss: 0.6442, acc: 0.7305\n","E2E-ABSA >>> 2022-09-02 05:19:45\n","loss: 0.6417, acc: 0.7313\n","E2E-ABSA >>> 2022-09-02 05:19:46\n",">>> val_acc: 0.6848, val_precision: 0.6848 val_recall: 0.6848, val_f1: 0.6848\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:46\n","loss: 0.6442, acc: 0.7355\n","E2E-ABSA >>> 2022-09-02 05:19:47\n","loss: 0.6449, acc: 0.7288\n","E2E-ABSA >>> 2022-09-02 05:19:48\n","loss: 0.6367, acc: 0.7336\n","E2E-ABSA >>> 2022-09-02 05:19:49\n",">>> val_acc: 0.6976, val_precision: 0.6976 val_recall: 0.6976, val_f1: 0.6976\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.6976\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:49\n","loss: 0.6587, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 05:19:50\n","loss: 0.6176, acc: 0.7494\n","E2E-ABSA >>> 2022-09-02 05:19:51\n","loss: 0.6222, acc: 0.7445\n","E2E-ABSA >>> 2022-09-02 05:19:51\n","loss: 0.6348, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 05:19:52\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:52\n","loss: 0.6726, acc: 0.7127\n","E2E-ABSA >>> 2022-09-02 05:19:53\n","loss: 0.6435, acc: 0.7233\n","E2E-ABSA >>> 2022-09-02 05:19:54\n","loss: 0.6387, acc: 0.7304\n","E2E-ABSA >>> 2022-09-02 05:19:55\n","loss: 0.6364, acc: 0.7316\n","E2E-ABSA >>> 2022-09-02 05:19:55\n",">>> val_acc: 0.6976, val_precision: 0.6976 val_recall: 0.6976, val_f1: 0.6976\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:56\n","loss: 0.6201, acc: 0.7281\n","E2E-ABSA >>> 2022-09-02 05:19:56\n","loss: 0.6230, acc: 0.7331\n","E2E-ABSA >>> 2022-09-02 05:19:57\n","loss: 0.6343, acc: 0.7281\n","E2E-ABSA >>> 2022-09-02 05:19:58\n",">>> val_acc: 0.6896, val_precision: 0.6896 val_recall: 0.6896, val_f1: 0.6896\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:19:58\n","loss: 0.6031, acc: 0.7422\n","E2E-ABSA >>> 2022-09-02 05:19:59\n","loss: 0.6193, acc: 0.7386\n","E2E-ABSA >>> 2022-09-02 05:20:00\n","loss: 0.6302, acc: 0.7336\n","E2E-ABSA >>> 2022-09-02 05:20:00\n","loss: 0.6352, acc: 0.7333\n","E2E-ABSA >>> 2022-09-02 05:20:00\n",">>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:01\n","loss: 0.6012, acc: 0.7480\n","E2E-ABSA >>> 2022-09-02 05:20:02\n","loss: 0.6276, acc: 0.7363\n","E2E-ABSA >>> 2022-09-02 05:20:03\n","loss: 0.6324, acc: 0.7333\n","E2E-ABSA >>> 2022-09-02 05:20:03\n",">>> val_acc: 0.7040, val_precision: 0.7040 val_recall: 0.7040, val_f1: 0.7040\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.704\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:04\n","loss: 0.6124, acc: 0.7415\n","E2E-ABSA >>> 2022-09-02 05:20:04\n","loss: 0.6190, acc: 0.7465\n","E2E-ABSA >>> 2022-09-02 05:20:05\n","loss: 0.6288, acc: 0.7390\n","E2E-ABSA >>> 2022-09-02 05:20:06\n","loss: 0.6315, acc: 0.7367\n","E2E-ABSA >>> 2022-09-02 05:20:06\n",">>> val_acc: 0.7040, val_precision: 0.7040 val_recall: 0.7040, val_f1: 0.7040\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:07\n","loss: 0.6039, acc: 0.7595\n","E2E-ABSA >>> 2022-09-02 05:20:08\n","loss: 0.6301, acc: 0.7406\n","E2E-ABSA >>> 2022-09-02 05:20:08\n","loss: 0.6273, acc: 0.7382\n","E2E-ABSA >>> 2022-09-02 05:20:09\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:09\n","loss: 0.6382, acc: 0.7328\n","E2E-ABSA >>> 2022-09-02 05:20:10\n","loss: 0.6247, acc: 0.7379\n","E2E-ABSA >>> 2022-09-02 05:20:11\n","loss: 0.6321, acc: 0.7326\n","E2E-ABSA >>> 2022-09-02 05:20:12\n","loss: 0.6322, acc: 0.7349\n","E2E-ABSA >>> 2022-09-02 05:20:12\n",">>> val_acc: 0.6864, val_precision: 0.6864 val_recall: 0.6864, val_f1: 0.6864\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:13\n","loss: 0.6261, acc: 0.7443\n","E2E-ABSA >>> 2022-09-02 05:20:13\n","loss: 0.6302, acc: 0.7301\n","E2E-ABSA >>> 2022-09-02 05:20:14\n","loss: 0.6295, acc: 0.7361\n","E2E-ABSA >>> 2022-09-02 05:20:15\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:15\n","loss: 0.6259, acc: 0.7396\n","E2E-ABSA >>> 2022-09-02 05:20:16\n","loss: 0.6069, acc: 0.7431\n","E2E-ABSA >>> 2022-09-02 05:20:17\n","loss: 0.6214, acc: 0.7368\n","E2E-ABSA >>> 2022-09-02 05:20:17\n","loss: 0.6257, acc: 0.7370\n","E2E-ABSA >>> 2022-09-02 05:20:18\n",">>> val_acc: 0.6944, val_precision: 0.6944 val_recall: 0.6944, val_f1: 0.6944\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:18\n","loss: 0.6206, acc: 0.7440\n","E2E-ABSA >>> 2022-09-02 05:20:19\n","loss: 0.6423, acc: 0.7323\n","E2E-ABSA >>> 2022-09-02 05:20:20\n","loss: 0.6323, acc: 0.7355\n","E2E-ABSA >>> 2022-09-02 05:20:21\n",">>> val_acc: 0.6976, val_precision: 0.6976 val_recall: 0.6976, val_f1: 0.6976\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:21\n","loss: 0.5817, acc: 0.7520\n","E2E-ABSA >>> 2022-09-02 05:20:22\n","loss: 0.6037, acc: 0.7543\n","E2E-ABSA >>> 2022-09-02 05:20:22\n","loss: 0.6241, acc: 0.7443\n","E2E-ABSA >>> 2022-09-02 05:20:23\n","loss: 0.6241, acc: 0.7428\n","E2E-ABSA >>> 2022-09-02 05:20:23\n",">>> val_acc: 0.7072, val_precision: 0.7072 val_recall: 0.7072, val_f1: 0.7072\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.7072\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:24\n","loss: 0.6130, acc: 0.7469\n","E2E-ABSA >>> 2022-09-02 05:20:25\n","loss: 0.6217, acc: 0.7444\n","E2E-ABSA >>> 2022-09-02 05:20:26\n","loss: 0.6269, acc: 0.7391\n","E2E-ABSA >>> 2022-09-02 05:20:26\n",">>> val_acc: 0.7056, val_precision: 0.7056 val_recall: 0.7056, val_f1: 0.7056\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:26\n","loss: 0.6261, acc: 0.7254\n","E2E-ABSA >>> 2022-09-02 05:20:27\n","loss: 0.6370, acc: 0.7285\n","E2E-ABSA >>> 2022-09-02 05:20:28\n","loss: 0.6306, acc: 0.7379\n","E2E-ABSA >>> 2022-09-02 05:20:29\n","loss: 0.6282, acc: 0.7355\n","E2E-ABSA >>> 2022-09-02 05:20:29\n",">>> val_acc: 0.7024, val_precision: 0.7024 val_recall: 0.7024, val_f1: 0.7024\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:30\n","loss: 0.6435, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 05:20:30\n","loss: 0.6338, acc: 0.7365\n","E2E-ABSA >>> 2022-09-02 05:20:31\n","loss: 0.6265, acc: 0.7403\n","E2E-ABSA >>> 2022-09-02 05:20:32\n",">>> val_acc: 0.7056, val_precision: 0.7056 val_recall: 0.7056, val_f1: 0.7056\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:32\n","loss: 0.6297, acc: 0.7552\n","E2E-ABSA >>> 2022-09-02 05:20:33\n","loss: 0.6249, acc: 0.7429\n","E2E-ABSA >>> 2022-09-02 05:20:34\n","loss: 0.6262, acc: 0.7427\n","E2E-ABSA >>> 2022-09-02 05:20:34\n","loss: 0.6196, acc: 0.7446\n","E2E-ABSA >>> 2022-09-02 05:20:35\n",">>> val_acc: 0.6912, val_precision: 0.6912 val_recall: 0.6912, val_f1: 0.6912\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:35\n","loss: 0.6153, acc: 0.7370\n","E2E-ABSA >>> 2022-09-02 05:20:36\n","loss: 0.6236, acc: 0.7351\n","E2E-ABSA >>> 2022-09-02 05:20:37\n","loss: 0.6216, acc: 0.7328\n","E2E-ABSA >>> 2022-09-02 05:20:38\n",">>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 90.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:38\n","loss: 0.5948, acc: 0.7719\n","E2E-ABSA >>> 2022-09-02 05:20:39\n","loss: 0.6112, acc: 0.7573\n","E2E-ABSA >>> 2022-09-02 05:20:39\n","loss: 0.6304, acc: 0.7432\n","E2E-ABSA >>> 2022-09-02 05:20:40\n","loss: 0.6267, acc: 0.7387\n","E2E-ABSA >>> 2022-09-02 05:20:41\n",">>> val_acc: 0.7056, val_precision: 0.7056 val_recall: 0.7056, val_f1: 0.7056\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 91.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:41\n","loss: 0.6238, acc: 0.7307\n","E2E-ABSA >>> 2022-09-02 05:20:42\n","loss: 0.6197, acc: 0.7388\n","E2E-ABSA >>> 2022-09-02 05:20:43\n","loss: 0.6214, acc: 0.7390\n","E2E-ABSA >>> 2022-09-02 05:20:43\n",">>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 92.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:44\n","loss: 0.6633, acc: 0.7188\n","E2E-ABSA >>> 2022-09-02 05:20:44\n","loss: 0.6358, acc: 0.7349\n","E2E-ABSA >>> 2022-09-02 05:20:45\n","loss: 0.6298, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 05:20:46\n","loss: 0.6206, acc: 0.7417\n","E2E-ABSA >>> 2022-09-02 05:20:46\n",">>> val_acc: 0.7008, val_precision: 0.7008 val_recall: 0.7008, val_f1: 0.7008\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 93.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:47\n","loss: 0.6139, acc: 0.7314\n","E2E-ABSA >>> 2022-09-02 05:20:47\n","loss: 0.6153, acc: 0.7409\n","E2E-ABSA >>> 2022-09-02 05:20:48\n","loss: 0.6161, acc: 0.7393\n","E2E-ABSA >>> 2022-09-02 05:20:49\n",">>> val_acc: 0.6976, val_precision: 0.6976 val_recall: 0.6976, val_f1: 0.6976\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 94.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:49\n","loss: 0.6403, acc: 0.7292\n","E2E-ABSA >>> 2022-09-02 05:20:50\n","loss: 0.6230, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 05:20:51\n","loss: 0.6211, acc: 0.7373\n","E2E-ABSA >>> 2022-09-02 05:20:51\n","loss: 0.6188, acc: 0.7410\n","E2E-ABSA >>> 2022-09-02 05:20:52\n",">>> val_acc: 0.7072, val_precision: 0.7072 val_recall: 0.7072, val_f1: 0.7072\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 95.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:52\n","loss: 0.6254, acc: 0.7219\n","E2E-ABSA >>> 2022-09-02 05:20:53\n","loss: 0.6170, acc: 0.7340\n","E2E-ABSA >>> 2022-09-02 05:20:54\n","loss: 0.6116, acc: 0.7425\n","E2E-ABSA >>> 2022-09-02 05:20:55\n",">>> val_acc: 0.7120, val_precision: 0.7120 val_recall: 0.7120, val_f1: 0.7120\n",">> saved: state_dict/memnet_acl14shortdata_know_val_f1_0.712\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 96.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:55\n","loss: 0.5730, acc: 0.8047\n","E2E-ABSA >>> 2022-09-02 05:20:56\n","loss: 0.6321, acc: 0.7402\n","E2E-ABSA >>> 2022-09-02 05:20:56\n","loss: 0.6284, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 05:20:57\n","loss: 0.6238, acc: 0.7368\n","E2E-ABSA >>> 2022-09-02 05:20:58\n",">>> val_acc: 0.7072, val_precision: 0.7072 val_recall: 0.7072, val_f1: 0.7072\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 97.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:20:58\n","loss: 0.6071, acc: 0.7623\n","E2E-ABSA >>> 2022-09-02 05:20:59\n","loss: 0.6152, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 05:21:00\n","loss: 0.6074, acc: 0.7493\n","E2E-ABSA >>> 2022-09-02 05:21:01\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 98.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:21:01\n","loss: 0.6458, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 05:21:01\n","loss: 0.5975, acc: 0.7512\n","E2E-ABSA >>> 2022-09-02 05:21:02\n","loss: 0.6045, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 05:21:03\n","loss: 0.6167, acc: 0.7393\n","E2E-ABSA >>> 2022-09-02 05:21:03\n",">>> val_acc: 0.7040, val_precision: 0.7040 val_recall: 0.7040, val_f1: 0.7040\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 99.\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","E2E-ABSA >>> 2022-09-02 05:21:04\n","loss: 0.6007, acc: 0.7476\n","E2E-ABSA >>> 2022-09-02 05:21:05\n","loss: 0.6135, acc: 0.7459\n","E2E-ABSA >>> 2022-09-02 05:21:05\n","loss: 0.6177, acc: 0.7460\n","E2E-ABSA >>> 2022-09-02 05:21:06\n","loss: 0.6144, acc: 0.7457\n","E2E-ABSA >>> 2022-09-02 05:21:06\n",">>> val_acc: 0.7056, val_precision: 0.7056 val_recall: 0.7056, val_f1: 0.7056\n","you can download the best model from state_dict/memnet_acl14shortdata_know_val_f1_0.712\n","/content/DictionaryFused-E2E-ABSA/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",">>> test_acc: 0.7120, test_precision: 0.7120, test_recall: 0.7120, test_f1: 0.7120\n"]}]},{"cell_type":"markdown","source":["# 增加字典知识后：Training **acl14shortdata** dataset on model(**CABASC**)\n"],"metadata":{"id":"EXZVsmNUXy13"}},{"cell_type":"code","source":["!pwd\n","!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && pwd && ls && python3 train_insert.py --model_name cabasc --dataset acl14shortdata_know --embed_dim 300 --patience 30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJkUxSOIXy8w","outputId":"072140d0-79a9-4cc5-cd8b-2eedb0a95e51","executionInfo":{"status":"ok","timestamp":1662097892704,"user_tz":-480,"elapsed":1824449,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/DictionaryFused-E2E-ABSA\n","datasets\t    infer_example.py\t   __pycache__\t     train.py\n","data_utils.py\t    layers\t\t   README.md\n","deberta_abas.ipynb  many_model_absa.ipynb  requirements.txt\n","glove_embeddings    models\t\t   train_insert.py\n",">>> 使用设备:cuda 训练.\n","加载预训练向量...\n",">>> 使用 ./glove_embeddings/glove.42B.300d.txt 作为预训练单词的向量.\n","预训练向量加载完毕.\n","> training dataset count: 4917.\n","> testing dataset count: 539.\n","cuda memory allocated: 22565888\n","> n_trainable_params: 1446005, n_nontrainable_params: 4136100\n","> training arguments:\n",">>> model_name: cabasc\n",">>> dataset: acl14shortdata_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f2712413c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 30\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.cabasc.Cabasc'>\n",">>> dataset_file: {'train': './datasets/acl14shortdata/output_know_insert/train.tsv', 'test': './datasets/acl14shortdata/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices', 'left_with_aspect_indices', 'right_with_aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 05:21:54\n","loss: 1.0933, acc: 0.3856\n","E2E-ABSA >>> 2022-09-02 05:22:00\n","loss: 1.0600, acc: 0.4447\n","E2E-ABSA >>> 2022-09-02 05:22:06\n","loss: 1.0527, acc: 0.4585\n","E2E-ABSA >>> 2022-09-02 05:22:08\n",">>> val_acc: 0.4583, val_precision: 0.4583 val_recall: 0.4583, val_f1: 0.4583\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.4583\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 05:22:14\n","loss: 1.0088, acc: 0.5190\n","E2E-ABSA >>> 2022-09-02 05:22:20\n","loss: 1.0127, acc: 0.5091\n","E2E-ABSA >>> 2022-09-02 05:22:26\n","loss: 1.0106, acc: 0.5051\n","E2E-ABSA >>> 2022-09-02 05:22:28\n",">>> val_acc: 0.4601, val_precision: 0.4601 val_recall: 0.4601, val_f1: 0.4601\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.4601\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 05:22:34\n","loss: 0.9782, acc: 0.5357\n","E2E-ABSA >>> 2022-09-02 05:22:40\n","loss: 0.9887, acc: 0.5146\n","E2E-ABSA >>> 2022-09-02 05:22:46\n","loss: 0.9872, acc: 0.5079\n","E2E-ABSA >>> 2022-09-02 05:22:49\n",">>> val_acc: 0.5213, val_precision: 0.5213 val_recall: 0.5213, val_f1: 0.5213\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.5213\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 05:22:54\n","loss: 0.9534, acc: 0.5403\n","E2E-ABSA >>> 2022-09-02 05:23:00\n","loss: 0.9313, acc: 0.5671\n","E2E-ABSA >>> 2022-09-02 05:23:06\n","loss: 0.9346, acc: 0.5548\n","E2E-ABSA >>> 2022-09-02 05:23:09\n",">>> val_acc: 0.5325, val_precision: 0.5325 val_recall: 0.5325, val_f1: 0.5325\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.5325\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 05:23:13\n","loss: 0.9022, acc: 0.5846\n","E2E-ABSA >>> 2022-09-02 05:23:19\n","loss: 0.9057, acc: 0.5763\n","E2E-ABSA >>> 2022-09-02 05:23:25\n","loss: 0.9026, acc: 0.5765\n","E2E-ABSA >>> 2022-09-02 05:23:29\n",">>> val_acc: 0.5380, val_precision: 0.5380 val_recall: 0.5380, val_f1: 0.5380\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.538\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 05:23:32\n","loss: 0.9010, acc: 0.5771\n","E2E-ABSA >>> 2022-09-02 05:23:38\n","loss: 0.8963, acc: 0.5746\n","E2E-ABSA >>> 2022-09-02 05:23:44\n","loss: 0.8912, acc: 0.5815\n","E2E-ABSA >>> 2022-09-02 05:23:48\n",">>> val_acc: 0.5436, val_precision: 0.5436 val_recall: 0.5436, val_f1: 0.5436\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.5436\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 05:23:52\n","loss: 0.8903, acc: 0.5877\n","E2E-ABSA >>> 2022-09-02 05:23:58\n","loss: 0.8770, acc: 0.5855\n","E2E-ABSA >>> 2022-09-02 05:24:04\n","loss: 0.8784, acc: 0.5871\n","E2E-ABSA >>> 2022-09-02 05:24:09\n",">>> val_acc: 0.5492, val_precision: 0.5492 val_recall: 0.5492, val_f1: 0.5492\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.5492\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 05:24:11\n","loss: 0.8925, acc: 0.5852\n","E2E-ABSA >>> 2022-09-02 05:24:17\n","loss: 0.8665, acc: 0.6011\n","E2E-ABSA >>> 2022-09-02 05:24:23\n","loss: 0.8722, acc: 0.5917\n","E2E-ABSA >>> 2022-09-02 05:24:28\n",">>> val_acc: 0.5566, val_precision: 0.5566 val_recall: 0.5566, val_f1: 0.5566\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.5566\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 05:24:31\n","loss: 0.8751, acc: 0.6024\n","E2E-ABSA >>> 2022-09-02 05:24:37\n","loss: 0.8618, acc: 0.6048\n","E2E-ABSA >>> 2022-09-02 05:24:42\n","loss: 0.8673, acc: 0.6014\n","E2E-ABSA >>> 2022-09-02 05:24:48\n",">>> val_acc: 0.5640, val_precision: 0.5640 val_recall: 0.5640, val_f1: 0.5640\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.564\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 05:24:50\n","loss: 0.8793, acc: 0.5938\n","E2E-ABSA >>> 2022-09-02 05:24:56\n","loss: 0.8673, acc: 0.5996\n","E2E-ABSA >>> 2022-09-02 05:25:02\n","loss: 0.8652, acc: 0.6022\n","E2E-ABSA >>> 2022-09-02 05:25:08\n",">>> val_acc: 0.5659, val_precision: 0.5659 val_recall: 0.5659, val_f1: 0.5659\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.5659\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 05:25:09\n","loss: 0.8240, acc: 0.6406\n","E2E-ABSA >>> 2022-09-02 05:25:15\n","loss: 0.8569, acc: 0.6104\n","E2E-ABSA >>> 2022-09-02 05:25:21\n","loss: 0.8561, acc: 0.6114\n","E2E-ABSA >>> 2022-09-02 05:25:28\n",">>> val_acc: 0.5714, val_precision: 0.5714 val_recall: 0.5714, val_f1: 0.5714\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.5714\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 05:25:29\n","loss: 0.8689, acc: 0.5938\n","E2E-ABSA >>> 2022-09-02 05:25:34\n","loss: 0.8498, acc: 0.6183\n","E2E-ABSA >>> 2022-09-02 05:25:40\n","loss: 0.8519, acc: 0.6108\n","E2E-ABSA >>> 2022-09-02 05:25:47\n",">>> val_acc: 0.5788, val_precision: 0.5788 val_recall: 0.5788, val_f1: 0.5788\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.5788\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 05:25:48\n","loss: 0.8261, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 05:25:54\n","loss: 0.8404, acc: 0.6154\n","E2E-ABSA >>> 2022-09-02 05:26:00\n","loss: 0.8362, acc: 0.6232\n","E2E-ABSA >>> 2022-09-02 05:26:06\n","loss: 0.8458, acc: 0.6129\n","E2E-ABSA >>> 2022-09-02 05:26:08\n",">>> val_acc: 0.5788, val_precision: 0.5788 val_recall: 0.5788, val_f1: 0.5788\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 05:26:13\n","loss: 0.8475, acc: 0.6172\n","E2E-ABSA >>> 2022-09-02 05:26:19\n","loss: 0.8392, acc: 0.6205\n","E2E-ABSA >>> 2022-09-02 05:26:25\n","loss: 0.8398, acc: 0.6182\n","E2E-ABSA >>> 2022-09-02 05:26:27\n",">>> val_acc: 0.5770, val_precision: 0.5770 val_recall: 0.5770, val_f1: 0.5770\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 05:26:33\n","loss: 0.8418, acc: 0.6129\n","E2E-ABSA >>> 2022-09-02 05:26:39\n","loss: 0.8275, acc: 0.6220\n","E2E-ABSA >>> 2022-09-02 05:26:44\n","loss: 0.8386, acc: 0.6161\n","E2E-ABSA >>> 2022-09-02 05:26:47\n",">>> val_acc: 0.5788, val_precision: 0.5788 val_recall: 0.5788, val_f1: 0.5788\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 05:26:52\n","loss: 0.8347, acc: 0.6203\n","E2E-ABSA >>> 2022-09-02 05:26:58\n","loss: 0.8349, acc: 0.6188\n","E2E-ABSA >>> 2022-09-02 05:27:04\n","loss: 0.8391, acc: 0.6163\n","E2E-ABSA >>> 2022-09-02 05:27:07\n",">>> val_acc: 0.5881, val_precision: 0.5881 val_recall: 0.5881, val_f1: 0.5881\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.5881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 05:27:11\n","loss: 0.8199, acc: 0.6215\n","E2E-ABSA >>> 2022-09-02 05:27:17\n","loss: 0.8312, acc: 0.6119\n","E2E-ABSA >>> 2022-09-02 05:27:23\n","loss: 0.8363, acc: 0.6149\n","E2E-ABSA >>> 2022-09-02 05:27:26\n",">>> val_acc: 0.5881, val_precision: 0.5881 val_recall: 0.5881, val_f1: 0.5881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 05:27:30\n","loss: 0.8476, acc: 0.6074\n","E2E-ABSA >>> 2022-09-02 05:27:36\n","loss: 0.8318, acc: 0.6159\n","E2E-ABSA >>> 2022-09-02 05:27:42\n","loss: 0.8309, acc: 0.6222\n","E2E-ABSA >>> 2022-09-02 05:27:46\n",">>> val_acc: 0.5900, val_precision: 0.5900 val_recall: 0.5900, val_f1: 0.5900\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.59\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 05:27:50\n","loss: 0.8208, acc: 0.6183\n","E2E-ABSA >>> 2022-09-02 05:27:55\n","loss: 0.8326, acc: 0.6190\n","E2E-ABSA >>> 2022-09-02 05:28:01\n","loss: 0.8303, acc: 0.6196\n","E2E-ABSA >>> 2022-09-02 05:28:06\n",">>> val_acc: 0.5955, val_precision: 0.5955 val_recall: 0.5955, val_f1: 0.5955\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.5955\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 05:28:09\n","loss: 0.8293, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 05:28:15\n","loss: 0.8288, acc: 0.6161\n","E2E-ABSA >>> 2022-09-02 05:28:21\n","loss: 0.8280, acc: 0.6169\n","E2E-ABSA >>> 2022-09-02 05:28:26\n",">>> val_acc: 0.5844, val_precision: 0.5844 val_recall: 0.5844, val_f1: 0.5844\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 05:28:29\n","loss: 0.8697, acc: 0.5969\n","E2E-ABSA >>> 2022-09-02 05:28:34\n","loss: 0.8238, acc: 0.6232\n","E2E-ABSA >>> 2022-09-02 05:28:40\n","loss: 0.8260, acc: 0.6237\n","E2E-ABSA >>> 2022-09-02 05:28:46\n",">>> val_acc: 0.5974, val_precision: 0.5974 val_recall: 0.5974, val_f1: 0.5974\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.5974\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 05:28:48\n","loss: 0.8305, acc: 0.6270\n","E2E-ABSA >>> 2022-09-02 05:28:54\n","loss: 0.8124, acc: 0.6283\n","E2E-ABSA >>> 2022-09-02 05:29:00\n","loss: 0.8169, acc: 0.6258\n","E2E-ABSA >>> 2022-09-02 05:29:06\n",">>> val_acc: 0.5993, val_precision: 0.5993 val_recall: 0.5993, val_f1: 0.5993\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.5993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 05:29:07\n","loss: 0.8238, acc: 0.6354\n","E2E-ABSA >>> 2022-09-02 05:29:13\n","loss: 0.8311, acc: 0.6139\n","E2E-ABSA >>> 2022-09-02 05:29:19\n","loss: 0.8193, acc: 0.6247\n","E2E-ABSA >>> 2022-09-02 05:29:26\n",">>> val_acc: 0.5993, val_precision: 0.5993 val_recall: 0.5993, val_f1: 0.5993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 05:29:27\n","loss: 0.8504, acc: 0.5977\n","E2E-ABSA >>> 2022-09-02 05:29:33\n","loss: 0.8232, acc: 0.6180\n","E2E-ABSA >>> 2022-09-02 05:29:39\n","loss: 0.8215, acc: 0.6207\n","E2E-ABSA >>> 2022-09-02 05:29:45\n",">>> val_acc: 0.5955, val_precision: 0.5955 val_recall: 0.5955, val_f1: 0.5955\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 05:29:46\n","loss: 0.8505, acc: 0.5938\n","E2E-ABSA >>> 2022-09-02 05:29:52\n","loss: 0.8116, acc: 0.6372\n","E2E-ABSA >>> 2022-09-02 05:29:58\n","loss: 0.8202, acc: 0.6277\n","E2E-ABSA >>> 2022-09-02 05:30:04\n","loss: 0.8201, acc: 0.6246\n","E2E-ABSA >>> 2022-09-02 05:30:06\n",">>> val_acc: 0.5918, val_precision: 0.5918 val_recall: 0.5918, val_f1: 0.5918\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 05:30:12\n","loss: 0.8306, acc: 0.6181\n","E2E-ABSA >>> 2022-09-02 05:30:18\n","loss: 0.8175, acc: 0.6281\n","E2E-ABSA >>> 2022-09-02 05:30:24\n","loss: 0.8203, acc: 0.6221\n","E2E-ABSA >>> 2022-09-02 05:30:26\n",">>> val_acc: 0.6030, val_precision: 0.6030 val_recall: 0.6030, val_f1: 0.6030\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.603\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 05:30:31\n","loss: 0.7983, acc: 0.6399\n","E2E-ABSA >>> 2022-09-02 05:30:37\n","loss: 0.8069, acc: 0.6322\n","E2E-ABSA >>> 2022-09-02 05:30:43\n","loss: 0.8169, acc: 0.6246\n","E2E-ABSA >>> 2022-09-02 05:30:45\n",">>> val_acc: 0.6067, val_precision: 0.6067 val_recall: 0.6067, val_f1: 0.6067\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.6067\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 05:30:50\n","loss: 0.8160, acc: 0.6153\n","E2E-ABSA >>> 2022-09-02 05:30:56\n","loss: 0.8145, acc: 0.6230\n","E2E-ABSA >>> 2022-09-02 05:31:02\n","loss: 0.8175, acc: 0.6213\n","E2E-ABSA >>> 2022-09-02 05:31:05\n",">>> val_acc: 0.6104, val_precision: 0.6104 val_recall: 0.6104, val_f1: 0.6104\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.6104\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 05:31:10\n","loss: 0.8202, acc: 0.6118\n","E2E-ABSA >>> 2022-09-02 05:31:15\n","loss: 0.8162, acc: 0.6239\n","E2E-ABSA >>> 2022-09-02 05:31:21\n","loss: 0.8163, acc: 0.6266\n","E2E-ABSA >>> 2022-09-02 05:31:25\n",">>> val_acc: 0.6011, val_precision: 0.6011 val_recall: 0.6011, val_f1: 0.6011\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 05:31:29\n","loss: 0.7888, acc: 0.6507\n","E2E-ABSA >>> 2022-09-02 05:31:35\n","loss: 0.8072, acc: 0.6321\n","E2E-ABSA >>> 2022-09-02 05:31:40\n","loss: 0.8135, acc: 0.6262\n","E2E-ABSA >>> 2022-09-02 05:31:44\n",">>> val_acc: 0.5993, val_precision: 0.5993 val_recall: 0.5993, val_f1: 0.5993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 05:31:48\n","loss: 0.8456, acc: 0.6062\n","E2E-ABSA >>> 2022-09-02 05:31:54\n","loss: 0.8136, acc: 0.6293\n","E2E-ABSA >>> 2022-09-02 05:32:00\n","loss: 0.8116, acc: 0.6300\n","E2E-ABSA >>> 2022-09-02 05:32:04\n",">>> val_acc: 0.6011, val_precision: 0.6011 val_recall: 0.6011, val_f1: 0.6011\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 05:32:07\n","loss: 0.8044, acc: 0.6262\n","E2E-ABSA >>> 2022-09-02 05:32:13\n","loss: 0.8075, acc: 0.6324\n","E2E-ABSA >>> 2022-09-02 05:32:19\n","loss: 0.8105, acc: 0.6272\n","E2E-ABSA >>> 2022-09-02 05:32:24\n",">>> val_acc: 0.6141, val_precision: 0.6141 val_recall: 0.6141, val_f1: 0.6141\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.6141\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 05:32:27\n","loss: 0.7871, acc: 0.6349\n","E2E-ABSA >>> 2022-09-02 05:32:33\n","loss: 0.7986, acc: 0.6315\n","E2E-ABSA >>> 2022-09-02 05:32:39\n","loss: 0.8127, acc: 0.6253\n","E2E-ABSA >>> 2022-09-02 05:32:44\n",">>> val_acc: 0.6011, val_precision: 0.6011 val_recall: 0.6011, val_f1: 0.6011\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 05:32:46\n","loss: 0.7579, acc: 0.6753\n","E2E-ABSA >>> 2022-09-02 05:32:52\n","loss: 0.7917, acc: 0.6402\n","E2E-ABSA >>> 2022-09-02 05:32:58\n","loss: 0.8055, acc: 0.6292\n","E2E-ABSA >>> 2022-09-02 05:33:03\n",">>> val_acc: 0.6104, val_precision: 0.6104 val_recall: 0.6104, val_f1: 0.6104\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 05:33:05\n","loss: 0.7945, acc: 0.6272\n","E2E-ABSA >>> 2022-09-02 05:33:11\n","loss: 0.8165, acc: 0.6240\n","E2E-ABSA >>> 2022-09-02 05:33:17\n","loss: 0.8077, acc: 0.6280\n","E2E-ABSA >>> 2022-09-02 05:33:23\n",">>> val_acc: 0.5974, val_precision: 0.5974 val_recall: 0.5974, val_f1: 0.5974\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 05:33:24\n","loss: 0.8165, acc: 0.6219\n","E2E-ABSA >>> 2022-09-02 05:33:30\n","loss: 0.8045, acc: 0.6354\n","E2E-ABSA >>> 2022-09-02 05:33:36\n","loss: 0.8123, acc: 0.6267\n","E2E-ABSA >>> 2022-09-02 05:33:43\n",">>> val_acc: 0.6104, val_precision: 0.6104 val_recall: 0.6104, val_f1: 0.6104\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 05:33:43\n","loss: 0.8235, acc: 0.6198\n","E2E-ABSA >>> 2022-09-02 05:33:49\n","loss: 0.8060, acc: 0.6272\n","E2E-ABSA >>> 2022-09-02 05:33:55\n","loss: 0.7957, acc: 0.6386\n","E2E-ABSA >>> 2022-09-02 05:34:02\n",">>> val_acc: 0.5993, val_precision: 0.5993 val_recall: 0.5993, val_f1: 0.5993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 05:34:02\n","loss: 0.9164, acc: 0.5938\n","E2E-ABSA >>> 2022-09-02 05:34:08\n","loss: 0.8017, acc: 0.6394\n","E2E-ABSA >>> 2022-09-02 05:34:15\n","loss: 0.8045, acc: 0.6369\n","E2E-ABSA >>> 2022-09-02 05:34:21\n","loss: 0.8076, acc: 0.6314\n","E2E-ABSA >>> 2022-09-02 05:34:22\n",">>> val_acc: 0.6085, val_precision: 0.6085 val_recall: 0.6085, val_f1: 0.6085\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 05:34:28\n","loss: 0.7871, acc: 0.6393\n","E2E-ABSA >>> 2022-09-02 05:34:34\n","loss: 0.8009, acc: 0.6323\n","E2E-ABSA >>> 2022-09-02 05:34:40\n","loss: 0.8046, acc: 0.6334\n","E2E-ABSA >>> 2022-09-02 05:34:42\n",">>> val_acc: 0.6067, val_precision: 0.6067 val_recall: 0.6067, val_f1: 0.6067\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 05:34:47\n","loss: 0.8116, acc: 0.6108\n","E2E-ABSA >>> 2022-09-02 05:34:53\n","loss: 0.8143, acc: 0.6197\n","E2E-ABSA >>> 2022-09-02 05:34:59\n","loss: 0.8095, acc: 0.6287\n","E2E-ABSA >>> 2022-09-02 05:35:02\n",">>> val_acc: 0.6030, val_precision: 0.6030 val_recall: 0.6030, val_f1: 0.6030\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 05:35:06\n","loss: 0.7747, acc: 0.6508\n","E2E-ABSA >>> 2022-09-02 05:35:12\n","loss: 0.7969, acc: 0.6372\n","E2E-ABSA >>> 2022-09-02 05:35:18\n","loss: 0.8058, acc: 0.6319\n","E2E-ABSA >>> 2022-09-02 05:35:21\n",">>> val_acc: 0.6104, val_precision: 0.6104 val_recall: 0.6104, val_f1: 0.6104\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 05:35:26\n","loss: 0.8155, acc: 0.6311\n","E2E-ABSA >>> 2022-09-02 05:35:32\n","loss: 0.8069, acc: 0.6330\n","E2E-ABSA >>> 2022-09-02 05:35:37\n","loss: 0.8035, acc: 0.6333\n","E2E-ABSA >>> 2022-09-02 05:35:41\n",">>> val_acc: 0.6067, val_precision: 0.6067 val_recall: 0.6067, val_f1: 0.6067\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 05:35:45\n","loss: 0.8110, acc: 0.6367\n","E2E-ABSA >>> 2022-09-02 05:35:51\n","loss: 0.7991, acc: 0.6406\n","E2E-ABSA >>> 2022-09-02 05:35:57\n","loss: 0.7992, acc: 0.6364\n","E2E-ABSA >>> 2022-09-02 05:36:01\n",">>> val_acc: 0.6104, val_precision: 0.6104 val_recall: 0.6104, val_f1: 0.6104\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 05:36:04\n","loss: 0.8100, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 05:36:10\n","loss: 0.8052, acc: 0.6266\n","E2E-ABSA >>> 2022-09-02 05:36:16\n","loss: 0.8038, acc: 0.6287\n","E2E-ABSA >>> 2022-09-02 05:36:21\n",">>> val_acc: 0.6048, val_precision: 0.6048 val_recall: 0.6048, val_f1: 0.6048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 05:36:24\n","loss: 0.7742, acc: 0.6367\n","E2E-ABSA >>> 2022-09-02 05:36:30\n","loss: 0.7913, acc: 0.6410\n","E2E-ABSA >>> 2022-09-02 05:36:35\n","loss: 0.7965, acc: 0.6366\n","E2E-ABSA >>> 2022-09-02 05:36:41\n",">>> val_acc: 0.6122, val_precision: 0.6122 val_recall: 0.6122, val_f1: 0.6122\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 05:36:43\n","loss: 0.8318, acc: 0.6125\n","E2E-ABSA >>> 2022-09-02 05:36:49\n","loss: 0.8090, acc: 0.6304\n","E2E-ABSA >>> 2022-09-02 05:36:55\n","loss: 0.8056, acc: 0.6323\n","E2E-ABSA >>> 2022-09-02 05:37:00\n",">>> val_acc: 0.6104, val_precision: 0.6104 val_recall: 0.6104, val_f1: 0.6104\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 46.\n","E2E-ABSA >>> 2022-09-02 05:37:02\n","loss: 0.7660, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 05:37:08\n","loss: 0.7784, acc: 0.6420\n","E2E-ABSA >>> 2022-09-02 05:37:14\n","loss: 0.7962, acc: 0.6342\n","E2E-ABSA >>> 2022-09-02 05:37:20\n",">>> val_acc: 0.6122, val_precision: 0.6122 val_recall: 0.6122, val_f1: 0.6122\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 47.\n","E2E-ABSA >>> 2022-09-02 05:37:21\n","loss: 0.7579, acc: 0.6615\n","E2E-ABSA >>> 2022-09-02 05:37:27\n","loss: 0.7942, acc: 0.6341\n","E2E-ABSA >>> 2022-09-02 05:37:33\n","loss: 0.7997, acc: 0.6348\n","E2E-ABSA >>> 2022-09-02 05:37:39\n",">>> val_acc: 0.6048, val_precision: 0.6048 val_recall: 0.6048, val_f1: 0.6048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 48.\n","E2E-ABSA >>> 2022-09-02 05:37:40\n","loss: 0.8864, acc: 0.5469\n","E2E-ABSA >>> 2022-09-02 05:37:46\n","loss: 0.8115, acc: 0.6185\n","E2E-ABSA >>> 2022-09-02 05:37:52\n","loss: 0.8013, acc: 0.6293\n","E2E-ABSA >>> 2022-09-02 05:37:59\n",">>> val_acc: 0.6030, val_precision: 0.6030 val_recall: 0.6030, val_f1: 0.6030\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 49.\n","E2E-ABSA >>> 2022-09-02 05:37:59\n","loss: 0.8363, acc: 0.6016\n","E2E-ABSA >>> 2022-09-02 05:38:05\n","loss: 0.7907, acc: 0.6447\n","E2E-ABSA >>> 2022-09-02 05:38:11\n","loss: 0.7983, acc: 0.6376\n","E2E-ABSA >>> 2022-09-02 05:38:17\n","loss: 0.7991, acc: 0.6356\n","E2E-ABSA >>> 2022-09-02 05:38:19\n",">>> val_acc: 0.6141, val_precision: 0.6141 val_recall: 0.6141, val_f1: 0.6141\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 50.\n","E2E-ABSA >>> 2022-09-02 05:38:25\n","loss: 0.7883, acc: 0.6369\n","E2E-ABSA >>> 2022-09-02 05:38:31\n","loss: 0.7938, acc: 0.6331\n","E2E-ABSA >>> 2022-09-02 05:38:37\n","loss: 0.7973, acc: 0.6371\n","E2E-ABSA >>> 2022-09-02 05:38:39\n",">>> val_acc: 0.6085, val_precision: 0.6085 val_recall: 0.6085, val_f1: 0.6085\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 51.\n","E2E-ABSA >>> 2022-09-02 05:38:44\n","loss: 0.7790, acc: 0.6501\n","E2E-ABSA >>> 2022-09-02 05:38:50\n","loss: 0.7882, acc: 0.6432\n","E2E-ABSA >>> 2022-09-02 05:38:56\n","loss: 0.7959, acc: 0.6396\n","E2E-ABSA >>> 2022-09-02 05:38:58\n",">>> val_acc: 0.6048, val_precision: 0.6048 val_recall: 0.6048, val_f1: 0.6048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 52.\n","E2E-ABSA >>> 2022-09-02 05:39:03\n","loss: 0.7946, acc: 0.6339\n","E2E-ABSA >>> 2022-09-02 05:39:09\n","loss: 0.7957, acc: 0.6372\n","E2E-ABSA >>> 2022-09-02 05:39:15\n","loss: 0.7984, acc: 0.6358\n","E2E-ABSA >>> 2022-09-02 05:39:18\n",">>> val_acc: 0.6160, val_precision: 0.6160 val_recall: 0.6160, val_f1: 0.6160\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.616\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 53.\n","E2E-ABSA >>> 2022-09-02 05:39:22\n","loss: 0.7786, acc: 0.6480\n","E2E-ABSA >>> 2022-09-02 05:39:28\n","loss: 0.7939, acc: 0.6381\n","E2E-ABSA >>> 2022-09-02 05:39:34\n","loss: 0.7988, acc: 0.6347\n","E2E-ABSA >>> 2022-09-02 05:39:38\n",">>> val_acc: 0.6122, val_precision: 0.6122 val_recall: 0.6122, val_f1: 0.6122\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 54.\n","E2E-ABSA >>> 2022-09-02 05:39:42\n","loss: 0.8275, acc: 0.6011\n","E2E-ABSA >>> 2022-09-02 05:39:48\n","loss: 0.8063, acc: 0.6324\n","E2E-ABSA >>> 2022-09-02 05:39:54\n","loss: 0.7970, acc: 0.6383\n","E2E-ABSA >>> 2022-09-02 05:39:57\n",">>> val_acc: 0.6160, val_precision: 0.6160 val_recall: 0.6160, val_f1: 0.6160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 55.\n","E2E-ABSA >>> 2022-09-02 05:40:01\n","loss: 0.8041, acc: 0.6271\n","E2E-ABSA >>> 2022-09-02 05:40:07\n","loss: 0.8019, acc: 0.6270\n","E2E-ABSA >>> 2022-09-02 05:40:13\n","loss: 0.7950, acc: 0.6368\n","E2E-ABSA >>> 2022-09-02 05:40:17\n",">>> val_acc: 0.6011, val_precision: 0.6011 val_recall: 0.6011, val_f1: 0.6011\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 56.\n","E2E-ABSA >>> 2022-09-02 05:40:20\n","loss: 0.8108, acc: 0.6286\n","E2E-ABSA >>> 2022-09-02 05:40:27\n","loss: 0.8007, acc: 0.6386\n","E2E-ABSA >>> 2022-09-02 05:40:33\n","loss: 0.7972, acc: 0.6367\n","E2E-ABSA >>> 2022-09-02 05:40:37\n",">>> val_acc: 0.6178, val_precision: 0.6178 val_recall: 0.6178, val_f1: 0.6178\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.6178\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 57.\n","E2E-ABSA >>> 2022-09-02 05:40:40\n","loss: 0.7915, acc: 0.6506\n","E2E-ABSA >>> 2022-09-02 05:40:46\n","loss: 0.7962, acc: 0.6354\n","E2E-ABSA >>> 2022-09-02 05:40:52\n","loss: 0.7977, acc: 0.6401\n","E2E-ABSA >>> 2022-09-02 05:40:57\n",">>> val_acc: 0.6067, val_precision: 0.6067 val_recall: 0.6067, val_f1: 0.6067\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 58.\n","E2E-ABSA >>> 2022-09-02 05:40:59\n","loss: 0.7763, acc: 0.6441\n","E2E-ABSA >>> 2022-09-02 05:41:05\n","loss: 0.7899, acc: 0.6420\n","E2E-ABSA >>> 2022-09-02 05:41:11\n","loss: 0.7930, acc: 0.6361\n","E2E-ABSA >>> 2022-09-02 05:41:17\n",">>> val_acc: 0.6234, val_precision: 0.6234 val_recall: 0.6234, val_f1: 0.6234\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.6234\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 59.\n","E2E-ABSA >>> 2022-09-02 05:41:18\n","loss: 0.7872, acc: 0.6696\n","E2E-ABSA >>> 2022-09-02 05:41:24\n","loss: 0.7908, acc: 0.6426\n","E2E-ABSA >>> 2022-09-02 05:41:30\n","loss: 0.7862, acc: 0.6425\n","E2E-ABSA >>> 2022-09-02 05:41:36\n",">>> val_acc: 0.6252, val_precision: 0.6252 val_recall: 0.6252, val_f1: 0.6252\n",">> saved: state_dict/cabasc_acl14shortdata_know_val_f1_0.6252\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 60.\n","E2E-ABSA >>> 2022-09-02 05:41:37\n","loss: 0.7568, acc: 0.6656\n","E2E-ABSA >>> 2022-09-02 05:41:43\n","loss: 0.7970, acc: 0.6385\n","E2E-ABSA >>> 2022-09-02 05:41:49\n","loss: 0.7904, acc: 0.6446\n","E2E-ABSA >>> 2022-09-02 05:41:56\n",">>> val_acc: 0.6215, val_precision: 0.6215 val_recall: 0.6215, val_f1: 0.6215\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 61.\n","E2E-ABSA >>> 2022-09-02 05:41:57\n","loss: 0.8288, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 05:42:02\n","loss: 0.8204, acc: 0.6261\n","E2E-ABSA >>> 2022-09-02 05:42:08\n","loss: 0.7960, acc: 0.6403\n","E2E-ABSA >>> 2022-09-02 05:42:15\n",">>> val_acc: 0.6141, val_precision: 0.6141 val_recall: 0.6141, val_f1: 0.6141\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 62.\n","E2E-ABSA >>> 2022-09-02 05:42:16\n","loss: 0.6490, acc: 0.7500\n","E2E-ABSA >>> 2022-09-02 05:42:21\n","loss: 0.7822, acc: 0.6466\n","E2E-ABSA >>> 2022-09-02 05:42:27\n","loss: 0.7947, acc: 0.6363\n","E2E-ABSA >>> 2022-09-02 05:42:34\n","loss: 0.7918, acc: 0.6380\n","E2E-ABSA >>> 2022-09-02 05:42:36\n",">>> val_acc: 0.6067, val_precision: 0.6067 val_recall: 0.6067, val_f1: 0.6067\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 63.\n","E2E-ABSA >>> 2022-09-02 05:42:41\n","loss: 0.7685, acc: 0.6595\n","E2E-ABSA >>> 2022-09-02 05:42:47\n","loss: 0.7894, acc: 0.6406\n","E2E-ABSA >>> 2022-09-02 05:42:53\n","loss: 0.7900, acc: 0.6425\n","E2E-ABSA >>> 2022-09-02 05:42:55\n",">>> val_acc: 0.6122, val_precision: 0.6122 val_recall: 0.6122, val_f1: 0.6122\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 64.\n","E2E-ABSA >>> 2022-09-02 05:43:00\n","loss: 0.7753, acc: 0.6577\n","E2E-ABSA >>> 2022-09-02 05:43:06\n","loss: 0.7916, acc: 0.6430\n","E2E-ABSA >>> 2022-09-02 05:43:12\n","loss: 0.7944, acc: 0.6378\n","E2E-ABSA >>> 2022-09-02 05:43:15\n",">>> val_acc: 0.6104, val_precision: 0.6104 val_recall: 0.6104, val_f1: 0.6104\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 65.\n","E2E-ABSA >>> 2022-09-02 05:43:20\n","loss: 0.7735, acc: 0.6562\n","E2E-ABSA >>> 2022-09-02 05:43:25\n","loss: 0.7828, acc: 0.6448\n","E2E-ABSA >>> 2022-09-02 05:43:31\n","loss: 0.7900, acc: 0.6440\n","E2E-ABSA >>> 2022-09-02 05:43:35\n",">>> val_acc: 0.6048, val_precision: 0.6048 val_recall: 0.6048, val_f1: 0.6048\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 66.\n","E2E-ABSA >>> 2022-09-02 05:43:39\n","loss: 0.7677, acc: 0.6441\n","E2E-ABSA >>> 2022-09-02 05:43:45\n","loss: 0.7783, acc: 0.6479\n","E2E-ABSA >>> 2022-09-02 05:43:51\n","loss: 0.7868, acc: 0.6369\n","E2E-ABSA >>> 2022-09-02 05:43:54\n",">>> val_acc: 0.6178, val_precision: 0.6178 val_recall: 0.6178, val_f1: 0.6178\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 67.\n","E2E-ABSA >>> 2022-09-02 05:43:58\n","loss: 0.7893, acc: 0.6416\n","E2E-ABSA >>> 2022-09-02 05:44:04\n","loss: 0.7924, acc: 0.6410\n","E2E-ABSA >>> 2022-09-02 05:44:10\n","loss: 0.7896, acc: 0.6439\n","E2E-ABSA >>> 2022-09-02 05:44:14\n",">>> val_acc: 0.6104, val_precision: 0.6104 val_recall: 0.6104, val_f1: 0.6104\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 68.\n","E2E-ABSA >>> 2022-09-02 05:44:17\n","loss: 0.7968, acc: 0.6629\n","E2E-ABSA >>> 2022-09-02 05:44:23\n","loss: 0.7750, acc: 0.6554\n","E2E-ABSA >>> 2022-09-02 05:44:29\n","loss: 0.7855, acc: 0.6411\n","E2E-ABSA >>> 2022-09-02 05:44:34\n",">>> val_acc: 0.6178, val_precision: 0.6178 val_recall: 0.6178, val_f1: 0.6178\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 69.\n","E2E-ABSA >>> 2022-09-02 05:44:37\n","loss: 0.7897, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 05:44:43\n","loss: 0.7822, acc: 0.6347\n","E2E-ABSA >>> 2022-09-02 05:44:49\n","loss: 0.7907, acc: 0.6389\n","E2E-ABSA >>> 2022-09-02 05:44:54\n",">>> val_acc: 0.6122, val_precision: 0.6122 val_recall: 0.6122, val_f1: 0.6122\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 70.\n","E2E-ABSA >>> 2022-09-02 05:44:56\n","loss: 0.8102, acc: 0.6266\n","E2E-ABSA >>> 2022-09-02 05:45:02\n","loss: 0.7949, acc: 0.6348\n","E2E-ABSA >>> 2022-09-02 05:45:08\n","loss: 0.7919, acc: 0.6380\n","E2E-ABSA >>> 2022-09-02 05:45:13\n",">>> val_acc: 0.6067, val_precision: 0.6067 val_recall: 0.6067, val_f1: 0.6067\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 71.\n","E2E-ABSA >>> 2022-09-02 05:45:15\n","loss: 0.7936, acc: 0.6348\n","E2E-ABSA >>> 2022-09-02 05:45:21\n","loss: 0.7863, acc: 0.6425\n","E2E-ABSA >>> 2022-09-02 05:45:27\n","loss: 0.7879, acc: 0.6439\n","E2E-ABSA >>> 2022-09-02 05:45:33\n",">>> val_acc: 0.6141, val_precision: 0.6141 val_recall: 0.6141, val_f1: 0.6141\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 72.\n","E2E-ABSA >>> 2022-09-02 05:45:35\n","loss: 0.7153, acc: 0.6719\n","E2E-ABSA >>> 2022-09-02 05:45:40\n","loss: 0.7851, acc: 0.6366\n","E2E-ABSA >>> 2022-09-02 05:45:46\n","loss: 0.7886, acc: 0.6378\n","E2E-ABSA >>> 2022-09-02 05:45:53\n",">>> val_acc: 0.6160, val_precision: 0.6160 val_recall: 0.6160, val_f1: 0.6160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 73.\n","E2E-ABSA >>> 2022-09-02 05:45:54\n","loss: 0.7994, acc: 0.6094\n","E2E-ABSA >>> 2022-09-02 05:46:00\n","loss: 0.7702, acc: 0.6519\n","E2E-ABSA >>> 2022-09-02 05:46:06\n","loss: 0.7867, acc: 0.6389\n","E2E-ABSA >>> 2022-09-02 05:46:13\n",">>> val_acc: 0.6197, val_precision: 0.6197 val_recall: 0.6197, val_f1: 0.6197\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 74.\n","E2E-ABSA >>> 2022-09-02 05:46:13\n","loss: 0.8197, acc: 0.6250\n","E2E-ABSA >>> 2022-09-02 05:46:19\n","loss: 0.7847, acc: 0.6481\n","E2E-ABSA >>> 2022-09-02 05:46:25\n","loss: 0.7966, acc: 0.6364\n","E2E-ABSA >>> 2022-09-02 05:46:31\n","loss: 0.7880, acc: 0.6417\n","E2E-ABSA >>> 2022-09-02 05:46:32\n",">>> val_acc: 0.6197, val_precision: 0.6197 val_recall: 0.6197, val_f1: 0.6197\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 75.\n","E2E-ABSA >>> 2022-09-02 05:46:38\n","loss: 0.7755, acc: 0.6538\n","E2E-ABSA >>> 2022-09-02 05:46:45\n","loss: 0.7863, acc: 0.6428\n","E2E-ABSA >>> 2022-09-02 05:46:51\n","loss: 0.7876, acc: 0.6408\n","E2E-ABSA >>> 2022-09-02 05:46:53\n",">>> val_acc: 0.6234, val_precision: 0.6234 val_recall: 0.6234, val_f1: 0.6234\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 76.\n","E2E-ABSA >>> 2022-09-02 05:46:58\n","loss: 0.7832, acc: 0.6535\n","E2E-ABSA >>> 2022-09-02 05:47:04\n","loss: 0.7858, acc: 0.6468\n","E2E-ABSA >>> 2022-09-02 05:47:10\n","loss: 0.7897, acc: 0.6396\n","E2E-ABSA >>> 2022-09-02 05:47:12\n",">>> val_acc: 0.6085, val_precision: 0.6085 val_recall: 0.6085, val_f1: 0.6085\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 77.\n","E2E-ABSA >>> 2022-09-02 05:47:17\n","loss: 0.7757, acc: 0.6466\n","E2E-ABSA >>> 2022-09-02 05:47:23\n","loss: 0.7935, acc: 0.6335\n","E2E-ABSA >>> 2022-09-02 05:47:29\n","loss: 0.7870, acc: 0.6446\n","E2E-ABSA >>> 2022-09-02 05:47:32\n",">>> val_acc: 0.6197, val_precision: 0.6197 val_recall: 0.6197, val_f1: 0.6197\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 78.\n","E2E-ABSA >>> 2022-09-02 05:47:36\n","loss: 0.8002, acc: 0.6192\n","E2E-ABSA >>> 2022-09-02 05:47:42\n","loss: 0.7814, acc: 0.6364\n","E2E-ABSA >>> 2022-09-02 05:47:48\n","loss: 0.7854, acc: 0.6384\n","E2E-ABSA >>> 2022-09-02 05:47:51\n",">>> val_acc: 0.6141, val_precision: 0.6141 val_recall: 0.6141, val_f1: 0.6141\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 79.\n","E2E-ABSA >>> 2022-09-02 05:47:55\n","loss: 0.7707, acc: 0.6608\n","E2E-ABSA >>> 2022-09-02 05:48:01\n","loss: 0.7793, acc: 0.6536\n","E2E-ABSA >>> 2022-09-02 05:48:07\n","loss: 0.7850, acc: 0.6432\n","E2E-ABSA >>> 2022-09-02 05:48:11\n",">>> val_acc: 0.6197, val_precision: 0.6197 val_recall: 0.6197, val_f1: 0.6197\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 80.\n","E2E-ABSA >>> 2022-09-02 05:48:15\n","loss: 0.7763, acc: 0.6677\n","E2E-ABSA >>> 2022-09-02 05:48:20\n","loss: 0.7598, acc: 0.6668\n","E2E-ABSA >>> 2022-09-02 05:48:26\n","loss: 0.7794, acc: 0.6493\n","E2E-ABSA >>> 2022-09-02 05:48:30\n",">>> val_acc: 0.6067, val_precision: 0.6067 val_recall: 0.6067, val_f1: 0.6067\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 81.\n","E2E-ABSA >>> 2022-09-02 05:48:33\n","loss: 0.7509, acc: 0.6707\n","E2E-ABSA >>> 2022-09-02 05:48:39\n","loss: 0.7746, acc: 0.6517\n","E2E-ABSA >>> 2022-09-02 05:48:46\n","loss: 0.7789, acc: 0.6476\n","E2E-ABSA >>> 2022-09-02 05:48:51\n",">>> val_acc: 0.6160, val_precision: 0.6160 val_recall: 0.6160, val_f1: 0.6160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 82.\n","E2E-ABSA >>> 2022-09-02 05:48:53\n","loss: 0.8030, acc: 0.6222\n","E2E-ABSA >>> 2022-09-02 05:48:59\n","loss: 0.7771, acc: 0.6484\n","E2E-ABSA >>> 2022-09-02 05:49:05\n","loss: 0.7823, acc: 0.6432\n","E2E-ABSA >>> 2022-09-02 05:49:11\n",">>> val_acc: 0.6122, val_precision: 0.6122 val_recall: 0.6122, val_f1: 0.6122\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 83.\n","E2E-ABSA >>> 2022-09-02 05:49:13\n","loss: 0.7699, acc: 0.6458\n","E2E-ABSA >>> 2022-09-02 05:49:19\n","loss: 0.7769, acc: 0.6406\n","E2E-ABSA >>> 2022-09-02 05:49:25\n","loss: 0.7870, acc: 0.6401\n","E2E-ABSA >>> 2022-09-02 05:49:31\n",">>> val_acc: 0.6160, val_precision: 0.6160 val_recall: 0.6160, val_f1: 0.6160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 84.\n","E2E-ABSA >>> 2022-09-02 05:49:32\n","loss: 0.7903, acc: 0.6429\n","E2E-ABSA >>> 2022-09-02 05:49:38\n","loss: 0.7858, acc: 0.6475\n","E2E-ABSA >>> 2022-09-02 05:49:44\n","loss: 0.7786, acc: 0.6461\n","E2E-ABSA >>> 2022-09-02 05:49:50\n",">>> val_acc: 0.6085, val_precision: 0.6085 val_recall: 0.6085, val_f1: 0.6085\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 85.\n","E2E-ABSA >>> 2022-09-02 05:49:52\n","loss: 0.7225, acc: 0.7094\n","E2E-ABSA >>> 2022-09-02 05:49:57\n","loss: 0.7804, acc: 0.6531\n","E2E-ABSA >>> 2022-09-02 05:50:03\n","loss: 0.7842, acc: 0.6429\n","E2E-ABSA >>> 2022-09-02 05:50:10\n",">>> val_acc: 0.6122, val_precision: 0.6122 val_recall: 0.6122, val_f1: 0.6122\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 86.\n","E2E-ABSA >>> 2022-09-02 05:50:11\n","loss: 0.7571, acc: 0.6510\n","E2E-ABSA >>> 2022-09-02 05:50:17\n","loss: 0.7894, acc: 0.6390\n","E2E-ABSA >>> 2022-09-02 05:50:23\n","loss: 0.7706, acc: 0.6498\n","E2E-ABSA >>> 2022-09-02 05:50:30\n",">>> val_acc: 0.6160, val_precision: 0.6160 val_recall: 0.6160, val_f1: 0.6160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 87.\n","E2E-ABSA >>> 2022-09-02 05:50:30\n","loss: 0.8348, acc: 0.5781\n","E2E-ABSA >>> 2022-09-02 05:50:36\n","loss: 0.7992, acc: 0.6364\n","E2E-ABSA >>> 2022-09-02 05:50:42\n","loss: 0.7907, acc: 0.6403\n","E2E-ABSA >>> 2022-09-02 05:50:48\n","loss: 0.7845, acc: 0.6423\n","E2E-ABSA >>> 2022-09-02 05:50:49\n",">>> val_acc: 0.6178, val_precision: 0.6178 val_recall: 0.6178, val_f1: 0.6178\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 88.\n","E2E-ABSA >>> 2022-09-02 05:50:56\n","loss: 0.7728, acc: 0.6530\n","E2E-ABSA >>> 2022-09-02 05:51:02\n","loss: 0.7775, acc: 0.6464\n","E2E-ABSA >>> 2022-09-02 05:51:07\n","loss: 0.7840, acc: 0.6429\n","E2E-ABSA >>> 2022-09-02 05:51:10\n",">>> val_acc: 0.6141, val_precision: 0.6141 val_recall: 0.6141, val_f1: 0.6141\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 89.\n","E2E-ABSA >>> 2022-09-02 05:51:15\n","loss: 0.7759, acc: 0.6491\n","E2E-ABSA >>> 2022-09-02 05:51:21\n","loss: 0.7855, acc: 0.6433\n","E2E-ABSA >>> 2022-09-02 05:51:27\n","loss: 0.7796, acc: 0.6458\n","E2E-ABSA >>> 2022-09-02 05:51:29\n",">>> val_acc: 0.6197, val_precision: 0.6197 val_recall: 0.6197, val_f1: 0.6197\n","E2E-ABSA >>> 2022-09-02 05:51:29\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6252, val_precision: 0.6252 val_recall: 0.6252, val_f1: 0.6252\n","you can download the best model from state_dict/cabasc_acl14shortdata_know_val_f1_0.6252\n",">>> test_acc: 0.6252, test_precision: 0.6252, test_recall: 0.6252, test_f1: 0.6252\n"]}]},{"cell_type":"markdown","source":["# 测试五个数据集在Bert_spc上的效果\n","**BERT_BASED - MODEL**"],"metadata":{"id":"IZLAPmxY9Ytb"}},{"cell_type":"markdown","source":["跑Bert前最好检测一下是否cuda可用"],"metadata":{"id":"yDvO9P7Nn_gR"}},{"cell_type":"code","source":["import torch\n","torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVNLcD8FnxuQ","outputId":"e44512b5-3864-4cfb-df67-a88222961626","executionInfo":{"status":"ok","timestamp":1662097893312,"user_tz":-480,"elapsed":619,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["增加字典知识后： Training **Twitter** dataset on model**(bert_spc)**"],"metadata":{"id":"RxgICN44uIe9"}},{"cell_type":"code","source":["!cd /content/DictionaryFused-E2E-ABSA && python3 train_insert.py --model_name bert_spc --dataset twitter_know --log_step 20  # batch_size 是16，所以每300个样本测一下"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTC3yjgvuTMZ","outputId":"a68d6219-3c0a-4da0-dbe8-8a1731ea09bd","executionInfo":{"status":"ok","timestamp":1662099550575,"user_tz":-480,"elapsed":1657264,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> 使用设备:cuda 训练.\n","加载Bert...\n","Downloading: 100% 232k/232k [00:00<00:00, 677kB/s]\n","Downloading: 100% 570/570 [00:00<00:00, 606kB/s]\n","Downloading: 100% 440M/440M [00:06<00:00, 73.3MB/s]\n","Bert加载完毕.\n","> training dataset count: 1664.\n","> testing dataset count: 419.\n","cuda memory allocated: 439075328\n","> n_trainable_params: 109484547, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: bert_spc\n",">>> dataset: twitter_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f809f435c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 20\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 20\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",">>> dataset_file: {'train': './datasets/twitter/output_know_insert/train.tsv', 'test': './datasets/twitter/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 05:52:11\n","loss: 0.9487, acc: 0.6188\n","E2E-ABSA >>> 2022-09-02 05:52:19\n","loss: 0.9148, acc: 0.6234\n","E2E-ABSA >>> 2022-09-02 05:52:27\n","loss: 0.8820, acc: 0.6375\n","E2E-ABSA >>> 2022-09-02 05:52:35\n","loss: 0.8690, acc: 0.6453\n","E2E-ABSA >>> 2022-09-02 05:52:43\n","loss: 0.8592, acc: 0.6538\n","E2E-ABSA >>> 2022-09-02 05:52:48\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">> saved: state_dict/bert_spc_twitter_know_val_f1_0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 05:52:55\n","loss: 0.8099, acc: 0.6523\n","E2E-ABSA >>> 2022-09-02 05:53:03\n","loss: 0.8197, acc: 0.6580\n","E2E-ABSA >>> 2022-09-02 05:53:11\n","loss: 0.8225, acc: 0.6585\n","E2E-ABSA >>> 2022-09-02 05:53:19\n","loss: 0.8222, acc: 0.6546\n","E2E-ABSA >>> 2022-09-02 05:53:26\n","loss: 0.8048, acc: 0.6673\n","E2E-ABSA >>> 2022-09-02 05:53:33\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">> saved: state_dict/bert_spc_twitter_know_val_f1_0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 05:53:39\n","loss: 0.7175, acc: 0.7135\n","E2E-ABSA >>> 2022-09-02 05:53:46\n","loss: 0.7238, acc: 0.7051\n","E2E-ABSA >>> 2022-09-02 05:53:54\n","loss: 0.7398, acc: 0.6899\n","E2E-ABSA >>> 2022-09-02 05:54:02\n","loss: 0.7468, acc: 0.6840\n","E2E-ABSA >>> 2022-09-02 05:54:10\n","loss: 0.7474, acc: 0.6773\n","E2E-ABSA >>> 2022-09-02 05:54:18\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 05:54:21\n","loss: 0.6818, acc: 0.7109\n","E2E-ABSA >>> 2022-09-02 05:54:29\n","loss: 0.6317, acc: 0.7411\n","E2E-ABSA >>> 2022-09-02 05:54:36\n","loss: 0.6258, acc: 0.7435\n","E2E-ABSA >>> 2022-09-02 05:54:44\n","loss: 0.6341, acc: 0.7335\n","E2E-ABSA >>> 2022-09-02 05:54:52\n","loss: 0.6356, acc: 0.7393\n","E2E-ABSA >>> 2022-09-02 05:55:01\n",">>> val_acc: 0.7566, val_precision: 0.7566 val_recall: 0.7566, val_f1: 0.7566\n",">> saved: state_dict/bert_spc_twitter_know_val_f1_0.7566\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 05:55:04\n","loss: 0.4766, acc: 0.8281\n","E2E-ABSA >>> 2022-09-02 05:55:12\n","loss: 0.4869, acc: 0.7891\n","E2E-ABSA >>> 2022-09-02 05:55:20\n","loss: 0.4760, acc: 0.8011\n","E2E-ABSA >>> 2022-09-02 05:55:27\n","loss: 0.4692, acc: 0.8066\n","E2E-ABSA >>> 2022-09-02 05:55:35\n","loss: 0.4789, acc: 0.8028\n","E2E-ABSA >>> 2022-09-02 05:55:43\n","loss: 0.4765, acc: 0.8035\n","E2E-ABSA >>> 2022-09-02 05:55:46\n",">>> val_acc: 0.7017, val_precision: 0.7017 val_recall: 0.7017, val_f1: 0.7017\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 05:55:54\n","loss: 0.3561, acc: 0.8562\n","E2E-ABSA >>> 2022-09-02 05:56:02\n","loss: 0.2943, acc: 0.8906\n","E2E-ABSA >>> 2022-09-02 05:56:10\n","loss: 0.3141, acc: 0.8792\n","E2E-ABSA >>> 2022-09-02 05:56:17\n","loss: 0.3244, acc: 0.8734\n","E2E-ABSA >>> 2022-09-02 05:56:25\n","loss: 0.3232, acc: 0.8712\n","E2E-ABSA >>> 2022-09-02 05:56:30\n",">>> val_acc: 0.7375, val_precision: 0.7375 val_recall: 0.7375, val_f1: 0.7375\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 05:56:36\n","loss: 0.1525, acc: 0.9492\n","E2E-ABSA >>> 2022-09-02 05:56:44\n","loss: 0.1610, acc: 0.9427\n","E2E-ABSA >>> 2022-09-02 05:56:52\n","loss: 0.1551, acc: 0.9520\n","E2E-ABSA >>> 2022-09-02 05:56:59\n","loss: 0.1841, acc: 0.9400\n","E2E-ABSA >>> 2022-09-02 05:57:07\n","loss: 0.1957, acc: 0.9329\n","E2E-ABSA >>> 2022-09-02 05:57:13\n",">>> val_acc: 0.7327, val_precision: 0.7327 val_recall: 0.7327, val_f1: 0.7327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 05:57:18\n","loss: 0.1279, acc: 0.9688\n","E2E-ABSA >>> 2022-09-02 05:57:26\n","loss: 0.0948, acc: 0.9707\n","E2E-ABSA >>> 2022-09-02 05:57:34\n","loss: 0.0834, acc: 0.9760\n","E2E-ABSA >>> 2022-09-02 05:57:41\n","loss: 0.0829, acc: 0.9774\n","E2E-ABSA >>> 2022-09-02 05:57:49\n","loss: 0.1068, acc: 0.9701\n","E2E-ABSA >>> 2022-09-02 05:57:57\n",">>> val_acc: 0.7422, val_precision: 0.7422 val_recall: 0.7422, val_f1: 0.7422\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 05:58:00\n","loss: 0.0738, acc: 0.9766\n","E2E-ABSA >>> 2022-09-02 05:58:08\n","loss: 0.0556, acc: 0.9888\n","E2E-ABSA >>> 2022-09-02 05:58:16\n","loss: 0.0839, acc: 0.9792\n","E2E-ABSA >>> 2022-09-02 05:58:23\n","loss: 0.0915, acc: 0.9724\n","E2E-ABSA >>> 2022-09-02 05:58:31\n","loss: 0.1001, acc: 0.9688\n","E2E-ABSA >>> 2022-09-02 05:58:41\n",">>> val_acc: 0.7613, val_precision: 0.7613 val_recall: 0.7613, val_f1: 0.7613\n",">> saved: state_dict/bert_spc_twitter_know_val_f1_0.7613\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 05:58:43\n","loss: 0.0743, acc: 0.9688\n","E2E-ABSA >>> 2022-09-02 05:58:51\n","loss: 0.0590, acc: 0.9792\n","E2E-ABSA >>> 2022-09-02 05:58:59\n","loss: 0.0496, acc: 0.9844\n","E2E-ABSA >>> 2022-09-02 05:59:07\n","loss: 0.0580, acc: 0.9824\n","E2E-ABSA >>> 2022-09-02 05:59:15\n","loss: 0.0583, acc: 0.9829\n","E2E-ABSA >>> 2022-09-02 05:59:22\n","loss: 0.0615, acc: 0.9808\n","E2E-ABSA >>> 2022-09-02 05:59:26\n",">>> val_acc: 0.7494, val_precision: 0.7494 val_recall: 0.7494, val_f1: 0.7494\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 05:59:33\n","loss: 0.0679, acc: 0.9781\n","E2E-ABSA >>> 2022-09-02 05:59:41\n","loss: 0.1003, acc: 0.9703\n","E2E-ABSA >>> 2022-09-02 05:59:49\n","loss: 0.1199, acc: 0.9594\n","E2E-ABSA >>> 2022-09-02 05:59:57\n","loss: 0.1097, acc: 0.9641\n","E2E-ABSA >>> 2022-09-02 06:00:05\n","loss: 0.1066, acc: 0.9637\n","E2E-ABSA >>> 2022-09-02 06:00:09\n",">>> val_acc: 0.6993, val_precision: 0.6993 val_recall: 0.6993, val_f1: 0.6993\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 06:00:16\n","loss: 0.0561, acc: 0.9805\n","E2E-ABSA >>> 2022-09-02 06:00:23\n","loss: 0.0981, acc: 0.9653\n","E2E-ABSA >>> 2022-09-02 06:00:31\n","loss: 0.0999, acc: 0.9632\n","E2E-ABSA >>> 2022-09-02 06:00:39\n","loss: 0.1052, acc: 0.9622\n","E2E-ABSA >>> 2022-09-02 06:00:47\n","loss: 0.1213, acc: 0.9551\n","E2E-ABSA >>> 2022-09-02 06:00:53\n",">>> val_acc: 0.7327, val_precision: 0.7327 val_recall: 0.7327, val_f1: 0.7327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 06:00:58\n","loss: 0.1213, acc: 0.9635\n","E2E-ABSA >>> 2022-09-02 06:01:06\n","loss: 0.0889, acc: 0.9766\n","E2E-ABSA >>> 2022-09-02 06:01:13\n","loss: 0.0759, acc: 0.9784\n","E2E-ABSA >>> 2022-09-02 06:01:21\n","loss: 0.0772, acc: 0.9757\n","E2E-ABSA >>> 2022-09-02 06:01:29\n","loss: 0.0757, acc: 0.9735\n","E2E-ABSA >>> 2022-09-02 06:01:37\n",">>> val_acc: 0.7255, val_precision: 0.7255 val_recall: 0.7255, val_f1: 0.7255\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 06:01:40\n","loss: 0.1569, acc: 0.9297\n","E2E-ABSA >>> 2022-09-02 06:01:48\n","loss: 0.1000, acc: 0.9576\n","E2E-ABSA >>> 2022-09-02 06:01:55\n","loss: 0.0853, acc: 0.9674\n","E2E-ABSA >>> 2022-09-02 06:02:03\n","loss: 0.0781, acc: 0.9715\n","E2E-ABSA >>> 2022-09-02 06:02:11\n","loss: 0.0655, acc: 0.9773\n","E2E-ABSA >>> 2022-09-02 06:02:20\n",">>> val_acc: 0.7327, val_precision: 0.7327 val_recall: 0.7327, val_f1: 0.7327\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 06:02:22\n","loss: 0.0285, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 06:02:30\n","loss: 0.0735, acc: 0.9792\n","E2E-ABSA >>> 2022-09-02 06:02:37\n","loss: 0.0685, acc: 0.9787\n","E2E-ABSA >>> 2022-09-02 06:02:45\n","loss: 0.0694, acc: 0.9775\n","E2E-ABSA >>> 2022-09-02 06:02:53\n","loss: 0.0754, acc: 0.9754\n","E2E-ABSA >>> 2022-09-02 06:03:01\n","loss: 0.0849, acc: 0.9718\n","E2E-ABSA >>> 2022-09-02 06:03:04\n",">>> val_acc: 0.7160, val_precision: 0.7160 val_recall: 0.7160, val_f1: 0.7160\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 06:03:12\n","loss: 0.0615, acc: 0.9844\n","E2E-ABSA >>> 2022-09-02 06:03:19\n","loss: 0.0431, acc: 0.9859\n","E2E-ABSA >>> 2022-09-02 06:03:27\n","loss: 0.0377, acc: 0.9885\n","E2E-ABSA >>> 2022-09-02 06:03:35\n","loss: 0.0437, acc: 0.9891\n","E2E-ABSA >>> 2022-09-02 06:03:43\n","loss: 0.0653, acc: 0.9800\n","E2E-ABSA >>> 2022-09-02 06:03:47\n",">>> val_acc: 0.7375, val_precision: 0.7375 val_recall: 0.7375, val_f1: 0.7375\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 06:03:54\n","loss: 0.0767, acc: 0.9727\n","E2E-ABSA >>> 2022-09-02 06:04:01\n","loss: 0.0813, acc: 0.9740\n","E2E-ABSA >>> 2022-09-02 06:04:09\n","loss: 0.0793, acc: 0.9743\n","E2E-ABSA >>> 2022-09-02 06:04:17\n","loss: 0.0652, acc: 0.9803\n","E2E-ABSA >>> 2022-09-02 06:04:25\n","loss: 0.0567, acc: 0.9831\n","E2E-ABSA >>> 2022-09-02 06:04:31\n",">>> val_acc: 0.7685, val_precision: 0.7685 val_recall: 0.7685, val_f1: 0.7685\n",">> saved: state_dict/bert_spc_twitter_know_val_f1_0.7685\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 06:04:37\n","loss: 0.1427, acc: 0.9635\n","E2E-ABSA >>> 2022-09-02 06:04:45\n","loss: 0.0993, acc: 0.9707\n","E2E-ABSA >>> 2022-09-02 06:04:52\n","loss: 0.0828, acc: 0.9760\n","E2E-ABSA >>> 2022-09-02 06:05:00\n","loss: 0.0807, acc: 0.9748\n","E2E-ABSA >>> 2022-09-02 06:05:08\n","loss: 0.0729, acc: 0.9776\n","E2E-ABSA >>> 2022-09-02 06:05:16\n",">>> val_acc: 0.7470, val_precision: 0.7470 val_recall: 0.7470, val_f1: 0.7470\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 06:05:19\n","loss: 0.0373, acc: 0.9922\n","E2E-ABSA >>> 2022-09-02 06:05:27\n","loss: 0.0644, acc: 0.9777\n","E2E-ABSA >>> 2022-09-02 06:05:35\n","loss: 0.0923, acc: 0.9661\n","E2E-ABSA >>> 2022-09-02 06:05:42\n","loss: 0.0923, acc: 0.9651\n","E2E-ABSA >>> 2022-09-02 06:05:50\n","loss: 0.0982, acc: 0.9616\n","E2E-ABSA >>> 2022-09-02 06:06:00\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 06:06:01\n","loss: 0.0985, acc: 0.9531\n","E2E-ABSA >>> 2022-09-02 06:06:09\n","loss: 0.1371, acc: 0.9531\n","E2E-ABSA >>> 2022-09-02 06:06:17\n","loss: 0.0985, acc: 0.9673\n","E2E-ABSA >>> 2022-09-02 06:06:24\n","loss: 0.0755, acc: 0.9756\n","E2E-ABSA >>> 2022-09-02 06:06:32\n","loss: 0.0642, acc: 0.9799\n","E2E-ABSA >>> 2022-09-02 06:06:40\n","loss: 0.0593, acc: 0.9808\n","E2E-ABSA >>> 2022-09-02 06:06:43\n",">>> val_acc: 0.7637, val_precision: 0.7637 val_recall: 0.7637, val_f1: 0.7637\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 06:06:51\n","loss: 0.0730, acc: 0.9750\n","E2E-ABSA >>> 2022-09-02 06:06:59\n","loss: 0.0946, acc: 0.9656\n","E2E-ABSA >>> 2022-09-02 06:07:06\n","loss: 0.0957, acc: 0.9656\n","E2E-ABSA >>> 2022-09-02 06:07:14\n","loss: 0.0824, acc: 0.9711\n","E2E-ABSA >>> 2022-09-02 06:07:22\n","loss: 0.0695, acc: 0.9762\n","E2E-ABSA >>> 2022-09-02 06:07:27\n",">>> val_acc: 0.7208, val_precision: 0.7208 val_recall: 0.7208, val_f1: 0.7208\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 06:07:33\n","loss: 0.0324, acc: 0.9883\n","E2E-ABSA >>> 2022-09-02 06:07:41\n","loss: 0.0562, acc: 0.9774\n","E2E-ABSA >>> 2022-09-02 06:07:48\n","loss: 0.0603, acc: 0.9788\n","E2E-ABSA >>> 2022-09-02 06:07:56\n","loss: 0.0727, acc: 0.9745\n","E2E-ABSA >>> 2022-09-02 06:08:04\n","loss: 0.0731, acc: 0.9746\n","E2E-ABSA >>> 2022-09-02 06:08:10\n",">>> val_acc: 0.7279, val_precision: 0.7279 val_recall: 0.7279, val_f1: 0.7279\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 06:08:15\n","loss: 0.0297, acc: 0.9844\n","E2E-ABSA >>> 2022-09-02 06:08:23\n","loss: 0.0312, acc: 0.9863\n","E2E-ABSA >>> 2022-09-02 06:08:30\n","loss: 0.0289, acc: 0.9892\n","E2E-ABSA >>> 2022-09-02 06:08:38\n","loss: 0.0457, acc: 0.9870\n","E2E-ABSA >>> 2022-09-02 06:08:46\n","loss: 0.0414, acc: 0.9871\n","E2E-ABSA >>> 2022-09-02 06:08:54\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 06:08:57\n","loss: 0.0210, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 06:09:05\n","loss: 0.0248, acc: 0.9933\n","E2E-ABSA >>> 2022-09-02 06:09:13\n","loss: 0.0240, acc: 0.9948\n","E2E-ABSA >>> 2022-09-02 06:09:20\n","loss: 0.0312, acc: 0.9899\n","E2E-ABSA >>> 2022-09-02 06:09:28\n","loss: 0.0549, acc: 0.9830\n","E2E-ABSA >>> 2022-09-02 06:09:38\n",">>> val_acc: 0.6754, val_precision: 0.6754 val_recall: 0.6754, val_f1: 0.6754\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 06:09:39\n","loss: 0.1251, acc: 0.9219\n","E2E-ABSA >>> 2022-09-02 06:09:47\n","loss: 0.1517, acc: 0.9401\n","E2E-ABSA >>> 2022-09-02 06:09:55\n","loss: 0.1125, acc: 0.9574\n","E2E-ABSA >>> 2022-09-02 06:10:02\n","loss: 0.1079, acc: 0.9609\n","E2E-ABSA >>> 2022-09-02 06:10:10\n","loss: 0.1243, acc: 0.9516\n","E2E-ABSA >>> 2022-09-02 06:10:18\n","loss: 0.1172, acc: 0.9549\n","E2E-ABSA >>> 2022-09-02 06:10:21\n",">>> val_acc: 0.7399, val_precision: 0.7399 val_recall: 0.7399, val_f1: 0.7399\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 06:10:29\n","loss: 0.0200, acc: 0.9938\n","E2E-ABSA >>> 2022-09-02 06:10:37\n","loss: 0.0556, acc: 0.9781\n","E2E-ABSA >>> 2022-09-02 06:10:45\n","loss: 0.0638, acc: 0.9719\n","E2E-ABSA >>> 2022-09-02 06:10:52\n","loss: 0.0649, acc: 0.9742\n","E2E-ABSA >>> 2022-09-02 06:11:00\n","loss: 0.0677, acc: 0.9744\n","E2E-ABSA >>> 2022-09-02 06:11:05\n",">>> val_acc: 0.7303, val_precision: 0.7303 val_recall: 0.7303, val_f1: 0.7303\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 06:11:11\n","loss: 0.0404, acc: 0.9883\n","E2E-ABSA >>> 2022-09-02 06:11:19\n","loss: 0.0307, acc: 0.9896\n","E2E-ABSA >>> 2022-09-02 06:11:27\n","loss: 0.0278, acc: 0.9922\n","E2E-ABSA >>> 2022-09-02 06:11:34\n","loss: 0.0238, acc: 0.9934\n","E2E-ABSA >>> 2022-09-02 06:11:42\n","loss: 0.0306, acc: 0.9915\n","E2E-ABSA >>> 2022-09-02 06:11:49\n",">>> val_acc: 0.6778, val_precision: 0.6778 val_recall: 0.6778, val_f1: 0.6778\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 06:11:53\n","loss: 0.0170, acc: 0.9948\n","E2E-ABSA >>> 2022-09-02 06:12:01\n","loss: 0.0139, acc: 0.9961\n","E2E-ABSA >>> 2022-09-02 06:12:09\n","loss: 0.0136, acc: 0.9964\n","E2E-ABSA >>> 2022-09-02 06:12:17\n","loss: 0.0188, acc: 0.9931\n","E2E-ABSA >>> 2022-09-02 06:12:24\n","loss: 0.0287, acc: 0.9891\n","E2E-ABSA >>> 2022-09-02 06:12:32\n",">>> val_acc: 0.6706, val_precision: 0.6706 val_recall: 0.6706, val_f1: 0.6706\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 06:12:35\n","loss: 0.0653, acc: 0.9766\n","E2E-ABSA >>> 2022-09-02 06:12:43\n","loss: 0.0902, acc: 0.9665\n","E2E-ABSA >>> 2022-09-02 06:12:51\n","loss: 0.0761, acc: 0.9714\n","E2E-ABSA >>> 2022-09-02 06:12:59\n","loss: 0.0597, acc: 0.9779\n","E2E-ABSA >>> 2022-09-02 06:13:06\n","loss: 0.0572, acc: 0.9794\n","E2E-ABSA >>> 2022-09-02 06:13:16\n",">>> val_acc: 0.7255, val_precision: 0.7255 val_recall: 0.7255, val_f1: 0.7255\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 06:13:17\n","loss: 0.0269, acc: 0.9844\n","E2E-ABSA >>> 2022-09-02 06:13:25\n","loss: 0.0326, acc: 0.9870\n","E2E-ABSA >>> 2022-09-02 06:13:33\n","loss: 0.0449, acc: 0.9844\n","E2E-ABSA >>> 2022-09-02 06:13:41\n","loss: 0.0439, acc: 0.9854\n","E2E-ABSA >>> 2022-09-02 06:13:48\n","loss: 0.0532, acc: 0.9807\n","E2E-ABSA >>> 2022-09-02 06:13:56\n","loss: 0.0626, acc: 0.9784\n","E2E-ABSA >>> 2022-09-02 06:13:59\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 06:14:07\n","loss: 0.0522, acc: 0.9844\n","E2E-ABSA >>> 2022-09-02 06:14:15\n","loss: 0.0768, acc: 0.9719\n","E2E-ABSA >>> 2022-09-02 06:14:23\n","loss: 0.0757, acc: 0.9708\n","E2E-ABSA >>> 2022-09-02 06:14:30\n","loss: 0.0806, acc: 0.9711\n","E2E-ABSA >>> 2022-09-02 06:14:38\n","loss: 0.0866, acc: 0.9700\n","E2E-ABSA >>> 2022-09-02 06:14:43\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 06:14:49\n","loss: 0.0268, acc: 0.9922\n","E2E-ABSA >>> 2022-09-02 06:14:57\n","loss: 0.0292, acc: 0.9948\n","E2E-ABSA >>> 2022-09-02 06:15:05\n","loss: 0.0235, acc: 0.9955\n","E2E-ABSA >>> 2022-09-02 06:15:12\n","loss: 0.0309, acc: 0.9910\n","E2E-ABSA >>> 2022-09-02 06:15:20\n","loss: 0.0373, acc: 0.9896\n","E2E-ABSA >>> 2022-09-02 06:15:27\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 06:15:31\n","loss: 0.0441, acc: 0.9844\n","E2E-ABSA >>> 2022-09-02 06:15:39\n","loss: 0.0294, acc: 0.9902\n","E2E-ABSA >>> 2022-09-02 06:15:47\n","loss: 0.0472, acc: 0.9856\n","E2E-ABSA >>> 2022-09-02 06:15:55\n","loss: 0.0432, acc: 0.9870\n","E2E-ABSA >>> 2022-09-02 06:16:02\n","loss: 0.0422, acc: 0.9871\n","E2E-ABSA >>> 2022-09-02 06:16:10\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 06:16:13\n","loss: 0.0196, acc: 0.9922\n","E2E-ABSA >>> 2022-09-02 06:16:21\n","loss: 0.0388, acc: 0.9888\n","E2E-ABSA >>> 2022-09-02 06:16:29\n","loss: 0.0542, acc: 0.9792\n","E2E-ABSA >>> 2022-09-02 06:16:37\n","loss: 0.0633, acc: 0.9798\n","E2E-ABSA >>> 2022-09-02 06:16:44\n","loss: 0.0683, acc: 0.9766\n","E2E-ABSA >>> 2022-09-02 06:16:54\n",">>> val_acc: 0.6468, val_precision: 0.6468 val_recall: 0.6468, val_f1: 0.6468\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 06:16:55\n","loss: 0.0334, acc: 0.9844\n","E2E-ABSA >>> 2022-09-02 06:17:03\n","loss: 0.0560, acc: 0.9818\n","E2E-ABSA >>> 2022-09-02 06:17:11\n","loss: 0.0739, acc: 0.9773\n","E2E-ABSA >>> 2022-09-02 06:17:19\n","loss: 0.0661, acc: 0.9805\n","E2E-ABSA >>> 2022-09-02 06:17:26\n","loss: 0.0646, acc: 0.9799\n","E2E-ABSA >>> 2022-09-02 06:17:34\n","loss: 0.0640, acc: 0.9802\n","E2E-ABSA >>> 2022-09-02 06:17:37\n",">>> val_acc: 0.7399, val_precision: 0.7399 val_recall: 0.7399, val_f1: 0.7399\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 06:17:45\n","loss: 0.0162, acc: 0.9969\n","E2E-ABSA >>> 2022-09-02 06:17:53\n","loss: 0.0149, acc: 0.9984\n","E2E-ABSA >>> 2022-09-02 06:18:01\n","loss: 0.0194, acc: 0.9958\n","E2E-ABSA >>> 2022-09-02 06:18:08\n","loss: 0.0222, acc: 0.9953\n","E2E-ABSA >>> 2022-09-02 06:18:16\n","loss: 0.0250, acc: 0.9931\n","E2E-ABSA >>> 2022-09-02 06:18:21\n",">>> val_acc: 0.7375, val_precision: 0.7375 val_recall: 0.7375, val_f1: 0.7375\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 06:18:27\n","loss: 0.0538, acc: 0.9844\n","E2E-ABSA >>> 2022-09-02 06:18:35\n","loss: 0.0481, acc: 0.9809\n","E2E-ABSA >>> 2022-09-02 06:18:43\n","loss: 0.0456, acc: 0.9833\n","E2E-ABSA >>> 2022-09-02 06:18:50\n","loss: 0.0575, acc: 0.9811\n","E2E-ABSA >>> 2022-09-02 06:18:58\n","loss: 0.0548, acc: 0.9831\n","E2E-ABSA >>> 2022-09-02 06:19:05\n",">>> val_acc: 0.7064, val_precision: 0.7064 val_recall: 0.7064, val_f1: 0.7064\n","E2E-ABSA >>> 2022-09-02 06:19:05\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7685, val_precision: 0.7685 val_recall: 0.7685, val_f1: 0.7685\n","you can download the best model from state_dict/bert_spc_twitter_know_val_f1_0.7685\n",">>> test_acc: 0.7685, test_precision: 0.7685, test_recall: 0.7685, test_f1: 0.7685\n"]}]},{"cell_type":"markdown","source":["增加字典知识后：Training **SemEval2014** dataset on model**(Bert_spc)**"],"metadata":{"id":"DyAwLQsihgkx"}},{"cell_type":"code","source":["!cd /content/DictionaryFused-E2E-ABSA && python3 train_insert.py --model_name bert_spc --dataset SemEval2014_know --log_step 100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osaCQQ4eiLgF","outputId":"8ed1e5cb-3ea4-4d67-8216-a35b6263eae9","executionInfo":{"status":"ok","timestamp":1662101288755,"user_tz":-480,"elapsed":1738190,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> 使用设备:cuda 训练.\n","加载Bert...\n","Bert加载完毕.\n","> training dataset count: 3093.\n","> testing dataset count: 329.\n","cuda memory allocated: 439075328\n","> n_trainable_params: 109484547, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: bert_spc\n",">>> dataset: SemEval2014_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f1683550c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 20\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",">>> dataset_file: {'train': './datasets/laprest14/output_know_insert/train.tsv', 'test': './datasets/laprest14/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 06:20:22\n","loss: 0.9993, acc: 0.5569\n","E2E-ABSA >>> 2022-09-02 06:21:01\n",">>> val_acc: 0.5714, val_precision: 0.5714 val_recall: 0.5714, val_f1: 0.5714\n",">> saved: state_dict/bert_spc_SemEval2014_know_val_f1_0.5714\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 06:21:05\n","loss: 1.0478, acc: 0.5312\n","E2E-ABSA >>> 2022-09-02 06:21:43\n","loss: 0.9766, acc: 0.5619\n","E2E-ABSA >>> 2022-09-02 06:22:20\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">> saved: state_dict/bert_spc_SemEval2014_know_val_f1_0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 06:22:26\n","loss: 1.0273, acc: 0.5312\n","E2E-ABSA >>> 2022-09-02 06:23:04\n","loss: 0.9966, acc: 0.5592\n","E2E-ABSA >>> 2022-09-02 06:23:38\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 06:23:45\n","loss: 1.0014, acc: 0.5625\n","E2E-ABSA >>> 2022-09-02 06:24:23\n","loss: 0.9866, acc: 0.5699\n","E2E-ABSA >>> 2022-09-02 06:24:55\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 06:25:04\n","loss: 0.9919, acc: 0.5599\n","E2E-ABSA >>> 2022-09-02 06:25:43\n","loss: 0.9926, acc: 0.5554\n","E2E-ABSA >>> 2022-09-02 06:26:12\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 06:26:23\n","loss: 1.0037, acc: 0.5437\n","E2E-ABSA >>> 2022-09-02 06:27:02\n","loss: 0.9899, acc: 0.5659\n","E2E-ABSA >>> 2022-09-02 06:27:29\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 06:27:43\n","loss: 0.9790, acc: 0.5729\n","E2E-ABSA >>> 2022-09-02 06:28:21\n","loss: 0.9814, acc: 0.5666\n","E2E-ABSA >>> 2022-09-02 06:28:46\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 06:29:02\n","loss: 0.9894, acc: 0.5714\n","E2E-ABSA >>> 2022-09-02 06:29:41\n","loss: 0.9915, acc: 0.5651\n","E2E-ABSA >>> 2022-09-02 06:30:03\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 06:30:21\n","loss: 0.9827, acc: 0.5690\n","E2E-ABSA >>> 2022-09-02 06:31:00\n","loss: 0.9789, acc: 0.5714\n","E2E-ABSA >>> 2022-09-02 06:31:20\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 06:31:41\n","loss: 0.9915, acc: 0.5475\n","E2E-ABSA >>> 2022-09-02 06:32:19\n","loss: 0.9894, acc: 0.5617\n","E2E-ABSA >>> 2022-09-02 06:32:37\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 06:33:00\n","loss: 0.9701, acc: 0.5833\n","E2E-ABSA >>> 2022-09-02 06:33:39\n","loss: 0.9811, acc: 0.5652\n","E2E-ABSA >>> 2022-09-02 06:33:54\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 06:34:20\n","loss: 0.9803, acc: 0.5710\n","E2E-ABSA >>> 2022-09-02 06:34:58\n","loss: 0.9859, acc: 0.5610\n","E2E-ABSA >>> 2022-09-02 06:35:12\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 06:35:39\n","loss: 0.9650, acc: 0.5877\n","E2E-ABSA >>> 2022-09-02 06:36:18\n","loss: 0.9793, acc: 0.5705\n","E2E-ABSA >>> 2022-09-02 06:36:29\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 06:36:59\n","loss: 0.9738, acc: 0.5793\n","E2E-ABSA >>> 2022-09-02 06:37:37\n","loss: 0.9694, acc: 0.5741\n","E2E-ABSA >>> 2022-09-02 06:37:46\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 06:38:18\n","loss: 0.9848, acc: 0.5670\n","E2E-ABSA >>> 2022-09-02 06:38:57\n","loss: 0.9821, acc: 0.5645\n","E2E-ABSA >>> 2022-09-02 06:39:03\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 06:39:38\n","loss: 0.9708, acc: 0.5729\n","E2E-ABSA >>> 2022-09-02 06:40:16\n","loss: 0.9768, acc: 0.5691\n","E2E-ABSA >>> 2022-09-02 06:40:20\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 06:40:57\n","loss: 0.9913, acc: 0.5547\n","E2E-ABSA >>> 2022-09-02 06:41:38\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 06:41:38\n","loss: 0.9941, acc: 0.4688\n","E2E-ABSA >>> 2022-09-02 06:42:17\n","loss: 0.9813, acc: 0.5643\n","E2E-ABSA >>> 2022-09-02 06:42:55\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 06:42:58\n","loss: 1.0683, acc: 0.4922\n","E2E-ABSA >>> 2022-09-02 06:43:37\n","loss: 0.9746, acc: 0.5752\n","E2E-ABSA >>> 2022-09-02 06:44:12\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 06:44:17\n","loss: 0.9666, acc: 0.5804\n","E2E-ABSA >>> 2022-09-02 06:44:56\n","loss: 0.9690, acc: 0.5779\n","E2E-ABSA >>> 2022-09-02 06:45:29\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 06:45:37\n","loss: 0.9965, acc: 0.5531\n","E2E-ABSA >>> 2022-09-02 06:46:16\n","loss: 0.9834, acc: 0.5635\n","E2E-ABSA >>> 2022-09-02 06:46:46\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 06:46:56\n","loss: 1.0154, acc: 0.5264\n","E2E-ABSA >>> 2022-09-02 06:47:35\n","loss: 0.9805, acc: 0.5685\n","E2E-ABSA >>> 2022-09-02 06:48:04\n",">>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n","E2E-ABSA >>> 2022-09-02 06:48:04\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.5745, val_precision: 0.5745 val_recall: 0.5745, val_f1: 0.5745\n","you can download the best model from state_dict/bert_spc_SemEval2014_know_val_f1_0.5745\n",">>> test_acc: 0.5745, test_precision: 0.5745, test_recall: 0.5745, test_f1: 0.5745\n"]}]},{"cell_type":"markdown","source":["增加字典知识后：Training **SemEval2015** dataset on model**(bert_spc)**"],"metadata":{"id":"01RauAGlGWCC"}},{"cell_type":"code","source":["!cd /content/DictionaryFused-E2E-ABSA && python3 train_insert.py --model_name bert_spc --dataset SemEval2015_know --log_step 100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZK6muB2Gf-O","outputId":"6ef9ec5f-5e78-4033-da74-3bb1974f2231","executionInfo":{"status":"ok","timestamp":1662108067934,"user_tz":-480,"elapsed":942146,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> 使用设备:cuda 训练.\n","加载Bert...\n","Downloading: 100% 232k/232k [00:00<00:00, 2.67MB/s]\n","Downloading: 100% 570/570 [00:00<00:00, 617kB/s]\n","Downloading: 100% 440M/440M [00:05<00:00, 75.8MB/s]\n","Bert加载完毕.\n","> training dataset count: 750.\n","> testing dataset count: 82.\n","cuda memory allocated: 439075328\n","> n_trainable_params: 109484547, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: bert_spc\n",">>> dataset: SemEval2015_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f770c5dfc20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 20\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",">>> dataset_file: {'train': './datasets/rest15/output_know_insert/train.tsv', 'test': './datasets/rest15/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 08:26:08\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">> saved: state_dict/bert_spc_SemEval2015_know_val_f1_0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 08:26:28\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">> saved: state_dict/bert_spc_SemEval2015_know_val_f1_0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 08:26:32\n","loss: 0.5156, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 08:26:49\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 08:27:09\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 08:27:14\n","loss: 0.4878, acc: 0.8385\n","E2E-ABSA >>> 2022-09-02 08:27:29\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 08:27:49\n",">>> val_acc: 0.9024, val_precision: 0.9024 val_recall: 0.9024, val_f1: 0.9024\n",">> saved: state_dict/bert_spc_SemEval2015_know_val_f1_0.9024\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 08:27:57\n","loss: 0.1825, acc: 0.9375\n","E2E-ABSA >>> 2022-09-02 08:28:09\n",">>> val_acc: 0.9268, val_precision: 0.9268 val_recall: 0.9268, val_f1: 0.9268\n",">> saved: state_dict/bert_spc_SemEval2015_know_val_f1_0.9268\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 08:28:30\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 08:28:40\n","loss: 0.0361, acc: 0.9922\n","E2E-ABSA >>> 2022-09-02 08:28:50\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 08:29:10\n",">>> val_acc: 0.8902, val_precision: 0.8902 val_recall: 0.8902, val_f1: 0.8902\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 08:29:22\n","loss: 0.0431, acc: 0.9875\n","E2E-ABSA >>> 2022-09-02 08:29:30\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 08:29:50\n",">>> val_acc: 0.8780, val_precision: 0.8780 val_recall: 0.8780, val_f1: 0.8780\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 08:30:04\n","loss: 0.0072, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 08:30:09\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 08:30:29\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 08:30:46\n","loss: 0.0190, acc: 0.9940\n","E2E-ABSA >>> 2022-09-02 08:30:49\n",">>> val_acc: 0.9024, val_precision: 0.9024 val_recall: 0.9024, val_f1: 0.9024\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 08:31:09\n",">>> val_acc: 0.9146, val_precision: 0.9146 val_recall: 0.9146, val_f1: 0.9146\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 08:31:29\n",">>> val_acc: 0.9024, val_precision: 0.9024 val_recall: 0.9024, val_f1: 0.9024\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 08:31:29\n","loss: 0.0149, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 08:31:48\n",">>> val_acc: 0.8780, val_precision: 0.8780 val_recall: 0.8780, val_f1: 0.8780\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 08:32:08\n",">>> val_acc: 0.8902, val_precision: 0.8902 val_recall: 0.8902, val_f1: 0.8902\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 08:32:11\n","loss: 0.0096, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 08:32:28\n",">>> val_acc: 0.9024, val_precision: 0.9024 val_recall: 0.9024, val_f1: 0.9024\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 08:32:48\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 08:32:53\n","loss: 0.0271, acc: 0.9952\n","E2E-ABSA >>> 2022-09-02 08:33:08\n",">>> val_acc: 0.9146, val_precision: 0.9146 val_recall: 0.9146, val_f1: 0.9146\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 08:33:28\n",">>> val_acc: 0.8902, val_precision: 0.8902 val_recall: 0.8902, val_f1: 0.8902\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 08:33:36\n","loss: 0.0199, acc: 0.9934\n","E2E-ABSA >>> 2022-09-02 08:33:48\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 08:34:07\n",">>> val_acc: 0.9268, val_precision: 0.9268 val_recall: 0.9268, val_f1: 0.9268\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 08:34:18\n","loss: 0.0067, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 08:34:27\n",">>> val_acc: 0.9512, val_precision: 0.9512 val_recall: 0.9512, val_f1: 0.9512\n",">> saved: state_dict/bert_spc_SemEval2015_know_val_f1_0.9512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 08:34:48\n",">>> val_acc: 0.9390, val_precision: 0.9390 val_recall: 0.9390, val_f1: 0.9390\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 08:35:01\n","loss: 0.0465, acc: 0.9879\n","E2E-ABSA >>> 2022-09-02 08:35:08\n",">>> val_acc: 0.9024, val_precision: 0.9024 val_recall: 0.9024, val_f1: 0.9024\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 08:35:28\n",">>> val_acc: 0.9146, val_precision: 0.9146 val_recall: 0.9146, val_f1: 0.9146\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 08:35:43\n","loss: 0.0287, acc: 0.9966\n","E2E-ABSA >>> 2022-09-02 08:35:48\n",">>> val_acc: 0.9512, val_precision: 0.9512 val_recall: 0.9512, val_f1: 0.9512\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 08:36:08\n",">>> val_acc: 0.9146, val_precision: 0.9146 val_recall: 0.9146, val_f1: 0.9146\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 08:36:25\n","loss: 0.0150, acc: 0.9956\n","E2E-ABSA >>> 2022-09-02 08:36:28\n",">>> val_acc: 0.8780, val_precision: 0.8780 val_recall: 0.8780, val_f1: 0.8780\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 08:36:47\n",">>> val_acc: 0.8902, val_precision: 0.8902 val_recall: 0.8902, val_f1: 0.8902\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 08:37:07\n",">>> val_acc: 0.8902, val_precision: 0.8902 val_recall: 0.8902, val_f1: 0.8902\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 08:37:08\n","loss: 0.0007, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 08:37:27\n",">>> val_acc: 0.8902, val_precision: 0.8902 val_recall: 0.8902, val_f1: 0.8902\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 08:37:47\n",">>> val_acc: 0.8780, val_precision: 0.8780 val_recall: 0.8780, val_f1: 0.8780\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 08:37:50\n","loss: 0.0016, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 08:38:07\n",">>> val_acc: 0.9024, val_precision: 0.9024 val_recall: 0.9024, val_f1: 0.9024\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 08:38:27\n",">>> val_acc: 0.8902, val_precision: 0.8902 val_recall: 0.8902, val_f1: 0.8902\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 08:38:32\n","loss: 0.0610, acc: 0.9911\n","E2E-ABSA >>> 2022-09-02 08:38:46\n",">>> val_acc: 0.9146, val_precision: 0.9146 val_recall: 0.9146, val_f1: 0.9146\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 39.\n","E2E-ABSA >>> 2022-09-02 08:39:06\n",">>> val_acc: 0.9268, val_precision: 0.9268 val_recall: 0.9268, val_f1: 0.9268\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 40.\n","E2E-ABSA >>> 2022-09-02 08:39:14\n","loss: 0.0962, acc: 0.9656\n","E2E-ABSA >>> 2022-09-02 08:39:26\n",">>> val_acc: 0.9268, val_precision: 0.9268 val_recall: 0.9268, val_f1: 0.9268\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 41.\n","E2E-ABSA >>> 2022-09-02 08:39:46\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 42.\n","E2E-ABSA >>> 2022-09-02 08:39:56\n","loss: 0.0133, acc: 0.9952\n","E2E-ABSA >>> 2022-09-02 08:40:05\n",">>> val_acc: 0.9024, val_precision: 0.9024 val_recall: 0.9024, val_f1: 0.9024\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 43.\n","E2E-ABSA >>> 2022-09-02 08:40:25\n",">>> val_acc: 0.9390, val_precision: 0.9390 val_recall: 0.9390, val_f1: 0.9390\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 44.\n","E2E-ABSA >>> 2022-09-02 08:40:38\n","loss: 0.0259, acc: 0.9922\n","E2E-ABSA >>> 2022-09-02 08:40:45\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 45.\n","E2E-ABSA >>> 2022-09-02 08:41:05\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n","E2E-ABSA >>> 2022-09-02 08:41:05\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.9512, val_precision: 0.9512 val_recall: 0.9512, val_f1: 0.9512\n","you can download the best model from state_dict/bert_spc_SemEval2015_know_val_f1_0.9512\n",">>> test_acc: 0.9512, test_precision: 0.9512, test_recall: 0.9512, test_f1: 0.9512\n"]}]},{"cell_type":"markdown","source":["增加字典知识后：Training **SemEval2016** dataset on model**(bert_spc)**"],"metadata":{"id":"8NAujbDMG-Gj"}},{"cell_type":"code","source":["!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && python3 train_insert.py --model_name bert_spc --dataset SemEval2016_know --log_step 100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVHx2kCxGi6r","outputId":"8e4917e7-8792-4fc2-b936-510f97534260","executionInfo":{"status":"ok","timestamp":1662109640343,"user_tz":-480,"elapsed":1171772,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> 使用设备:cuda 训练.\n","加载Bert...\n","Bert加载完毕.\n","> training dataset count: 1112.\n","> testing dataset count: 118.\n","cuda memory allocated: 439075328\n","> n_trainable_params: 109484547, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: bert_spc\n",">>> dataset: SemEval2016_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f13fbfe1c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 20\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",">>> dataset_file: {'train': './datasets/rest16/output_know_insert/train.tsv', 'test': './datasets/rest16/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 08:48:33\n",">>> val_acc: 0.7373, val_precision: 0.7373 val_recall: 0.7373, val_f1: 0.7373\n",">> saved: state_dict/bert_spc_SemEval2016_know_val_f1_0.7373\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 08:48:46\n","loss: 0.7208, acc: 0.7167\n","E2E-ABSA >>> 2022-09-02 08:49:02\n",">>> val_acc: 0.7458, val_precision: 0.7458 val_recall: 0.7458, val_f1: 0.7458\n",">> saved: state_dict/bert_spc_SemEval2016_know_val_f1_0.7458\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 08:49:27\n","loss: 0.7171, acc: 0.7271\n","E2E-ABSA >>> 2022-09-02 08:49:32\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 08:50:02\n",">>> val_acc: 0.7373, val_precision: 0.7373 val_recall: 0.7373, val_f1: 0.7373\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 08:50:10\n","loss: 0.6386, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 08:50:31\n",">>> val_acc: 0.8390, val_precision: 0.8390 val_recall: 0.8390, val_f1: 0.8390\n",">> saved: state_dict/bert_spc_SemEval2016_know_val_f1_0.839\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 08:50:53\n","loss: 0.4050, acc: 0.8575\n","E2E-ABSA >>> 2022-09-02 08:51:02\n",">>> val_acc: 0.8729, val_precision: 0.8729 val_recall: 0.8729, val_f1: 0.8729\n",">> saved: state_dict/bert_spc_SemEval2016_know_val_f1_0.8729\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 08:51:33\n",">>> val_acc: 0.8644, val_precision: 0.8644 val_recall: 0.8644, val_f1: 0.8644\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 08:51:37\n","loss: 0.1467, acc: 0.9563\n","E2E-ABSA >>> 2022-09-02 08:52:02\n",">>> val_acc: 0.8898, val_precision: 0.8898 val_recall: 0.8898, val_f1: 0.8898\n",">> saved: state_dict/bert_spc_SemEval2016_know_val_f1_0.8898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 08:52:20\n","loss: 0.1128, acc: 0.9656\n","E2E-ABSA >>> 2022-09-02 08:52:33\n",">>> val_acc: 0.8898, val_precision: 0.8898 val_recall: 0.8898, val_f1: 0.8898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 08:53:01\n","loss: 0.0887, acc: 0.9658\n","E2E-ABSA >>> 2022-09-02 08:53:02\n",">>> val_acc: 0.8983, val_precision: 0.8983 val_recall: 0.8983, val_f1: 0.8983\n",">> saved: state_dict/bert_spc_SemEval2016_know_val_f1_0.8983\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 08:53:33\n",">>> val_acc: 0.8814, val_precision: 0.8814 val_recall: 0.8814, val_f1: 0.8814\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 08:53:45\n","loss: 0.0950, acc: 0.9708\n","E2E-ABSA >>> 2022-09-02 08:54:02\n",">>> val_acc: 0.8814, val_precision: 0.8814 val_recall: 0.8814, val_f1: 0.8814\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 08:54:27\n","loss: 0.0294, acc: 0.9906\n","E2E-ABSA >>> 2022-09-02 08:54:32\n",">>> val_acc: 0.9068, val_precision: 0.9068 val_recall: 0.9068, val_f1: 0.9068\n",">> saved: state_dict/bert_spc_SemEval2016_know_val_f1_0.9068\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 08:55:02\n",">>> val_acc: 0.8898, val_precision: 0.8898 val_recall: 0.8898, val_f1: 0.8898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 08:55:11\n","loss: 0.0260, acc: 0.9906\n","E2E-ABSA >>> 2022-09-02 08:55:32\n",">>> val_acc: 0.8814, val_precision: 0.8814 val_recall: 0.8814, val_f1: 0.8814\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 08:55:52\n","loss: 0.0147, acc: 0.9950\n","E2E-ABSA >>> 2022-09-02 08:56:01\n",">>> val_acc: 0.9068, val_precision: 0.9068 val_recall: 0.9068, val_f1: 0.9068\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 08:56:30\n",">>> val_acc: 0.9068, val_precision: 0.9068 val_recall: 0.9068, val_f1: 0.9068\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 08:56:34\n","loss: 0.0199, acc: 0.9938\n","E2E-ABSA >>> 2022-09-02 08:57:00\n",">>> val_acc: 0.8898, val_precision: 0.8898 val_recall: 0.8898, val_f1: 0.8898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 08:57:16\n","loss: 0.0394, acc: 0.9875\n","E2E-ABSA >>> 2022-09-02 08:57:29\n",">>> val_acc: 0.9153, val_precision: 0.9153 val_recall: 0.9153, val_f1: 0.9153\n",">> saved: state_dict/bert_spc_SemEval2016_know_val_f1_0.9153\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 08:57:59\n","loss: 0.0231, acc: 0.9937\n","E2E-ABSA >>> 2022-09-02 08:58:00\n",">>> val_acc: 0.8983, val_precision: 0.8983 val_recall: 0.8983, val_f1: 0.8983\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 08:58:29\n",">>> val_acc: 0.8644, val_precision: 0.8644 val_recall: 0.8644, val_f1: 0.8644\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 08:58:41\n","loss: 0.0837, acc: 0.9750\n","E2E-ABSA >>> 2022-09-02 08:58:58\n",">>> val_acc: 0.9153, val_precision: 0.9153 val_recall: 0.9153, val_f1: 0.9153\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 08:59:23\n","loss: 0.1075, acc: 0.9688\n","E2E-ABSA >>> 2022-09-02 08:59:28\n",">>> val_acc: 0.9153, val_precision: 0.9153 val_recall: 0.9153, val_f1: 0.9153\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 23.\n","E2E-ABSA >>> 2022-09-02 08:59:57\n",">>> val_acc: 0.8898, val_precision: 0.8898 val_recall: 0.8898, val_f1: 0.8898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 24.\n","E2E-ABSA >>> 2022-09-02 09:00:05\n","loss: 0.0094, acc: 0.9969\n","E2E-ABSA >>> 2022-09-02 09:00:26\n",">>> val_acc: 0.8644, val_precision: 0.8644 val_recall: 0.8644, val_f1: 0.8644\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 25.\n","E2E-ABSA >>> 2022-09-02 09:00:47\n","loss: 0.0643, acc: 0.9825\n","E2E-ABSA >>> 2022-09-02 09:00:56\n",">>> val_acc: 0.9068, val_precision: 0.9068 val_recall: 0.9068, val_f1: 0.9068\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 26.\n","E2E-ABSA >>> 2022-09-02 09:01:25\n",">>> val_acc: 0.9068, val_precision: 0.9068 val_recall: 0.9068, val_f1: 0.9068\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 27.\n","E2E-ABSA >>> 2022-09-02 09:01:29\n","loss: 0.0033, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 09:01:54\n",">>> val_acc: 0.9153, val_precision: 0.9153 val_recall: 0.9153, val_f1: 0.9153\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 28.\n","E2E-ABSA >>> 2022-09-02 09:02:11\n","loss: 0.0112, acc: 0.9969\n","E2E-ABSA >>> 2022-09-02 09:02:24\n",">>> val_acc: 0.9068, val_precision: 0.9068 val_recall: 0.9068, val_f1: 0.9068\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 29.\n","E2E-ABSA >>> 2022-09-02 09:02:52\n","loss: 0.0803, acc: 0.9694\n","E2E-ABSA >>> 2022-09-02 09:02:53\n",">>> val_acc: 0.8729, val_precision: 0.8729 val_recall: 0.8729, val_f1: 0.8729\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 30.\n","E2E-ABSA >>> 2022-09-02 09:03:22\n",">>> val_acc: 0.9153, val_precision: 0.9153 val_recall: 0.9153, val_f1: 0.9153\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 31.\n","E2E-ABSA >>> 2022-09-02 09:03:34\n","loss: 0.0189, acc: 0.9938\n","E2E-ABSA >>> 2022-09-02 09:03:52\n",">>> val_acc: 0.8814, val_precision: 0.8814 val_recall: 0.8814, val_f1: 0.8814\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 32.\n","E2E-ABSA >>> 2022-09-02 09:04:16\n","loss: 0.0694, acc: 0.9792\n","E2E-ABSA >>> 2022-09-02 09:04:21\n",">>> val_acc: 0.9068, val_precision: 0.9068 val_recall: 0.9068, val_f1: 0.9068\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 33.\n","E2E-ABSA >>> 2022-09-02 09:04:50\n",">>> val_acc: 0.8898, val_precision: 0.8898 val_recall: 0.8898, val_f1: 0.8898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 34.\n","E2E-ABSA >>> 2022-09-02 09:04:58\n","loss: 0.0109, acc: 0.9969\n","E2E-ABSA >>> 2022-09-02 09:05:20\n",">>> val_acc: 0.8729, val_precision: 0.8729 val_recall: 0.8729, val_f1: 0.8729\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 35.\n","E2E-ABSA >>> 2022-09-02 09:05:40\n","loss: 0.0540, acc: 0.9812\n","E2E-ABSA >>> 2022-09-02 09:05:49\n",">>> val_acc: 0.8136, val_precision: 0.8136 val_recall: 0.8136, val_f1: 0.8136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 36.\n","E2E-ABSA >>> 2022-09-02 09:06:18\n",">>> val_acc: 0.8644, val_precision: 0.8644 val_recall: 0.8644, val_f1: 0.8644\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 37.\n","E2E-ABSA >>> 2022-09-02 09:06:22\n","loss: 0.0195, acc: 0.9938\n","E2E-ABSA >>> 2022-09-02 09:06:48\n",">>> val_acc: 0.8814, val_precision: 0.8814 val_recall: 0.8814, val_f1: 0.8814\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 38.\n","E2E-ABSA >>> 2022-09-02 09:07:04\n","loss: 0.0217, acc: 0.9953\n","E2E-ABSA >>> 2022-09-02 09:07:17\n",">>> val_acc: 0.8898, val_precision: 0.8898 val_recall: 0.8898, val_f1: 0.8898\n","E2E-ABSA >>> 2022-09-02 09:07:17\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.9153, val_precision: 0.9153 val_recall: 0.9153, val_f1: 0.9153\n","you can download the best model from state_dict/bert_spc_SemEval2016_know_val_f1_0.9153\n",">>> test_acc: 0.9153, test_precision: 0.9153, test_recall: 0.9153, test_f1: 0.9153\n"]}]},{"cell_type":"markdown","source":["增加字典知识后：Training **acl14shortdata** dataset on model**(bert_spc)**"],"metadata":{"id":"-HoH3AZ0HEEv"}},{"cell_type":"code","source":["!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && python3 train_insert.py --model_name bert_spc --dataset acl14shortdata_know --log_step 100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"npYo7gqBGkWk","outputId":"f2568dde-8229-4f38-b6f8-59c3ed614b68","executionInfo":{"status":"ok","timestamp":1662113127043,"user_tz":-480,"elapsed":1134471,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> 使用设备:cuda 训练.\n","加载Bert...\n","Bert加载完毕.\n","> training dataset count: 5623.\n","> testing dataset count: 625.\n","cuda memory allocated: 439075328\n","> n_trainable_params: 109484547, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: bert_spc\n",">>> dataset: acl14shortdata_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f493dd53c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 100\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 20\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",">>> dataset_file: {'train': './datasets/acl14shortdata/output_know_insert/train.tsv', 'test': './datasets/acl14shortdata/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 09:08:58\n","loss: 1.0747, acc: 0.4756\n","E2E-ABSA >>> 2022-09-02 09:09:38\n","loss: 1.0391, acc: 0.4831\n","E2E-ABSA >>> 2022-09-02 09:10:19\n","loss: 0.9623, acc: 0.5348\n","E2E-ABSA >>> 2022-09-02 09:10:46\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">> saved: state_dict/bert_spc_acl14shortdata_know_val_f1_0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 09:11:07\n","loss: 0.5960, acc: 0.7669\n","E2E-ABSA >>> 2022-09-02 09:11:48\n","loss: 0.6021, acc: 0.7593\n","E2E-ABSA >>> 2022-09-02 09:12:29\n","loss: 0.5915, acc: 0.7571\n","E2E-ABSA >>> 2022-09-02 09:13:10\n","loss: 0.5913, acc: 0.7547\n","E2E-ABSA >>> 2022-09-02 09:13:17\n",">>> val_acc: 0.7472, val_precision: 0.7472 val_recall: 0.7472, val_f1: 0.7472\n",">> saved: state_dict/bert_spc_acl14shortdata_know_val_f1_0.7472\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 09:13:58\n","loss: 0.4875, acc: 0.8001\n","E2E-ABSA >>> 2022-09-02 09:14:39\n","loss: 0.4753, acc: 0.8071\n","E2E-ABSA >>> 2022-09-02 09:15:19\n","loss: 0.4868, acc: 0.7981\n","E2E-ABSA >>> 2022-09-02 09:15:47\n",">>> val_acc: 0.7568, val_precision: 0.7568 val_recall: 0.7568, val_f1: 0.7568\n",">> saved: state_dict/bert_spc_acl14shortdata_know_val_f1_0.7568\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 09:16:07\n","loss: 0.4162, acc: 0.8281\n","E2E-ABSA >>> 2022-09-02 09:16:48\n","loss: 0.4160, acc: 0.8325\n","E2E-ABSA >>> 2022-09-02 09:17:29\n","loss: 0.4273, acc: 0.8248\n","E2E-ABSA >>> 2022-09-02 09:18:10\n","loss: 0.4322, acc: 0.8214\n","E2E-ABSA >>> 2022-09-02 09:18:18\n",">>> val_acc: 0.7520, val_precision: 0.7520 val_recall: 0.7520, val_f1: 0.7520\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 09:18:56\n","loss: 0.3647, acc: 0.8621\n","E2E-ABSA >>> 2022-09-02 09:19:36\n","loss: 0.3632, acc: 0.8630\n","E2E-ABSA >>> 2022-09-02 09:20:17\n","loss: 0.3660, acc: 0.8594\n","E2E-ABSA >>> 2022-09-02 09:20:47\n",">>> val_acc: 0.7472, val_precision: 0.7472 val_recall: 0.7472, val_f1: 0.7472\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 09:21:03\n","loss: 0.2256, acc: 0.9266\n","E2E-ABSA >>> 2022-09-02 09:21:44\n","loss: 0.3026, acc: 0.8884\n","E2E-ABSA >>> 2022-09-02 09:22:24\n","loss: 0.3326, acc: 0.8750\n","E2E-ABSA >>> 2022-09-02 09:23:05\n","loss: 0.3465, acc: 0.8676\n","E2E-ABSA >>> 2022-09-02 09:23:15\n",">>> val_acc: 0.7328, val_precision: 0.7328 val_recall: 0.7328, val_f1: 0.7328\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 09:23:51\n","loss: 0.2915, acc: 0.8885\n","E2E-ABSA >>> 2022-09-02 09:24:32\n","loss: 0.3223, acc: 0.8757\n","E2E-ABSA >>> 2022-09-02 09:25:13\n","loss: 0.3303, acc: 0.8698\n","E2E-ABSA >>> 2022-09-02 09:25:44\n",">>> val_acc: 0.7152, val_precision: 0.7152 val_recall: 0.7152, val_f1: 0.7152\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 09:25:59\n","loss: 0.2650, acc: 0.9080\n","E2E-ABSA >>> 2022-09-02 09:26:40\n","loss: 0.2695, acc: 0.8957\n","E2E-ABSA >>> 2022-09-02 09:27:20\n","loss: 0.3006, acc: 0.8845\n","E2E-ABSA >>> 2022-09-02 09:28:01\n","loss: 0.3100, acc: 0.8791\n","E2E-ABSA >>> 2022-09-02 09:28:13\n",">>> val_acc: 0.7504, val_precision: 0.7504 val_recall: 0.7504, val_f1: 0.7504\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 09:28:47\n","loss: 0.2111, acc: 0.9241\n","E2E-ABSA >>> 2022-09-02 09:29:27\n","loss: 0.2343, acc: 0.9120\n","E2E-ABSA >>> 2022-09-02 09:30:08\n","loss: 0.2774, acc: 0.8922\n","E2E-ABSA >>> 2022-09-02 09:30:41\n",">>> val_acc: 0.7312, val_precision: 0.7312 val_recall: 0.7312, val_f1: 0.7312\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 09:30:54\n","loss: 0.2273, acc: 0.9258\n","E2E-ABSA >>> 2022-09-02 09:31:35\n","loss: 0.2561, acc: 0.9067\n","E2E-ABSA >>> 2022-09-02 09:32:15\n","loss: 0.2681, acc: 0.8992\n","E2E-ABSA >>> 2022-09-02 09:32:56\n","loss: 0.2780, acc: 0.8944\n","E2E-ABSA >>> 2022-09-02 09:33:09\n",">>> val_acc: 0.7328, val_precision: 0.7328 val_recall: 0.7328, val_f1: 0.7328\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 09:33:42\n","loss: 0.2309, acc: 0.9141\n","E2E-ABSA >>> 2022-09-02 09:34:22\n","loss: 0.2396, acc: 0.9101\n","E2E-ABSA >>> 2022-09-02 09:35:03\n","loss: 0.2545, acc: 0.9054\n","E2E-ABSA >>> 2022-09-02 09:35:37\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 09:35:49\n","loss: 0.2517, acc: 0.8929\n","E2E-ABSA >>> 2022-09-02 09:36:29\n","loss: 0.2618, acc: 0.8984\n","E2E-ABSA >>> 2022-09-02 09:37:10\n","loss: 0.2309, acc: 0.9126\n","E2E-ABSA >>> 2022-09-02 09:37:51\n","loss: 0.2459, acc: 0.9064\n","E2E-ABSA >>> 2022-09-02 09:38:06\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 09:38:37\n","loss: 0.2156, acc: 0.9317\n","E2E-ABSA >>> 2022-09-02 09:39:17\n","loss: 0.2003, acc: 0.9343\n","E2E-ABSA >>> 2022-09-02 09:39:58\n","loss: 0.2195, acc: 0.9239\n","E2E-ABSA >>> 2022-09-02 09:40:34\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 09:40:44\n","loss: 0.1806, acc: 0.9297\n","E2E-ABSA >>> 2022-09-02 09:41:25\n","loss: 0.2024, acc: 0.9259\n","E2E-ABSA >>> 2022-09-02 09:42:05\n","loss: 0.2066, acc: 0.9286\n","E2E-ABSA >>> 2022-09-02 09:42:46\n","loss: 0.2078, acc: 0.9257\n","E2E-ABSA >>> 2022-09-02 09:43:03\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 14.\n","E2E-ABSA >>> 2022-09-02 09:43:32\n","loss: 0.1600, acc: 0.9410\n","E2E-ABSA >>> 2022-09-02 09:44:13\n","loss: 0.1677, acc: 0.9404\n","E2E-ABSA >>> 2022-09-02 09:44:53\n","loss: 0.1812, acc: 0.9350\n","E2E-ABSA >>> 2022-09-02 09:45:31\n",">>> val_acc: 0.6928, val_precision: 0.6928 val_recall: 0.6928, val_f1: 0.6928\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 15.\n","E2E-ABSA >>> 2022-09-02 09:45:39\n","loss: 0.0701, acc: 0.9812\n","E2E-ABSA >>> 2022-09-02 09:46:20\n","loss: 0.1301, acc: 0.9536\n","E2E-ABSA >>> 2022-09-02 09:47:01\n","loss: 0.1561, acc: 0.9412\n","E2E-ABSA >>> 2022-09-02 09:47:42\n","loss: 0.1731, acc: 0.9367\n","E2E-ABSA >>> 2022-09-02 09:48:00\n",">>> val_acc: 0.6992, val_precision: 0.6992 val_recall: 0.6992, val_f1: 0.6992\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 16.\n","E2E-ABSA >>> 2022-09-02 09:48:28\n","loss: 0.1424, acc: 0.9393\n","E2E-ABSA >>> 2022-09-02 09:49:08\n","loss: 0.1452, acc: 0.9401\n","E2E-ABSA >>> 2022-09-02 09:49:49\n","loss: 0.1619, acc: 0.9366\n","E2E-ABSA >>> 2022-09-02 09:50:28\n",">>> val_acc: 0.6960, val_precision: 0.6960 val_recall: 0.6960, val_f1: 0.6960\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 17.\n","E2E-ABSA >>> 2022-09-02 09:50:35\n","loss: 0.0720, acc: 0.9883\n","E2E-ABSA >>> 2022-09-02 09:51:15\n","loss: 0.1336, acc: 0.9558\n","E2E-ABSA >>> 2022-09-02 09:51:56\n","loss: 0.1552, acc: 0.9465\n","E2E-ABSA >>> 2022-09-02 09:52:37\n","loss: 0.1596, acc: 0.9446\n","E2E-ABSA >>> 2022-09-02 09:52:56\n",">>> val_acc: 0.6848, val_precision: 0.6848 val_recall: 0.6848, val_f1: 0.6848\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 18.\n","E2E-ABSA >>> 2022-09-02 09:53:23\n","loss: 0.0986, acc: 0.9639\n","E2E-ABSA >>> 2022-09-02 09:54:03\n","loss: 0.1235, acc: 0.9505\n","E2E-ABSA >>> 2022-09-02 09:54:44\n","loss: 0.1458, acc: 0.9432\n","E2E-ABSA >>> 2022-09-02 09:55:25\n",">>> val_acc: 0.6832, val_precision: 0.6832 val_recall: 0.6832, val_f1: 0.6832\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 19.\n","E2E-ABSA >>> 2022-09-02 09:55:30\n","loss: 0.0906, acc: 0.9896\n","E2E-ABSA >>> 2022-09-02 09:56:11\n","loss: 0.1243, acc: 0.9598\n","E2E-ABSA >>> 2022-09-02 09:56:52\n","loss: 0.1352, acc: 0.9558\n","E2E-ABSA >>> 2022-09-02 09:57:32\n","loss: 0.1382, acc: 0.9531\n","E2E-ABSA >>> 2022-09-02 09:57:53\n",">>> val_acc: 0.6880, val_precision: 0.6880 val_recall: 0.6880, val_f1: 0.6880\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 20.\n","E2E-ABSA >>> 2022-09-02 09:58:18\n","loss: 0.0998, acc: 0.9698\n","E2E-ABSA >>> 2022-09-02 09:58:59\n","loss: 0.1191, acc: 0.9598\n","E2E-ABSA >>> 2022-09-02 09:59:39\n","loss: 0.1183, acc: 0.9591\n","E2E-ABSA >>> 2022-09-02 10:00:22\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 21.\n","E2E-ABSA >>> 2022-09-02 10:00:25\n","loss: 0.1858, acc: 0.9141\n","E2E-ABSA >>> 2022-09-02 10:01:06\n","loss: 0.1153, acc: 0.9624\n","E2E-ABSA >>> 2022-09-02 10:01:47\n","loss: 0.1213, acc: 0.9588\n","E2E-ABSA >>> 2022-09-02 10:02:28\n","loss: 0.1266, acc: 0.9560\n","E2E-ABSA >>> 2022-09-02 10:02:51\n",">>> val_acc: 0.6752, val_precision: 0.6752 val_recall: 0.6752, val_f1: 0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 22.\n","E2E-ABSA >>> 2022-09-02 10:03:14\n","loss: 0.0685, acc: 0.9799\n","E2E-ABSA >>> 2022-09-02 10:03:55\n","loss: 0.0948, acc: 0.9696\n","E2E-ABSA >>> 2022-09-02 10:04:35\n","loss: 0.1085, acc: 0.9658\n","E2E-ABSA >>> 2022-09-02 10:05:19\n",">>> val_acc: 0.6784, val_precision: 0.6784 val_recall: 0.6784, val_f1: 0.6784\n","E2E-ABSA >>> 2022-09-02 10:05:19\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7568, val_precision: 0.7568 val_recall: 0.7568, val_f1: 0.7568\n","you can download the best model from state_dict/bert_spc_acl14shortdata_know_val_f1_0.7568\n",">>> test_acc: 0.7568, test_precision: 0.7568, test_recall: 0.7568, test_f1: 0.7568\n"]}]},{"cell_type":"markdown","source":["跑Bert前最好检测一下是否cuda可用"],"metadata":{"id":"S-Ef3wlp6YNK"}},{"cell_type":"code","source":["import torch\n","torch.cuda.is_available()"],"metadata":{"id":"6mj7FJaS6YVL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["增加字典知识后： Training **Twitter** dataset on model**(lfc_bert)**"],"metadata":{"id":"5JkjOHbY6YnE"}},{"cell_type":"code","source":["!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && python3 train_insert.py --model_name lcf_bert --dataset twitter_know --log_step 20 --patience 5 --max_seq_len 125  # batch_size 是16，所以每300个样本测一下"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YcvKpO9O6YuB","outputId":"7aa46039-1cb8-46de-b281-f3de2f701114","executionInfo":{"status":"ok","timestamp":1662114258162,"user_tz":-480,"elapsed":1131120,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> 使用设备:cuda 训练.\n","加载Bert...\n","Bert加载完毕.\n","> training dataset count: 1664.\n","> testing dataset count: 419.\n","cuda memory allocated: 455608832\n","> n_trainable_params: 113617923, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: lcf_bert\n",">>> dataset: twitter_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f583dd45c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 20\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.lcf_bert.LCF_BERT'>\n",">>> dataset_file: {'train': './datasets/twitter/output_know_insert/train.tsv', 'test': './datasets/twitter/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices', 'text_bert_indices', 'aspect_bert_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 10:06:05\n","loss: 0.9051, acc: 0.6375\n","E2E-ABSA >>> 2022-09-02 10:06:22\n","loss: 0.8883, acc: 0.6078\n","E2E-ABSA >>> 2022-09-02 10:06:38\n","loss: 0.8581, acc: 0.6271\n","E2E-ABSA >>> 2022-09-02 10:06:54\n","loss: 0.8532, acc: 0.6320\n","E2E-ABSA >>> 2022-09-02 10:07:10\n","loss: 0.8306, acc: 0.6438\n","E2E-ABSA >>> 2022-09-02 10:07:21\n",">>> val_acc: 0.6874, val_precision: 0.6874 val_recall: 0.6874, val_f1: 0.6874\n",">> saved: state_dict/lcf_bert_twitter_know_val_f1_0.6874\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 10:07:35\n","loss: 0.7431, acc: 0.6484\n","E2E-ABSA >>> 2022-09-02 10:07:51\n","loss: 0.7549, acc: 0.6736\n","E2E-ABSA >>> 2022-09-02 10:08:08\n","loss: 0.7218, acc: 0.6920\n","E2E-ABSA >>> 2022-09-02 10:08:24\n","loss: 0.7333, acc: 0.6924\n","E2E-ABSA >>> 2022-09-02 10:08:40\n","loss: 0.7457, acc: 0.6797\n","E2E-ABSA >>> 2022-09-02 10:08:53\n",">>> val_acc: 0.7279, val_precision: 0.7279 val_recall: 0.7279, val_f1: 0.7279\n",">> saved: state_dict/lcf_bert_twitter_know_val_f1_0.7279\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 10:09:04\n","loss: 0.6072, acc: 0.7344\n","E2E-ABSA >>> 2022-09-02 10:09:21\n","loss: 0.5721, acc: 0.7637\n","E2E-ABSA >>> 2022-09-02 10:09:37\n","loss: 0.5328, acc: 0.7716\n","E2E-ABSA >>> 2022-09-02 10:09:53\n","loss: 0.5413, acc: 0.7734\n","E2E-ABSA >>> 2022-09-02 10:10:09\n","loss: 0.5442, acc: 0.7670\n","E2E-ABSA >>> 2022-09-02 10:10:26\n",">>> val_acc: 0.7661, val_precision: 0.7661 val_recall: 0.7661, val_f1: 0.7661\n",">> saved: state_dict/lcf_bert_twitter_know_val_f1_0.7661\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 10:10:34\n","loss: 0.3954, acc: 0.8438\n","E2E-ABSA >>> 2022-09-02 10:10:50\n","loss: 0.3867, acc: 0.8281\n","E2E-ABSA >>> 2022-09-02 10:11:06\n","loss: 0.3971, acc: 0.8294\n","E2E-ABSA >>> 2022-09-02 10:11:22\n","loss: 0.3768, acc: 0.8428\n","E2E-ABSA >>> 2022-09-02 10:11:38\n","loss: 0.3789, acc: 0.8438\n","E2E-ABSA >>> 2022-09-02 10:11:59\n",">>> val_acc: 0.7637, val_precision: 0.7637 val_recall: 0.7637, val_f1: 0.7637\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 10:12:02\n","loss: 0.2045, acc: 0.9219\n","E2E-ABSA >>> 2022-09-02 10:12:18\n","loss: 0.2248, acc: 0.9089\n","E2E-ABSA >>> 2022-09-02 10:12:34\n","loss: 0.2375, acc: 0.9048\n","E2E-ABSA >>> 2022-09-02 10:12:50\n","loss: 0.2401, acc: 0.8994\n","E2E-ABSA >>> 2022-09-02 10:13:06\n","loss: 0.2433, acc: 0.9010\n","E2E-ABSA >>> 2022-09-02 10:13:22\n","loss: 0.2454, acc: 0.9002\n","E2E-ABSA >>> 2022-09-02 10:13:29\n",">>> val_acc: 0.7446, val_precision: 0.7446 val_recall: 0.7446, val_f1: 0.7446\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 10:13:46\n","loss: 0.1122, acc: 0.9594\n","E2E-ABSA >>> 2022-09-02 10:14:02\n","loss: 0.1028, acc: 0.9594\n","E2E-ABSA >>> 2022-09-02 10:14:18\n","loss: 0.1393, acc: 0.9458\n","E2E-ABSA >>> 2022-09-02 10:14:34\n","loss: 0.1893, acc: 0.9273\n","E2E-ABSA >>> 2022-09-02 10:14:50\n","loss: 0.1850, acc: 0.9287\n","E2E-ABSA >>> 2022-09-02 10:15:01\n",">>> val_acc: 0.7351, val_precision: 0.7351 val_recall: 0.7351, val_f1: 0.7351\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 10:15:13\n","loss: 0.0951, acc: 0.9688\n","E2E-ABSA >>> 2022-09-02 10:15:30\n","loss: 0.0830, acc: 0.9722\n","E2E-ABSA >>> 2022-09-02 10:15:46\n","loss: 0.0732, acc: 0.9710\n","E2E-ABSA >>> 2022-09-02 10:16:02\n","loss: 0.0963, acc: 0.9630\n","E2E-ABSA >>> 2022-09-02 10:16:18\n","loss: 0.1052, acc: 0.9616\n","E2E-ABSA >>> 2022-09-02 10:16:32\n",">>> val_acc: 0.7852, val_precision: 0.7852 val_recall: 0.7852, val_f1: 0.7852\n",">> saved: state_dict/lcf_bert_twitter_know_val_f1_0.7852\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 10:16:44\n","loss: 0.0648, acc: 0.9688\n","E2E-ABSA >>> 2022-09-02 10:17:00\n","loss: 0.0845, acc: 0.9648\n","E2E-ABSA >>> 2022-09-02 10:17:16\n","loss: 0.0906, acc: 0.9615\n","E2E-ABSA >>> 2022-09-02 10:17:32\n","loss: 0.0897, acc: 0.9609\n","E2E-ABSA >>> 2022-09-02 10:17:48\n","loss: 0.0900, acc: 0.9620\n","E2E-ABSA >>> 2022-09-02 10:18:05\n",">>> val_acc: 0.7709, val_precision: 0.7709 val_recall: 0.7709, val_f1: 0.7709\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 10:18:12\n","loss: 0.0218, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 10:18:28\n","loss: 0.0603, acc: 0.9799\n","E2E-ABSA >>> 2022-09-02 10:18:44\n","loss: 0.0708, acc: 0.9766\n","E2E-ABSA >>> 2022-09-02 10:19:00\n","loss: 0.0695, acc: 0.9770\n","E2E-ABSA >>> 2022-09-02 10:19:16\n","loss: 0.0782, acc: 0.9730\n","E2E-ABSA >>> 2022-09-02 10:19:36\n",">>> val_acc: 0.7757, val_precision: 0.7757 val_recall: 0.7757, val_f1: 0.7757\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 10:19:39\n","loss: 0.0869, acc: 0.9688\n","E2E-ABSA >>> 2022-09-02 10:19:55\n","loss: 0.0583, acc: 0.9844\n","E2E-ABSA >>> 2022-09-02 10:20:11\n","loss: 0.0543, acc: 0.9844\n","E2E-ABSA >>> 2022-09-02 10:20:27\n","loss: 0.0752, acc: 0.9766\n","E2E-ABSA >>> 2022-09-02 10:20:43\n","loss: 0.0971, acc: 0.9665\n","E2E-ABSA >>> 2022-09-02 10:20:59\n","loss: 0.0922, acc: 0.9688\n","E2E-ABSA >>> 2022-09-02 10:21:07\n",">>> val_acc: 0.7733, val_precision: 0.7733 val_recall: 0.7733, val_f1: 0.7733\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 10:21:23\n","loss: 0.0370, acc: 0.9812\n","E2E-ABSA >>> 2022-09-02 10:21:39\n","loss: 0.0691, acc: 0.9688\n","E2E-ABSA >>> 2022-09-02 10:21:55\n","loss: 0.0610, acc: 0.9750\n","E2E-ABSA >>> 2022-09-02 10:22:11\n","loss: 0.0600, acc: 0.9758\n","E2E-ABSA >>> 2022-09-02 10:22:27\n","loss: 0.0547, acc: 0.9775\n","E2E-ABSA >>> 2022-09-02 10:22:38\n",">>> val_acc: 0.7088, val_precision: 0.7088 val_recall: 0.7088, val_f1: 0.7088\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 10:22:50\n","loss: 0.0460, acc: 0.9688\n","E2E-ABSA >>> 2022-09-02 10:23:07\n","loss: 0.0531, acc: 0.9774\n","E2E-ABSA >>> 2022-09-02 10:23:23\n","loss: 0.0605, acc: 0.9766\n","E2E-ABSA >>> 2022-09-02 10:23:39\n","loss: 0.0661, acc: 0.9762\n","E2E-ABSA >>> 2022-09-02 10:23:55\n","loss: 0.0867, acc: 0.9688\n","E2E-ABSA >>> 2022-09-02 10:24:09\n",">>> val_acc: 0.7255, val_precision: 0.7255 val_recall: 0.7255, val_f1: 0.7255\n","E2E-ABSA >>> 2022-09-02 10:24:09\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7852, val_precision: 0.7852 val_recall: 0.7852, val_f1: 0.7852\n","you can download the best model from state_dict/lcf_bert_twitter_know_val_f1_0.7852\n",">>> test_acc: 0.7852, test_precision: 0.7852, test_recall: 0.7852, test_f1: 0.7852\n"]}]},{"cell_type":"markdown","source":["增加字典知识后： Training **SemEval2014** dataset on model**(lfc_bert)**"],"metadata":{"id":"8rUNRbKt6Y_H"}},{"cell_type":"code","source":["!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && python3 train_insert.py --model_name lcf_bert --dataset SemEval2014_know --log_step 20 --patience 5 --max_seq_len 125  # batch_size 是16，所以每300个样本测一下"],"metadata":{"id":"9ETOKs7X6ZEt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c7d2661b-1f3e-4e7c-f44c-ae994b28c39a","executionInfo":{"status":"ok","timestamp":1662115915232,"user_tz":-480,"elapsed":1657070,"user":{"displayName":"weiqiang jin","userId":"09187084991684249191"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> 使用设备:cuda 训练.\n","加载Bert...\n","Bert加载完毕.\n","> training dataset count: 3093.\n","> testing dataset count: 329.\n","cuda memory allocated: 455608832\n","> n_trainable_params: 113617923, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: lcf_bert\n",">>> dataset: SemEval2014_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f85ae5afc20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 20\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.lcf_bert.LCF_BERT'>\n",">>> dataset_file: {'train': './datasets/laprest14/output_know_insert/train.tsv', 'test': './datasets/laprest14/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices', 'text_bert_indices', 'aspect_bert_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 10:25:05\n","loss: 1.0245, acc: 0.5719\n","E2E-ABSA >>> 2022-09-02 10:25:21\n","loss: 0.9854, acc: 0.5734\n","E2E-ABSA >>> 2022-09-02 10:25:38\n","loss: 0.9629, acc: 0.5813\n","E2E-ABSA >>> 2022-09-02 10:25:54\n","loss: 0.9567, acc: 0.5805\n","E2E-ABSA >>> 2022-09-02 10:26:10\n","loss: 0.9179, acc: 0.5975\n","E2E-ABSA >>> 2022-09-02 10:26:26\n","loss: 0.8872, acc: 0.6104\n","E2E-ABSA >>> 2022-09-02 10:26:42\n","loss: 0.8533, acc: 0.6246\n","E2E-ABSA >>> 2022-09-02 10:26:58\n","loss: 0.8245, acc: 0.6379\n","E2E-ABSA >>> 2022-09-02 10:27:14\n","loss: 0.7992, acc: 0.6486\n","E2E-ABSA >>> 2022-09-02 10:27:30\n",">>> val_acc: 0.7599, val_precision: 0.7599 val_recall: 0.7599, val_f1: 0.7599\n",">> saved: state_dict/lcf_bert_SemEval2014_know_val_f1_0.7599\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 10:27:37\n","loss: 0.5225, acc: 0.8021\n","E2E-ABSA >>> 2022-09-02 10:27:53\n","loss: 0.4943, acc: 0.7909\n","E2E-ABSA >>> 2022-09-02 10:28:09\n","loss: 0.5247, acc: 0.7717\n","E2E-ABSA >>> 2022-09-02 10:28:25\n","loss: 0.5208, acc: 0.7680\n","E2E-ABSA >>> 2022-09-02 10:28:41\n","loss: 0.5180, acc: 0.7769\n","E2E-ABSA >>> 2022-09-02 10:28:57\n","loss: 0.5120, acc: 0.7824\n","E2E-ABSA >>> 2022-09-02 10:29:13\n","loss: 0.5181, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 10:29:29\n","loss: 0.5088, acc: 0.7864\n","E2E-ABSA >>> 2022-09-02 10:29:45\n","loss: 0.4981, acc: 0.7929\n","E2E-ABSA >>> 2022-09-02 10:30:01\n","loss: 0.4967, acc: 0.7937\n","E2E-ABSA >>> 2022-09-02 10:30:13\n",">>> val_acc: 0.8298, val_precision: 0.8298 val_recall: 0.8298, val_f1: 0.8298\n",">> saved: state_dict/lcf_bert_SemEval2014_know_val_f1_0.8298\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 10:30:24\n","loss: 0.2985, acc: 0.8958\n","E2E-ABSA >>> 2022-09-02 10:30:40\n","loss: 0.3134, acc: 0.8750\n","E2E-ABSA >>> 2022-09-02 10:30:57\n","loss: 0.3015, acc: 0.8858\n","E2E-ABSA >>> 2022-09-02 10:31:13\n","loss: 0.3196, acc: 0.8793\n","E2E-ABSA >>> 2022-09-02 10:31:29\n","loss: 0.3268, acc: 0.8764\n","E2E-ABSA >>> 2022-09-02 10:31:45\n","loss: 0.3258, acc: 0.8761\n","E2E-ABSA >>> 2022-09-02 10:32:01\n","loss: 0.3338, acc: 0.8731\n","E2E-ABSA >>> 2022-09-02 10:32:17\n","loss: 0.3404, acc: 0.8688\n","E2E-ABSA >>> 2022-09-02 10:32:33\n","loss: 0.3432, acc: 0.8674\n","E2E-ABSA >>> 2022-09-02 10:32:49\n","loss: 0.3438, acc: 0.8656\n","E2E-ABSA >>> 2022-09-02 10:32:56\n",">>> val_acc: 0.8298, val_precision: 0.8298 val_recall: 0.8298, val_f1: 0.8298\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 10:33:10\n","loss: 0.2552, acc: 0.9201\n","E2E-ABSA >>> 2022-09-02 10:33:27\n","loss: 0.2676, acc: 0.9030\n","E2E-ABSA >>> 2022-09-02 10:33:43\n","loss: 0.2736, acc: 0.8933\n","E2E-ABSA >>> 2022-09-02 10:33:59\n","loss: 0.2751, acc: 0.8910\n","E2E-ABSA >>> 2022-09-02 10:34:15\n","loss: 0.2887, acc: 0.8807\n","E2E-ABSA >>> 2022-09-02 10:34:31\n","loss: 0.2783, acc: 0.8861\n","E2E-ABSA >>> 2022-09-02 10:34:47\n","loss: 0.2854, acc: 0.8841\n","E2E-ABSA >>> 2022-09-02 10:35:03\n","loss: 0.2830, acc: 0.8857\n","E2E-ABSA >>> 2022-09-02 10:35:19\n","loss: 0.2826, acc: 0.8866\n","E2E-ABSA >>> 2022-09-02 10:35:37\n",">>> val_acc: 0.8085, val_precision: 0.8085 val_recall: 0.8085, val_f1: 0.8085\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 10:35:40\n","loss: 0.1719, acc: 0.9375\n","E2E-ABSA >>> 2022-09-02 10:35:56\n","loss: 0.1539, acc: 0.9427\n","E2E-ABSA >>> 2022-09-02 10:36:12\n","loss: 0.1435, acc: 0.9403\n","E2E-ABSA >>> 2022-09-02 10:36:29\n","loss: 0.1706, acc: 0.9365\n","E2E-ABSA >>> 2022-09-02 10:36:45\n","loss: 0.1674, acc: 0.9375\n","E2E-ABSA >>> 2022-09-02 10:37:01\n","loss: 0.1727, acc: 0.9333\n","E2E-ABSA >>> 2022-09-02 10:37:17\n","loss: 0.1767, acc: 0.9309\n","E2E-ABSA >>> 2022-09-02 10:37:33\n","loss: 0.1867, acc: 0.9275\n","E2E-ABSA >>> 2022-09-02 10:37:49\n","loss: 0.1896, acc: 0.9272\n","E2E-ABSA >>> 2022-09-02 10:38:05\n","loss: 0.2001, acc: 0.9226\n","E2E-ABSA >>> 2022-09-02 10:38:18\n",">>> val_acc: 0.8419, val_precision: 0.8419 val_recall: 0.8419, val_f1: 0.8419\n",">> saved: state_dict/lcf_bert_SemEval2014_know_val_f1_0.8419\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 10:38:29\n","loss: 0.1437, acc: 0.9375\n","E2E-ABSA >>> 2022-09-02 10:38:45\n","loss: 0.1072, acc: 0.9604\n","E2E-ABSA >>> 2022-09-02 10:39:01\n","loss: 0.1259, acc: 0.9525\n","E2E-ABSA >>> 2022-09-02 10:39:17\n","loss: 0.1400, acc: 0.9509\n","E2E-ABSA >>> 2022-09-02 10:39:33\n","loss: 0.1429, acc: 0.9486\n","E2E-ABSA >>> 2022-09-02 10:39:49\n","loss: 0.1423, acc: 0.9472\n","E2E-ABSA >>> 2022-09-02 10:40:05\n","loss: 0.1452, acc: 0.9476\n","E2E-ABSA >>> 2022-09-02 10:40:21\n","loss: 0.1531, acc: 0.9433\n","E2E-ABSA >>> 2022-09-02 10:40:38\n","loss: 0.1563, acc: 0.9423\n","E2E-ABSA >>> 2022-09-02 10:40:54\n","loss: 0.1592, acc: 0.9414\n","E2E-ABSA >>> 2022-09-02 10:41:02\n",">>> val_acc: 0.7964, val_precision: 0.7964 val_recall: 0.7964, val_f1: 0.7964\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 10:41:15\n","loss: 0.1356, acc: 0.9570\n","E2E-ABSA >>> 2022-09-02 10:41:31\n","loss: 0.1466, acc: 0.9479\n","E2E-ABSA >>> 2022-09-02 10:41:47\n","loss: 0.1260, acc: 0.9565\n","E2E-ABSA >>> 2022-09-02 10:42:03\n","loss: 0.1178, acc: 0.9589\n","E2E-ABSA >>> 2022-09-02 10:42:19\n","loss: 0.1169, acc: 0.9590\n","E2E-ABSA >>> 2022-09-02 10:42:35\n","loss: 0.1268, acc: 0.9558\n","E2E-ABSA >>> 2022-09-02 10:42:51\n","loss: 0.1247, acc: 0.9563\n","E2E-ABSA >>> 2022-09-02 10:43:07\n","loss: 0.1358, acc: 0.9535\n","E2E-ABSA >>> 2022-09-02 10:43:23\n","loss: 0.1446, acc: 0.9482\n","E2E-ABSA >>> 2022-09-02 10:43:43\n",">>> val_acc: 0.8055, val_precision: 0.8055 val_recall: 0.8055, val_f1: 0.8055\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 10:43:45\n","loss: 0.0952, acc: 0.9375\n","E2E-ABSA >>> 2022-09-02 10:44:01\n","loss: 0.1763, acc: 0.9318\n","E2E-ABSA >>> 2022-09-02 10:44:17\n","loss: 0.1332, acc: 0.9524\n","E2E-ABSA >>> 2022-09-02 10:44:33\n","loss: 0.1226, acc: 0.9577\n","E2E-ABSA >>> 2022-09-02 10:44:49\n","loss: 0.1256, acc: 0.9573\n","E2E-ABSA >>> 2022-09-02 10:45:05\n","loss: 0.1243, acc: 0.9577\n","E2E-ABSA >>> 2022-09-02 10:45:21\n","loss: 0.1196, acc: 0.9585\n","E2E-ABSA >>> 2022-09-02 10:45:37\n","loss: 0.1252, acc: 0.9564\n","E2E-ABSA >>> 2022-09-02 10:45:53\n","loss: 0.1286, acc: 0.9552\n","E2E-ABSA >>> 2022-09-02 10:46:09\n","loss: 0.1269, acc: 0.9574\n","E2E-ABSA >>> 2022-09-02 10:46:24\n",">>> val_acc: 0.8116, val_precision: 0.8116 val_recall: 0.8116, val_f1: 0.8116\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 10:46:31\n","loss: 0.0272, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 10:46:47\n","loss: 0.0508, acc: 0.9866\n","E2E-ABSA >>> 2022-09-02 10:47:03\n","loss: 0.1224, acc: 0.9583\n","E2E-ABSA >>> 2022-09-02 10:47:19\n","loss: 0.1901, acc: 0.9329\n","E2E-ABSA >>> 2022-09-02 10:47:35\n","loss: 0.1790, acc: 0.9382\n","E2E-ABSA >>> 2022-09-02 10:47:51\n","loss: 0.1654, acc: 0.9439\n","E2E-ABSA >>> 2022-09-02 10:48:07\n","loss: 0.1542, acc: 0.9487\n","E2E-ABSA >>> 2022-09-02 10:48:23\n","loss: 0.1475, acc: 0.9497\n","E2E-ABSA >>> 2022-09-02 10:48:39\n","loss: 0.1525, acc: 0.9457\n","E2E-ABSA >>> 2022-09-02 10:48:55\n","loss: 0.1524, acc: 0.9455\n","E2E-ABSA >>> 2022-09-02 10:49:06\n",">>> val_acc: 0.8176, val_precision: 0.8176 val_recall: 0.8176, val_f1: 0.8176\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 10:49:17\n","loss: 0.1103, acc: 0.9554\n","E2E-ABSA >>> 2022-09-02 10:49:33\n","loss: 0.1053, acc: 0.9614\n","E2E-ABSA >>> 2022-09-02 10:49:49\n","loss: 0.0812, acc: 0.9699\n","E2E-ABSA >>> 2022-09-02 10:50:05\n","loss: 0.0899, acc: 0.9679\n","E2E-ABSA >>> 2022-09-02 10:50:21\n","loss: 0.0885, acc: 0.9681\n","E2E-ABSA >>> 2022-09-02 10:50:37\n","loss: 0.0924, acc: 0.9660\n","E2E-ABSA >>> 2022-09-02 10:50:53\n","loss: 0.0934, acc: 0.9660\n","E2E-ABSA >>> 2022-09-02 10:51:10\n","loss: 0.1032, acc: 0.9606\n","E2E-ABSA >>> 2022-09-02 10:51:26\n","loss: 0.1039, acc: 0.9608\n","E2E-ABSA >>> 2022-09-02 10:51:41\n","loss: 0.1040, acc: 0.9618\n","E2E-ABSA >>> 2022-09-02 10:51:47\n",">>> val_acc: 0.8055, val_precision: 0.8055 val_recall: 0.8055, val_f1: 0.8055\n","E2E-ABSA >>> 2022-09-02 10:51:47\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.8419, val_precision: 0.8419 val_recall: 0.8419, val_f1: 0.8419\n","you can download the best model from state_dict/lcf_bert_SemEval2014_know_val_f1_0.8419\n",">>> test_acc: 0.8419, test_precision: 0.8419, test_recall: 0.8419, test_f1: 0.8419\n"]}]},{"cell_type":"markdown","source":["增加字典知识后： Training **SemEval2015** dataset on model**(lfc_bert)**"],"metadata":{"id":"ycqD9lFT6ZWk"}},{"cell_type":"code","source":["# 下载实验项目\n","!git clone https://github.com/albert-jin/DictionaryFused-E2E-ABSA.git\n","!pip install -r /content/DictionaryFused-E2E-ABSA/requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S_fT8675A2B0","executionInfo":{"status":"ok","timestamp":1662124550197,"user_tz":-480,"elapsed":109364,"user":{"displayName":"杜Ivans","userId":"06426873524705231011"}},"outputId":"6178967b-dfaf-4f9b-9a37-4d24409e84c1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'DictionaryFused-E2E-ABSA'...\n","remote: Enumerating objects: 183, done.\u001b[K\n","remote: Counting objects: 100% (183/183), done.\u001b[K\n","remote: Compressing objects: 100% (107/107), done.\u001b[K\n","remote: Total 183 (delta 97), reused 148 (delta 74), pack-reused 0\u001b[K\n","Receiving objects: 100% (183/183), 2.07 MiB | 5.21 MiB/s, done.\n","Resolving deltas: 100% (97/97), done.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from -r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 1)) (1.21.6)\n","Collecting torch==1.7\n","  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n","\u001b[K     |████████████████████████████████| 776.7 MB 4.5 kB/s \n","\u001b[?25hCollecting transformers<4.0.0,>=3.5.1\n","  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 55.9 MB/s \n","\u001b[?25hCollecting sklearn\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 2)) (0.16.0)\n","Collecting dataclasses\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 2)) (4.1.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (3.17.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (3.8.0)\n","Collecting sentencepiece==0.1.91\n","  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 60.8 MB/s \n","\u001b[?25hCollecting tokenizers==0.9.3\n","  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 39.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (2022.6.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 66.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (4.64.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 4)) (1.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.0.0,>=3.5.1->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 3)) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 4)) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r /content/DictionaryFused-E2E-ABSA/requirements.txt (line 4)) (1.7.3)\n","Building wheels for collected packages: sklearn, sacremoses\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=35ea96357bcea034ac35b93f717860beff1538887a9b13fd3544534329b14a2d\n","  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=9fc5a629d22d129a56c3051cc89bd29f154957009ce0b61baceca812c4849b80\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sklearn sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, dataclasses, transformers, torch, sklearn\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.7.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.7.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.7.0 which is incompatible.\u001b[0m\n","Successfully installed dataclasses-0.6 sacremoses-0.0.53 sentencepiece-0.1.91 sklearn-0.0 tokenizers-0.9.3 torch-1.7.0 transformers-3.5.1\n"]}]},{"cell_type":"code","source":["!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && python3 train_insert.py --model_name lcf_bert --dataset SemEval2015_know --log_step 20 --patience 5 --max_seq_len 125  # batch_size 是16，所以每300个样本测一下"],"metadata":{"id":"3jjH1hud6ZgV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"02f51346-5149-45b5-8bb9-33828a704dd8","executionInfo":{"status":"ok","timestamp":1662125110566,"user_tz":-480,"elapsed":560372,"user":{"displayName":"杜Ivans","userId":"06426873524705231011"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> 使用设备:cuda 训练.\n","加载Bert...\n","\rDownloading:   0% 0.00/232k [00:00<?, ?B/s]\rDownloading: 100% 232k/232k [00:00<00:00, 21.7MB/s]\n","Downloading: 100% 570/570 [00:00<00:00, 872kB/s]\n","Downloading: 100% 440M/440M [00:05<00:00, 74.4MB/s]\n","Bert加载完毕.\n","> training dataset count: 750.\n","> testing dataset count: 82.\n","cuda memory allocated: 455608832\n","> n_trainable_params: 113617923, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: lcf_bert\n",">>> dataset: SemEval2015_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f82fed95c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 20\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.lcf_bert.LCF_BERT'>\n",">>> dataset_file: {'train': './datasets/rest15/output_know_insert/train.tsv', 'test': './datasets/rest15/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices', 'text_bert_indices', 'aspect_bert_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 13:16:27\n","loss: 0.6908, acc: 0.7688\n","E2E-ABSA >>> 2022-09-02 13:16:41\n","loss: 0.6764, acc: 0.7641\n","E2E-ABSA >>> 2022-09-02 13:16:47\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">> saved: state_dict/lcf_bert_SemEval2015_know_val_f1_0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 13:16:58\n","loss: 0.6386, acc: 0.7740\n","E2E-ABSA >>> 2022-09-02 13:17:12\n","loss: 0.6553, acc: 0.7443\n","E2E-ABSA >>> 2022-09-02 13:17:24\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 13:17:28\n","loss: 0.5916, acc: 0.7812\n","E2E-ABSA >>> 2022-09-02 13:17:43\n","loss: 0.5491, acc: 0.7909\n","E2E-ABSA >>> 2022-09-02 13:17:59\n","loss: 0.4745, acc: 0.8261\n","E2E-ABSA >>> 2022-09-02 13:18:01\n",">>> val_acc: 0.8780, val_precision: 0.8780 val_recall: 0.8780, val_f1: 0.8780\n",">> saved: state_dict/lcf_bert_SemEval2015_know_val_f1_0.878\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 13:18:17\n","loss: 0.3422, acc: 0.8849\n","E2E-ABSA >>> 2022-09-02 13:18:34\n","loss: 0.3524, acc: 0.8766\n","E2E-ABSA >>> 2022-09-02 13:18:41\n",">>> val_acc: 0.8537, val_precision: 0.8537 val_recall: 0.8537, val_f1: 0.8537\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 13:18:51\n","loss: 0.1896, acc: 0.9375\n","E2E-ABSA >>> 2022-09-02 13:19:06\n","loss: 0.2123, acc: 0.9277\n","E2E-ABSA >>> 2022-09-02 13:19:19\n",">>> val_acc: 0.8902, val_precision: 0.8902 val_recall: 0.8902, val_f1: 0.8902\n",">> saved: state_dict/lcf_bert_SemEval2015_know_val_f1_0.8902\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 13:19:24\n","loss: 0.1421, acc: 0.9625\n","E2E-ABSA >>> 2022-09-02 13:19:40\n","loss: 0.1138, acc: 0.9700\n","E2E-ABSA >>> 2022-09-02 13:19:56\n","loss: 0.1036, acc: 0.9653\n","E2E-ABSA >>> 2022-09-02 13:19:59\n",">>> val_acc: 0.8293, val_precision: 0.8293 val_recall: 0.8293, val_f1: 0.8293\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 13:20:13\n","loss: 0.0482, acc: 0.9861\n","E2E-ABSA >>> 2022-09-02 13:20:29\n","loss: 0.0491, acc: 0.9868\n","E2E-ABSA >>> 2022-09-02 13:20:37\n",">>> val_acc: 0.8171, val_precision: 0.8171 val_recall: 0.8171, val_f1: 0.8171\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 13:20:45\n","loss: 0.0241, acc: 0.9886\n","E2E-ABSA >>> 2022-09-02 13:21:01\n","loss: 0.0367, acc: 0.9819\n","E2E-ABSA >>> 2022-09-02 13:21:15\n",">>> val_acc: 0.8780, val_precision: 0.8780 val_recall: 0.8780, val_f1: 0.8780\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 13:21:18\n","loss: 0.1948, acc: 0.9531\n","E2E-ABSA >>> 2022-09-02 13:21:34\n","loss: 0.0636, acc: 0.9792\n","E2E-ABSA >>> 2022-09-02 13:21:50\n","loss: 0.0920, acc: 0.9730\n","E2E-ABSA >>> 2022-09-02 13:21:53\n",">>> val_acc: 0.9024, val_precision: 0.9024 val_recall: 0.9024, val_f1: 0.9024\n",">> saved: state_dict/lcf_bert_SemEval2015_know_val_f1_0.9024\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 13:22:08\n","loss: 0.0848, acc: 0.9669\n","E2E-ABSA >>> 2022-09-02 13:22:24\n","loss: 0.0683, acc: 0.9764\n","E2E-ABSA >>> 2022-09-02 13:22:33\n",">>> val_acc: 0.8780, val_precision: 0.8780 val_recall: 0.8780, val_f1: 0.8780\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 13:22:41\n","loss: 0.0205, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 13:22:56\n","loss: 0.0116, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 13:23:11\n",">>> val_acc: 0.9024, val_precision: 0.9024 val_recall: 0.9024, val_f1: 0.9024\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 13:23:13\n","loss: 0.0173, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 13:23:29\n","loss: 0.0123, acc: 0.9973\n","E2E-ABSA >>> 2022-09-02 13:23:45\n","loss: 0.0081, acc: 0.9985\n","E2E-ABSA >>> 2022-09-02 13:23:49\n",">>> val_acc: 0.8902, val_precision: 0.8902 val_recall: 0.8902, val_f1: 0.8902\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 12.\n","E2E-ABSA >>> 2022-09-02 13:24:02\n","loss: 0.0033, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 13:24:18\n","loss: 0.0035, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 13:24:28\n",">>> val_acc: 0.9024, val_precision: 0.9024 val_recall: 0.9024, val_f1: 0.9024\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 13.\n","E2E-ABSA >>> 2022-09-02 13:24:35\n","loss: 0.0040, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 13:24:50\n","loss: 0.0028, acc: 1.0000\n","E2E-ABSA >>> 2022-09-02 13:25:06\n",">>> val_acc: 0.8415, val_precision: 0.8415 val_recall: 0.8415, val_f1: 0.8415\n","E2E-ABSA >>> 2022-09-02 13:25:06\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.9024, val_precision: 0.9024 val_recall: 0.9024, val_f1: 0.9024\n","you can download the best model from state_dict/lcf_bert_SemEval2015_know_val_f1_0.9024\n",">>> test_acc: 0.9024, test_precision: 0.9024, test_recall: 0.9024, test_f1: 0.9024\n"]}]},{"cell_type":"markdown","source":["增加字典知识后： Training **SemEval2016** dataset on model**(lfc_bert)**"],"metadata":{"id":"F14mQtiE6WmN"}},{"cell_type":"code","source":["!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict\n","!cd /content/DictionaryFused-E2E-ABSA && python3 train_insert.py --model_name lcf_bert --dataset SemEval2016_know --log_step 20 --patience 5 --max_seq_len 125  # batch_size 是16，所以每300个样本测一下"],"metadata":{"id":"kNoDIVFCAbOW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662126861583,"user_tz":-480,"elapsed":701768,"user":{"displayName":"杜Ivans","userId":"06426873524705231011"}},"outputId":"26a7b366-600c-4156-b4af-aef962c4631f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> 使用设备:cuda 训练.\n","加载Bert...\n","Bert加载完毕.\n","> training dataset count: 1112.\n","> testing dataset count: 118.\n","cuda memory allocated: 455608832\n","> n_trainable_params: 113617923, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: lcf_bert\n",">>> dataset: SemEval2016_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7fb80e980c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 20\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.lcf_bert.LCF_BERT'>\n",">>> dataset_file: {'train': './datasets/rest16/output_know_insert/train.tsv', 'test': './datasets/rest16/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices', 'text_bert_indices', 'aspect_bert_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 13:43:10\n","loss: 0.7276, acc: 0.6969\n","E2E-ABSA >>> 2022-09-02 13:43:24\n","loss: 0.7467, acc: 0.7031\n","E2E-ABSA >>> 2022-09-02 13:43:38\n","loss: 0.7371, acc: 0.7083\n","E2E-ABSA >>> 2022-09-02 13:43:47\n",">>> val_acc: 0.7288, val_precision: 0.7288 val_recall: 0.7288, val_f1: 0.7288\n",">> saved: state_dict/lcf_bert_SemEval2016_know_val_f1_0.7288\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 13:43:55\n","loss: 0.6699, acc: 0.7125\n","E2E-ABSA >>> 2022-09-02 13:44:10\n","loss: 0.6482, acc: 0.7208\n","E2E-ABSA >>> 2022-09-02 13:44:25\n","loss: 0.6356, acc: 0.7412\n","E2E-ABSA >>> 2022-09-02 13:44:40\n","loss: 0.6073, acc: 0.7572\n","E2E-ABSA >>> 2022-09-02 13:44:43\n",">>> val_acc: 0.7881, val_precision: 0.7881 val_recall: 0.7881, val_f1: 0.7881\n",">> saved: state_dict/lcf_bert_SemEval2016_know_val_f1_0.7881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 13:45:00\n","loss: 0.3649, acc: 0.8688\n","E2E-ABSA >>> 2022-09-02 13:45:16\n","loss: 0.3443, acc: 0.8781\n","E2E-ABSA >>> 2022-09-02 13:45:32\n","loss: 0.3426, acc: 0.8833\n","E2E-ABSA >>> 2022-09-02 13:45:41\n",">>> val_acc: 0.8644, val_precision: 0.8644 val_recall: 0.8644, val_f1: 0.8644\n",">> saved: state_dict/lcf_bert_SemEval2016_know_val_f1_0.8644\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 13:45:51\n","loss: 0.2394, acc: 0.9250\n","E2E-ABSA >>> 2022-09-02 13:46:06\n","loss: 0.2546, acc: 0.9229\n","E2E-ABSA >>> 2022-09-02 13:46:22\n","loss: 0.2495, acc: 0.9250\n","E2E-ABSA >>> 2022-09-02 13:46:38\n","loss: 0.2392, acc: 0.9236\n","E2E-ABSA >>> 2022-09-02 13:46:40\n",">>> val_acc: 0.8814, val_precision: 0.8814 val_recall: 0.8814, val_f1: 0.8814\n",">> saved: state_dict/lcf_bert_SemEval2016_know_val_f1_0.8814\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 13:46:57\n","loss: 0.1197, acc: 0.9656\n","E2E-ABSA >>> 2022-09-02 13:47:13\n","loss: 0.1310, acc: 0.9594\n","E2E-ABSA >>> 2022-09-02 13:47:28\n","loss: 0.1489, acc: 0.9531\n","E2E-ABSA >>> 2022-09-02 13:47:38\n",">>> val_acc: 0.8814, val_precision: 0.8814 val_recall: 0.8814, val_f1: 0.8814\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 13:47:46\n","loss: 0.1355, acc: 0.9563\n","E2E-ABSA >>> 2022-09-02 13:48:01\n","loss: 0.1007, acc: 0.9625\n","E2E-ABSA >>> 2022-09-02 13:48:17\n","loss: 0.0979, acc: 0.9663\n","E2E-ABSA >>> 2022-09-02 13:48:32\n","loss: 0.1063, acc: 0.9631\n","E2E-ABSA >>> 2022-09-02 13:48:34\n",">>> val_acc: 0.8729, val_precision: 0.8729 val_recall: 0.8729, val_f1: 0.8729\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 13:48:50\n","loss: 0.0803, acc: 0.9844\n","E2E-ABSA >>> 2022-09-02 13:49:06\n","loss: 0.0760, acc: 0.9781\n","E2E-ABSA >>> 2022-09-02 13:49:22\n","loss: 0.0780, acc: 0.9760\n","E2E-ABSA >>> 2022-09-02 13:49:31\n",">>> val_acc: 0.8898, val_precision: 0.8898 val_recall: 0.8898, val_f1: 0.8898\n",">> saved: state_dict/lcf_bert_SemEval2016_know_val_f1_0.8898\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 7.\n","E2E-ABSA >>> 2022-09-02 13:49:41\n","loss: 0.0683, acc: 0.9812\n","E2E-ABSA >>> 2022-09-02 13:49:57\n","loss: 0.0764, acc: 0.9771\n","E2E-ABSA >>> 2022-09-02 13:50:12\n","loss: 0.0687, acc: 0.9788\n","E2E-ABSA >>> 2022-09-02 13:50:28\n","loss: 0.0543, acc: 0.9829\n","E2E-ABSA >>> 2022-09-02 13:50:30\n",">>> val_acc: 0.8814, val_precision: 0.8814 val_recall: 0.8814, val_f1: 0.8814\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 8.\n","E2E-ABSA >>> 2022-09-02 13:50:46\n","loss: 0.0415, acc: 0.9844\n","E2E-ABSA >>> 2022-09-02 13:51:01\n","loss: 0.0636, acc: 0.9797\n","E2E-ABSA >>> 2022-09-02 13:51:17\n","loss: 0.0653, acc: 0.9802\n","E2E-ABSA >>> 2022-09-02 13:51:27\n",">>> val_acc: 0.8729, val_precision: 0.8729 val_recall: 0.8729, val_f1: 0.8729\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 9.\n","E2E-ABSA >>> 2022-09-02 13:51:34\n","loss: 0.0237, acc: 0.9938\n","E2E-ABSA >>> 2022-09-02 13:51:50\n","loss: 0.0429, acc: 0.9875\n","E2E-ABSA >>> 2022-09-02 13:52:06\n","loss: 0.0479, acc: 0.9862\n","E2E-ABSA >>> 2022-09-02 13:52:21\n","loss: 0.0506, acc: 0.9829\n","E2E-ABSA >>> 2022-09-02 13:52:23\n",">>> val_acc: 0.8814, val_precision: 0.8814 val_recall: 0.8814, val_f1: 0.8814\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 10.\n","E2E-ABSA >>> 2022-09-02 13:52:39\n","loss: 0.0139, acc: 0.9938\n","E2E-ABSA >>> 2022-09-02 13:52:55\n","loss: 0.0227, acc: 0.9906\n","E2E-ABSA >>> 2022-09-02 13:53:11\n","loss: 0.0193, acc: 0.9927\n","E2E-ABSA >>> 2022-09-02 13:53:20\n",">>> val_acc: 0.8814, val_precision: 0.8814 val_recall: 0.8814, val_f1: 0.8814\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 11.\n","E2E-ABSA >>> 2022-09-02 13:53:28\n","loss: 0.0606, acc: 0.9938\n","E2E-ABSA >>> 2022-09-02 13:53:44\n","loss: 0.0547, acc: 0.9854\n","E2E-ABSA >>> 2022-09-02 13:54:00\n","loss: 0.0494, acc: 0.9862\n","E2E-ABSA >>> 2022-09-02 13:54:15\n","loss: 0.0539, acc: 0.9838\n","E2E-ABSA >>> 2022-09-02 13:54:17\n",">>> val_acc: 0.8814, val_precision: 0.8814 val_recall: 0.8814, val_f1: 0.8814\n","E2E-ABSA >>> 2022-09-02 13:54:17\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.8898, val_precision: 0.8898 val_recall: 0.8898, val_f1: 0.8898\n","you can download the best model from state_dict/lcf_bert_SemEval2016_know_val_f1_0.8898\n",">>> test_acc: 0.8898, test_precision: 0.8898, test_recall: 0.8898, test_f1: 0.8898\n"]}]},{"cell_type":"markdown","source":["增加字典知识后： Training **acl14shortdata** dataset on model**(lfc_bert)**"],"metadata":{"id":"4UXpYO3X6OEn"}},{"cell_type":"code","source":["!rm -rf /content/DictionaryFused-E2E-ABSA/state_dict  \n","!cd /content/DictionaryFused-E2E-ABSA && python3 train_insert.py --model_name lcf_bert --dataset acl14shortdata_know --log_step 20 --patience 5 --max_seq_len 125  # batch_size 是16，所以每300个样本测一下"],"metadata":{"id":"ZD6efeMl6EpB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662128950847,"user_tz":-480,"elapsed":2089268,"user":{"displayName":"杜Ivans","userId":"06426873524705231011"}},"outputId":"2257195c-93fe-4b4b-cbfb-f63988bb4a02"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> 使用设备:cuda 训练.\n","加载Bert...\n","Bert加载完毕.\n","> training dataset count: 5623.\n","> testing dataset count: 625.\n","cuda memory allocated: 455608832\n","> n_trainable_params: 113617923, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: lcf_bert\n",">>> dataset: acl14shortdata_know\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7ff6de210c20>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 100\n",">>> batch_size: 16\n",">>> log_step: 20\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 125\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda\n",">>> seed: 1234\n",">>> valset_ratio: 0\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.lcf_bert.LCF_BERT'>\n",">>> dataset_file: {'train': './datasets/acl14shortdata/output_know_insert/train.tsv', 'test': './datasets/acl14shortdata/output_know_insert/dev.tsv'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices', 'text_bert_indices', 'aspect_bert_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 0.\n","E2E-ABSA >>> 2022-09-02 13:55:29\n","loss: 1.0983, acc: 0.5125\n","E2E-ABSA >>> 2022-09-02 13:55:46\n","loss: 1.0706, acc: 0.4953\n","E2E-ABSA >>> 2022-09-02 13:56:02\n","loss: 1.0700, acc: 0.4760\n","E2E-ABSA >>> 2022-09-02 13:56:18\n","loss: 1.0608, acc: 0.4828\n","E2E-ABSA >>> 2022-09-02 13:56:33\n","loss: 1.0493, acc: 0.4919\n","E2E-ABSA >>> 2022-09-02 13:56:49\n","loss: 1.0375, acc: 0.5016\n","E2E-ABSA >>> 2022-09-02 13:57:05\n","loss: 1.0200, acc: 0.5156\n","E2E-ABSA >>> 2022-09-02 13:57:21\n","loss: 1.0024, acc: 0.5242\n","E2E-ABSA >>> 2022-09-02 13:57:37\n","loss: 0.9832, acc: 0.5340\n","E2E-ABSA >>> 2022-09-02 13:57:52\n","loss: 0.9601, acc: 0.5466\n","E2E-ABSA >>> 2022-09-02 13:58:08\n","loss: 0.9356, acc: 0.5605\n","E2E-ABSA >>> 2022-09-02 13:58:24\n","loss: 0.9131, acc: 0.5721\n","E2E-ABSA >>> 2022-09-02 13:58:40\n","loss: 0.8908, acc: 0.5853\n","E2E-ABSA >>> 2022-09-02 13:58:56\n","loss: 0.8691, acc: 0.5964\n","E2E-ABSA >>> 2022-09-02 13:59:11\n","loss: 0.8547, acc: 0.6058\n","E2E-ABSA >>> 2022-09-02 13:59:27\n","loss: 0.8427, acc: 0.6123\n","E2E-ABSA >>> 2022-09-02 13:59:43\n","loss: 0.8302, acc: 0.6182\n","E2E-ABSA >>> 2022-09-02 14:00:03\n",">>> val_acc: 0.7376, val_precision: 0.7376 val_recall: 0.7376, val_f1: 0.7376\n",">> saved: state_dict/lcf_bert_acl14shortdata_know_val_f1_0.7376\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 1.\n","E2E-ABSA >>> 2022-09-02 14:00:12\n","loss: 0.5290, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 14:00:27\n","loss: 0.5511, acc: 0.7790\n","E2E-ABSA >>> 2022-09-02 14:00:43\n","loss: 0.5609, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 14:00:59\n","loss: 0.5723, acc: 0.7675\n","E2E-ABSA >>> 2022-09-02 14:01:15\n","loss: 0.5601, acc: 0.7749\n","E2E-ABSA >>> 2022-09-02 14:01:31\n","loss: 0.5696, acc: 0.7708\n","E2E-ABSA >>> 2022-09-02 14:01:47\n","loss: 0.5753, acc: 0.7666\n","E2E-ABSA >>> 2022-09-02 14:02:02\n","loss: 0.5674, acc: 0.7686\n","E2E-ABSA >>> 2022-09-02 14:02:18\n","loss: 0.5695, acc: 0.7641\n","E2E-ABSA >>> 2022-09-02 14:02:34\n","loss: 0.5645, acc: 0.7663\n","E2E-ABSA >>> 2022-09-02 14:02:50\n","loss: 0.5653, acc: 0.7674\n","E2E-ABSA >>> 2022-09-02 14:03:05\n","loss: 0.5672, acc: 0.7681\n","E2E-ABSA >>> 2022-09-02 14:03:21\n","loss: 0.5684, acc: 0.7676\n","E2E-ABSA >>> 2022-09-02 14:03:37\n","loss: 0.5704, acc: 0.7656\n","E2E-ABSA >>> 2022-09-02 14:03:53\n","loss: 0.5727, acc: 0.7645\n","E2E-ABSA >>> 2022-09-02 14:04:09\n","loss: 0.5693, acc: 0.7652\n","E2E-ABSA >>> 2022-09-02 14:04:25\n","loss: 0.5655, acc: 0.7668\n","E2E-ABSA >>> 2022-09-02 14:04:40\n","loss: 0.5684, acc: 0.7647\n","E2E-ABSA >>> 2022-09-02 14:04:54\n",">>> val_acc: 0.7488, val_precision: 0.7488 val_recall: 0.7488, val_f1: 0.7488\n",">> saved: state_dict/lcf_bert_acl14shortdata_know_val_f1_0.7488\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 2.\n","E2E-ABSA >>> 2022-09-02 14:05:09\n","loss: 0.4541, acc: 0.8242\n","E2E-ABSA >>> 2022-09-02 14:05:25\n","loss: 0.4554, acc: 0.8125\n","E2E-ABSA >>> 2022-09-02 14:05:41\n","loss: 0.4849, acc: 0.7980\n","E2E-ABSA >>> 2022-09-02 14:05:56\n","loss: 0.4873, acc: 0.7952\n","E2E-ABSA >>> 2022-09-02 14:06:12\n","loss: 0.4887, acc: 0.7975\n","E2E-ABSA >>> 2022-09-02 14:06:28\n","loss: 0.4827, acc: 0.8017\n","E2E-ABSA >>> 2022-09-02 14:06:44\n","loss: 0.4851, acc: 0.7996\n","E2E-ABSA >>> 2022-09-02 14:07:00\n","loss: 0.4852, acc: 0.7977\n","E2E-ABSA >>> 2022-09-02 14:07:15\n","loss: 0.4845, acc: 0.7987\n","E2E-ABSA >>> 2022-09-02 14:07:31\n","loss: 0.4843, acc: 0.7988\n","E2E-ABSA >>> 2022-09-02 14:07:47\n","loss: 0.4838, acc: 0.7983\n","E2E-ABSA >>> 2022-09-02 14:08:03\n","loss: 0.4891, acc: 0.7971\n","E2E-ABSA >>> 2022-09-02 14:08:18\n","loss: 0.4893, acc: 0.7957\n","E2E-ABSA >>> 2022-09-02 14:08:34\n","loss: 0.4942, acc: 0.7942\n","E2E-ABSA >>> 2022-09-02 14:08:50\n","loss: 0.4939, acc: 0.7937\n","E2E-ABSA >>> 2022-09-02 14:09:06\n","loss: 0.4927, acc: 0.7949\n","E2E-ABSA >>> 2022-09-02 14:09:22\n","loss: 0.4923, acc: 0.7965\n","E2E-ABSA >>> 2022-09-02 14:09:45\n",">>> val_acc: 0.6880, val_precision: 0.6880 val_recall: 0.6880, val_f1: 0.6880\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 3.\n","E2E-ABSA >>> 2022-09-02 14:09:48\n","loss: 0.4815, acc: 0.7969\n","E2E-ABSA >>> 2022-09-02 14:10:03\n","loss: 0.4265, acc: 0.8385\n","E2E-ABSA >>> 2022-09-02 14:10:19\n","loss: 0.4091, acc: 0.8409\n","E2E-ABSA >>> 2022-09-02 14:10:35\n","loss: 0.4111, acc: 0.8379\n","E2E-ABSA >>> 2022-09-02 14:10:51\n","loss: 0.4036, acc: 0.8445\n","E2E-ABSA >>> 2022-09-02 14:11:07\n","loss: 0.4131, acc: 0.8395\n","E2E-ABSA >>> 2022-09-02 14:11:22\n","loss: 0.4197, acc: 0.8342\n","E2E-ABSA >>> 2022-09-02 14:11:38\n","loss: 0.4284, acc: 0.8299\n","E2E-ABSA >>> 2022-09-02 14:11:54\n","loss: 0.4391, acc: 0.8266\n","E2E-ABSA >>> 2022-09-02 14:12:10\n","loss: 0.4343, acc: 0.8298\n","E2E-ABSA >>> 2022-09-02 14:12:26\n","loss: 0.4307, acc: 0.8287\n","E2E-ABSA >>> 2022-09-02 14:12:42\n","loss: 0.4329, acc: 0.8265\n","E2E-ABSA >>> 2022-09-02 14:12:57\n","loss: 0.4351, acc: 0.8261\n","E2E-ABSA >>> 2022-09-02 14:13:13\n","loss: 0.4370, acc: 0.8250\n","E2E-ABSA >>> 2022-09-02 14:13:29\n","loss: 0.4392, acc: 0.8228\n","E2E-ABSA >>> 2022-09-02 14:13:45\n","loss: 0.4434, acc: 0.8213\n","E2E-ABSA >>> 2022-09-02 14:14:01\n","loss: 0.4453, acc: 0.8202\n","E2E-ABSA >>> 2022-09-02 14:14:16\n","loss: 0.4434, acc: 0.8205\n","E2E-ABSA >>> 2022-09-02 14:14:33\n",">>> val_acc: 0.7376, val_precision: 0.7376 val_recall: 0.7376, val_f1: 0.7376\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 4.\n","E2E-ABSA >>> 2022-09-02 14:14:43\n","loss: 0.3473, acc: 0.9062\n","E2E-ABSA >>> 2022-09-02 14:14:58\n","loss: 0.3539, acc: 0.8867\n","E2E-ABSA >>> 2022-09-02 14:15:14\n","loss: 0.3511, acc: 0.8798\n","E2E-ABSA >>> 2022-09-02 14:15:30\n","loss: 0.3621, acc: 0.8707\n","E2E-ABSA >>> 2022-09-02 14:15:46\n","loss: 0.3591, acc: 0.8702\n","E2E-ABSA >>> 2022-09-02 14:16:02\n","loss: 0.3718, acc: 0.8599\n","E2E-ABSA >>> 2022-09-02 14:16:18\n","loss: 0.3664, acc: 0.8641\n","E2E-ABSA >>> 2022-09-02 14:16:33\n","loss: 0.3790, acc: 0.8602\n","E2E-ABSA >>> 2022-09-02 14:16:49\n","loss: 0.3741, acc: 0.8612\n","E2E-ABSA >>> 2022-09-02 14:17:05\n","loss: 0.3755, acc: 0.8607\n","E2E-ABSA >>> 2022-09-02 14:17:21\n","loss: 0.3693, acc: 0.8623\n","E2E-ABSA >>> 2022-09-02 14:17:37\n","loss: 0.3750, acc: 0.8594\n","E2E-ABSA >>> 2022-09-02 14:17:52\n","loss: 0.3750, acc: 0.8589\n","E2E-ABSA >>> 2022-09-02 14:18:08\n","loss: 0.3753, acc: 0.8596\n","E2E-ABSA >>> 2022-09-02 14:18:24\n","loss: 0.3796, acc: 0.8579\n","E2E-ABSA >>> 2022-09-02 14:18:40\n","loss: 0.3852, acc: 0.8544\n","E2E-ABSA >>> 2022-09-02 14:18:55\n","loss: 0.3891, acc: 0.8539\n","E2E-ABSA >>> 2022-09-02 14:19:11\n","loss: 0.3938, acc: 0.8520\n","E2E-ABSA >>> 2022-09-02 14:19:22\n",">>> val_acc: 0.7248, val_precision: 0.7248 val_recall: 0.7248, val_f1: 0.7248\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 5.\n","E2E-ABSA >>> 2022-09-02 14:19:37\n","loss: 0.2674, acc: 0.8906\n","E2E-ABSA >>> 2022-09-02 14:19:53\n","loss: 0.3156, acc: 0.8781\n","E2E-ABSA >>> 2022-09-02 14:20:09\n","loss: 0.3182, acc: 0.8781\n","E2E-ABSA >>> 2022-09-02 14:20:25\n","loss: 0.2974, acc: 0.8867\n","E2E-ABSA >>> 2022-09-02 14:20:41\n","loss: 0.3184, acc: 0.8800\n","E2E-ABSA >>> 2022-09-02 14:20:56\n","loss: 0.3183, acc: 0.8776\n","E2E-ABSA >>> 2022-09-02 14:21:12\n","loss: 0.3337, acc: 0.8719\n","E2E-ABSA >>> 2022-09-02 14:21:28\n","loss: 0.3398, acc: 0.8699\n","E2E-ABSA >>> 2022-09-02 14:21:44\n","loss: 0.3457, acc: 0.8663\n","E2E-ABSA >>> 2022-09-02 14:21:59\n","loss: 0.3424, acc: 0.8672\n","E2E-ABSA >>> 2022-09-02 14:22:15\n","loss: 0.3470, acc: 0.8659\n","E2E-ABSA >>> 2022-09-02 14:22:31\n","loss: 0.3511, acc: 0.8651\n","E2E-ABSA >>> 2022-09-02 14:22:47\n","loss: 0.3476, acc: 0.8666\n","E2E-ABSA >>> 2022-09-02 14:23:03\n","loss: 0.3504, acc: 0.8663\n","E2E-ABSA >>> 2022-09-02 14:23:18\n","loss: 0.3579, acc: 0.8625\n","E2E-ABSA >>> 2022-09-02 14:23:34\n","loss: 0.3613, acc: 0.8615\n","E2E-ABSA >>> 2022-09-02 14:23:50\n","loss: 0.3639, acc: 0.8597\n","E2E-ABSA >>> 2022-09-02 14:24:10\n",">>> val_acc: 0.7184, val_precision: 0.7184 val_recall: 0.7184, val_f1: 0.7184\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",">>> epoch: 6.\n","E2E-ABSA >>> 2022-09-02 14:24:16\n","loss: 0.4116, acc: 0.8438\n","E2E-ABSA >>> 2022-09-02 14:24:32\n","loss: 0.3567, acc: 0.8482\n","E2E-ABSA >>> 2022-09-02 14:24:48\n","loss: 0.3473, acc: 0.8581\n","E2E-ABSA >>> 2022-09-02 14:25:04\n","loss: 0.3301, acc: 0.8640\n","E2E-ABSA >>> 2022-09-02 14:25:19\n","loss: 0.3331, acc: 0.8651\n","E2E-ABSA >>> 2022-09-02 14:25:35\n","loss: 0.3242, acc: 0.8698\n","E2E-ABSA >>> 2022-09-02 14:25:51\n","loss: 0.3172, acc: 0.8721\n","E2E-ABSA >>> 2022-09-02 14:26:07\n","loss: 0.3163, acc: 0.8733\n","E2E-ABSA >>> 2022-09-02 14:26:23\n","loss: 0.3287, acc: 0.8672\n","E2E-ABSA >>> 2022-09-02 14:26:38\n","loss: 0.3279, acc: 0.8690\n","E2E-ABSA >>> 2022-09-02 14:26:54\n","loss: 0.3297, acc: 0.8696\n","E2E-ABSA >>> 2022-09-02 14:27:10\n","loss: 0.3315, acc: 0.8709\n","E2E-ABSA >>> 2022-09-02 14:27:26\n","loss: 0.3263, acc: 0.8722\n","E2E-ABSA >>> 2022-09-02 14:27:41\n","loss: 0.3318, acc: 0.8703\n","E2E-ABSA >>> 2022-09-02 14:27:57\n","loss: 0.3366, acc: 0.8683\n","E2E-ABSA >>> 2022-09-02 14:28:13\n","loss: 0.3414, acc: 0.8671\n","E2E-ABSA >>> 2022-09-02 14:28:29\n","loss: 0.3439, acc: 0.8657\n","E2E-ABSA >>> 2022-09-02 14:28:45\n","loss: 0.3458, acc: 0.8648\n","E2E-ABSA >>> 2022-09-02 14:28:58\n",">>> val_acc: 0.7072, val_precision: 0.7072 val_recall: 0.7072, val_f1: 0.7072\n","E2E-ABSA >>> 2022-09-02 14:28:58\n",">>> early stop.\n","BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7488, val_precision: 0.7488 val_recall: 0.7488, val_f1: 0.7488\n","you can download the best model from state_dict/lcf_bert_acl14shortdata_know_val_f1_0.7488\n",">>> test_acc: 0.7488, test_precision: 0.7488, test_recall: 0.7488, test_f1: 0.7488\n"]}]},{"cell_type":"code","source":["# OVER"],"metadata":{"id":"5V6sT7FXJMca"},"execution_count":null,"outputs":[]}]}